<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Fully connected four-layer neural network &lt;br&gt;Solves a huge number of cases, classification and regression &lt;br&gt;The following sequence explains how to use with the help of two example files. &lt;br&gt;The first file contains the learning process, where the neural network finds its weights &lt;br&gt;The second file demonstrates the network's ability to make predictions on new, unseen data that is not part of the training set &lt;br&gt;&lt;br&gt;#&lt;b&gt;-----Files without comments:--------------------------------------- &lt;/b&gt;&lt;br&gt;&lt;br&gt;#-----FILE TO MACHINE LEARNING &lt;br&gt;&lt;br&gt;import tupa123 as tu &lt;br&gt;&lt;br&gt;X = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=1, columnquantity=5, linesquantity=300) &lt;br&gt;y = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=6, columnquantity=2, linesquantity=300) &lt;br&gt;&lt;br&gt;model = tu.nnet4(norma=5, coef=0, nn1c=5, nn2c=7, nn3c=5, nn4c=2, rate=0.01, epochs=2000, fa2c=5, fa3c=5, fa4c=0) &lt;br&gt;model.Fit_ADAM(X, y) &lt;br&gt;model.Plotconv() &lt;br&gt;&lt;br&gt;input('end') &lt;br&gt;&lt;br&gt;#-----FILE TO APPLICATION OF MACHINE LEARNING &lt;br&gt;&lt;br&gt;import tupa123 as tu &lt;br&gt;&lt;br&gt;model = tu.nnet4(norma=5, coef=0, normout=1, nn1c=5, nn2c=7, nn3c=5, nn4c=2, fa2c=5, fa3c=5, fa4c=0) &lt;br&gt;X_new = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=1, columnquantity=5, linesquantity=1000) &lt;br&gt;y_resposta = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=6, columnquantity=2, linesquantity=1000) &lt;br&gt;y_pred = model.Predict(X_new) &lt;br&gt;&lt;br&gt;tu.Statistics(y_pred, y_resposta) &lt;br&gt;tu.PlotCorrelation(y_pred, y_resposta) &lt;br&gt;tu.PlotComparative(y_pred, y_resposta) &lt;br&gt;input('end') &lt;br&gt;&lt;br&gt;#&lt;b&gt;------Commented file:------------------------------------------&lt;/b&gt; &lt;br&gt;&lt;br&gt;#-----MACHINE LEARNING &lt;br&gt;&lt;br&gt;&lt;b&gt;import tupa123 as tu&lt;/b&gt; &lt;br&gt;#import the library &lt;br&gt;&lt;br&gt;&lt;b&gt;X = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=1, columnquantity=5, linesquantity=300)&lt;/b&gt; &lt;br&gt;&lt;b&gt;y = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=6, columnquantity=2, linesquantity=300)&lt;/b&gt; &lt;br&gt;#learning data &lt;br&gt;#The data can come from any source, but the ExcelMatrix function allows a practical interaction with Excel &lt;br&gt;#ExcelMatrix = collect data from excel, the spreadsheet needs to be in the same folder as the python file &lt;br&gt;#'ALETAS.xlsm' = example name of the excel file / 'Sheet1' = example name of the tab where the data are &lt;br&gt;#Lineini=2, Columini=1 = example initial row and column of data &lt;br&gt;#linesquantity = number of lines of learning data &lt;br&gt;#X = regression input data / y = data to be predicted &lt;br&gt;&lt;br&gt;&lt;b&gt;model = tu.nnet4(norma=5, coef=0, normout=1, nn1c=5, nn2c=7, nn3c=5, nn4c=2, rate=0.01, epochs=2000, fa2c=5, fa3c=5, fa4c=0, cost=0, regu=0, namenet='')&lt;/b&gt; &lt;br&gt;#creates the Neural Network model &lt;br&gt;&lt;br&gt;#norma = type of data normalization: (default=2)&lt;br&gt;#=-1, standardization &lt;br&gt;#=0, do anything &lt;br&gt;#=1, between 0 and 1 &lt;br&gt;#=2, between -1 and 1 &lt;br&gt;#=3, log(x+coef) &lt;br&gt;#=4, log(x+coef)  between 0 and 1 &lt;br&gt;#=5, log(x+coef)  between -1 and 1 &lt;br&gt;#=6, log(x+coef)  and standardization &lt;br&gt;#coef = used to avoid zero in log normalizations, example 0.0012345 (default=0)&lt;br&gt;#normout = if 1 normalizes the output (default=1), 0 dont &lt;br&gt;&lt;br&gt;#nn1c=5, nn2c=7, nn3c=5, nn4c=2 = number of neurons from the first to the fourth layer (default=1,5,5,1) &lt;br&gt;#rate = learning rate (default=0.01) &lt;br&gt;#epochs = number of epochs (default=1000)&lt;br&gt;#fa2c=5, fa3c=5, fa4c=0 = second to fourth layer activation functions (default=5,5,0) &lt;br&gt;#for regression the fourth layer is recommended as linear = 0 &lt;br&gt;#cost=0, cost function, (default=0). 0 = MSE, mean squared error for regression and classification / 1 = BCE, binary cross entropy for classification &lt;br&gt;#regu= regularization, (default=0). Usual value for regression = 0.01 &lt;br&gt;#namenet= name of the folder where the weights are saved, default is the same directory as the .py file, necessary when working with more than one neural network &lt;br&gt;&lt;br&gt;#Activation functions: &lt;br&gt;#=0 linear &lt;br&gt; #=1 Sigmoide &lt;br&gt;#=2 softpluss &lt;br&gt;#=3 gaussinana &lt;br&gt;#=4 ReLU &lt;br&gt;#=5 tanh &lt;br&gt;#=6 LReLU &lt;br&gt;#=7 arctan &lt;br&gt;#=8 exp &lt;br&gt;#=9 seno &lt;br&gt;#=10 swish &lt;br&gt;#=11 selu &lt;br&gt;#=12 logsigmoide &lt;br&gt;#=13 X**2 &lt;br&gt;#=14 X**3 &lt;br&gt;#=15 Symmetric Rectified Linear &lt;br&gt;&lt;br&gt;&lt;b&gt;model.Fit_ADAM(X, y) &lt;/b&gt;&lt;br&gt;#machine learning &lt;br&gt;#model.Fit_ADAM(X, y) = single batch interpolation of all learning data, with ADAM accelerator &lt;br&gt;#model.Fit_STOC(X, y) = case-by-case interpolation, stochastic gradient descent &lt;br&gt;&lt;br&gt;&lt;b&gt;model.Plotconv()&lt;/b&gt; &lt;br&gt;#Plot the convergence process &lt;br&gt;&lt;br&gt;input('End') &lt;br&gt;&lt;br&gt;#-----APPLICATION OF MACHINE LEARNING &lt;br&gt;&lt;br&gt;&lt;b&gt;import tupa123 as tu&lt;/b&gt; &lt;br&gt;&lt;br&gt;&lt;b&gt;model = tu.nnet4(norma=5, coef=0, nn1c=5, nn2c=7, nn3c=5, nn4c=2, fa2c=5, fa3c=5, fa4c=0) &lt;/b&gt;&lt;br&gt;#application file must be in the same folder as the learning file &lt;br&gt;#where some .txt files were generated with the neural network settings &lt;br&gt;#neural network must have the same configuration that was used in the learning phase &lt;br&gt;&lt;br&gt;&lt;b&gt;X_new = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=1, columnquantity=5, linesquantity=1000)&lt;/b&gt; &lt;br&gt;#variables to be predicted &lt;br&gt;&lt;br&gt;&lt;b&gt;y_resposta = tu.ExcelMatrix('ALETAS.xlsm', 'Plan1', Lineini=2, Columini=6, columnquantity=2, linesquantity=1000) &lt;/b&gt;&lt;br&gt;#right answer to compare, to evaluate neural network performance &lt;br&gt;&lt;br&gt;&lt;b&gt;y_pred = model.Predict(X_new) &lt;/b&gt;&lt;br&gt;#prediction, neural network result &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.Statistics(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Statistical evaluation of the results &lt;br&gt;#It does some basic statistics: mean difference, standard deviation and correlation coefficient between predicted and target variable &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotCorrelation(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Calculated and target correlation plot &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotCorrelation2(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Calculated and target correlation plot with standard deviation lines&lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotComparative(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Calculated and target comparative plot &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotComparative2(y_pred, y_resposta, window_size=1000) &lt;/b&gt;&lt;br&gt;#Error plot with movel average&lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotComparative3(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Calculated and target comparative plot with standard deviation areas &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotComparative4(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Plot 2 sigma tandard deviation areas with target &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotDispe(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Error dispersion &lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotDispe2(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Error dispersion with error proportion&lt;br&gt;&lt;br&gt;&lt;b&gt;tu.PlotHisto(y_pred, y_resposta) &lt;/b&gt;&lt;br&gt;#Percentage error histogram &lt;br&gt;&lt;br&gt;input('end') &lt;br&gt;</longdescription>
</pkgmetadata>