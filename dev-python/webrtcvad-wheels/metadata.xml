<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>.. image:: https://travis-ci.org/daanzu/py-webrtcvad-wheels.svg?branch=release    :target: https://travis-ci.org/daanzu/py-webrtcvad-wheels.. image:: https://img.shields.io/pypi/v/webrtcvad-wheels.svg    :target: https://pypi.python.org/pypi/webrtcvad-wheels/.. image:: https://img.shields.io/pypi/wheel/webrtcvad-wheels.svg    :target: https://pypi.python.org/pypi/webrtcvad-wheels/py-webrtcvad-wheels===================This is a python interface to the WebRTC Voice Activity Detector (VAD). It is compatible with Python 2 and Python 3.  It is forked from`wiseman/py-webrtcvad &lt;https://github.com/wiseman/py-webrtcvad&gt;`_ toprovide releases with binary wheels.A `VAD &lt;https://en.wikipedia.org/wiki/Voice_activity_detection&gt;`_classifies a piece of audio data as being voiced or unvoiced. It canbe useful for telephony and speech recognition.The VAD that Google developed for the `WebRTC &lt;https://webrtc.org/&gt;`_project is reportedly one of the best available, being fast, modernand free.How to use it-------------0. Install the webrtcvad module::    pip install webrtcvad1. Create a ``Vad`` object::    import webrtcvad    vad = webrtcvad.Vad()2. Optionally, set its aggressiveness mode, which is an integer   between 0 and 3. 0 is the least aggressive about filtering out   non-speech, 3 is the most aggressive. (You can also set the mode   when you create the VAD, e.g. ``vad = webrtcvad.Vad(3)``)::    vad.set_mode(1)3. Give it a short segment (&quot;frame&quot;) of audio. The WebRTC VAD only   accepts 16-bit mono PCM audio, sampled at 8000, 16000, 32000 or 48000 Hz.   A frame must be either 10, 20, or 30 ms in duration::    # Run the VAD on 10 ms of silence. The result should be False.    sample_rate = 16000    frame_duration = 10  # ms    frame = b'\x00\x00' * int(sample_rate * frame_duration / 1000)    print 'Contains speech: %s' % (vad.is_speech(frame, sample_rate)See `example.py&lt;https://github.com/wiseman/py-webrtcvad/blob/master/example.py&gt;`_ fora more detailed example that will process a .wav file, find the voicedsegments, and write each one as a separate .wav.How to run unit tests---------------------To run unit tests::    pip install -e &quot;.[dev]&quot;    python setup.py testHistory-------2.0.10    Fixed memory leak. Thank you, `bond005    &lt;https://github.com/bond005&gt;`_!2.0.9    Improved example code. Added WebRTC license.2.0.8    Fixed Windows compilation errors. Thank you, `xiongyihui    &lt;https://github.com/xiongyihui&gt;`_!</longdescription>
</pkgmetadata>