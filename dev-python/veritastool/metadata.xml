<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Veritas Toolkit[![codecov](https://codecov.io/gh/mas-veritas2/veritastool/branch/main/graph/badge.svg?token=0J3QEBHBDU)](https://codecov.io/gh/mas-veritas2/veritastool)[![PyPI version](https://badge.fury.io/py/veritastool.svg)](https://badge.fury.io/py/veritastool)[![Python 3.10](https://img.shields.io/badge/python-3.10-green)](https://www.python.org/downloads/release/python-3110/) [![Python 3.9](https://img.shields.io/badge/python-3.9-green)](https://www.python.org/downloads/release/python-3916/) [![Python 3.8](https://img.shields.io/badge/python-3.8-green)](https://www.python.org/downloads/release/python-3816/)[![GitHub license](https://img.shields.io/github/license/mas-veritas2/veritastool.svg)](https://github.com/mas-veritas2/veritastool/blob/master/license.txt)[![Python package](https://github.com/mas-veritas2/veritastool/actions/workflows/python-package.yml/badge.svg)](https://github.com/mas-veritas2/veritastool/actions/workflows/python-package.yml) &lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/main/icon/veritas_logo_new.png&quot; &gt;&lt;/p&gt;The purpose of this toolkit is to facilitate the adoption of Veritas Methodology on Fairness &amp; Transparency Assessment and spur industry development. It will alsobenefit customers by improving the fairness and transparency of financial services delivered by AIDA systems.  ## InstallationThe easiest way to install veritastool is to download it from [`PyPI`](https://pypi.org/project/veritastool/). It's going to install the library itself and its prerequisites as well. It is suggested to create virtual environment with requirements.txt file first.```pythonpip install veritastool```Then, you will be able to import the library and use its functionalities. Before we do that, we can run a test function on our sample datasets to see if our codes are performing as expected.```pythonfrom veritastool.util.utility import test_function_cstest_function_cs()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/test_evaluate_cs.png&quot; width=&quot;800&quot; height=&quot;100&quot;&gt;&lt;/p&gt;### Initialization ##You can now import the custom library that you would to use for diagnosis. In this example we will use the Credit Scoring custom library. ```pythonfrom veritastool.model.modelwrapper import ModelWrapperfrom veritastool.model.model_container import ModelContainerfrom veritastool.usecases.credit_scoring import CreditScoring```Once the relevant use case object (CreditScoring) and model container (ModelContainer) has been imported, you can upload your contents into the container and initialize the object for diagnosis.```pythonimport pickleimport numpy as np#Load Credit Scoring Test Data# NOTE: Assume current working directory is the root folder of the cloned veritastool repositoryfile = &quot;./veritastool/examples/data/credit_score_dict.pickle&quot;input_file = open(file, &quot;rb&quot;)cs = pickle.load(input_file)#Model Contariner Parametersy_true = np.array(cs[&quot;y_test&quot;])y_pred = np.array(cs[&quot;y_pred&quot;])y_train = np.array(cs[&quot;y_train&quot;])p_grp = {'SEX': [1], 'MARRIAGE':[1]}up_grp = {'SEX': [2], 'MARRIAGE':[2]}x_train = cs[&quot;X_train&quot;]x_test = cs[&quot;X_test&quot;]model_name = &quot;credit_scoring&quot;model_type = &quot;classification&quot;y_prob = cs[&quot;y_prob&quot;]model_obj = LogisticRegression(C=0.1)model_obj.fit(x_train, y_train) #fit the model as required for transparency analysis#Create Model Container container = ModelContainer(y_true, p_grp, model_type, model_name, y_pred, y_prob, y_train, x_train=x_train, \                           x_test=x_test, model_object=model_obj, up_grp=up_grp)#Create Use Case Objectcre_sco_obj= CreditScoring(model_params = [container], fair_threshold = 80, fair_concern = &quot;eligible&quot;, \                           fair_priority = &quot;benefit&quot;, fair_impact = &quot;normal&quot;, perf_metric_name=&quot;accuracy&quot;, \                           tran_row_num = [20,40], tran_max_sample = 1000, tran_pdp_feature = ['LIMIT_BAL'], tran_max_display = 10)                                                     ```###  API functions ###Below are the API functions that the user can execute to obtain the fairness and transparency diagnosis of their use cases.**Evaluate**The evaluate API function computes all performance and fairness metrics and renders it in a table format (default). Italso highlights the primary performance and fairness metrics (automatic if not specified by user).```pythoncre_sco_obj.evaluate()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/evaluate_2.png&quot; width=&quot;608&quot; height=&quot;596&quot;&gt;&lt;/p&gt;You can also toggle the widget to view your results in a interactive visualization format.```pythoncre_sco_obj.evaluate(visualize = True)```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/evaluate_2_visualize.png&quot; width=&quot;858&quot; height=&quot;530&quot;&gt;&lt;/p&gt;**Tradeoff**Computes trade-off between performance and fairness.```pythoncre_sco_obj.tradeoff()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/tradeoff_2.png&quot; width=&quot;625&quot; height=&quot;516&quot;&gt;&lt;/p&gt;** Note: Replace {Balanced Accuracy} with the respective given metrics. **Feature Importance**Computes feature importance of protected features using leave one out analysis.```pythoncre_sco_obj.feature_importance()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/faeture_imp_2.png&quot; width=&quot;828&quot; height=&quot;653&quot;&gt;&lt;/p&gt;**Root Cause**Computes the importance of variables contributing to the bias.```pythoncre_sco_obj.root_cause()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/rootcause_2.png&quot; width=&quot;581&quot; height=&quot;530&quot;&gt;&lt;/p&gt;**Mitigate**User can choose methods to mitigate the bias.```pythonmitigated = cre_sco_obj.mitigate(p_var=[], method=['reweigh', 'correlation', 'threshold'])```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/mitigate_2.png&quot; width=&quot;576&quot; height=&quot;662&quot;&gt;&lt;/p&gt;**Explain**Runs the transparency analysis - global &amp; local interpretability, partial dependence analysis and permutation importance```python#run the entire transparency analysiscre_sco_obj.explain()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/explain_2.png&quot; width=&quot;624&quot; height=&quot;1034&quot;&gt;&lt;/p&gt;```python#get the local interpretability plot for specific row index and modelcre_sco_obj.explain(local_row_num = 20)```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/local_2.png&quot; width=&quot;514&quot; height=&quot;464&quot;&gt;&lt;/p&gt;**Compile**Generates model artifact file in JSON format. This function also runs all the API functions if it hasn't already been run.```pythoncre_sco_obj.compile()```Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/compile_2.png&quot; width=&quot;529&quot; height=&quot;209&quot;&gt;&lt;/p&gt;**Model Artifact**A JSON file that stores all the results from all the APIs.Output:&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mas-veritas2/veritastool/master/icon/json_2.png&quot; width=&quot;456&quot; height=&quot;494&quot;&gt;&lt;/p&gt;## ExamplesYou may refer to our example notebooks below to see how the toolkit can be applied:| Filename               | Description      | | -----------------------| -------------    | | [`CS_Demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/CS_demo.ipynb)| Tutorial notebook to diagnose a credit scoring model for predicting customers' loan repayment.            | | [`CM_Demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/customer_marketing_example/CM_demo.ipynb)          | Tutorial notebook to diagnose a customer marketing uplift model for selecting existing customers for a marketing call to increase the sales of loan product.            || [`BaseClassification_demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/BaseClassification_demo.ipynb)          | Tutorial notebook for a multi-class propensity model           | | [`BaseRegression_demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/BaseRegression_demo.ipynb)          | Tutorial notebook for a prediciton of a continuous target variable          | | [`PUW_demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/PUW_demo.ipynb)          | Tutorial notebook for a binary classification model to predict whether to award insurance policy by assessing risk          | | [`NewUseCaseCreation_demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/NewUseCaseCreation_demo.ipynb)          | Tutorial notebook to create a new use case note-book and add custom metrics         | | [`nonPythonModel_customMetric_demo.ipynb`](https://github.com/mas-veritas2/veritastool/blob/master/veritastool/examples/nonPythonModel_customMetric_demo.ipynb)          | Tutorial notebook to diagnose a credit scoring model by LibSVM (non-Python) with custom metric.            | ## LicenseVeritas Toolkit is licensed under the Apache License, Version 2.0 - see [`LICENSE`](https://raw.githubusercontent.com/mas-veritas2/veritastool/master/license.txt) for more details. </longdescription>
</pkgmetadata>