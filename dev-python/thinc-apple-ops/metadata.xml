<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;a href=&quot;https://explosion.ai&quot;&gt;&lt;img src=&quot;https://explosion.ai/assets/img/logo.svg&quot; width=&quot;125&quot; height=&quot;125&quot; align=&quot;right&quot; /&gt;&lt;/a&gt;# thinc-apple-opsMake [spaCy](https://spacy.io) and [Thinc](https://thinc.ai) **up to 8 &amp;times; faster**on macOS by calling into Apple's native libraries.## ‚è≥ InstallMake sure you have [Xcode](https://developer.apple.com/xcode/) installed andthen install with `pip`:```bashpip install thinc-apple-ops```## üè´ MotivationMatrix multiplication is one of the primary operations in machine learning.Since matrix multiplication is computationally expensive, using a fast matrixmultiplication implementation can speed up training and predictionsignificantly.Most linear algebra libraries provide matrix multiplication in the form of thestandardized[BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) `gemm`functions. The work behind scences is done by a set of matrix multiplicationkernels that are meticulously tuned for specific architectures. Matrixmultiplication kernels use architecture-specific[SIMD](https://en.wikipedia.org/wiki/SIMD) instructions for data-level parallismand can take factors such as cache sizes and intstruction latency into account.[Thinc](https://github.com/explosion/thinc) uses the[BLIS](https://github.com/flame/blis) linear algebra library, which providesoptimized matrix multiplication kernels for most x86_64 and some ARM CPUs.Recent [Apple Silicon](https://en.wikipedia.org/wiki/Apple_silicon) CPUs, suchas the [M-series](https://en.wikipedia.org/wiki/Apple_silicon#M_series) used inMacs, differ from traditional x86_64 and ARM CPUs in that they have a separatematrix co-processor(s) called AMX. Since AMX is not well-documented, it isunclear how many AMX units Apple M CPUs have. It is certain that the (single)performance cluster of the M1 has an AMX unit and there is [empiricalevidence](https://twitter.com/danieldekok/status/1454383754512945155?s=20) thatboth performance clusters of the M1 Pro/Max have an AMX unit.Even though AMX units use a set of [undocumentedinstructions](https://gist.github.com/dougallj/7a75a3be1ec69ca550e7c36dc75e0d6f),the units can be used through Apple's[Accelerate](https://developer.apple.com/documentation/accelerate) linearalgebra library. Since Accelerate implements the BLAS interface, it can be usedas a replacement of the BLIS library that is used by Thinc. This is where the`thinc-apple-ops` package comes in. `thinc-apple-ops` extends the default Thincops, so that `gemm` matrix multiplication from Accelerate is used in place ofthe BLIS implementation of `gemm`. As a result, matrix multiplication in Thincis performed on the fast AMX unit(s).## ‚è± BenchmarksUsing `thinc-apple-ops` leads to large speedups in prediction and training onApple Silicon Macs, as shown by the benchmarks below.### PredictionThis first benchmark compares prediction speed of the `de_core_news_lg` spaCymodel between the M1 with and without `thinc-apple-ops`. Results for an IntelMac Mini and AMD Ryzen 5900X are also provided for comparison. Results are inwords per second. In this prediction benchmark, using `thinc-apple-ops` improvesperformance by **4.3** times.| *CPU*                      | *BLIS* | *thinc-apple-ops* | *Package power (Watt)* || -------------------------- | -----: | ----------------: | ---------------------: || Mac Mini (M1)              |   6492 |             27676 |                      5 || MacBook Air Core i5 2020   |   9790 |             10983 |                      9 || Mac Mini Core i7 Late 2018 |  16364 |             14858 |                     31 || AMD Ryzen 5900X            |  22568 |               N/A |                     52 |### TrainingIn the second benchmark, we compare the training speed of the `de_core_news_lg`spaCy model (without NER). The results are in training iterations per second.Using `thinc-apple-ops` improves training time by **3.0** times.| *CPU*                      | *BLIS* | *thinc-apple-ops* | *Package power (Watt)* || -------------------------- | -----: | ----------------: | ---------------------: || Mac Mini M1 2020           |   3.34 |             10.07 |                      5 || MacBook Air Core i5 2020   |   3.10 |              3.27 |                     10 || Mac Mini Core i7 Late 2018 |   4.71 |              4.93 |                     32 || AMD Ryzen 5900X            |   6.53 |               N/A |                     53 |</longdescription>
</pkgmetadata>