<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># visionai-data-format`VisionAI` format is Dataverse[&quot;url&quot;] standardized annotation format to label objects and sequences in the context of Autonomous Driving System(ADS). `VisionAI` provides consistent and effective driving environment description and categorization in the real-world case.This tool provides validator of `VisionAI` format schema. Currently, the library supports:  - Validate created `VisionAI` data format  - Validate `VisionAI` data attributes with given `Ontology` information.[Package (PyPi)](https://pypi.org/project/visionai-data-format/)    |   [Source code](https://github.com/linkernetworks/visionai-data-format)## Getting started(WIP)### Install the package```pip install visionai-data-format```**Prerequisites**: You must have [Python 3.7](https://www.python.org/downloads/) and above to use this package.## ExampleThe following sections provide examples for the following:* [Validate VisionAI schema](###validate-visionai-schema)* [Validate VisionAI data with given Ontology](###validate-visionai-data-with-given-ontology)### Validate VisionAI schemaTo validate `VisionAI` data structure, could follow the example below:```Pythonfrom visionai_data_format.schemas.visionai_schema import VisionAIModel# your custom visionai datacustom_visionai_data = {    &quot;visionai&quot;: {        &quot;frame_intervals&quot;: [            {                &quot;frame_start&quot;: 0,                &quot;frame_end&quot;: 0            }        ],        &quot;frames&quot;: {            &quot;000000000000&quot;: {                &quot;objects&quot;: {                    &quot;893ac389-7782-4bc3-8f61-09a8e48c819f&quot;: {                        &quot;object_data&quot;: {                            &quot;bbox&quot;: [                                {                                    &quot;name&quot;: &quot;bbox_shape&quot;,                                    &quot;stream&quot;:&quot;camera1&quot;,                                    &quot;val&quot;: [761.565,225.46,98.33000000000004, 164.92000000000002]                                }                            ],                            &quot;cuboid&quot;: [                                {                                    &quot;name&quot;: &quot;cuboid_shape&quot;,                                    &quot;stream&quot;: &quot;lidar1&quot;,                                    &quot;val&quot;: [                                        8.727633224700037,-1.8557590122690717,-0.6544039394148177, 0.0,                                        0.0,-1.5807963267948966,1.2,0.48,1.89                                    ]                                }                            ]                        }                    }                },                &quot;frame_properties&quot;: {                    &quot;streams&quot;: {                        &quot;camera1&quot;: {                            &quot;uri&quot;: &quot;https://helenmlopsstorageqatest.blob.core.windows.net/vainewformat/kitti/kitti_small/data/000000000000/data/camera1/000000000000.png&quot;                        },                        &quot;lidar1&quot;: {                            &quot;uri&quot;: &quot;https://helenmlopsstorageqatest.blob.core.windows.net/vainewformat/kitti/kitti_small/data/000000000000/data/lidar1/000000000000.pcd&quot;                        }                    }                }            }        },        &quot;objects&quot;: {            &quot;893ac389-7782-4bc3-8f61-09a8e48c819f&quot;: {                &quot;frame_intervals&quot;: [                    {                        &quot;frame_start&quot;: 0,                        &quot;frame_end&quot;: 0                    }                ],                &quot;name&quot;: &quot;pedestrian&quot;,                &quot;object_data_pointers&quot;: {                    &quot;bbox_shape&quot;: {                        &quot;frame_intervals&quot;: [                            {                                &quot;frame_start&quot;: 0,                                &quot;frame_end&quot;: 0                            }                        ],                        &quot;type&quot;: &quot;bbox&quot;                    },                    &quot;cuboid_shape&quot;: {                        &quot;frame_intervals&quot;: [                            {                                &quot;frame_start&quot;: 0,                                &quot;frame_end&quot;: 0                            }                        ],                        &quot;type&quot;: &quot;cuboid&quot;                    }                },                &quot;type&quot;: &quot;pedestrian&quot;            }        },        &quot;coordinate_systems&quot;: {            &quot;lidar1&quot;: {                &quot;type&quot;: &quot;sensor_cs&quot;,                &quot;parent&quot;: &quot;&quot;,                &quot;children&quot;: [                    &quot;camera1&quot;                ]            },            &quot;camera1&quot;: {                &quot;type&quot;: &quot;sensor_cs&quot;,                &quot;parent&quot;: &quot;lidar1&quot;,                &quot;children&quot;: [],                &quot;pose_wrt_parent&quot;: {                    &quot;matrix4x4&quot;: [                        -0.00159609942076306,                        -0.005270645688933059,                        0.999984790046273,                        0.3321936949138632,                        -0.9999162467477257,                        0.012848695454066989,                        -0.0015282672486530082,                        -0.022106263278130818,                        -0.012840436309973332,                        -0.9999035522454274,                        -0.0052907123281999745,                        -0.06171977032225582,                        0.0,                        0.0,                        0.0,                        1.0                    ]                }            }        },        &quot;streams&quot;: {            &quot;camera1&quot;: {                &quot;type&quot;: &quot;camera&quot;,                &quot;uri&quot;: &quot;https://helenmlopsstorageqatest.blob.core.windows.net/vainewformat/kitti/kitti_small/data/000000000000/data/camera1/000000000000.png&quot;,                &quot;description&quot;: &quot;Frontal camera&quot;,                &quot;stream_properties&quot;: {                    &quot;intrinsics_pinhole&quot;: {                        &quot;camera_matrix_3x4&quot;: [                            -1.1285209781809271,                            -706.9900823216068,                            -181.46849639413674,                            0.2499212908887926,                            -3.726606344908137,                            9.084661126711246,                            -1.8645282480709864,                            -0.31027342289053916,                            707.0385458128643,                            -1.0805602883730354,                            603.7910589125847,                            45.42556655376811                        ],                        &quot;height_px&quot;: 370,                        &quot;width_px&quot;: 1224                    }                }            },            &quot;lidar1&quot;: {                &quot;type&quot;: &quot;lidar&quot;,                &quot;uri&quot;: &quot;https://helenmlopsstorageqatest.blob.core.windows.net/vainewformat/kitti/kitti_small/data/000000000000/data/lidar1/000000000000.pcd&quot;,                &quot;description&quot;: &quot;Central lidar&quot;            }        },        &quot;metadata&quot;: {            &quot;schema_version&quot;: &quot;1.0.0&quot;        }    }}# validate custom data# If the data structure doesn't meets the VisionAI requirements, it would raise BaseModel error message# otherwise, it will returns dictionary of validated visionai datavalidated_visionai = VisionAIModel(**custom_visionai_data).dict()```First, we declare our custom `VisionAI` data, then call `VisionAI(**custom_visionai_data).dict()` to validate our custom data visionai schema. It will raise error if any of required fields is missing or the value type doesn't meet with defined data type ( `BaseModel` error message). Otherwise, it will return dictionary of validated `VisionAI` data### Validate VisionAI data with given OntologyBefore upload dataset into `Dataverse` platform, we could try to validate a `VisionAI` annotation with `Ontology` schema. `Ontology` schema works as a predefined `Project Ontology` data in `Dataverse`.`Ontology` contains `contexts`, `objects`, `streams`, and `tags` four main elements similar to `VisioniAI` schema. The difference is that `Ontology` is the union of all categories and attributes that will be compared with a `VisionAI` data.1. `contexts`    need to be filled if only the project ontology is `classification` type.2. `objects`    need to be filled for other project ontologies instead of `classification`, such as `bounding_box` or `semantic_segmentation`, etc.3. `streams`    required to be filled, since it is the project sensor related information.4. `tags`    need to be filled in case of `semantic_segmentation` project ontology.Following is the example of `Ontology` Schema and how to validate `VisionAI` data with it:```Pythonfrom visionai_data_format.schemas.ontology import Ontologycustom_ontology = {    &quot;objects&quot;: {        &quot;pedestrian&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                },                &quot;activity&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                }            }        },        &quot;truck&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                },                &quot;color&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                },                &quot;new&quot;: {                    &quot;type&quot;: &quot;boolean&quot;,                    &quot;value&quot;: []                },                &quot;year&quot;: {                    &quot;type&quot;: &quot;num&quot;,                    &quot;value&quot;: []                },                &quot;status&quot;: {                    &quot;type&quot;: &quot;vec&quot;,                    &quot;value&quot;: [                        &quot;stop&quot;,                        &quot;run&quot;,                        &quot;small&quot;,                        &quot;large&quot;                    ]                }            }        },        &quot;car&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                },                &quot;color&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                },                &quot;new&quot;: {                    &quot;type&quot;: &quot;boolean&quot;,                    &quot;value&quot;: []                },                &quot;year&quot;: {                    &quot;type&quot;: &quot;num&quot;,                    &quot;value&quot;: []                },                &quot;status&quot;: {                    &quot;type&quot;: &quot;vec&quot;,                    &quot;value&quot;: [                        &quot;stop&quot;,                        &quot;run&quot;,                        &quot;small&quot;,                        &quot;large&quot;                    ]                }            }        },        &quot;cyclist&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                }            }        },        &quot;dontcare&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                }            }        },        &quot;misc&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                },                &quot;color&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                },                &quot;info&quot;: {                    &quot;type&quot;: &quot;vec&quot;,                    &quot;value&quot;: [                        &quot;toyota&quot;,                        &quot;new&quot;                    ]                }            }        },        &quot;van&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                }            }        },        &quot;tram&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                }            }        },        &quot;person_sitting&quot;: {            &quot;attributes&quot;: {                &quot;bbox_shape&quot;: {                    &quot;type&quot;: &quot;bbox&quot;,                    &quot;value&quot;: None                },                &quot;cuboid_shape&quot;: {                    &quot;type&quot;: &quot;cuboid&quot;,                    &quot;value&quot;: None                }            }        }    },    &quot;contexts&quot;:{        &quot;*tagging&quot;: {            &quot;attributes&quot;:{                &quot;profession&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                },                &quot;roadname&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                },                &quot;name&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                },                &quot;unknown_object&quot;: {                    &quot;type&quot;: &quot;vec&quot;,                    &quot;value&quot;: [                        &quot;sky&quot;,                        &quot;leaves&quot;,                        &quot;wheel_vehicle&quot;,                        &quot;fire&quot;,                        &quot;water&quot;                    ]                },                &quot;static_status&quot;: {                    &quot;type&quot;: &quot;boolean&quot;,                    &quot;value&quot;: [                        &quot;true&quot;,                        &quot;false&quot;                    ]                },                &quot;year&quot;: {                    &quot;type&quot;: &quot;num&quot;,                    &quot;value&quot;: []                },                &quot;weather&quot;: {                    &quot;type&quot;: &quot;text&quot;,                    &quot;value&quot;: []                }            }        }    },    &quot;streams&quot;: {        &quot;camera1&quot;: {            &quot;type&quot;: &quot;camera&quot;        },        &quot;lidar1&quot;: {            &quot;type&quot;: &quot;lidar&quot;        }    },    &quot;tags&quot;: None}# Validate your custom ontologyvalidated_ontology = Ontology(**custom_ontology).dict()# Validate VisionAI data with our ontology, custom_visionai_data is the custom data from upper exampleerrors = VisionAIModel(**custom_visionai_data).validate_with_ontology(ontology=validated_ontology)# Shows the errors# If there is any error occurred, it will returns list of error messages# Otherwise, it will return empty list# example of errors :# &gt;[&quot;validate objects error: Missing attributes from data pointers : {('893ac389-7782-4bc3-8f61-09a8e48c819f', 'bbox_shape'), ('893ac389-7782-4bc3-8f61-09a8e48c819f', 'cuboid_shape')} \n&quot;]print(errors)```First, create a new `Ontology` that contains the project ontology. Then, call `validate_with_ontology(ontology=validated_ontology)` to validate whether current `VisionAI` data meets the `Ontology` data information. It will returns list of error messages if any error occured, otherwise it returns empty list.## Tools### Convert `VisionAI` format data to `BDD` formatThe script below could help convert `VisionAI` annotation data to `BDD` json file```python visionai_data_format/vai_to_bdd.py -vai_src_folder /path_for_visionai_root_folder -bdd_dest_file /dest_path/bdd.json -company_code 99 -storage_name storge1 -container_name dataset1 -annotation_name groundtruth```## Troubleshooting(WIP)## Next steps(WIP)## Contributing(WIP)## Links to language repos(WIP)[Python Readme](https://github.com/linkernetworks/visionai-data-format/tree/develop/README.md)</longdescription>
</pkgmetadata>