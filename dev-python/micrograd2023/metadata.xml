<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>micrograd2023================&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;&lt;img src='./media/mArtificialNeuralNetwork_title.gif' width=100% height=auto&gt;## IntroductionI have done several projects## How to installThe [micrograd2023](https://pypi.org/project/micrograd2023/) package wasuploaded to [PyPI](https://pypi.org/) and can be easily installed usingthe below command.`pip install micrograd2023`### Developer installIf you want to develop `micrograd2023` yourself, please use an editableinstallation.`git clone https://github.com/hdocmsu/micrograd2023.git``pip install -e &quot;micrograd2023[dev]&quot;`You also need to use an editable installation of[nbdev](https://github.com/fastai/nbdev),[fastcore](https://github.com/fastai/fastcore), and[execnb](https://github.com/fastai/execnb).Happy Coding!!!## How to useHere are examples of using micrograd2023.``` python# import necessary objects and functionsfrom micrograd2023.engine import Valuefrom micrograd2023.nn import Neuron, Layer, MLPfrom micrograd2023.utils import draw_dotimport random`````` python# inputs xs, weights ws, and bias bw1 = Value(1.1)x1 = Value(0.5)w2 = Value(0.12)x2 = Value(1.7)b = Value(0.34)# pre-activations = w1*x1 + x2*w2 + b# activationy = s.tanh()# automatic differentiationy.backward()# show the computation graph of the perceptrondraw_dot(y)```![](index_files/figure-commonmark/cell-4-output-1.svg)``` python# added random seed for reproducibilityrandom.seed(1234)n = Neuron(3)x = [Value(0.15), Value(-0.21), Value(-0.91) ]y = n(x)y.backward()draw_dot(y)```![](index_files/figure-commonmark/cell-5-output-1.svg)You can use `micrograd2023` to train a MLP and learn fundamentalconcepts such as overfilling, optimal learning rate, etc.Good training&lt;img src='./media/MPL_good_training_decision_boundary.png' width=100% height=auto &gt;&lt;img src='./media/MPL_good_training_loss_acc_plots.png' width=100% height=auto &gt;Overfitting&lt;img src='./media/MPL_overfitting_decision_boundary.png' width=100% height=auto &gt;&lt;img src='./media/MPL_overfitting_loss_acc_plots.png' width=100% height=auto &gt;## TestingsTo perform unit testing, using terminal to navigate to the directory,which contains `tests` folder, then simply type `python -m pytest` onthe terminal. Note that,[PyTorch](https://pytorch.org/get-started/locally/) is needed for thetest to run since derivatives calculated using `micrograd2023` arecompared against those calculated using `PyTorch` as references.`python -m pytest`</longdescription>
</pkgmetadata>