<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![Build Status](https://travis-ci.com/mastak/airflow_multi_dagrun.svg?branch=master)](https://travis-ci.com/mastak/airflow_multi_dagrun)# Multi dag runThis plugin contains operators for triggering a DAG run multiple timesand you can dynamically specify how many DAG run instances create.It can be useful when you have to handle a big data and you want to split itinto chunks and run multiple instances of the same task in parallel.When you see a lot launched target DAGs you can set up more workers.So this makes it pretty easy to scale.## Install```bashpip install airflow_multi_dagrun```## ExampleCode for scheduling dags```pythonimport datetime as dtfrom airflow import DAGfrom airflow_multi_dagrun.operators import TriggerMultiDagRunOperatordef generate_dag_run():    for i in range(100):        yield {'index': i}default_args = {    'owner': 'airflow',    'start_date': dt.datetime(2015, 6, 1),}dag = DAG('reindex_scheduler', schedule_interval=None, default_args=default_args)ran_dags = TriggerMultiDagRunOperator(    task_id='gen_target_dag_run',    dag=dag,    trigger_dag_id='example_target_dag',    python_callable=generate_dag_run,)```This code will schedule dag with id `example_target_dag` 100 times and pass payload to it.Example of triggered dag: ```pythondag = DAG(    dag_id='example_target_dag',    schedule_interval=None,    default_args={'start_date': datetime.utcnow(), 'owner': 'airflow'},)def run_this_func(dag_run, **kwargs):    print(&quot;Chunk received: {}&quot;.format(dag_run.conf['index']))chunk_handler = PythonOperator(    task_id='chunk_handler',    provide_context=True,    python_callable=run_this_func,    dag=dag)```## Run exampleThere is docker-compose config, so it requires docker to be installed: `docker`, `docker-compose`1. `make init` - create db2. `make add-admin` - create `admin` user (is asks a password)3. `make web` - start docker containers, run airflow webserver4. `make scheduler` - start docker containers, run airflow scheduler`make down` will stop and remove docker containers ## ContributionsIf you have found a bug or have some idea for improvement feel free to create an issueor pull request.## LicenseApache 2.0</longdescription>
</pkgmetadata>