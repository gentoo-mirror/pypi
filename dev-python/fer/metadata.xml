<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>FER===Facial expression recognition.![image](https://github.com/justinshenk/fer/raw/master/result.jpg)[![PyPI version](https://badge.fury.io/py/fer.svg)](https://badge.fury.io/py/fer) [![Build Status](https://travis-ci.org/justinshenk/fer.svg?branch=master)](https://travis-ci.org/justinshenk/fer) [![Downloads](https://pepy.tech/badge/fer)](https://pepy.tech/project/fer)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/justinshenk/fer/blob/master/fer-video-demo.ipynb)[![DOI](https://zenodo.org/badge/150107943.svg)](https://zenodo.org/badge/latestdoi/150107943)INSTALLATION============Currently FER only supports Python 3.6 onwards. It can be installedthrough pip:```bash$ pip install fer```This implementation requires OpenCV\&gt;=3.2 and Tensorflow\&gt;=1.7.0installed in the system, with bindings for Python3.They can be installed through pip (if pip version \&gt;= 9.0.1):```bash$ pip install tensorflow&gt;=1.7 opencv-contrib-python==3.3.0.9```or compiled directly from sources([OpenCV3](https://github.com/opencv/opencv/archive/3.4.0.zip),[Tensorflow](https://www.tensorflow.org/install/install_sources)).Note that a tensorflow-gpu version can be used instead if a GPU deviceis available on the system, which will speedup the results. It can beinstalled with pip:```bash$ pip install tensorflow-gpu\&gt;=1.7.0```To extract videos that includes sound, ffmpeg and moviepy packages must be installed with pip:```bash$ pip install ffmpeg moviepy ```USAGE=====The following example illustrates the ease of use of this package:```pythonfrom fer import FERimport cv2img = cv2.imread(&quot;justin.jpg&quot;)detector = FER()detector.detect_emotions(img)```Sample output:```[{'box': [277, 90, 48, 63], 'emotions': {'angry': 0.02, 'disgust': 0.0, 'fear': 0.05, 'happy': 0.16, 'neutral': 0.09, 'sad': 0.27, 'surprise': 0.41}]```Pretty print it with `import pprint; pprint.pprint(result)`.Just want the top emotion? Try:```pythonemotion, score = detector.top_emotion(img) # 'happy', 0.99```#### MTCNN Facial RecognitionFaces by default are detected using OpenCV's Haar Cascade classifier. To use the more accurate MTCNN network,add the parameter:```pythondetector = FER(mtcnn=True)```#### VideoFor recognizing facial expressions in video, the `Video` class splits video into frames. It can use a local Keras model (default) or Peltarion API for the backend:```pythonfrom fer import Videofrom fer import FERvideo_filename = &quot;tests/woman2.mp4&quot;video = Video(video_filename)# Analyze video, displaying the outputdetector = FER(mtcnn=True)raw_data = video.analyze(detector, display=True)df = video.to_pandas(raw_data)```The detector returns a list of JSON objects. Each JSON object containstwo keys: 'box' and 'emotions':-   The bounding box is formatted as [x, y, width, height] under the key    'box'.-   The emotions are formatted into a JSON object with the keys 'anger',    'disgust', 'fear', 'happy', 'sad', surprise', and 'neutral'.Other good examples of usage can be found in the files[demo.py](demo.py) located in the root of this repository.To run the examples, install click for command line with `pip install click` and enter `python demo.py [image|video|webcam]` --help.TF-SERVING==========Support running with online TF Serving docker image.To use: Run `docker-compose up` and initialize FER with `FER(..., tfserving=True)`.MODEL=====FER bundles a Keras model.The model is a convolutional neural network with weights saved to HDF5file in the `data` folder relative to the module's path. It can beoverriden by injecting it into the `FER()` constructor duringinstantiation with the `emotion_model` parameter.LICENSE=======[MIT License](LICENSE).CREDIT======This code includes methods and package structure copied or derived fromIv√°n de Paz Centeno's [implementation](https://github.com/ipazc/mtcnn/)of MTCNN and Octavio Arriaga's [facial expression recognitionrepo](https://github.com/oarriaga/face_classification/).REFERENCE---------FER 2013 dataset curated by Pierre Luc Carrier and Aaron Courville, described in:&quot;Challenges in Representation Learning: A report on three machine learning contests,&quot; by Ian J. Goodfellow, Dumitru Erhan, Pierre Luc Carrier, Aaron Courville, Mehdi Mirza, Ben Hamner, Will Cukierski, Yichuan Tang, David Thaler, Dong-Hyun Lee, Yingbo Zhou, Chetan Ramaiah, Fangxiang Feng, Ruifan Li, Xiaojie Wang, Dimitris Athanasakis, John Shawe-Taylor, Maxim Milakov, John Park, Radu Ionescu, Marius Popescu, Cristian Grozea, James Bergstra, Jingjing Xie, Lukasz Romaszko, Bing Xu, Zhang Chuang, and Yoshua Bengio, [arXiv:1307.0414](https://arxiv.org/abs/1307.0414).</longdescription>
</pkgmetadata>