<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Sample Metadata[![codecov](https://codecov.io/gh/populationgenomics/sample-metadata/branch/dev/graph/badge.svg?token=OI3XZYR9HK)](https://codecov.io/gh/populationgenomics/sample-metadata)The sample-metadata system is database that stores **de-identified** metadata.There are three components to the sample-metadata system:- System-versioned MariaDB database,- Python web API to manage permissions, and store frequently used queries,- An installable python library that wraps the Python web API (using OpenAPI generator)Every resource in sample-metadata belongs to a project. All resources are accesscontrolled through membership of the google groups:`$dataset-sample-metadata-main-{read,write}`. Note that members of google-groupsare cached in a secret as group-membership identity checks are slow.## APIThere are two ways to query metamist in Python:1. Use the REST interface with the predefined requests2. Use the GraphQL interface.To use the GraphQL interface in Python with the `sample_metadata` library, you can do the following:```pythonfrom sample_metadata.graphql import query_query = &quot;&quot;&quot;query YourQueryNameHere($sampleId: String!) {  sample(id: $sampleId) {    id    externalId  }}&quot;&quot;&quot;print(query(_query, {&quot;sampleId&quot;: &quot;CPG18&quot;}))```## Structure![Database structure](resources/2021-10-27_db-diagram.png)### Sample IDsIn an effort to reduce our dependency on potentially mutable external sample IDs with inconsistent format,the sample-metadata server generates an internal sample id for every sample. Internally they're anincrementing integer, but they're transformed externally to have a prefix, and checksum - this allows durabilitywhen transcribing sample IDs to reduce mistypes, and allow to quickly check whether a sample ID is valid.&gt; NB: The prefix and checksums are modified per environment (production, development, local) to avoid duplicates from these environments.For example, let's consider the production environment which uses the prefix of `CPG` and a checksum offset of 0:&gt; A sample is given the internal ID `12345`, we calculate the Luhn checksum to be `5` (with no offset applied).&gt; We can then concatenate the results, for the final sample ID to be `CPG123455`.### Reporting sexTo avoid ambiguity in reporting of gender, sex and karyotype - the sample metadata systemstores these values separately on the `participant` as:- `reported_gender` (string, expected `male` | `female` | _other values_)- `reported_sex` (follows pedigree convention: `unknown=0 | null`, `male=1`, `female=2`)- `inferred_karyotype` (string, eg: `XX` | `XY` | _other karyotypes_)If you import a pedigree, the sex value is written to the `reported_sex` attribute.## Local develompent of SMThe recommended way to develop the sample-metadata system is to run a local copy of SM.&gt; There have been some reported issues of running a local SM environment on an M1 mac.You can run MariaDB with a locally installed docker, or from within a docker container.You can configure the MariaDB connection with environment variables.### Creating the environmentDependencies for the `sample-metadata` API package are listed in `setup.py`.Additional dev requirements are listed in `requirements-dev.txt`, and packages forthe sever-side code are listed in `requirements.txt`.To create the full dev environment, run:```shellvirtualenv venvsource venv/bin/activatepip install -r requirements.txtpip install -r requirements-dev.txtpip install --editable .```### Default DB set-upThese are the default values for the SM database connection.Please alter them if you use any different values when setting up the database.```shellexport SM_DEV_DB_USER=rootexport SM_DEV_DB_PASSWORD= # empty passwordexport SM_DEV_DB_HOST=127.0.0.1export SM_DEV_DB_PORT=3306 # default mariadb port```Create the database in MariaDB (by default, we call it `sm_dev`):If you use a different databse name also set the following```shellexport SM_DEV_DB_NAME=sm_database_name```&gt; Sample-metadata stores all metadata in one database (_previously: one database per project_).```shellmysql -u root --execute 'CREATE DATABASE sm_dev'```Download the `mariadb-java-client` and create the schema using liquibase:```shellpushd db/wget https://repo1.maven.org/maven2/org/mariadb/jdbc/mariadb-java-client/3.0.3/mariadb-java-client-3.0.3.jarliquibase \    --changeLogFile project.xml \    --url jdbc:mariadb://localhost/sm_dev \    --driver org.mariadb.jdbc.Driver \    --classpath mariadb-java-client-3.0.3.jar \    --username root \    updatepopd```#### Using Maria DB docker imagePull mariadb image```bashdocker pull mariadb```Run a mariadb container that will server your database. `-p 3307:3306` remaps the port to 3307 in case if you local MySQL is already using 3306```bashdocker stop mysql-p3307  # stop and remove if the container already existsdocker rm mysql-p3307# run with an empty root passworddocker run -p 3307:3306 --name mysql-p3307 -e MYSQL_ALLOW_EMPTY_PASSWORD=true -d mariadb``````bashmysql --host=127.0.0.1 --port=3307 -u root -e 'CREATE DATABASE sm_dev;'mysql --host=127.0.0.1 --port=3307 -u root -e 'show databases;'```Go into the `db/` subdirectory, download the `mariadb-java-client` and create the schema using liquibase:```bashpushd db/wget https://repo1.maven.org/maven2/org/mariadb/jdbc/mariadb-java-client/3.0.3/mariadb-java-client-3.0.3.jarliquibase \    --changeLogFile project.xml \    --url jdbc:mariadb://127.0.0.1:3307/sm_dev \    --driver org.mariadb.jdbc.Driver \    --classpath mariadb-java-client-3.0.3.jar \    --username root \    updatepopd```Finally, make sure you configure the server (making use of the environment variables) to point it to your local Maria DB server```bashexport SM_DEV_DB_PORT=3307```### Running the serverYou'll want to set the following environment variables (permanently) in yourlocal development environment.```shell# ensures the SWAGGER page (localhost:8000/docs) points to your local environmentexport SM_ENVIRONMENT=LOCAL# skips permission checks in your local environmentexport SM_ALLOWALLACCESS=true# start the serverpython3 -m api.server# OR# uvicorn --port 8000 --host 0.0.0.0 api.server:app```In a different terminal, execute the followingrequest to create a new project called 'dev'```shellcurl -X 'PUT' \  'http://localhost:8000/api/v1/project/?name=dev&amp;dataset=dev&amp;gcp_id=dev&amp;create_test_project=false' \  -H 'accept: application/json' \  -H &quot;Authorization: Bearer $(gcloud auth print-identity-token)&quot;```#### Quickstart: Generate and install the installable APIIt's best to do this with an already running server:```shellpython3 regenerate_api.py \    &amp;&amp; pip install .```#### Debugging the server in VSCodeVSCode allows you to debug python modules, we could debug the web API at `api/server.py` by considering the following `launch.json`:```json{  &quot;version&quot;: &quot;0.2.0&quot;,  &quot;configurations&quot;: [    {      &quot;name&quot;: &quot;API server&quot;,      &quot;type&quot;: &quot;python&quot;,      &quot;request&quot;: &quot;launch&quot;,      &quot;module&quot;: &quot;api.server&quot;    }  ]}```We could now place breakpoints on the sample route (ie: `api/routes/sample.py`), and debug requests as they come in.#### Developing the UI```shell# Ensure you have started sm locally on your computer already, then in another tab open the UI.# This will automatically proxy request to the server.cd webnpm installnpm start```#### Unauthenticated accessYou'll want to set the `SM_LOCALONLY_DEFAULTUSER` environment variable along with `ALLOWALLACCESS` to allow access to a local sample-metadata server without providing a bearer token. This will allow you to test the front-end components that access data. This happens automatically on the production instance through the Google identity-aware-proxy.```shellexport SM_ALLOWALLACCESS=1export SM_LOCALONLY_DEFAULTUSER=$(whoami)```### OpenAPI and SwaggerThe Web API uses `apispec` with OpenAPI3 annotations on each route to describe interactions with the server. We can generate a swagger UI and an installablepython module based on these annotations.Some handy links:- [OpenAPI specification](https://swagger.io/specification/)- [Describing parameters](https://swagger.io/docs/specification/describing-parameters/)- [Describing request body](https://swagger.io/docs/specification/describing-request-body/)- [Media types](https://swagger.io/docs/specification/media-types/)The web API exposes this schema in two ways:- Swagger UI: `http://localhost:8000/docs`  - You can use this to construct requests to the server  - Make sure you fill in the Bearer token (at the top right )- OpenAPI schema: `http://localhost:8000/schema.json`  - Returns a JSON with the full OpenAPI 3 compliant schema.  - You could put this into the [Swagger editor](https://editor.swagger.io/) to see the same &quot;Swagger UI&quot; that `/api/docs` exposes.  - We generate the sample_metadata installable Python API based on this schema.#### Generating the installable APIThe installable API is automatically generated through the `package.yml` GitHub action and uploaded to PyPI.To generate the python api you'll need to install openapi generator v5.x.xTo install a specific version of the openapi-generator dow the following:```bashnpm install @openapitools/openapi-generator-cli -gopenapi-generator-cli version-manager set 5.3.0```Then set your environment variable OPENAPI_COMMAND to the following.You can also add an alias to your ~/.bash_profile or equivalent for running in theterminal.```bashexport OPENAPI_COMMAND=&quot;npx @openapitools/openapi-generator-cli&quot;alias openapi-generator=&quot;npx @openapitools/openapi-generator-cli&quot;```You could generate the installable API and install it with pip by running:```bash# this will start the api.server, so make sure you have the dependencies installed,python regenerate_api.py \    &amp;&amp; pip install .```Or you can build the docker file, and specify that```bash# SM_DOCKER is a known env variable to regenerate_api.pyexport SM_DOCKER=&quot;cpg/sample-metadata-server:dev&quot;docker build --build-arg SM_ENVIRONMENT=local -t $SM_DOCKER -f deploy/api/Dockerfile .python regenerate_apy.py```## DeploymentThe sample-metadata serverYou'll want to complete the following steps:- Ensure there is a database created for each project (with the database name being the project),- Ensure there are secrets in `projects/sample_metadata/secrets/databases/versions/latest`, that's an array of objects with keys `dbname, host, port, username, password`.- Ensure `google-cloud` was installed```bashexport SM_ENVIRONMENT='PRODUCTION'# OR, point to the dev instance withexport SM_ENVIRONMENT='DEVELOPMENT'```</longdescription>
</pkgmetadata>