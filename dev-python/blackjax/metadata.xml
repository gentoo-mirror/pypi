<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># BlackJAX![CI](https://github.com/blackjax-devs/blackjax/workflows/Run%20tests/badge.svg?branch=main)[![codecov](https://codecov.io/gh/blackjax-devs/blackjax/branch/main/graph/badge.svg)](https://codecov.io/gh/blackjax-devs/blackjax)## What is BlackJAX?BlackJAX is a library of samplers for [JAX](https://github.com/google/jax) thatworks on CPU as well as GPU.It is *not* a probabilistic programming library. However it integrates reallywell with PPLs as long as they can provide a (potentially unnormalized)log-probability density function compatible with JAX.## Who should use BlackJAX?BlackJAX should appeal to those who:- Have a logpdf and just need a sampler;- Need more than a general-purpose sampler;- Want to sample on GPU;- Want to build upon robust elementary blocks for their research;- Are building a probabilistic programming language;- Want to learn how sampling algorithms work.## Quickstart### InstallationYou can install BlackJAX using `pip`:```bashpip install blackjax```or via conda-forge:```bashconda install -c conda-forge blackjax```BlackJAX is written in pure Python but depends on XLA via JAX. By default, theversion of JAX that will be installed along with BlackJAX will make your coderun on CPU only. **If you want to use BlackJAX on GPU/TPU** we recommend you follow[these instructions](https://github.com/google/jax#installation) to install JAXwith the relevant hardware acceleration support.### ExampleLet us look at a simple self-contained example sampling with NUTS:```pythonimport jaximport jax.numpy as jnpimport jax.scipy.stats as statsimport numpy as npimport blackjaxobserved = np.random.normal(10, 20, size=1_000)def logprob_fn(x):  logpdf = stats.norm.logpdf(observed, x[&quot;loc&quot;], x[&quot;scale&quot;])  return jnp.sum(logpdf)# Build the kernelstep_size = 1e-3inverse_mass_matrix = jnp.array([1., 1.])nuts = blackjax.nuts(logprob_fn, step_size, inverse_mass_matrix)# Initialize the stateinitial_position = {&quot;loc&quot;: 1., &quot;scale&quot;: 2.}state = nuts.init(initial_position)# Iteraterng_key = jax.random.PRNGKey(0)for _ in range(100):    _, rng_key = jax.random.split(rng_key)    state, _ = nuts.step(rng_key, state)```See [thisnotebook](https://github.com/blackjax-devs/blackjax/blob/main/examples/Introduction.md) for more examples of how to use the library: how to write inference loops for one or several chains, how to use the Stan warmup, etc.## Philosophy### What is BlackJAX?BlackJAX bridges the gap between &quot;one liner&quot; frameworks and modular, customizablelibraries.Users can import the library and interact with robust, well-tested and performantsamplers with a few lines of code. These samplers are aimed at PPL developers,or people who have a logpdf and just need a sampler that works.But the true strength of BlackJAX lies in its internals and how they can be usedto experiment quickly on existing or new sampling schemes. This lower levelexposes the building blocks of inference algorithms: integrators, proposal,momentum generators, etc and makes it easy to combine them to build newalgorithms. It provides an opportunity to accelerate research on samplingalgorithms by providing robust, performant and reusable code.### Why BlackJAX?Sampling algorithms are too often integrated into PPLs and not decoupled fromthe rest of the framework, making them hard to use for people who do not needthe modeling language to build their logpdf. Their implementation is most ofthe time monolithic and it is impossible to reuse parts of the algorithm tobuild custom kernels. BlackJAX solves both problems.### How does it work?BlackJAX allows to build arbitrarily complex algorithms because it is builtaround a very general pattern. Everything that takes a state and returns a stateis a transition kernel, and is implemented as:```pythonnew_state, info =  kernel(rng_key, state)```kernels are stateless functions and all follow the same API; state andinformation related to the transition are returned separately. They can thus beeasily composed and exchanged. We specialize these kernels by closure instead ofpassing parameters.## Contributions### What contributions?We value the following contributions:- Bug fixes- Documentation- High-level sampling algorithms from any family of algorithms: random walk,  hamiltonian monte carlo, sequential monte carlo, variational inference,  inference compilation, etc.- New building blocks, e.g. new metrics for HMC, integrators, etc.### How to contribute?1. Run `pip install -r requirements.txt` to install all the dev   dependencies.2. Run `pre-commit run --all-files` and `make test` before pushing on the repo; CI should pass if   these pass locally.## Citing BlackjaxTo cite this repository:```@software{blackjax2020github,  author = {Lao, Junpeng and Louf, R\'emi},  title = {{B}lackjax: A sampling library for {JAX}},  url = {http://github.com/blackjax-devs/blackjax},  version = {&lt;insert current release tag&gt;},  year = {2020},}```In the above bibtex entry, names are in alphabetical order, the version numberis intended to be that from [blackjax/__init__.py](https://github.com/blackjax-devs/blackjax/blob/main/blackjax/__init__.py), and the year corresponds to the project's open-source release.## AcknowledgementsSome details of the NUTS implementation were largely inspired by[Numpyro](https://github.com/pyro-ppl/numpyro)'s.</longdescription>
</pkgmetadata>