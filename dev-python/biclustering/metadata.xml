<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># FIST-Biclustering-PythonImplementation of FIST algorithm for generating Biclusters, Frequent Closed Patterns, Association Rules using Python**Abstract**Association rule mining and biclustering are two popular techniques in data mining that can be used to uncover interesting patterns and relationships in large datasets. However, these techniques are often computationally expensive and can be challenging to apply to large da-tasets. This paper presents a novel approach that combines association rule mining and bi-clustering using a suffix tree data structure. It is based on the frequent closed itemsets framework and requires a unique scan of the database. This data structure is used to reduce memory usage and improve the extraction efficiency, allowing parallel processing of the tree branches. Experimental results show that the proposed algorithm (Frequent Itemset Suffix Tree: FIST) is effective in uncovering meaningful patterns and relationships in large datasets and outperforms existing state-of-the-art algorithms in terms of efficiency and scalability.**USER GUIDE**In this section of the chapter, we will discuss how to use this python implementation of the algorithm. We will be briefly discussing the following topics:- Environment &amp; python installation- Installation of external Libraries- Using the source code or the package- Transforming input dataset to suitable form- Integrating the dataset with the python program and generating outputs- Results**1. Environment &amp; python installation:**I have used an windows PC with 64-bit operating system, x64-based processor for running the python program.To run the program, a suitable python installation is required. I have used Python 3.10.6.To install Python 3 on your machine, Visit the official Python website [https://www.python.org](https://www.python.org/) and navigate to the Downloads section. Download a version of Python 3.10 or onwards.**2. Installation of external libraries:**In this project we are using 2 external libraries on top of default python installation:- Pandas- PyDotWe are using pandas for the useful functionalities it provides for handling CSV files and DataFrames. PyDot is an interface to GraphViz which helps in creating graph based diagrams using python script.To install Pandas use: python -m pip install pandasTo install PyDot: python -m pip install pydotYou may additionally need to install a GraphViz driver for PyDot to work properly.**3. &lt;a name=&quot;_hlk136724867&quot;&gt;&lt;/a&gt;Using the source code or the package**The source code of the program can be cloned from this git repository.Source Code: &lt;https://github.com/Mijanur08/biclusturing-using-suffixTree&gt;The program is also uploaded in pypi.org as a python package. The latest version is 2023.5.31.3Package link: &lt;https://pypi.org/project/biclustering/&gt;Instead of cloning the git repository, the package can be directly installed using the following pip install command.|python -m pip install biclustering --user|| :- |**4. Transforming Input Dataset into Suitable Form**The input dataset must be in csv file and have the following 2 attributes:- An ID attribute which is unique for each of the rows- An itemsets attribute which contains comma separated names or values – each name or value representing an item.An example of the input dataset is –**Exampledata.csv**ID,ItemsetsO1,&quot;P1,P3,A2,A4&quot;O2,&quot;P1,P3,A1,A2&quot;O3,&quot;P2,P5,A3&quot;O4,&quot;P1,P3,P4,A2,A4&quot;O5,&quot;P1,P2,P3,P5,A2,A4&quot;**5. Integrating the dataset with our python program and generating output**Our python implementation has module named fist.py. This file acts as an interface between the user and the complete algorithmic process.First import the class FIST from the fist module and initialize a FIST class.If we are using the source code from git repository, we need to specify the fist.py file while importing FIST class.|&lt;p&gt;from fist import FIST&lt;/p&gt;&lt;p&gt;fist = FIST()&lt;/p&gt;|| :- |Otherwise, if we are directly using the package after installing it by pip, then we need to specify the package name ‘biclustering’.|&lt;p&gt;from biclustering import FIST&lt;/p&gt;&lt;p&gt;fist = FIST()&lt;/p&gt;&lt;p&gt;&lt;/p&gt;|| :- |Next step is to call the fist.process function. This function has 9 parameters. The function signature and description of all parameters are given below-|&lt;p&gt;def process(self, input\_file\_dir: str, input\_dataset\_name:str,&lt;/p&gt;&lt;p&gt;id\_attribute: str, itemset\_attribute: str, max\_entries = 10000,&lt;/p&gt;&lt;p&gt;min\_supp\_percent=1.0, min\_conf\_percent=0.0,&lt;/p&gt;&lt;p&gt;min\_supp\_count\_outputs = 1,produce\_final\_img=False)-&gt;none&lt;/p&gt;&lt;p&gt;&lt;/p&gt;|| - |&lt;table&gt;&lt;tr&gt;&lt;th colspan=&quot;3&quot; valign=&quot;top&quot;&gt;&lt;b&gt;Parameters&lt;/b&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;Input_file_dir&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;String Literal&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;NA&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Path to the directory where the input CSV file (dataset) is located and the outputs will be generated in an output folder in that directory.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;input_dataset_name&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;String Literal&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;NA&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Filename of the input CSV file including its file extension&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;id_attribute&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;String Literal&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;NA&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Name of the ID column of the dataset. The ID column must have unique value for each row.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;itemset_attribute&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;String Literal&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;NA&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Name of the Item List column of the dataset. This column should contain comma separated item names. These item names will form itemsets.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;max_entries&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Integer&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;10000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;It specifies maximum number of  rows are to be read in a dataset. If a dataset has total number of rows greater than max_entries, the first max_entries number of rows will be read during the execution.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;min_support_percent&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Float&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1\.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;The provided percentage of the total number of rows will be used as minimum support count for constructing the number table.&lt;/p&gt;&lt;p&gt;This value will also be embedded within the file name of generated files.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;min_conf_percent&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Float&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;0\.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;Minimum confidence filters the generated association rules. If confidence of an association rule is greater than min_conf_percent, only then it will be written in the output.&lt;/p&gt;&lt;p&gt;This value will also be embedded within the file name of generated files.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;min_supp_count_outputs&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Integer&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;To extract the FCPs and Bi-clusters we can use a different support count than the previous minimum support. This parameter carries the value of minimum support count which is used for generating the outputs.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;produce_final_img&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Datatype&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Boolean&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Optional&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Default Value&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;False&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Description&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;This parameter decides whether to generate the image of the suffix tree or not.&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;Here is the sample code for execution in python :|fist.process(“./”,”sample.csv”,”ID”,”Itemsets”,min\_support\_percent=30,min\_conf\_percent=40,produce\_final\_img=True)|| - |**6. Results**To avoid error during the execution, ensure that output folder exists in the input file directory. All the output files will be generated in this output folder. After execution, total 24 files including the image of the suffix tree is generated. They are as follows:&lt;table&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot;&gt;Number Table&lt;/th&gt;&lt;th valign=&quot;top&quot;&gt;NumberTable.dataset={dataset name}.minSupport={value}.csv&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;SFD&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;SFD.dataset={dataset name}.minSupport={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; valign=&quot;top&quot;&gt;Suffix Tree&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;suffixTree.dataset={dataset name}.minSupport={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;suffixTree.dataset={dataset name}.minSupport={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; valign=&quot;top&quot;&gt;FCPs&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;FCP.dataset={dataset name}.minSupport={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;FCP.dataset={dataset name}.minSupport={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; valign=&quot;top&quot;&gt;Generators&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;Generators.dataset={dataset name}.minSupport={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Generators.dataset={dataset name}.minSupport={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;Bi-clusters&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;biclusters.dataset={dataset name}.minSupport{value}.minSize={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;biclusters.dataset={dataset name}.minSupport{value}.minSize={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Biclusters.withNames.dataset={dataset name}.minSupport{value}.minSize={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;Biclusters.withNames.dataset={dataset name}.minSupport{value}.minSize={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; valign=&quot;top&quot;&gt;&lt;p&gt;Association Rules&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;- Exact&lt;/p&gt;&lt;p&gt;- PB&lt;/p&gt;&lt;p&gt;- SB&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;top&quot;&gt;rule.{type}.dataset={dataset name}.minSupport={value}.minConf={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;rule.{type}.dataset={dataset name}.minSupport={value}.minConf={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;rule.withNames.{type}.dataset={dataset name}.minSupport={value}.minConf={value}.csv&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;rule.withNames.{type}.dataset={dataset name}.minSupport={value}.minConf={value}.json&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;**7. References**1\. Kartick Chandra Mondal, Nicolas Pasquier, Anirban Mukhopadhyay, Ujjwal Maulik, and Sanghamitra Bandhopadyay: A New Approach for Association Rule Mining and Bi-clustering Using Formal Concept Analysis. (2012) [[Link](https://link.springer.com/chapter/10.1007/978-3-642-31537-4_8)]2\. Katick Chandra Mondal: Algorithms for Data Mining and Bio-informatics. (2016) [[Link](https://hal.science/tel-01330152/document)]</longdescription>
</pkgmetadata>