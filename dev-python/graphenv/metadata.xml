<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![PyPI version](https://badge.fury.io/py/graphenv.svg)](https://badge.fury.io/py/graphenv)[![Total alerts](https://img.shields.io/lgtm/alerts/g/NREL/graph-env.svg?logo=lgtm&amp;logoWidth=18)](https://lgtm.com/projects/g/NREL/graph-env/alerts/)[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/NREL/graph-env.svg?logo=lgtm&amp;logoWidth=18)](https://lgtm.com/projects/g/NREL/graph-env/context:python)[![DOI](https://zenodo.org/badge/470330187.svg)](https://zenodo.org/badge/latestdoi/470330187)[![DOI](https://joss.theoj.org/papers/10.21105/joss.04621/status.svg)](https://doi.org/10.21105/joss.04621)# graph-envThe `graphenv` Python library is designed to1) make graph search problems more readily expressible as RL problems via an extension of the OpenAI gym API while2) enabling their solution via scalable learning algorithms in the popular RLLib library.RLLib provides out-of-the-box support for both parametrically-defined actions and masking of invalid actions. However, native support for action spaces where the action _choices_ change for each state is challenging to implement in a computationally efficient fashion. The `graphenv` library provides utility classes that simplify the flattening and masking of action observations for choosing from a set of successor states at every node in a graph search.## InstallationGraphenv can be installed with pip:```pip install graphenv```## Quick Start`graph-env` allows users to create a customized graph search by subclassing the `Vertex` class. Basic examples are provided in the [`graphenv/examples`](graphenv/examples) folder. The following code snippet shows how to randomly sample from valid actions for a random walk down a 1D corridor:```pythonimport randomfrom graphenv.examples.hallway.hallway_state import HallwayStatefrom graphenv.graph_env import GraphEnvstate = HallwayState(corridor_length=10)env = GraphEnv({&quot;state&quot;: state, &quot;max_num_children&quot;: 2})obs = env.make_observation()done = Falsetotal_reward = 0while not done:    action = random.choice(range(len(env.state.children)))    obs, reward, terminated, truncated, info = env.step(action)    done = terminated or truncated    total_reward += reward```Additional details on this example are given in the [documentation](https://nrel.github.io/graph-env/examples/hallway.html)## DocumentationThe documentation is hosted on [GitHub Pages](https://nrel.github.io/graph-env/)## ContributingWe welcome bug reports, suggestions for new features, and pull requests. See our [contributing guidelines](CONTRIBUTING.md) for more details.## License`graph-env` is licensed under the [BSD 3-Clause License](LICENSE).Copyright (c) 2022, Alliance for Sustainable Energy, LLC</longdescription>
</pkgmetadata>