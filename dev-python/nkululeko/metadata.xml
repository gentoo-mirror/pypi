<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Nkululeko* [Overview](#overview)* [Installation](#installation)* [Documentation](https://nkululeko.readthedocs.io)* [Usage](#usage)* [Hello World](#hello-world-example)* [Licence](#licence) ## OverviewA project to detect speaker characteristics by machine learning experiments with a high-level interface.The idea is to have a framework (based on e.g. sklearn and torch) that can be used to rapidly and automatically analyse and investigate audio data automatically.* NEW: Nkululeko now automatically generates PDF reports [sample for EmoDB](meta/images/emodb_report.pdf)* The latest features can be seen in [the ini-file](./ini_file.md) options that are used to control Nkululeko* Below is a [Hello World example](#helloworld) that should set you up fastly, also on [Google Colab](https://colab.research.google.com/drive/1GYNBd5cdZQ1QC3Jm58qoeMaJg3UuPhjw?usp=sharing#scrollTo=4G_SjuF9xeQf), and [with Kaggle](https://www.kaggle.com/felixburk/nkululeko-hello-world-example)* [Here's a blog post on how to set up nkululeko on your computer.](http://blog.syntheticspeech.de/2021/08/30/how-to-set-up-your-first-nkululeko-project/)* [Here is a slack channel to discuss issues related to nkululeko](https://join.slack.com/t/nkululekoworkspace/shared_invite/zt-1wtvbxtwz-P5YoRJq8whxKSee86ebhJg). Please click the link if interested in contributing.* [Here's a slide presentation about nkululeko](docs/nkululeko.pdf)* [Here's a video presentation about nkululeko](https://www.youtube.com/playlist?list=PLRceVavtxLg0y2jiLmpnUfiMtfvkK912D)* [Here's the 2022 LREC article on nkululeko](http://felix.syntheticspeech.de/publications/Nkululeko_LREC.pdf)Here are some examples of typical output:### Confusion matrixPer default, Nkululeko displays results as a confusion matrix using binning with regression.&lt;img src=&quot;meta/images/conf_mat.png&quot; width=&quot;500px&quot;/&gt;### Epoch progressionThe point when overfitting starts can sometimes be seen by looking at the results per epoch:&lt;img src=&quot;meta/images/epoch_progression.png&quot; width=&quot;500px&quot;/&gt;### Feature importanceUsing the *explore* interface, Nkululeko analyses the importance of acoustic features: &lt;img src=&quot;meta/images/feat_importance.png&quot; width=&quot;500px&quot;/&gt;### Feature distributionAnd can show the distribution of specific features per category:&lt;img src=&quot;meta/images/feat_dist.png&quot; width=&quot;500px&quot;/&gt;### t-SNE plotsA t-SNE plot can give you an estimate wether your acoustic features are useful at all:&lt;img src=&quot;meta/images/tsne.png&quot; width=&quot;500px&quot;/&gt;### Data distributionSometimes you only want to take a look at your data:&lt;img src=&quot;meta/images/data_plot.png&quot; width=&quot;500px&quot;/&gt;### Bias checkingIn cases you might wonder if there's bias in your data. You can try to detect this with automatically estimated speech properties, by visualizing the correlation of target label and predicted labels.&lt;img src=&quot;meta/images/emotion-pesq.png&quot; width=&quot;500px&quot;/&gt;## DocumentationThe documentation, along with extensions of installation, usage, INI file format, and examples, can be found [nkululeko.readthedocs.io](https://nkululeko.readthedocs.io).## InstallationCreate and activate a virtual Python environment and simply run```pip install nkululeko```We excluded some packages from the automatic installation because they might depend on your computer and some of them are only needed in special cases. So if the error```module x not found```appears, please try```pip install x```For many packages you will need the missing torch package.If you don't have a GPU (which is probably true if you don't know what that is), please use```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu```else, you can use the default:```pip install torch torchvision torchaudio```Some examples for *ini*-files (which you use to control nkululeko) are in the [tests folder](https://github.com/felixbur/nkululeko/tree/main/tests).## UsageBasically, you specify your experiment in an &quot;ini&quot; file (e.g. *experiment.ini*) and then call one of the Nkululeko interfaces to run the experiment like this:  * ```python -m nkululeko.nkululeko --config experiment.ini```A basic configuration looks like this:```[EXP]root = ./name = exp_emodb[DATA]databases = ['emodb']emodb = ./emodb/emodb.split_strategy = speaker_splittarget = emotionlabels = ['anger', 'boredom', 'disgust', 'fear'][FEATS]type = ['praat'][MODEL]type = svm[EXPL]model = treeplot_tree = True[PLOT]combine_per_speaker = mode```Read the [Hello World example](#hello-world-example) for initial usage with Emo-DB dataset.Here is an overview of the interfaces:* **nkululeko.nkululeko**: do machine learning experiments combining features and learners* **nkululeko.demo**: demo the current best model on the command line* **nkululeko.test**: predict a series of files with the current best model* **nkululeko.explore**: perform data exploration* **nkululeko.augment**: augment the current training data* **nkululeko.predict**: predict features like SNR, MOS, arousal/valence, age/gender, with DNN models* **nkululeko.segment**: segment a database based on VAD (voice activity detection)* **nkululeko.resample**: check on all sampling rates and change to 16kHz There's my [blog](http://blog.syntheticspeech.de/?s=nkululeko) with tutorials:* [Introduction](http://blog.syntheticspeech.de/2021/08/04/machine-learning-experiment-framework/)* [Nkulueko FAQ](http://blog.syntheticspeech.de/2022/07/07/nkululeko-faq/)* [How to set up your first nkululeko project](http://blog.syntheticspeech.de/2021/08/30/how-to-set-up-your-first-nkululeko-project/)* [Setting up a base nkululeko experiment](http://blog.syntheticspeech.de/2021/10/05/setting-up-a-base-nkululeko-experiment/)* [How to import a database](http://blog.syntheticspeech.de/2022/01/27/nkululeko-how-to-import-a-database/) * [Comparing classifiers and features](http://blog.syntheticspeech.de/2021/10/05/nkululeko-comparing-classifiers-and-features/)* [Use Praat features](http://blog.syntheticspeech.de/2022/06/27/how-to-use-selected-features-from-praat-with-nkululeko/)* [Combine feature sets](http://blog.syntheticspeech.de/2022/06/30/how-to-combine-feature-sets-with-nkululeko/)* [Classifying continuous variables](http://blog.syntheticspeech.de/2022/01/26/nkululeko-classifying-continuous-variables/) * [Try out / demo a trained model](http://blog.syntheticspeech.de/2022/01/24/nkululeko-try-out-demo-a-trained-model/) * [Perform cross database experiments](http://blog.syntheticspeech.de/2021/10/05/nkululeko-perform-cross-database-experiments/)* [Meta parameter optimization](http://blog.syntheticspeech.de/2021/09/03/perform-optimization-with-nkululeko/)* [How to set up wav2vec embedding](http://blog.syntheticspeech.de/2021/12/03/how-to-set-up-wav2vec-embedding-for-nkululeko/)* [How to soft-label a database](http://blog.syntheticspeech.de/2022/01/24/how-to-soft-label-a-database-with-nkululeko/) * [Re-generate the progressing confusion matrix animation wit a different framerate](demos/plot_faster_anim.py)* [How to limit/filter a dataset](http://blog.syntheticspeech.de/2022/02/22/how-to-limit-a-dataset-with-nkululeko/)* [Specifying database disk location](http://blog.syntheticspeech.de/2022/02/21/specifying-database-disk-location-with-nkululeko/) * [Add dropout with MLP models](http://blog.syntheticspeech.de/2022/02/25/adding-dropout-to-mlp-models-with-nkululeko/)* [Do cross-validation](http://blog.syntheticspeech.de/2022/03/23/how-to-do-cross-validation-with-nkululeko/)* [Combine predictions per speaker](http://blog.syntheticspeech.de/2022/03/24/how-to-combine-predictions-per-speaker-with-nkululeko/)* [Run multiple experiments in one go](http://blog.syntheticspeech.de/2022/03/28/how-to-run-multiple-experiments-in-one-go-with-nkululeko/)* [Compare several MLP layer layouts with each other](http://blog.syntheticspeech.de/2022/04/11/how-to-compare-several-mlp-layer-layouts-with-each-other/)* [Import features from outside the software](http://blog.syntheticspeech.de/2022/10/18/how-to-import-features-from-outside-the-nkululeko-software/)* [Explore feature importance](http://blog.syntheticspeech.de/2023/02/20/nkululeko-show-feature-importance/)* [Plot distributions for feature values](http://blog.syntheticspeech.de/2023/02/16/nkululeko-how-to-plot-distributions-of-feature-values/)* [Show feature importance](http://blog.syntheticspeech.de/2023/02/20/nkululeko-show-feature-importance/)* [Augment the training set](http://blog.syntheticspeech.de/2023/03/13/nkululeko-how-to-augment-the-training-set/)* [Visualize clusters of acoustic features](http://blog.syntheticspeech.de/2023/04/20/nkululeko-visualize-clusters-of-your-acoustic-features/)* [Visualize your data distribution](http://blog.syntheticspeech.de/2023/05/11/nkululeko-how-to-visualize-your-data-distribution/)* [Check your dataset](http://blog.syntheticspeech.de/2023/07/11/nkululeko-check-your-dataset/) * [Segmenting a database](http://blog.syntheticspeech.de/2023/07/14/nkululeko-segmenting-a-database/)* [Predict new labels for your data from public models and check bias](http://blog.syntheticspeech.de/2023/08/16/nkululeko-how-to-predict-labels-for-your-data-from-existing-models-and-check-them/)* [Resample](http://blog.syntheticspeech.de/2023/08/31/how-to-fix-different-sampling-rates-in-a-dataset-with-nkululeko/)* [Get some statistics on correlation and effect-size](http://blog.syntheticspeech.de/2023/09/05/nkululeko-get-some-statistics-on-correlation-and-effect-size/)* [Generate a latex / pdf report](http://blog.syntheticspeech.de/2023/09/26/nkululeko-generate-a-latex-pdf-report/)   The framework is targeted at the speech domain and supports experiments where different classifiers are combined with different feature extractors.Here's a rough UML-like sketch of the framework (and [here's the real one done with pyreverse](meta/images/classes.png)).![sketch](meta/images/class_diagram.png)Currently, the following linear classifiers are implemented (integrated from sklearn):* SVM, SVR, XGB, XGR, Tree, Tree_regressor, KNN, KNN_regressor, NaiveBayes, GMM  and the following ANNs* MLP, CNN (tbd)Here's [an animation that shows the progress of classification done with nkululeko](https://youtu.be/6Y0M382GjvM)### Initialization fileYou could * use a generic main python file (like my_experiment.py), * adapt the path to your nkululeko src * and then adapt an .ini file (again fitting at least the paths to src and data)  Here's [an overview of the ini-file options](./ini_file.md)### &lt;a name=&quot;helloworld&quot;&gt;Hello World example&lt;/a&gt;* NEW: [Here's a Google colab that runs this example out-of-the-box](https://colab.research.google.com/drive/1GYNBd5cdZQ1QC3Jm58qoeMaJg3UuPhjw?usp=sharing#scrollTo=4G_SjuF9xeQf), and here is the same [with Kaggle](https://www.kaggle.com/felixburk/nkululeko-hello-world-example)* [I made a video to show you how to do this on Windows](https://www.youtube.com/playlist?list=PLRceVavtxLg0y2jiLmpnUfiMtfvkK912D)* Set up Python on your computer, version &gt;= 3.6* Open a terminal/commandline/console window* Test python by typing ```python```, python should start with version &gt;3 (NOT 2!). You can leave the Python Interpreter by typing *exit()** Create a folder on your computer for this example, let's call it `nkulu_work`* Get a copy of the [Berlin emodb in audformat](https://tubcloud.tu-berlin.de/s/LfkysdXJfiobiEG) and unpack inside the folder you just created (`nkulu_work`)* Make sure the folder is called &quot;emodb&quot; and does contain the database files directly (not box-in-a-box)* Also, in the `nkulu_work` folder:   * Create a Python environment    * ```python -m venv venv```  * Then, activate it:    * under Linux / mac      * ```source venv/bin/activate```    * under Windows      * ```venv\Scripts\activate.bat```    * if that worked, you should see a ```(venv)``` in front of your prompt  * Install the required packages in your environment    * ```pip install nkululeko```    * Repeat until all error messages vanished (or fix them, or try to ignore them)...* Now you should have two folders in your *nkulu_work* folder:  * *emodb* and *venv** Download a copy of the file [exp_emodb.ini](meta/demos/exp_emodb.ini) to the current working directory (```nkulu_work```)* Run the demo  * ```python -m nkululeko.nkululeko --config exp_emodb.ini```* Find the results in the newly created folder exp_emodb   * Inspect ```exp_emodb/images/run_0/emodb_xgb_os_0_000_cnf.png```  * This is the main result of you experiment: a confusion matrix for the emodb emotional categories* Inspect and play around with the [demo configuration file](demos/exp_emodb.ini) that defined your experiment, then re-run.* There are many ways to experiment with different classifiers and acoustic features sets, [all described here](https://github.com/felixbur/nkululeko/blob/main/ini_file.md)  ### Features* Classifiers: Naive Bayes, KNN, Tree, XGBoost, SVM, MLP* Feature extractors: Praat, Opensmile, openXBOW BoAW, TRILL embeddings, Wav2vec2 embeddings, audModel embeddings, ...* Feature scaling* Label encoding* Binning (continuous to categorical)* Online demo interface for trained models ### Outlook* Classifiers: CNN* Feature extractors: mid-level descriptors, Mel-spectra## LicenseNkululeko can be used under the [MIT license](https://choosealicense.com/licenses/mit/)Changelog=========Version 0.66.13---------------* small changes related to github workerVersion 0.66.12---------------* fixed bug that prevented Praat features to be selected   Version 0.66.11---------------* removed torch from automatic install. depends on cpu/gpu machineVersion 0.66.10---------------* Removed print statements from feats_wav2vec2Version 0.66.9--------------* Version that should install without requiring opensmile which seems not to be supported by all Apple processors (arm CPU (Apple M1))Version 0.66.8--------------* forgot __init__.py in reporting moduleVersion 0.66.7--------------* minor changes to experiment classVersion 0.66.6--------------* minor cosmeticsVersion 0.66.5--------------* Latex report now with imagesVersion 0.66.4--------------* Pypi version mixupVersion 0.66.3--------------* made path to PDF output relative to experiment rootVersion 0.66.2--------------* enabled data-pathes with quotes * enabled missing category labels* used tgdm for progress displayVersion 0.66.1--------------* start on the latex report frameworkVersion 0.66.0--------------* added speechbrain speakerID embeddings   Version 0.65.9--------------* added a filter that ensures that the labels have the same size as the featuresVersion 0.65.8--------------* changed default behaviour of resampler to &quot;keep original files&quot;Version 0.65.7--------------* more databases and force wav while resamplingVersion 0.65.6--------------* minor catch for seaborn in plotsVersion 0.65.5--------------* added fill_na in plot effect sizeVersion 0.65.4--------------* added datasets to distribution* changes in wav2vec2Version 0.65.3--------------* various bugfixesVersion 0.65.2--------------* fixed bug in dataset.csv that prevented correct paths for relative files* fixed bug in export module concerning new file directoryVersion 0.65.1--------------* small enhancements with transformer featuresVersion 0.65.0--------------* introduced export moduleVersion 0.64.4--------------* added num_speakers for reloaded data* re-formatted all with blackVersion 0.64.3--------------* added number of speakers shown after data loadVersion 0.64.2--------------* added __init__.py for submodulesVersion 0.64.1--------------* fix error on csvVersion 0.64.0--------------* added bin_reals* added statistics for effect size and correlation to plotsVersion 0.63.4--------------* fixed bug in split selectionVersion 0.63.3--------------* Introduced data.audio_pathVersion 0.63.2--------------* re-introduced min and max_length for silero segmenatationVersion 0.63.1--------------* fixed bug in resampleVersion 0.63.0--------------* added wavlm model* added error on filename for modelsVersion 0.62.1--------------* added min and max_length for silero segmenatationVersion 0.62.0--------------* fixed segment silero bug* added all Wav2vec2 models* added resampler module* added error on file for embeddingsVersion 0.61.0--------------* added HUBERT embeddings  Version 0.60.0--------------* some bugfixes* new package structure* fixed wav2vec2 bugs* removed &quot;cross_data&quot; strategy Version 0.59.1--------------* bugfix, after fresh install, it seems some libraries have changed* added no_warnings* changed print() to util.debug()* added progress to opensmile extract  Version 0.59.0--------------* introduced SQUIM features* added SDR predict* added STOI predictVersion 0.58.0--------------* added dominance predict* added MOS predict * added PESQ predict Version 0.57.0--------------* renamed autopredict predict* added arousal autopredict* added valence autopredict Version 0.56.0--------------* added autopredict module* added snr as feature extractor* added gender autopredict* added age autopredict* added snr autopredictVersion 0.55.1--------------* changed error message in plot classVersion 0.55.0--------------* added segmentation moduleVersion 0.54.0--------------* added audeering public age and gender model embeddings and age and gender predictionsVersion 0.53.0--------------* added file checks: size in bytes and voice activity detection with sileroVersion 0.52.1--------------* bugfix: min/max duration_of_sample was not workingVersion 0.52.0--------------* added flexible value distribution plotsVersion 0.51.0--------------* added datafilterVersion 0.50.1--------------* added caller information for debug and error messages in UtilVersion 0.50.0--------------* removed loso and added pre-selected logo (leave-one-group-out), aka foldsVersion 0.49.1--------------* bugfix: samples selection for augmentation didn't workVersion 0.49.0--------------* added random-splicingVersion 0.48.1--------------* bugfix: database object was not loaded when dataframe was reusedVersion 0.48.0--------------* enabled specific feature selection for praat and opensmile featuresVersion 0.47.1--------------* enabled feature storage format csv for opensmile featuresVersion 0.47.0--------------* added praat speech rate featuresVersion 0.46.0--------------* added warnings for non-existent parameters* added sample selection for scatter plottingVersion 0.45.4--------------* added version attribute to setup.cfgVersion 0.45.4--------------* added __version__ attributeVersion 0.44.1--------------* bugfixing: feature importance: https://github.com/felixbur/nkululeko/issues/23* bugfixing: loading csv database with filewise index https://github.com/felixbur/nkululeko/issues/24 Version 0.45.2--------------* bugfix: sample_selection in EXPL was required wronglyVersion 0.45.2--------------* added sample_selection for sample distribution plotsVersion 0.45.1--------------* fixed dataframe.append bugVersion 0.45.0--------------* added auddim as features* added FEATS store_format* added device use to feat_audmodelVersion 0.44.1--------------* bugfixesVersion 0.44.0--------------* added scatter functions: tsne, pca, umapVersion 0.43.7--------------* added clap featuresVersion 0.43.6--------------* small bugsVersion 0.43.5--------------* because of difficulties with numba and audiomentations importing audiomentations only when augmentingVersion 0.43.4--------------* added error when experiment type and predictor don't matchVersion 0.43.3--------------* fixed further bugs and added augmentation to the test runsVersion 0.43.2--------------* fixed a bug when running continuous variable as classification problemVersion 0.43.1--------------* fixed test_runsVersion 0.43.0--------------* added augmentation module based on audiomentationVersion 0.42.0--------------* age labels should now be detected in databasesVersion 0.41.0--------------* added feature tree plotVersion 0.40.1--------------* fixed a bug: additional test database was not label encodedVersion 0.40.0--------------* added EXPL section and first functionality* added test module (for test databases)Version 0.39.0--------------* added feature distribution plots* added  plot formatVersion 0.38.3--------------* added demo mode with list argumentVersion 0.38.2--------------* fixed a bug concerned with &quot;no_reuse&quot; evaluationVersion 0.38.1--------------* demo mode with file argumentVersion 0.38.0--------------* fixed demo modeVersion 0.37.2--------------* mainly replaced pd.append with pd.concatVersion 0.37.1--------------* fixed bug preventing praat feature extraction to workVersion 0.37.0--------------* fixed bug cvs import not detecting multiindex Version 0.36.3--------------* published as a pypi moduleVersion 0.36.0--------------* added entry nkululeko.py scriptVersion 0.35.0--------------* fixed bug that prevented scaling (normalization)Version 0.34.2--------------* smaller bug fixed concerning the loss_stringVersion 0.34.1--------------* smaller bug fixes and tried Soft_f1 lossVersion 0.34.0--------------* smaller bug fixes and debug ouputsVersion 0.33.0--------------* added GMM as a model typeVersion 0.32.0--------------* added audmodel embeddings as featuresVersion 0.31.0--------------* added models: tree and tree_reg  Version 0.30.0--------------* added models: bayes, knn and knn_regVersion 0.29.2--------------* fixed hello world exampleVersion 0.29.1--------------* bug fix for 0.29Version 0.29.0--------------* added a new FeatureExtractor class to import external dataVersion 0.28.2--------------* removed some Pandas warnings* added no_reuse function to database.load()Version 0.28.1--------------* with database.value_counts show only the data that is actually usedVersion 0.28.0--------------* made &quot;label_data&quot; configuration automatic and added &quot;label_result&quot;Version 0.27.0--------------* added &quot;label_data&quot; configuration to label data with trained model (so now there can be train, dev and test set)Version 0.26.1--------------* Fixed some bugs caused by the multitude of feature sets* Added possibilty to distinguish between absolut or relative pathes in csv datasetsVersion 0.26.0--------------* added the rename_speakers funcionality to prevent identical speaker names in datasetsVersion 0.25.1--------------* fixed bug that no features were chosen if not selectedVersion 0.25.0--------------* made selectable features universal for feature setsVersion 0.24.0--------------* added multiple feature sets (will simply be concatenated)Version 0.23.0--------------* added selectable features for Praat interfaceVersion 0.22.0--------------* added David R. Feinberg's Praat features, praise also to parselmouthVersion 0.21.0--------------* Revoked 0.20.0* Added support for only_test = True, to enable later testing of trained models with new test dataVersion 0.20.0--------------* implemented reuse of trained and saved modelsVersion 0.19.0--------------* added &quot;max_duration_of_sample&quot; for datasetsVersion 0.18.6--------------* added support for learning and dropout rate as argumentVersion 0.18.5--------------* added support for epoch number as argument  Version 0.18.4--------------* added support for ANN layers as argumentsVersion 0.18.3--------------* added reuse of test and train file sets* added parameter to scale continous target values: target_divide_byVersion 0.18.2--------------* added preference of local dataset specs to global ones  Version 0.18.1--------------* added regression value display for confusion matricesVersion 0.18.0--------------* added leave one speaker group outVersion 0.17.2--------------* fixed scaler, added robustVersion 0.17.0--------------* Added minimum duration for test samplesVersion 0.16.4--------------* Added possibility to combine predictions per speaker (with mean or mode function)Version 0.16.3--------------* Added minimal sample length for databasesVersion 0.16.2--------------* Added k-fold-cross-validation for linear classifiersVersion 0.16.1--------------* Added leave-one-speaker-out for linear classifiersVersion 0.16.0--------------* Added random sample splits</longdescription>
</pkgmetadata>