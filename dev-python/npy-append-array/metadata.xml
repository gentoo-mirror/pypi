<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># NpyAppendArrayCreate Numpy `.npy` files by appending on the growth axis (0 for C order, -1for Fortran order). It behaves like `numpy.concatenate` with the differencethat the result is stored out-of-memory in a `.npy` file and can be reused forfurther appending. After creation, the file can then be read with memorymapping (e.g. by adding `mmap_mode=&quot;r&quot;`) which altogether allows to create andread files (optionally) larger than the machine's main memory.Some possible applications:1. efficiently create large `.npy` (optionally database-like) files   * Handling of offsets not included, can be done in an extra array   * Large legacy files can be made appendable by calling `ensure_appendable`       * can (optionally) be performed in-place to minimize disk space usage2. create binary log files (optionally on low-memory embedded devices)   * Check the option `rewrite_header_on_append=False` for extra efficiency   * Binary log files can be accessed very efficiently without parsing   * Incomplete files can be recovered efficiently by calling `recover`Another feature of this library is the (above mentioned) `recover` function,which makes incomplete `.npy` files readable by `numpy.load` again, no matterwhether they should be appended to or not.Incomplete files can be the result of broken downloads or unfinished writes.Recovery works by rewriting the header and inferring the growth axis (seeabove) by the file size. As the data length may not be evenly divisible by thenon-append-axis shape, incomplete entries can either be ignored(`zerofill_incomplete=False`), which probably makes sense in most scenarios.Alternatively, to squeeze out the as much information from the file aspossible, `zerofill_incomplete=True` can be used, which fills the incompletelast append axis item with zeros.Raises `ValueError` instead of `TypeError` since version 0.9.14 to be moreconsistent with Numpy.NpyAppendArray can be used in multithreaded environments.## Installation```bashconda install -c conda-forge npy-append-array```or```bashpip install npy-append-array```## Usage```pythonfrom npy_append_array import NpyAppendArrayimport numpy as nparr1 = np.array([[1,2],[3,4]])arr2 = np.array([[1,2],[3,4],[5,6]])filename = 'out.npy'with NpyAppendArray(filename) as npaa:    npaa.append(arr1)    npaa.append(arr2)    npaa.append(arr2)    data = np.load(filename, mmap_mode=&quot;r&quot;)print(data)```## ConcurrencyConcurrency can be achieved by multithreading: A single `NpyAppendArray`object (per file) needs to be created. Then, `append` can be called frommultiple threads and locks will ensure that file writes do not happen inparallel. When using with a `with` statement, make sure the `join` happenswithin it, compare `test.py`.Multithreaded writes are not the pinnacle of what is technically possible withmodern operating systems. It would be highly desirable to use `async` filewrites. However, although modules like `aiofile` exist, this is currently notsupported natively by Python or Numpy, comparehttps://github.com/python/cpython/issues/76742## Implementation DetailsNpyAppendArray contains a modified, partial version of `format.py` from theNumpy package. It ensures that array headers are created with 21(`=len(str(8*2**64-1))`) bytes of spare space. This allows to fit an array ofmaxed out dimensions (for a 64 bit machine) without increasing the arrayheader size. This allows to simply rewrite the header as we append data to theend of the `.npy` file.## Supported SystemsTestes with Ubuntu Linux, macOS and Windows.</longdescription>
</pkgmetadata>