<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div &gt;  &lt;a href=&quot;https://evadb.readthedocs.io/&quot;&gt;    &lt;img src=&quot;https://raw.githubusercontent.com/georgia-tech-db/eva/master/docs/images/eva/eva-banner.png&quot; alt=&quot;EVA&quot; width=&quot;1000px&quot; margin-left=&quot;-5px&quot;&gt;  &lt;/a&gt;  &lt;div&gt;        &lt;h3&gt;Try It Out!&lt;/h3&gt;        &lt;a href=&quot;https://github.com/georgia-tech-db/eva&quot;&gt;            &lt;img src=&quot;https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/georgia-tech-db/eva/master/docs/images/eva/v1.json&quot; alt=&quot;Logo&quot;/&gt;        &lt;/a&gt;        &lt;a href=&quot;https://colab.research.google.com/github/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb&quot;&gt;            &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open EVA on Colab&quot;/&gt;        &lt;/a&gt;        &lt;a href=&quot;https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg&quot;&gt;            &lt;img alt=&quot;Slack&quot; src=&quot;https://img.shields.io/badge/slack-eva-ff69b4.svg?logo=slack&quot;&gt;        &lt;/a&gt;            &lt;a href=&quot;https://github.com/georgia-tech-db/eva/discussions&quot;&gt;            &lt;img alt=&quot;Discuss on Github!&quot; src=&quot;https://img.shields.io/badge/-Discuss%20on%20Github!-blueviolet&quot;&gt;        &lt;/a&gt;        &lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/evadb.svg&quot;/&gt;        &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?logo=apache&quot;/&gt;        &lt;img alt=&quot;Python Versions&quot; src=&quot;https://img.shields.io/badge/Python--versions-3.7%20|%203.8%20|%203.9%20|%203.10-brightgreen&quot;/&gt;    &lt;/div&gt;&lt;/div&gt;# EVA AI-Relational Database System- â¡ï¸ 10-100x faster AI pipelines using SQL-like queries - ð° Save money spent on GPU-driven inference- ð¦ Built-in caching to avoid re-running deep learning models across queries- ð Over 20 AI-centric query optimization rules- â¨ï¸ First-party integrations for PyTorch and HuggingFace models- ð Installable via pip- ð¤ Fully implemented in PythonEVA is an open-source **AI-relational database with first-class support for deep learning models**. It supports next-generation AI-powered database applications that operate on structured (tables) and unstructured data (videos, text, podcasts, PDFs, etc.) with deep learning models.EVA accelerates AI pipelines by 10-100x using a collection of optimizations inspired by relational database systems, including function caching, sampling, and cost-based predicate reordering. It comes with a wide range of models for analyzing unstructured data, including models for image classification, object detection, OCR, text sentiment classification, face detection, etc. It is fully implemented in Python and licensed under the Apache license.EVA supports an AI-oriented query language tailored for analyzing unstructured data. Here are some illustrative applications: * &lt;a href=&quot;https://evadb.readthedocs.io/en/stable/source/tutorials/03-emotion-analysis.html&quot;&gt;Examining the emotion palette of actors in a movie&lt;/a&gt; * &lt;a href=&quot;https://evadb.readthedocs.io/en/stable/source/tutorials/02-object-detection.html&quot;&gt;Analysing traffic flow at an intersection &lt;/a&gt; * &lt;a href=&quot;https://evadb.readthedocs.io/en/stable/source/tutorials/01-mnist.html&quot;&gt;Classifying images based on their content&lt;/a&gt; * &lt;a href=&quot;https://github.com/georgia-tech-db/license-plate-recognition&quot;&gt;Recognizing license plates &lt;/a&gt; * &lt;a href=&quot;https://github.com/georgia-tech-db/toxicity-classification&quot;&gt;Analysing toxicity of social media memes &lt;/a&gt;If you are wondering why you might need an AI-relational database system, start with the page on &lt;a href=&quot;https://evadb.readthedocs.io/en/stable/source/overview/video.html#&quot;&gt;Video Database Systems&lt;/a&gt;. It describes how EVA lets you easily use deep learning models and save money spent on GPU-driven inference on large image or video datasets.The &lt;a href=&quot;https://evadb.readthedocs.io/en/stable/source/overview/installation.html&quot;&gt;Getting Started&lt;/a&gt; page shows how you can use EVA for different computer vision tasks: image classification, object detection, action recognition, and how you can easily extend EVA to support your custom deep learning model in the form of user-defined functions.The &lt;a href=&quot;https://evadb.readthedocs.io/en/stable/source/tutorials/index.html&quot;&gt;User Guides&lt;/a&gt; section contains Jupyter Notebooks that demonstrate how to use various features of EVA. Each notebook includes a link to Google Colab to run the code.## Why EVA? ##&lt;details&gt;  &lt;summary&gt;&lt;b&gt;Easily combine SQL and Deep Learning to build next-generation database applications&lt;/b&gt;&lt;/summary&gt;  Easily query videos in user-facing applications with a SQL-like interface for commonly used computer vision models.&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;&lt;b&gt;Speed up queries and save money spent on model inference&lt;/b&gt;&lt;/summary&gt;  EVA has built-in sampling, caching, and filtering optimizations inspired by time-tested relational database systems.&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;&lt;b&gt;Extensible by design to support custom deep learning models &lt;/b&gt;&lt;/summary&gt;  EVA has first-class support for user-defined functions that wrap around your deep learning models in PyTorch and HuggingFace.&lt;/details&gt;## Links* [Documentation](https://evadb.readthedocs.io/)* [Tutorials](https://github.com/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb)* [Join Slack](https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg)* [Demo](https://ada-00.cc.gatech.edu/eva/playground)## Quick Start- Install EVA using the pip package manager. EVA supports Python versions 3.7+.```shellpip install evadb```- To start and connect to an EVA server in a Jupyter notebook, check out this [illustrative emotion analysis notebook](https://github.com/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb):```shellcursor = connect_to_server()```- Load a video onto the EVA server (we use [ua_detrac.mp4](data/ua_detrac/ua_detrac.mp4) for illustration):```mysqlLOAD VIDEO &quot;data/ua_detrac/ua_detrac.mp4&quot; INTO UADETRAC;```- That's it! You can now run queries over the loaded video:```mysqlSELECT id, data FROM UADETRAC WHERE id &lt; 5;```- Search for frames in the video that contain a car```mysqlSELECT id, data FROM UADETRAC WHERE ['car'] &lt;@ YoloV5(data).labels;```| Source Video  | Query Result ||---------------|--------------||&lt;img alt=&quot;Source Video&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-input.webp&quot; width=&quot;300&quot;&gt; |&lt;img alt=&quot;Query Result&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-output.webp&quot; width=&quot;300&quot;&gt; |- Search for frames in the video that contain a pedestrian and a car```mysqlSELECT id, data FROM UADETRAC WHERE ['pedestrian', 'car'] &lt;@ YoloV5(data).labels;```- Search for frames with more than three cars```mysqlSELECT id, data FROM UADETRAC WHERE ArrayCount(YoloV5(data).labels, 'car') &gt; 3;```- You can **create a custom user-defined function (UDF)** that wraps around a fine-tuned or off-the-shelf deep learning model:```mysqlCREATE UDF IF NOT EXISTS MyUDFINPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))OUTPUT (labels NDARRAY STR(ANYDIM), bboxes NDARRAY FLOAT32(ANYDIM, 4),        scores NDARRAY FLOAT32(ANYDIM))TYPE  ClassificationIMPL  'eva/udfs/fastrcnn_object_detector.py';```- **Compose multiple user-defined functions in a single query** to accomplish complicated AI pipelines.```mysql   -- Analyse emotions of faces in a video   SELECT id, bbox, EmotionDetector(Crop(data, bbox))    FROM MyVideo JOIN LATERAL UNNEST(FaceDetector(data)) AS Face(bbox, conf)     WHERE id &lt; 15;```- Besides making it easy to write queries for complex AI pipelines, EVA **speeds up query execution using its AI-centric query optimizer**. Two illustrative  optimizations are:   ð¾ **Caching**: EVA automatically caches and reuses previous query results (especially model inference results), eliminating redundant computation and reducing query processing time.   ð¯ **Predicate Reordering**: EVA optimizes the order in which the query predicates are evaluated (e.g., runs the faster, more selective model first), leading to faster queries and lower inference costs.Consider these two exploratory queries on a dataset of dog images:&lt;img align=&quot;right&quot; style=&quot;display:inline;&quot; width=&quot;40%&quot; src=&quot;https://github.com/georgia-tech-db/eva/blob/master/data/assets/eva_performance_comparison.png?raw=true&quot;&gt;&lt;/a&gt;```mysql  -- Query 1: Find all images of black-colored dogs  SELECT id, bbox FROM dogs   JOIN LATERAL UNNEST(YoloV5(data)) AS Obj(label, bbox, score)   WHERE Obj.label = 'dog'     AND Color(Crop(data, bbox)) = 'black';   -- Query 2: Find all Great Danes that are black-colored  SELECT id, bbox FROM dogs   JOIN LATERAL UNNEST(YoloV5(data)) AS Obj(label, bbox, score)   WHERE Obj.label = 'dog'     AND DogBreedClassifier(Crop(data, bbox)) = 'great dane'     AND Color(Crop(data, bbox)) = 'black';```By reusing the results of the first query and reordering the predicates based on available cached results, EVA runs up the second query **10x faster**!## Illustrative EVA Applications ### Traffic Analysis (Object Detection Model)| Source Video  | Query Result ||---------------|--------------||&lt;img alt=&quot;Source Video&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-input.webp&quot; width=&quot;300&quot;&gt; |&lt;img alt=&quot;Query Result&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-output.webp&quot; width=&quot;300&quot;&gt; |### MNIST Digit Recognition (Image Classification Model)| Source Video  | Query Result ||---------------|--------------||&lt;img alt=&quot;Source Video&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/mnist-input.webp&quot; width=&quot;150&quot;&gt; |&lt;img alt=&quot;Query Result&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/mnist-output.webp&quot; width=&quot;150&quot;&gt; |### Movie Analysis (Face Detection + Emotion Classfication Models)| Source Video  | Query Result ||---------------|--------------||&lt;img alt=&quot;Source Video&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/gangubai-input.webp&quot; width=&quot;400&quot;&gt; |&lt;img alt=&quot;Query Result&quot; src=&quot;https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/gangubai-output.webp&quot; width=&quot;400&quot;&gt; |### [License Plate Recognition](https://github.com/georgia-tech-db/eva-application-template) (Plate Detection + OCR Extraction Models)| Query Result ||--------------|&lt;img alt=&quot;Query Result&quot; src=&quot;https://github.com/georgia-tech-db/license-plate-recognition/blob/main/README_files/README_12_3.png&quot; width=&quot;300&quot;&gt; |### [Meme Toxicity Classification](https://github.com/georgia-tech-db/toxicity-classification) (OCR Extraction + Toxicity Classification Models)| Query Result ||--------------|&lt;img alt=&quot;Query Result&quot; src=&quot;https://raw.githubusercontent.com/georgia-tech-db/toxicity-classification/main/README_files/README_16_2.png&quot; width=&quot;200&quot;&gt; |## CommunityJoin the EVA community on [Slack](https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg) to ask questions and to share your ideas for improving EVA.&lt;a href=&quot;https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg&quot;&gt;                  &lt;img src=&quot;https://raw.githubusercontent.com/georgia-tech-db/eva/master/docs/images/eva/eva-slack.png&quot; alt=&quot;EVA Slack Channel&quot; width=&quot;500&quot;&gt;&lt;/a&gt;### Architecture Diagram of EVA&lt;img src=&quot;https://raw.githubusercontent.com/georgia-tech-db/eva/master/docs/images/eva/eva-arch.png&quot; alt=&quot;EVA Architecture Diagram&quot; width=&quot;500&quot;&gt;## Contributing to EVA[![PyPI Version](https://img.shields.io/pypi/v/evadb.svg)](https://pypi.org/project/evadb)[![CI Status](https://circleci.com/gh/georgia-tech-db/eva.svg?style=svg)](https://circleci.com/gh/georgia-tech-db/eva)[![Coverage Status](https://coveralls.io/repos/github/georgia-tech-db/eva/badge.svg?branch=master)](https://coveralls.io/github/georgia-tech-db/eva?branch=master)[![Documentation Status](https://readthedocs.org/projects/evadb/badge/?version=stable)](https://evadb.readthedocs.io/en/stable/index.html)EVA is the beneficiary of many [contributors](https://github.com/georgia-tech-db/eva/graphs/contributors). All kinds of contributions to EVA are appreciated. To file a bug or to request a feature, please use &lt;a href=&quot;https://github.com/georgia-tech-db/eva/issues&quot;&gt;GitHub issues&lt;/a&gt;. &lt;a href=&quot;https://github.com/georgia-tech-db/eva/pulls&quot;&gt;Pull requests&lt;/a&gt; are welcome.For more information, see our[contribution guide](https://evadb.readthedocs.io/en/stable/source/contribute/index.html).## LicenseCopyright (c) 2018-2023 [Georgia Tech Database Group](http://db.cc.gatech.edu/).Licensed under [Apache License](LICENSE).</longdescription>
</pkgmetadata>