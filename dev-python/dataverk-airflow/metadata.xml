<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Dataverk airflowEnkelt wrapperbibliotek rundt [KubernetesPodOperator](https://airflow.apache.org/docs/stable/kubernetes.html) som lager Airflow task som kjører i en Kubernetes pod.## Våre operatorsAlle våre operators lar deg klone et annet repo enn der DAGene er definert, bare legg det til med `repo=&quot;navikt/&lt;repo&gt;`.Vi har også støtte for å installere Python pakker ved oppstart av Airflow task, spesifiser `requirements.txt`-filen din med `requirements_path=&quot;/path/to/requirements.txt&quot;`.Merk at hvis du kombinerer `repo` og `requirements_path`, må `requirements.txt` ligge i repoet nevnt i `repo`.### Quarto operatorDenne kjører Quarto render for deg.Man finner Quarto-token for ditt teamet i [Datamarkedsplassen](https://data.intern.nav.no/user/tokens). I eksempelt under lagrere vi tokenet i en Airflow variable som så brukes i DAG tasken under.Se offisiell [Airflow dokumentasjon](https://airflow.apache.org/docs/apache-airflow/stable/howto/variable.html) for hvordan man bruker `Variable.get()´ i en task.```pythonfrom airflow import DAGfrom airflow.utils.dates import days_agofrom airflow.models import Variablefrom dataverk_airflow import quarto_operatorwith DAG('navn-dag', start_date=days_ago(1), schedule_interval=&quot;*/10 * * * *&quot;) as dag:    t1 = quarto_operator(dag=dag,                         name=&quot;&lt;navn-på-task&gt;&quot;,                         repo=&quot;navikt/&lt;repo&gt;&quot;,                         quarto={                             &quot;path&quot;: &quot;/path/to/index.qmd&quot;,                             &quot;env&quot;: &quot;dev/prod&quot;,                             &quot;id&quot;:&quot;uuid&quot;,                             &quot;token&quot;: Variable.get(&quot;quarto_token&quot;),                         },                         slack_channel=&quot;&lt;#slack-alarm-kanal&gt;&quot;)```### Notebook operatorDenne lar deg kjøre en Jupyter notebook.```pythonfrom airflow import DAGfrom airflow.utils.dates import days_agofrom dataverk_airflow import notebook_operatorwith DAG('navn-dag', start_date=days_ago(1), schedule_interval=&quot;*/10 * * * *&quot;) as dag:    t1 = notebook_operator(dag=dag,                           name=&quot;&lt;navn-på-task&gt;&quot;,                           repo=&quot;navikt/&lt;repo&gt;&quot;,                           nb_path=&quot;/path/to/notebook.ipynb&quot;,                           slack_channel=&quot;&lt;#slack-alarm-kanal&gt;&quot;)```### Python operatorDenne lar deg kjøre vilkårlig Python-scripts.```pythonfrom airflow import DAGfrom airflow.utils.dates import days_agofrom dataverk_airflow import python_operatorwith DAG('navn-dag', start_date=days_ago(1), schedule_interval=&quot;*/10 * * * *&quot;) as dag:    t1 = python_operator(dag=dag,                         name=&quot;&lt;navn-på-task&gt;&quot;,                         repo=&quot;navikt/&lt;repo&gt;&quot;,                         script_path=&quot;/path/to/script.py&quot;,                         slack_channel=&quot;&lt;#slack-alarm-kanal&gt;&quot;)```### Kubernetes operatorVi tilbyr også vår egen Kubernetes operator som kloner et valg repo inn i containeren.```pythonfrom airflow import DAGfrom airflow.utils.dates import days_agofrom dataverk_airflow import kubernetes_operatorwith DAG('navn-dag', start_date=days_ago(1), schedule_interval=&quot;*/10 * * * *&quot;) as dag:    t1 = kubernetes_operator(dag=dag,                             name=&quot;&lt;navn-på-task&gt;&quot;,                             repo=&quot;navikt/&lt;repo&gt;&quot;,                             cmds=[&quot;/path/to/bin/&quot;, &quot;script-name.sh&quot;, &quot;argument1&quot;, &quot;argument2&quot;],                             image=&quot;europe-north1-docker.pkg.dev/nais-management-233d/ditt-team/ditt-image:din-tag&quot;,                             slack_channel=&quot;&lt;#slack-alarm-kanal&gt;&quot;)```Denne operatoren har støtte for to ekstra flagg som ikke er tilgjengelig fra de andre.```cmds: str: Command to run in podworking_dir: str: Path to working directory```### Allow listAlle operators støtter å sette allow list, men det er noen adresser som blir lagt til av Dataverk Airflow.Hvis du bruker `slack_channel` argumentet, vil vi legge til:- slack.comHvis du bruker `email` argumentet, vil vi legge til:- Riktig SMTP-adresseHvis du bruker `requirements_path` argumentet, vil vi legge til:- pypi.org- files.pythonhosted.org- pypi.python.orgFor `quarto_operator` vil vi legge til:- Adressen til riktig Datamarkedsplass- cdnjs.cloudflare.com### Felles argumenterAlle operatorene våre har støtte for disse argumentene i funksjonskallet.```dag: DAG: owner DAGname: str: Name of taskrepo: str: Github repoimage: str: Dockerimage the pod should usebranch: str: Branch in repo, default &quot;main&quot;email: str: Email of ownerslack_channel: str: Name of Slack channel, default None (no Slack notification)extra_envs: dict: dict with environment variables example: {&quot;key&quot;: &quot;value&quot;, &quot;key2&quot;: &quot;value2&quot;}allowlist: list: list of hosts and port the task needs to reach on the format host:portrequirements_path: bool: Path (including filename) to your requirements.txtresources: dict: Specify required cpu and memory requirements (keys in dict: request_memory, request_cpu, limit_memory, limit_cpu), default Nonestartup_timeout_seconds: int: pod startup timeoutretries: int: Number of retries for task before DAG fails, default 3delete_on_finish: bool: Whether to delete pod on completionretry_delay: timedelta: Time inbetween retries, default 5 secondsdo_xcom_push: bool: Enable xcom push of content in file &quot;/airflow/xcom/return.json&quot;, default Falseon_success_callback:: func: a function to be called when a task instance of this task succeeds```## Sette resource requirementsVi har støtte for å sette `requests` og `limits` for hver operator.Merk at man ikke trenger å sette `limits` på CPU da dette blir automatisk løst av plattformen.Ved å bruke `ephemeral-storage` kan man be om ekstra diskplass for lagring i en task.```pythonfrom airflow import DAGfrom airflow.utils.dates import days_agofrom dataverk_airflow import python_operatorwith DAG('navn-dag', start_date=days_ago(1), schedule_interval=&quot;*/10 * * * *&quot;) as dag:    t1 = python_operator(dag=dag,                         name=&quot;&lt;navn-på-task&gt;&quot;,                         repo=&quot;navikt/&lt;repo&gt;&quot;,                         script_path=&quot;/path/to/script.py&quot;,                         resources={                             &quot;requests&quot;: {                                 &quot;memory&quot;: &quot;50Mi&quot;,                                 &quot;cpu&quot;: &quot;100m&quot;,                                 &quot;ephemeral-storage&quot;: &quot;1Gi&quot;                             },                             &quot;limits&quot;: {                                 &quot;memory&quot;: &quot;100Mi&quot;                             }                         })```</longdescription>
</pkgmetadata>