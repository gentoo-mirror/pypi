<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>### Chronon Python API#### OverviewChronon Python API for materializing configs to be run by the Chronon Engine. Contains python helpers to help managed a repo of feature and join definitions to be executed by the chronon scala engine.#### User API Overview##### SourcesMost fields are self explanatory. Time columns are expected to be in milliseconds (unixtime).```python# File &lt;repo&gt;/sources/test_sources.pyfrom ai.chronon.query import (  Query,  select,)from ai.chronon.api.ttypes import Source, EventSource, EntitySource# Sample queryQuery(  selects=select(      user=&quot;user_id&quot;,      created_at=&quot;created_at&quot;,  ),  wheres=[&quot;has_availability = 1&quot;],  start_partition=&quot;2021-01-01&quot;,  # Defines the beginning of time for computations related to the source.  setups=[&quot;...UDF...&quot;],  time_column=&quot;ts&quot;,  end_partition=None,  mutation_time_column=&quot;mutation_timestamp&quot;,  reversal_column=&quot;CASE WHEN mutation_type IN ('DELETE', 'UPDATE_BEFORE') THEN true ELSE false END&quot;)user_activity = Source(entities=EntitySource(  snapshotTable=&quot;db_exports.table&quot;,  mutationTable=&quot;mutations_namespace.table_mutations&quot;,  mutationTopic=&quot;mutationsKafkaTopic&quot;,  query=Query(...))website__views = Source(events=EventSource(  table=&quot;namespace.table&quot;,  topic=&quot;kafkaTopicForEvents&quot;,)```##### Group By (Features)Group Bys are aggregations over sources that define features. For example:```python# File &lt;repo&gt;/group_bys/example_team/example_group_by.pyfrom ai.chronon.group_by import (  GroupBy,  Window,  TimeUnit,  Accuracy,  Operation,  Aggregations,  Aggregation,  DefaultAggregation,)from sources import test_sourcessum_cols = [f&quot;active_{x}_days&quot; for x in [30, 90, 120]]v0 = GroupBy(  sources=test_source.user_activity,  keys=[&quot;user&quot;],  aggregations=Aggregations(    user_active_1_day=Aggregation(operation=Operation.LAST),    second_feature=Aggregation(      input_column=&quot;active_7_days&quot;,      operation=Operation.SUM,      windows=[        Window(n, TimeUnit.DAYS) for n in [3, 5, 9]      ]    ),  ) + [    Aggregation(      input_column=col,      operation=Operation.SUM    ) for col in sum_columns           # Alternative syntax for defining aggregations.  ] + [    Aggregation(      input_column=&quot;device&quot;,      operation=LAST_K(10)    )  ],  dependencies=[    &quot;db_exports.table/ds={{ ds }}&quot;      # If not defined will be derived from the Source info.  ],  accuracy=Accuracy.SNAPSHOT,          # This could be TEMPORAL for point in time correctness.  env={    &quot;backfill&quot;: {                      # Execution environment variables for each of the modes for `run.py`      &quot;EXECUTOR_MEMORY&quot;: &quot;4G&quot;     },  },  online=True,                         # True if this group by needs to be uploaded to a KV Store.  production=False                     # True if this group by is production level.)```##### JoinA Join is a collection of feature values for the keys and (times if applicable) defined on the left (source). Example:```python# File &lt;repo&gt;/joins/example_team/example_join.pyfrom ai.chronon.join import Join, JoinPartfrom sources import test_sourcesfrom group_bys.example_team import example_group_byv1 = Join(    left=test_sources.website__views,    right_parts=[        JoinPart(group_by=example_group_by.v0),    ],    online=True,       # True if this join will be fetched in production.    production=False,  # True if this join should not use non-production group bys.    env={&quot;backfill&quot;: {&quot;PARALLELISM&quot;: &quot;10&quot;}, &quot;streaming&quot;: {&quot;STREAMING_ENV_VAR&quot;: &quot;VALUE&quot;}},)```</longdescription>
</pkgmetadata>