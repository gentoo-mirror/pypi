<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># ChunkDotMulti-threaded matrix multiplication and cosine similarity calculations for dense and sparse matrices. Appropriate for calculating the K most similar items for a large number of items by chunking the item matrix representation (embeddings) and using Numba to accelerate the calculations.## Related blog posts- [Cosine Similarity for 1 Trillion Pairs of Vectors](https://pub.towardsai.net/cosine-similarity-for-1-trillion-pairs-of-vectors-11f6a1ed6458)- [Bulk Similarity Calculations for Sparse Embeddings](https://pub.towardsai.net/scale-up-bulk-similarity-calculations-for-sparse-embeddings-fb3ecb624727)## Usage```bashpip install -U chunkdot```### Dense embeddingsCalculate the 50 most similar and dissimilar items for 100K items.```pythonimport numpy as npfrom chunkdot import cosine_similarity_top_kembeddings = np.random.randn(100000, 256)# using all you system's memorycosine_similarity_top_k(embeddings, top_k=50)# most dissimilar items using 20GBcosine_similarity_top_k(embeddings, top_k=-50, max_memory=20E9)``````&lt;100000x100000 sparse matrix of type '&lt;class 'numpy.float64'&gt;' with 5000000 stored elements in Compressed Sparse Row format&gt;``````python# with progress barcosine_similarity_top_k(embeddings, top_k=50, show_progress=True)``````100%|███████████████████████████████████████████████████████████████| 129.0/129 [01:04&lt;00:00,  1.80it/s]&lt;100000x100000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'  with 5000000 stored elements in Compressed Sparse Row format&gt;```Execution time```pythonfrom timeit import timeitimport numpy as npfrom chunkdot import cosine_similarity_top_kembeddings = np.random.randn(100000, 256)timeit(lambda: cosine_similarity_top_k(embeddings, top_k=50, max_memory=20E9), number=1)``````58.611996899999994```### Sparse embeddingsCalculate the 50 most similar and dissimilar items for 100K items. Items represented by 10K dimensional vectors and an embeddings matrix of 0.005 density.```pythonfrom scipy import sparsefrom chunkdot import cosine_similarity_top_kembeddings = sparse.rand(100000, 10000, density=0.005)# using all you system's memorycosine_similarity_top_k(embeddings, top_k=50)# most dissimilar items using 20GBcosine_similarity_top_k(embeddings, top_k=-50, max_memory=20E9)``````&lt;100000x100000 sparse matrix of type '&lt;class 'numpy.float64'&gt;' with 5000000 stored elements in Compressed Sparse Row format&gt;```Execution time```pythonfrom timeit import timeitfrom scipy import sparsefrom chunkdot import cosine_similarity_top_kembeddings = sparse.rand(100000, 10000, density=0.005)timeit(lambda: cosine_similarity_top_k(embeddings, top_k=50, max_memory=20E9), number=1)``````51.87472256699999```</longdescription>
</pkgmetadata>