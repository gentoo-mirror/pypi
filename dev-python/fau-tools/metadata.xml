<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>## IntroductionThis is an individual module, which is mainly for **pytorch CNN** training.Moreover, it also supports some awesome features: saving model, saving training process, plotting figures and so on...## Install`pip install fau-tools`## Usage### importThe following code is recommended.```pythonimport fau_tools```### quick startThe tutor will use a simple example to help you get started quickly!**The following example uses Fau-tools to train a model in MNIST hand-written digits dataset.**```pythonimport torchimport torch.nn as nnimport torch.utils.data as tdataimport torchvisionimport fau_tools# A simple CNN networkclass CNN(nn.Module):  def __init__(self):    super().__init__()    self.conv = nn.Sequential(      nn.Conv2d(1, 16, 3, 1, 1),  # -&gt; (16, 28, 28)      nn.ReLU(),      nn.MaxPool2d(2),  # -&gt; (16, 14, 14)      nn.Conv2d(16, 32, 3, 1, 1),  # -&gt; (32, 14, 14)      nn.ReLU(),      nn.MaxPool2d(2)  # -&gt; (32, 7, 7)    )    self.output = nn.Linear(32 * 7 * 7, 10)  def forward(self, x):    x = self.conv(x)    x = x.flatten(1)  # same as x = x.view(x.size(0), -1)    return self.output(x)# Hyper Parameters definitiontotal_epoch = 10lr = 1E-2batch_size = 1024# Load datasettrain_data      = torchvision.datasets.MNIST('datasets', True, torchvision.transforms.ToTensor(), download=True)test_data       = torchvision.datasets.MNIST('datasets', False, torchvision.transforms.ToTensor())train_data.data = train_data.data[:6000]  # mini datatest_data.data  = test_data.data[:2000]  # mini data# Get data loadertrain_loader = tdata.DataLoader(train_data, batch_size, True)test_loader  = tdata.DataLoader(test_data, batch_size)# Initialize model, optimizer and loss functionmodel = CNN()loss_function = nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters(), lr)# Train!fau_tools.TaskRunner(model, train_loader, test_loader, loss_function, optimizer, total_epoch, exp_path=&quot;MNIST&quot;).train()```Now, we can run the python file, and the training process will be visualized, just like the following picture.![training_visualization](github_attachment/training_visualization.png)&gt; Three files named `best.pth`, `scalars.csv` and `exp_info.txt` will be saved.&gt;&gt; The first file is the trained model.&gt;&gt; The second file records scalar value changes in the training process, which you can use matplotlib to visualize it.&gt;&gt; The third file saves some information about the experiment.---The above is the primary usage of this tool, but there are also some other snazzy features, which will be introduced later.## ENDHope you could like it! And welcome issues and pull requests.</longdescription>
</pkgmetadata>