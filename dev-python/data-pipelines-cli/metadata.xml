<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># data-pipelines-cli[![Python Version](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10-blue.svg)](https://github.com/getindata/data-pipelines-cli)[![PyPI Version](https://badge.fury.io/py/data-pipelines-cli.svg)](https://pypi.org/project/data-pipelines-cli/)[![Downloads](https://pepy.tech/badge/data-pipelines-cli)](https://pepy.tech/project/data-pipelines-cli)[![Maintainability](https://api.codeclimate.com/v1/badges/e44ed9383a42b59984f6/maintainability)](https://codeclimate.com/github/getindata/data-pipelines-cli/maintainability)[![Test Coverage](https://api.codeclimate.com/v1/badges/e44ed9383a42b59984f6/test_coverage)](https://codeclimate.com/github/getindata/data-pipelines-cli/test_coverage)[![Documentation Status](https://readthedocs.org/projects/data-pipelines-cli/badge/?version=latest)](https://data-pipelines-cli.readthedocs.io/en/latest/?badge=latest)CLI for data platform## DocumentationRead the full documentation at [https://data-pipelines-cli.readthedocs.io/](https://data-pipelines-cli.readthedocs.io/en/latest/index.html)## InstallationUse the package manager [pip](https://pip.pypa.io/en/stable/) to install [dp (data-pipelines-cli)](https://pypi.org/project/data-pipelines-cli/):```bashpip install data-pipelines-cli[bigquery,docker,datahub,gcs]```## UsageFirst, create a repository with a global configuration file that you or your organization will be using. The repositoryshould contain `dp.yml.tmpl` file looking similar to this:```yaml_templates_suffix: &quot;.tmpl&quot;_envops:    autoescape: false    block_end_string: &quot;%]&quot;    block_start_string: &quot;[%&quot;    comment_end_string: &quot;#]&quot;    comment_start_string: &quot;[#&quot;    keep_trailing_newline: true    variable_end_string: &quot;]]&quot;    variable_start_string: &quot;[[&quot;templates:  my-first-template:    template_name: my-first-template    template_path: https://github.com/&lt;YOUR_USERNAME&gt;/&lt;YOUR_TEMPLATE&gt;.gitvars:  username: [[ YOUR_USERNAME ]]```Thanks to the [copier](https://copier.readthedocs.io/en/stable/), you can leverage tmpl template syntax to createeasily modifiable configuration templates. Just create a `copier.yml` file next to the `dp.yml.tmpl` one and configurethe template questions (read more at [copier documentation](https://copier.readthedocs.io/en/stable/configuring/)).Then, run `dp init &lt;CONFIG_REPOSITORY_URL&gt;` to initialize **dp**. You can also drop `&lt;CONFIG_REPOSITORY_URL&gt;` argument,**dp** will get initialized with an empty config.### Project creationYou can use `dp create &lt;NEW_PROJECT_PATH&gt;` to choose one of the templates added before and create the project in the`&lt;NEW_PROJECT_PATH&gt;` directory. You can also use `dp create &lt;NEW_PROJECT_PATH&gt; &lt;LINK_TO_TEMPLATE_REPOSITORY&gt;` to pointdirectly to a template repository. If `&lt;LINK_TO_TEMPLATE_REPOSITORY&gt;` proves to be the name of the template defined in**dp**'s config file, `dp create` will choose the template by the name instead of trying to download the repository.`dp template-list` lists all added templates.### Project updateTo update your pipeline project use `dp update &lt;PIPELINE_PROJECT-PATH&gt;`. It will sync your existing project with updatedtemplate version selected by `--vcs-ref` option (default `HEAD`).### Project deployment`dp deploy` will sync with your bucket provider. The provider will be chosen automatically based on the remote URL.Usually, it is worth pointing `dp deploy` to JSON or YAML file with provider-specific data like access tokens or projectnames. E.g., to connect with Google Cloud Storage, one should run:```bashecho '{&quot;token&quot;: &quot;&lt;PATH_TO_YOUR_TOKEN&gt;&quot;, &quot;project_name&quot;: &quot;&lt;YOUR_PROJECT_NAME&gt;&quot;}' &gt; gs_args.jsondp deploy --dags-path &quot;gs://&lt;YOUR_GS_PATH&gt;&quot; --blob-args gs_args.json```However, in some cases you do not need to do so, e.g. when using `gcloud` with properly set local credentials. In suchcase, you can try to run just the `dp deploy --dags-path &quot;gs://&lt;YOUR_GS_PATH&gt;&quot;` command. Please refer to[documentation](https://data-pipelines-cli.readthedocs.io/en/latest/usage.html#project-deployment) for more information.When finished, call `dp clean` to remove compilation related directories.### VariablesYou can put a dictionary of variables to be passed to `dbt` in your `config/&lt;ENV&gt;/dbt.yml` file, following the conventionpresented in [the guide at the dbt site](https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-variables#defining-variables-in-dbt_projectyml).E.g., if one of the fields of `config/&lt;SNOWFLAKE_ENV&gt;/snowflake.yml` looks like this:```yamlschema: &quot;{{ var('snowflake_schema') }}&quot;```you should put the following in your `config/&lt;SNOWFLAKE_ENV&gt;/dbt.yml` file:```yamlvars:  snowflake_schema: EXAMPLE_SCHEMA```and then run your `dp run --env &lt;SNOWFLAKE_ENV&gt;` (or any similar command).## ContributingPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.Please make sure to update tests as appropriate.</longdescription>
</pkgmetadata>