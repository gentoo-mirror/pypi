<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;&lt;h1 align=&quot;center&quot;&gt;  &lt;a target=&quot;_blank&quot; href=&quot;https://dstack.ai&quot;&gt;    &lt;img alt=&quot;dstack&quot; src=&quot;https://raw.githubusercontent.com/dstackai/dstack/master/docs/assets/logo.svg&quot; width=&quot;400px&quot;/&gt;  &lt;/a&gt;&lt;/h1&gt;&lt;h4 align=&quot;center&quot;&gt;ML workflows as code&lt;/h4&gt;&lt;p align=&quot;center&quot;&gt;The easiest way to define ML workflows and run them on any cloud platform &lt;/p&gt;[![Slack](https://img.shields.io/badge/slack-join%20chat-blueviolet?logo=slack&amp;style=for-the-badge)](https://join.slack.com/t/dstackai/shared_invite/zt-xdnsytie-D4qU9BvJP8vkbkHXdi6clQ)&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://dstack.ai/docs/quick-start&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;Quick start&lt;/b&gt;&lt;/a&gt; • &lt;a href=&quot;https://dstack.ai/docs&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;Docs&lt;/b&gt;&lt;/a&gt; • &lt;a href=&quot;https://dstack.ai/tutorials/dolly&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;Tutorials&lt;/b&gt;&lt;/a&gt; •&lt;a href=&quot;https://dstack.ai/blog&quot; target=&quot;_blank&quot;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;[![Last commit](https://img.shields.io/github/last-commit/dstackai/dstack)](https://github.com/dstackai/dstack/commits/)[![PyPI - License](https://img.shields.io/pypi/l/dstack?style=flat&amp;color=blue)](https://github.com/dstackai/dstack/blob/master/LICENSE.md)&lt;/div&gt;## What is dstack?`dstack` makes it very easy to define ML workflowsand run them on any cloud platform. It provisions infrastructure,manages data, and monitors usage for you.Ideal for processing data, training models, running apps, and any other ML development tasks.## Install the CLIUse `pip` to install `dstack`:```shellpip install dstack```## Define workflowsDefine ML workflows, their output artifacts, hardware requirements, and dependencies via YAML.```yamlworkflows:  - name: train-mnist    provider: bash    commands:      - pip install torchvision pytorch-lightning tensorboard      - python examples/mnist/train_mnist.py    artifacts:      - path: ./lightning_logs```## Run locallyBy default, workflows run locally on your machine.```shelldstack run train-mnistRUN        WORKFLOW     SUBMITTED  STATUS     TAG  BACKENDSpenguin-1  train-mnist  now        Submitted       localProvisioning... It may take up to a minute. ✓To interrupt, press Ctrl+C.GPU available: True, used: TrueEpoch 1: [00:03&lt;00:00, 280.17it/s, loss=1.35, v_num=0]```## Run remotelyTo run workflows remotely in a configured cloud, you will need the Hub application, which can be installed either on adedicated server for team work or directly on your local machine.### Start the Hub applicationTo start the Hub application, use this command:&lt;div class=&quot;termy&quot;&gt;```shell$ dstack hub startThe hub is available at http://127.0.0.1:3000?token=b934d226-e24a-4eab-a284-eb92b353b10f```&lt;/div&gt;To login as an administrator, visit the URL in the output.### Create a projectGo ahead and create a new project.&lt;img src=&quot;https://dstack.ai/assets/dstack_hub_create_project.png&quot; width=&quot;800px&quot;/&gt;Choose a backend type (such as AWS or GCP), provide cloud credentials, and specify settings likeartifact storage bucket and the region where to run workflows.&lt;img src=&quot;https://dstack.ai/assets/dstack_hub_view_project.png&quot; width=&quot;800px&quot;/&gt;### Configure the CLICopy the CLI command from the project settings and execute it in your terminal to configure the project as a remote.&lt;div class=&quot;termy&quot;&gt;```shell$ dstack config hub --url http://127.0.0.1:3000 \  --project my-awesome-project \  --token b934d226-e24a-4eab-a284-eb92b353b10f```&lt;/div&gt;Now, you can run workflows remotely in the created project by adding the `--remote` flag to the `dstack run` commandand request hardware [`resources`](usage/resources.md) (like GPU, memory, interruptible instances, etc.) that you need.```shelldstack run train-mnist --remote --gpu 1RUN       WORKFLOW     SUBMITTED  STATUS     TAG  BACKENDSturtle-1  train-mnist  now        Submitted       awsProvisioning... It may take up to a minute. ✓To interrupt, press Ctrl+C.GPU available: True, used: TrueEpoch 1: [00:03&lt;00:00, 280.17it/s, loss=1.35, v_num=0]```The command will automatically provision the required cloud resources in the corresponding cloud upon workflow startup and tear them down upon completion.## More informationFor additional information and examples, see the following links:* [Quick start](https://dstack.ai/docs/quick-start)* [Docs](https://dstack.ai/docs)* [Tutorials](https://dstack.ai/tutorials/dolly)* [Blog](https://dstack.ai/blog) ##  Licence[Mozilla Public License 2.0](LICENSE.md)</longdescription>
</pkgmetadata>