<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># AlignedAligned helps improving ML system visibility, while also reducing technical, and data debt, as described in [Sculley et al. [2015]](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf).Want to look at examples of how to use `aligned`?View the [`MatsMoll/aligned-example` repo](https://github.com/MatsMoll/aligned-example).This is done by providing an new innovative way of describing feature transformations, and data flow in ML systems. While also collecting dependency metadata that would otherwise be too inconvenient and error prone to manually type out.Therefore, you get the following:- [Data Freshness](#data-freshness)- [Feature Store](https://matsmoll.github.io/posts/understanding-the-chaotic-landscape-of-mlops#feature-store)- [Feature Server](#feature-server)- [Stream Processing](#stream-worker)- Model Performance Monitoring - Documentation coming soon- Data Catalog - Documentation coming soon- Data Lineage - Documentation coming soon- [Data Quality Assurance](#data-quality)- [Easy Data Loading](#access-data)- [Load Form Multiple Sources](#fast-development)All from the simple API of defining- [Data Sources](#data-sources)- [Feature Views](#feature-views)- [Models](#describe-models)As a result, loading model features is as easy as:```pythonentities = {&quot;passenger_id&quot;: [1, 2, 3, 4]}await store.model(&quot;titanic&quot;).features_for(entities).to_pandas()```Aligned is still in active development, so changes are likely.## Feature ViewsWrite features as the should be, as data models.Then get code completion and typesafety by referencing them in other features.This makes the features light weight, data source indipendent, and flexible.```python@feature_view(    name=&quot;passenger&quot;,    description=&quot;Some features from the titanic dataset&quot;,    batch_source=FileSource.csv_at(&quot;titanic.csv&quot;),    stream_source=HttpStreamSource(topic_name=&quot;titanic&quot;))class TitanicPassenger:    passenger_id = Int32().as_entity()    age = (        Float()            .description(&quot;A float as some have decimals&quot;)            .is_required()            .lower_bound(0)            .upper_bound(110)    )    name = String()    sex = String().accepted_values([&quot;male&quot;, &quot;female&quot;])    survived = Bool().description(&quot;If the passenger survived&quot;)    sibsp = Int32().lower_bound(0, is_inclusive=True).description(&quot;Number of siblings on titanic&quot;)    cabin = String()    # Creates two one hot encoded values    is_male, is_female = sex.one_hot_encode(['male', 'female'])```## Data sourcesAlinged makes handling data sources easy, as you do not have to think about how it is done.Only define where the data is, and we handle the dirty work.```pythonmy_db = PostgreSQLConfig(env_var=&quot;DATABASE_URL&quot;)redis = RedisConfig(env_var=&quot;REDIS_URL&quot;)@feature_view(    name=&quot;passenger&quot;,    description=&quot;Some features from the titanic dataset&quot;,    batch_source=my_db.table(        &quot;passenger&quot;,        mapping_keys={            &quot;Passenger_Id&quot;: &quot;passenger_id&quot;        }    ),    stream_source=redis.stream(topic=&quot;titanic&quot;))class TitanicPassenger:    passenger_id = Int32().as_entity()    # Some features    ...```### Fast developmentMaking iterativ and fast exploration in ML is important. This is why Aligned also makes it super easy to combine, and test multiple sources.```pythonmy_db = PostgreSQLConfig.localhost()aws_bucket = AwsS3Config(...)@feature_view(    name=&quot;some_features&quot;,    description=&quot;...&quot;,    batch_source=my_db.table(&quot;local_features&quot;))class SomeFeatures:    # Some features    ...@feature_view(    name=&quot;aws&quot;,    description=&quot;...&quot;,    batch_source=aws_bucket.file_at(&quot;path/to/file.parquet&quot;))class AwsFeatures:    # Some features    ...```## Describe ModelsUsually will you need to combine multiple features for each model.This is where a `Model` comes in.Here can you define which features should be exposed.```pythonpassenger = TitanicPassenger()location = LocationFeatures()@model_contract(    name=&quot;titanic&quot;,    features=[ # aka. the model input        passenger.constant_filled_age,        passenger.ordinal_sex,        passenger.sibsp,        location.distance_to_shore,        location.distance_to_closest_boat    ])class Titanic:    # Referencing the passenger's survived feature as the target    did_survive = passenger.survived.as_classification_target()```## Data FreshnessMaking sure a source contains fresh data is a crucial part to create propper ML applications.Therefore, Aligned provides an easy way to check how fresh a source is.```python@feature_view(    name=&quot;departures&quot;,    description=&quot;Features related to the departure of a taxi ride&quot;,    batch_source=taxi_db.table(&quot;departures&quot;),)class TaxiDepartures:    trip_id = UUID().as_entity()    pickuped_at = EventTimestamp()    number_of_passengers = Int32()    dropoff_latitude = Float().is_required()    dropoff_longitude = Float().is_required()    pickup_latitude = Float().is_required()    pickup_longitude = Float().is_required()freshness = await TaxiDepartures.freshness_in_batch_source()if freshness &lt; datetime.now() - timedelta(days=2):    raise ValueError(&quot;To old data to create an ML model&quot;)```## Data EnrichersIn many cases will extra data be needed in order to generate some features.We therefore need some way of enriching the data.This can easily be done with Alinged's `DataEnricher`s.```pythonmy_db = PostgreSQLConfig.localhost()redis = RedisConfig.localhost()user_location = my_db.data_enricher( # Fetch all user locations    sql=&quot;SELECT * FROM user_location&quot;).cache( # Cache them for one day    ttl=timedelta(days=1),    cache_key=&quot;user_location_cache&quot;).lock( # Make sure only one processer fetches the data at a time    lock_name=&quot;user_location_lock&quot;,    redis_config=redis)async def distance_to_users(df: DataFrame) -&gt; Series:    user_location_df = await user_location.load()    ...    return distances@feature_view(...)class SomeFeatures:    latitude = Float()    longitude = Float()    distance_to_users = Float().transformed_using_features_pandas(        [latitude, longitude],        distance_to_users    )```## Access DataYou can easily create a feature store that contains all your feature definitions.This can then be used to genreate data sets, setup an instce to serve features, DAG's etc.```pythonstore = await FileSource.json_at(&quot;./feature-store.json&quot;).feature_store()# Select all features from a single feature viewdf = await store.all_for(&quot;passenger&quot;, limit=100).to_pandas()```### Centraliced Feature Store DefinitionYou would often share the features with other coworkers, or split them into different stages, like `staging`, `shadow`, or `production`.One option is therefore to reference the storage you use, and load the `FeatureStore` from there.```pythonaws_bucket = AwsS3Config(...)store = await aws_bucket.json_at(&quot;production.json&quot;).feature_store()# This switches from the production online store to the offline store# Aka. the batch sources defined on the feature viewsexperimental_store = store.offline_store()```This json file can be generated by running `aligned apply`.### Select multiple feature views```pythondf = await store.features_for({    &quot;passenger_id&quot;: [1, 50, 110]}, features=[    &quot;passenger:scaled_age&quot;,    &quot;passenger:is_male&quot;,    &quot;passenger:sibsp&quot;    &quot;other_features:distance_to_closest_boat&quot;,]).to_polars()```### Model ServiceSelecting features for a model is super simple.```pythondf = await store.model(&quot;titanic_model&quot;).features_for({    &quot;passenger_id&quot;: [1, 50, 110]}).to_pandas()```### Feature ViewIf you want to only select features for a specific feature view, then this is also possible.```pythonprev_30_days = await store.feature_view(&quot;match&quot;).previous(days=30).to_pandas()sample_of_20 = await store.feature_view(&quot;match&quot;).all(limit=20).to_pandas()```## Data qualityAlinged will make sure all the different features gets formatted as the correct datatype.In addition will aligned also make sure that the returend features aligne with defined constraints.```python@feature_view(...)class TitanicPassenger:    ...    age = (        Float()            .is_required()            .lower_bound(0)            .upper_bound(110)    )    sibsp = Int32().lower_bound(0, is_inclusive=True)```Then since our feature view have a `is_required` and a `lower_bound`, will the `.validate(...)` command filter out the entites that do not follow that behavior.```pythonfrom aligned.validation.pandera import PanderaValidatordf = await store.model(&quot;titanic_model&quot;).features_for({    &quot;passenger_id&quot;: [1, 50, 110]}).validate(    PanderaValidator()  # Validates all features).to_pandas()```## Feature ServerYou can define how to serve your features with the `FeatureServer`. Here can you define where you want to load, and potentially write your features to.By default will it `aligned` look for a file called `server.py`, and a `FeatureServer` object called `server`. However, this can be defined manually as well.```pythonfrom aligned import RedisConfig, FileSourcefrom aligned.schemas.repo_definition import FeatureServerstore = FileSource.json_at(&quot;feature-store.json&quot;)server = FeatureServer.from_reference(    store,    RedisConfig.localhost())```Then run `aligned serve`, and a FastAPI server will start. Here can you push new features, which then transforms and stores the features, or just fetch them.## Stream WorkerYou can also setup stream processing with a similar structure. However, here will a `StreamWorker` be used.by default will `aligned` look for a `worker.py` file with an object called `worker`. An example would be the following.```pythonfrom aligned import RedisConfig, FileSourcefrom aligned.schemas.repo_definition import FeatureServerstore = FileSource.json_at(&quot;feature-store.json&quot;)server = FeatureServer.from_reference(    store,    RedisConfig.localhost())```</longdescription>
</pkgmetadata>