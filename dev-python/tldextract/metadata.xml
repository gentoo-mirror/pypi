<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># tldextract [![PyPI version](https://badge.fury.io/py/tldextract.svg)](https://badge.fury.io/py/tldextract) [![Build Status](https://travis-ci.com/john-kurkowski/tldextract.svg?branch=master)](https://app.travis-ci.com/github/john-kurkowski/tldextract)`tldextract` accurately separates a URL's subdomain, domain, and public suffix,using [the Public Suffix List (PSL)](https://publicsuffix.org).Say you want just the &quot;google&quot; part of https://www.google.com. *Everybody getsthis wrong.* Splitting on the &quot;.&quot; and taking the 2nd-to-last element only worksfor simple domains, e.g. .com. Consider[http://forums.bbc.co.uk](http://forums.bbc.co.uk): the naive splitting methodwill give you &quot;co&quot; as the domain, instead of &quot;bbc&quot;. Rather than juggle TLDs,gTLDs, or ccTLDs  yourself, `tldextract` extracts the currently living publicsuffixes according to [the Public Suffix List](https://publicsuffix.org).&gt; A &quot;public suffix&quot; is one under which Internet users can directly register&gt; names.A public suffix is also sometimes called an effective TLD (eTLD).## Usage```python&gt;&gt;&gt; import tldextract&gt;&gt;&gt; tldextract.extract('http://forums.news.cnn.com/')ExtractResult(subdomain='forums.news', domain='cnn', suffix='com', is_private=False)&gt;&gt;&gt; tldextract.extract('http://forums.bbc.co.uk/') # United KingdomExtractResult(subdomain='forums', domain='bbc', suffix='co.uk', is_private=False)&gt;&gt;&gt; tldextract.extract('http://www.worldbank.org.kg/') # KyrgyzstanExtractResult(subdomain='www', domain='worldbank', suffix='org.kg', is_private=False)````ExtractResult` is a namedtuple, so it's simple to access the parts you want.```python&gt;&gt;&gt; ext = tldextract.extract('http://forums.bbc.co.uk')&gt;&gt;&gt; (ext.subdomain, ext.domain, ext.suffix)('forums', 'bbc', 'co.uk')&gt;&gt;&gt; # rejoin subdomain and domain&gt;&gt;&gt; '.'.join(ext[:2])'forums.bbc'&gt;&gt;&gt; # a common alias&gt;&gt;&gt; ext.registered_domain'bbc.co.uk'```Note subdomain and suffix are _optional_. Not all URL-like inputs have asubdomain or a valid suffix.```python&gt;&gt;&gt; tldextract.extract('google.com')ExtractResult(subdomain='', domain='google', suffix='com', is_private=False)&gt;&gt;&gt; tldextract.extract('google.notavalidsuffix')ExtractResult(subdomain='google', domain='notavalidsuffix', suffix='', is_private=False)&gt;&gt;&gt; tldextract.extract('http://127.0.0.1:8080/deployed/')ExtractResult(subdomain='', domain='127.0.0.1', suffix='', is_private=False)```If you want to rejoin the whole namedtuple, regardless of whether a subdomainor suffix were found:```python&gt;&gt;&gt; ext = tldextract.extract('http://127.0.0.1:8080/deployed/')&gt;&gt;&gt; # this has unwanted dots&gt;&gt;&gt; '.'.join(ext[:3])'.127.0.0.1.'&gt;&gt;&gt; # join each part only if it's truthy&gt;&gt;&gt; '.'.join(part for part in ext[:3] if part)'127.0.0.1'```By default, this package supports the public ICANN TLDs and their exceptions.You can optionally support the Public Suffix List's private domains as well.This package started by implementing the chosen answer from [this StackOverflow question ongetting the &quot;domain name&quot; from a URL](http://stackoverflow.com/questions/569137/how-to-get-domain-name-from-url/569219#569219).However, the proposed regex solution doesn't address many country codes likecom.au, or the exceptions to country codes like the registered domainparliament.uk. The Public Suffix List does, and so does this package.## InstallLatest release on PyPI:```zshpip install tldextract```Or the latest dev version:```zshpip install -e 'git://github.com/john-kurkowski/tldextract.git#egg=tldextract'```Command-line usage, splits the URL components by space:```zshtldextract http://forums.bbc.co.uk# forums bbc co.uk```## Note about cachingBeware when first calling `tldextract`, it updates its TLD list with a live HTTPrequest. This updated TLD set is usually cached indefinitely in `$HOME/.cache/python-tldextract`.To control the cache's location, set TLDEXTRACT_CACHE environment variable or set thecache_dir path in TLDExtract initialization.(Arguably runtime bootstrapping like that shouldn't be the default behavior,like for production systems. But I want you to have the latest TLDs, especiallywhen I haven't kept this code up to date.)```python# extract callable that falls back to the included TLD snapshot, no live HTTP fetchingno_fetch_extract = tldextract.TLDExtract(suffix_list_urls=())no_fetch_extract('http://www.google.com')# extract callable that reads/writes the updated TLD set to a different pathcustom_cache_extract = tldextract.TLDExtract(cache_dir='/path/to/your/cache/')custom_cache_extract('http://www.google.com')# extract callable that doesn't use cachingno_cache_extract = tldextract.TLDExtract(cache_dir=None)no_cache_extract('http://www.google.com')```If you want to stay fresh with the TLD definitions--though they don't changeoften--delete the cache file occasionally, or run```zshtldextract --update```or:```zshenv TLDEXTRACT_CACHE=&quot;~/tldextract.cache&quot; tldextract --update```It is also recommended to delete the file after upgrading this lib.## Advanced usage### Public vs. private domainsThe PSL [maintains a concept of &quot;private&quot;domains](https://publicsuffix.org/list/).&gt; PRIVATE domains are amendments submitted by the domain holder, as an&gt; expression of how they operate their domain security policy. â€¦ While some&gt; applications, such as browsers when considering cookie-setting, treat all&gt; entries the same, other applications may wish to treat ICANN domains and&gt; PRIVATE domains differently.By default, `tldextract` treats public and private domains the same.```python&gt;&gt;&gt; extract = tldextract.TLDExtract()&gt;&gt;&gt; extract('waiterrant.blogspot.com')ExtractResult(subdomain='waiterrant', domain='blogspot', suffix='com', is_private=False)```The following overrides this.```python&gt;&gt;&gt; extract = tldextract.TLDExtract()&gt;&gt;&gt; extract('waiterrant.blogspot.com', include_psl_private_domains=True)ExtractResult(subdomain='', domain='waiterrant', suffix='blogspot.com', is_private=True)```or to change the default for all extract calls,```python&gt;&gt;&gt; extract = tldextract.TLDExtract( include_psl_private_domains=True)&gt;&gt;&gt; extract('waiterrant.blogspot.com')ExtractResult(subdomain='', domain='waiterrant', suffix='blogspot.com', is_private=True)```The thinking behind the default is, it's the more common case when peoplementally parse a domain name. It doesn't assume familiarity with the PSL northat the PSL makes a public/private distinction. Note this default may runcounter to the default parsing behavior of other, PSL-based libraries.### Specifying your own URL or file for Public Suffix List dataYou can specify your own input data in place of the default Mozilla Public Suffix List:```pythonextract = tldextract.TLDExtract(    suffix_list_urls=[&quot;http://foo.bar.baz&quot;],    # Recommended: Specify your own cache file, to minimize ambiguities about where    # tldextract is getting its data, or cached data, from.    cache_dir='/path/to/your/cache/',    fallback_to_snapshot=False)```The above snippet will fetch from the URL *you* specified, upon first need to download thesuffix list (i.e. if the cached version doesn't exist).If you want to use input data from your local filesystem, just use the `file://` protocol:```pythonextract = tldextract.TLDExtract(    suffix_list_urls=[&quot;file://absolute/path/to/your/local/suffix/list/file&quot;],    cache_dir='/path/to/your/cache/',    fallback_to_snapshot=False)```Use an absolute path when specifying the `suffix_list_urls` keyword argument.`os.path` is your friend.The command line update command can be used with a URL or local file you specify:```zshtldextract --update --suffix_list_url &quot;http://foo.bar.baz&quot;```This could be useful in production when you don't want the delay associated with updating the suffixlist on first use, or if you are behind a complex firewall that prevents a simple update from working.## FAQ### Can you add suffix \_\_\_\_? Can you make an exception for domain \_\_\_\_?This project doesn't contain an actual list of public suffixes. That comes from[the Public Suffix List (PSL)](https://publicsuffix.org/). Submit amendments there.(In the meantime, you can tell tldextract about your exception by eitherforking the PSL and using your fork in the `suffix_list_urls` param, or addingyour suffix piecemeal with the `extra_suffixes` param.)### I see my suffix in [the Public Suffix List (PSL)](https://publicsuffix.org/), but this library doesn't extract it.Check if your suffix is in the private section of the list. See [thisdocumentation](#public-vs-private-domains).### If I pass an invalid URL, I still get a result, no error. What gives?To keep `tldextract` light in LoC &amp; overhead, and because there are plenty ofURL validators out there, this library is very lenient with input. If validURLs are important to you, validate them before calling `tldextract`.To avoid parsing a string twice, you can pass `tldextract` the output of[`urllib.parse`](https://docs.python.org/3/library/urllib.parse.html) methods.For example:```pyextractor = TLDExtract()split_url = urllib.parse.urlsplit(&quot;https://foo.bar.com:8080&quot;)split_suffix = extractor.extract_urllib(split_url)url_to_crawl = f&quot;{split_url.scheme}://{split_suffix.registered_domain}:{split_url.port}&quot;````tldextract`'s lenient string parsing stance lowers the learning curve of usingthe library, at the cost of desensitizing users to the nuances of URLs. Thiscould be overhauled. For example, users could opt into validation, eitherreceiving exceptions or error metadata on results.## Contribute### Setting up1. `git clone` this repository.2. Change into the new directory.3. `pip install tox`### Running the test suiteRun all tests against all supported Python versions:```zshtox --parallel```Run all tests against a specific Python environment configuration:```zshtox -ltox -e py37```### Code StyleAutomatically format all code:```zshpip install blackblack .```</longdescription>
</pkgmetadata>