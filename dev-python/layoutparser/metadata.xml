<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://github.com/Layout-Parser/layout-parser/raw/main/.github/layout-parser.png&quot; alt=&quot;Layout Parser Logo&quot; width=&quot;35%&quot;&gt;  &lt;h3 align=&quot;center&quot;&gt;  A unified toolkit for Deep Learning Based Document Image Analysis  &lt;/h3&gt;&lt;/p&gt;&lt;p align=center&gt;&lt;a href=&quot;https://pypi.org/project/layoutparser/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/layoutparser?color=%23099cec&amp;label=PyPI%20package&amp;logo=pypi&amp;logoColor=white&quot; title=&quot;The current version of Layout Parser&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Layout-Parser/layout-parser/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/l/layoutparser&quot; title=&quot;Layout Parser uses Apache 2 License&quot;&gt;&lt;/a&gt;&lt;img alt=&quot;PyPI - Downloads&quot; src=&quot;https://img.shields.io/pypi/dm/layoutparser&quot;&gt;&lt;/p&gt;&lt;p align=center&gt;&lt;a href=&quot;https://arxiv.org/abs/2103.15348&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/paper-2103.15348-b31b1b.svg&quot; title=&quot;Layout Parser Paper&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://layout-parser.github.io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/website-layout--parser.github.io-informational.svg&quot; title=&quot;Layout Parser Paper&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://layout-parser.readthedocs.io/en/latest/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/doc-layout--parser.readthedocs.io-light.svg&quot; title=&quot;Layout Parser Documentation&quot;&gt;&lt;/a&gt;&lt;/p&gt;---## What is LayoutParser![Example Usage](https://github.com/Layout-Parser/layout-parser/raw/main/.github/example.png)LayoutParser aims to provide a wide range of tools that aims to streamline Document Image Analysis (DIA) tasks. Please check the LayoutParser [demo video](https://youtu.be/8yA5xB4Dg8c) (1 min) or [full talk](https://www.youtube.com/watch?v=YG0qepPgyGY) (15 min) for details. And here are some key features:- LayoutParser provides a rich repository of deep learning models for layout detection as well as a set of unified APIs for using them. For example,     &lt;details&gt;  &lt;summary&gt;Perform DL layout detection in 4 lines of code&lt;/summary&gt;    ```python  import layoutparser as lp  model = lp.AutoLayoutModel('lp://EfficientDete/PubLayNet')  # image = Image.open(&quot;path/to/image&quot;)  layout = model.detect(image)   ```    &lt;/details&gt;- LayoutParser comes with a set of layout data structures with carefully designed APIs that are optimized for document image analysis tasks. For example,   &lt;details&gt;  &lt;summary&gt;Selecting layout/textual elements in the left column of a page&lt;/summary&gt;    ```python  image_width = image.size[0]  left_column = lp.Interval(0, image_width/2, axis='x')  layout.filter_by(left_column, center=True) # select objects in the left column   ```    &lt;/details&gt;  &lt;details&gt;  &lt;summary&gt;Performing OCR for each detected Layout Region&lt;/summary&gt;    ```python  ocr_agent = lp.TesseractAgent()  for layout_region in layout:       image_segment = layout_region.crop(image)      text = ocr_agent.detect(image_segment)  ```    &lt;/details&gt;        &lt;details&gt;  &lt;summary&gt;Flexible APIs for visualizing the detected layouts&lt;/summary&gt;    ```python  lp.draw_box(image, layout, box_width=1, show_element_id=True, box_alpha=0.25)  ```    &lt;/details&gt;        &lt;/details&gt;        &lt;details&gt;  &lt;summary&gt;Loading layout data stored in json, csv, and even PDFs&lt;/summary&gt;    ```python   layout = lp.load_json(&quot;path/to/json&quot;)  layout = lp.load_csv(&quot;path/to/csv&quot;)  pdf_layout = lp.load_pdf(&quot;path/to/pdf&quot;)  ```    &lt;/details&gt;- LayoutParser is also a open platform that enables the sharing of layout detection models and DIA pipelines among the community.   &lt;details&gt;  &lt;summary&gt;&lt;a href=&quot;https://layout-parser.github.io/platform/&quot;&gt;Check&lt;/a&gt; the LayoutParser open platform&lt;/summary&gt;  &lt;/details&gt;  &lt;details&gt;  &lt;summary&gt;&lt;a href=&quot;https://github.com/Layout-Parser/platform&quot;&gt;Submit&lt;/a&gt; your models/pipelines to LayoutParser&lt;/summary&gt;  &lt;/details&gt;## Installation After several major updates, layoutparser provides various functionalities and deep learning models from different backends. But it still easy to install layoutparser, and we designed the installation method in a way such that you can choose to install only the needed dependencies for your project:```bashpip install layoutparser # Install the base layoutparser library with  pip install &quot;layoutparser[layoutmodels]&quot; # Install DL layout model toolkit pip install &quot;layoutparser[ocr]&quot; # Install OCR toolkit```Extra steps are needed if you want to use Detectron2-based models. Please check [installation.md](installation.md) for additional details on layoutparser installation. ## Examples We provide a series of examples for to help you start using the layout parser library: 1. [Table OCR and Results Parsing](https://github.com/Layout-Parser/layout-parser/blob/main/examples/OCR%20Tables%20and%20Parse%20the%20Output.ipynb): `layoutparser` can be used for conveniently OCR documents and convert the output in to structured data. 2. [Deep Layout Parsing Example](https://github.com/Layout-Parser/layout-parser/blob/main/examples/Deep%20Layout%20Parsing.ipynb): With the help of Deep Learning, `layoutparser` supports the analysis very complex documents and processing of the hierarchical structure in the layouts. ## ContributingWe encourage you to contribute to Layout Parser! Please check out the [Contributing guidelines](.github/CONTRIBUTING.md) for guidelines about how to proceed. Join us!## Citing `layoutparser`If you find `layoutparser` helpful to your work, please consider citing our tool and [paper](https://arxiv.org/pdf/2103.15348.pdf) using the following BibTeX entry.```@article{shen2021layoutparser,  title={LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis},  author={Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},  journal={arXiv preprint arXiv:2103.15348},  year={2021}}```</longdescription>
</pkgmetadata>