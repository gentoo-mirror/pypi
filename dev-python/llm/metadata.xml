<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># LLM[![PyPI](https://img.shields.io/pypi/v/llm.svg)](https://pypi.org/project/llm/)[![Documentation](https://readthedocs.org/projects/llm/badge/?version=latest)](https://llm.datasette.io/)[![Changelog](https://img.shields.io/github/v/release/simonw/llm?include_prereleases&amp;label=changelog)](https://llm.datasette.io/en/stable/changelog.html)[![Tests](https://github.com/simonw/llm/workflows/Test/badge.svg)](https://github.com/simonw/llm/actions?query=workflow%3ATest)[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/simonw/llm/blob/main/LICENSE)[![Discord](https://img.shields.io/discord/823971286308356157?label=discord)](https://datasette.io/discord-llm)[![Homebrew](https://img.shields.io/homebrew/installs/dy/llm?color=yellow&amp;label=homebrew&amp;logo=homebrew)](https://formulae.brew.sh/formula/llm)A CLI utility and Python library for interacting with Large Language Models, both via remote APIs and models that can be installed and run on your own machine.[Run prompts from the command-line](https://llm.datasette.io/en/stable/usage.html#executing-a-prompt), [store the results in SQLite](https://llm.datasette.io/en/stable/logging.html), [generate embeddings](https://llm.datasette.io/en/stable/embeddings/index.html) and more.Full documentation: **[llm.datasette.io](https://llm.datasette.io/)**Background on this project:- [llm, ttok and strip-tagsâ€”CLI tools for working with ChatGPT and other LLMs](https://simonwillison.net/2023/May/18/cli-tools-for-llms/)- [The LLM CLI tool now supports self-hosted language models via plugins](https://simonwillison.net/2023/Jul/12/llm/)- [Accessing Llama 2 from the command-line with the llm-replicate plugin](https://simonwillison.net/2023/Jul/18/accessing-llama-2/)- [Run Llama 2 on your own Mac using LLM and Homebrew](https://simonwillison.net/2023/Aug/1/llama-2-mac/)- [Catching up on the weird world of LLMs](https://simonwillison.net/2023/Aug/3/weird-world-of-llms/)- [LLM now provides tools for working with embeddings](https://simonwillison.net/2023/Sep/4/llm-embeddings/)- [Build an image search engine with llm-clip, chat with models with llm chat](https://simonwillison.net/2023/Sep/12/llm-clip-and-chat/)## InstallationInstall this tool using `pip`:```bashpip install llm```Or using [Homebrew](https://brew.sh/):```bashbrew install llm```[Detailed installation instructions](https://llm.datasette.io/en/stable/setup.html).## Getting startedIf you have an [OpenAI API key](https://platform.openai.com/account/api-keys) you can get started using the OpenAI models right away.As an alternative to OpenAI, you can [install plugins](https://llm.datasette.io/en/stable/plugins/installing-plugins.html) to access models by other providers, including models that can be installed and run on your own device.Save your OpenAI API key like this:```bashllm keys set openai```This will prompt you for your key like so:```Enter key: &lt;paste here&gt;```Now that you've saved a key you can run a prompt like this:```bashllm &quot;Five cute names for a pet penguin&quot;``````1. Waddles2. Pebbles3. Bubbles4. Flappy5. Chilly```Read the [usage instructions](https://llm.datasette.io/en/stable/usage.html) for more.## Installing a model that runs on your own machine[LLM plugins](https://llm.datasette.io/en/stable/plugins/index.html) can add support for alternative models, including models that run on your own machine.To download and run Llama 2 13B locally, you can install the [llm-mlc](https://github.com/simonw/llm-mlc) plugin:```bashllm install llm-mlcllm mlc pip install --pre --force-reinstall \  mlc-ai-nightly \  mlc-chat-nightly \  -f https://mlc.ai/wheelsllm mlc setup```Then download the 15GB Llama 2 13B model like this:```bashllm mlc download-model Llama-2-7b-chat --alias llama2```And run a prompt through it:```bashllm -m llama2 'difference between a llama and an alpaca'```You can also start a chat session with the model using the `llm chat` command:```bashllm chat -m llama2``````Chatting with mlc-chat-Llama-2-13b-chat-hf-q4f16_1Type 'exit' or 'quit' to exitType '!multi' to enter multiple lines, then '!end' to finish&gt; ```## Using a system promptYou can use the `-s/--system` option to set a system prompt, providing instructions for processing other input to the tool.To describe how the code a file works, try this:```bashcat mycode.py | llm -s &quot;Explain this code&quot;```## HelpFor help, run:    llm --helpYou can also use:    python -m llm --help</longdescription>
</pkgmetadata>