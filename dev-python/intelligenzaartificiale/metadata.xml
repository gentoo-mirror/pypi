<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>###### üöß La libreria √® ancora in fase di SVILUPPO üöß# Intelligenza Artificiale###### _La libreira python creata per neofiti e datascientist che semplifica l'analisi dati e lo sviluppo di modelli di apprendimento automatico e profondo._&amp;nbsp;#&amp;nbsp;Intelligenza-Artificiale √® l'unica libreria python MADE in ITALY che permette a qualsiasi persona di :- Leggere, Manipolare, Pulire dataset di ogni tipo- Analizzare i dati per trasformarli in importanti informazioni- Creare in meno di 5 righe di codice modelli di ML- Sviluppare reti neurali- &amp; molto molto altro ancora- ###### **richiamando i metodi in italiano !**&amp;nbsp;#&amp;nbsp;#  Installazione LibreriaLa libreria intelligenzaartificiale richiede [PYTHON](https://PYTHON.org/) v3.6+ Per installare la libreria puoi usare il comando pip3 .```shpip3 install intelligenzaartificiale```se invece utilizzi google colab...```sh!pip install intelligenzaartificiale```&amp;nbsp;#&amp;nbsp;# Partizione LibreriaAl momento abbiamo deciso di partizionare la libreria in moduli, per rendere il codice il pi√π portabile e leggero possibile.| Modulo | Import | Utilizzo| ------ | ------ | ------| Dataset | from intelligenzaartificiale import dataset as dt | lettura e manipolazine set di dati ( .csv , .xlsx , .xls , .html , .json , sql )| BigDataset | from intelligenzaartificiale import bigdataset as bdt | lettura e manipolazine set di dati molto grandi compresi bigdata| Statistica | from intelligenzaartificiale import statistica as st | analisi dati| Preprocessing | from intelligenzaartificiale import preprocessing as pp | pulizia, manipolazione e preprocessing dei dati| TextPreprocessing | from intelligenzaartificiale import textpreprocessing as tpp | pulizia, manipolazione e preprocessing per dati testuali| Visualizzazione | from intelligenzaartificiale import visualizzazione as vz | creazione grafici e visualizzazione dati| Machine Learning | from intelligenzaartificiale import machinelearning as ml | creazione di modelli di apprendimento automatico| Deep Learning | from intelligenzaartificiale import depplearning as dl | creazione di reti neurali | NLP | from intelligenzaartificiale import nlp | trattamento delle informazioni testuali &amp;nbsp;#&amp;nbsp;# DocumentazioneQui sotto troverai elencati tutti i metodi della libreria con degli esempi## _Step 1 ---_  **Modulo Dataset e BigDataset**Con questo modulo potrai leggere qualsiasi tipo di dataset&amp;nbsp;**Leggere un file .csv**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)```&amp;nbsp;**Leggere file .csv enormi**```shfrom intelligenzaartificiale import bigdataset as bdtil_mio_dataset = bdt.leggi_csv(&quot;Bigfile.csv&quot;)#per convertire il file molto grande in un file leggibile anche con il modulo DATASETbdt.salva_feather(il_mio_dataset,&quot;nuovoFile&quot;)from intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_feather(&quot;nuovoFile.feather&quot;)```&amp;nbsp;**Leggere un file excel**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_xls(&quot;file_name.xls&quot;)```**Leggere un foglio specifico di un file excel**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_sheet(&quot;file_name.xls&quot;,&quot;nome_foglio&quot;)```&amp;nbsp;**Leggere un file html**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_html(&quot;file_name.html&quot;)```&amp;nbsp;**Leggere un file json**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_json(&quot;file_name.json&quot;)```&amp;nbsp;**Carica e lavora su oltre 750+ dataset gi√† caricati**```shfrom intelligenzaartificiale import dataset as dt#ritorna la lista dei nomi degli oltre 750 dataset disponibiliprint(dt.lista_datasets())#ritorna la documentazione del dataset sceltoprint(dt.documentazione_dataset(&quot;iris&quot;))#ritorna il dataframe del dataset richiestoil_mio_dataset= dt.importa_dataset(&quot;iris&quot;)```&amp;nbsp;**Ottenere informazioni di base sulle colonne**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)print(dt.lista_colonne(il_mio_dataset))print(dt.tipo_colonne(il_mio_dataset))```&amp;nbsp;**Rimuovere una o pi√π colonne**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)nuovo_dataset = dt.rimuovi_colonna(il_mio_dataset, &quot;colonna_da_eliminare&quot;)colonne_inutili = [&quot;colonna3&quot;, &quot;colonna12&quot; , &quot;colonna33&quot;]nuovo_dataset = dt.rimuovi_colonne(il_mio_dataset, colonne_inutili)```&amp;nbsp;**Separare i vari tipi di dato**```shfrom intelligenzaartificiale import dataset as dtil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)valori_numerici = dt.numerici(il_mio_dataset)valori_categorici = dt.categorici(il_mio_dataset)valori_booleani = dt.booleani(il_mio_dataset)```**Scarica degli esempi pratici**- ##### [Esempio Completo modulo Dataset](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_667621fb03c2447380c0be19e5e79cf7.pdf)-  ##### [Esempio 2 Completo modulo Dataset](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_023e791741564cccb9ded05475f067bb.pdf)&amp;nbsp;#&amp;nbsp;## _Step 2 ---_  **Modulo Statistica**Con questo modulo potrai fare statistiche, report e analisi sui tuoi dati&amp;nbsp;**Valori Nulli o Corrotti**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import statistica as stil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)print(st.valori_nan(il_mio_dataset))print(st.percentuale_nan(il_mio_dataset))#nel modulo preprocessing vedremmo come eliminare o sostituire i valori null o corrotti```&amp;nbsp;**Statistiche di base**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import statistica as stil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#statistiche su tutto il datasetprint(st.statistiche(il_mio_dataset))#statistiche su specifica colonna del datasetprint(st.statistiche_colonna(il_mio_dataset,&quot;nome_colonna&quot;))#contare valori unici di una specifica colonnaprint(st.conta_valori_unici(il_mio_dataset,&quot;nome_colonna&quot;))```&amp;nbsp;**Statistiche di base su colonna**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import statistica as stil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#mediaprint(st.media(il_mio_dataset,&quot;nome_colonna&quot;))#varianzaprint(st.varianza_colonna(il_mio_dataset,&quot;nome_colonna&quot;))#quantiliprint(st.quantile_25(il_mio_dataset,&quot;nome_colonna&quot;))print(st.quantile_50(il_mio_dataset,&quot;nome_colonna&quot;))print(st.quantile_75(il_mio_dataset,&quot;nome_colonna&quot;))#min e maxprint(st.min(il_mio_dataset,&quot;nome_colonna&quot;))print(st.max(il_mio_dataset,&quot;nome_colonna&quot;))```&amp;nbsp;**Analizzare le correlazioni**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import statistica as stil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#Correlazione tra i campi del datasetprint(st.correlazione(il_mio_dataset))#correlazione tra una colonna target e un altra colonnaprint(st.correlazione_radio(il_mio_dataset, &quot;colonna&quot; ,&quot;target_colonna&quot;))#correlazione di Spearman tra una colonna target e un altra colonnaprint(st.correlazione_spearman(il_mio_dataset, &quot;colonna&quot; ,&quot;target_colonna&quot;))#correlazione di Pearson tra una colonna target e un altra colonnaprint(st.correlazione_pearson(il_mio_dataset, &quot;colonna&quot; ,&quot;target_colonna&quot;))#classifica correlazione tra una colonna target e un altra colonnaprint(st.classifica_correlazione_colonna(il_mio_dataset, &quot;target_colonna&quot;))```&amp;nbsp;**Report Automatizzati** ```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import statistica as stil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#Scarica report htmlst.report_dataset(il_mio_dataset)#Salver√† nella corrente un report html#apri il tuo dataset sul webst.apri_dataframe_nel_browser(il_mio_dataset)#Ti consigliamo viviamente di provare questa funzione sul tuo set di dati```&amp;nbsp;**Scarica degli esempi pratici**- ##### [Esempio Completo modulo Statistica](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_c15e0aa70e9c46c388730d23e0c91ea3.pdf)&amp;nbsp;#&amp;nbsp;## _Step 3 ---_  **Modulo PreProcessing**Con questo modulo potrai pulire, manipolare, standardizzare e scalare i tuoi dati&amp;nbsp;**Gestire Nulli o Corrotti**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import preprocessing as ppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#rimuovere righe con valori nulli o corrottiil_mio_dataset = pp.rimuovi_nan(il_mio_dataset)#sostituire valori nulli o corrotti con il valore medioil_mio_dataset[&quot;colonna&quot;] = pp.sostituisci_nan_media(il_mio_dataset,&quot;colonna&quot;)#sostituire valori nulli o corrotti con il valore pi√π frequenteil_mio_dataset[&quot;colonna&quot;] = pp.sostituisci_nan_frequenti(il_mio_dataset,&quot;colonna&quot;)```&amp;nbsp;**Gestire gli outliers**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import preprocessing as ppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#Rimuovere i valori outlieril_mio_dataset[&quot;colonna&quot;] = pp.rimuovi_outliers(il_mio_dataset,&quot;colonna&quot;)#Rimuovere i valori outlier e valori nulliil_mio_dataset[&quot;colonna&quot;] = pp.rimuovi_outliers_nan(il_mio_dataset,&quot;colonna&quot;)```&amp;nbsp;**Gestire variabili testuali e categoriche**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import preprocessing as ppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#effettuare il labelencodingil_mio_dataset[&quot;nuova_colonna&quot;] = pp.label_encoding(il_mio_dataset,&quot;colonna&quot;)#effettuare il labelencoding su pi√π colonneil_mio_dataset[&quot;nuova_colonna&quot;] = pp.label_encoding_multiplo(il_mio_dataset,[&quot;colonna1&quot;, &quot;colonna2&quot;])#effettuare il one hot encodingil_mio_dataset[&quot;nuova_colonna&quot;] = pp.onehot_encoding(il_mio_dataset,&quot;colonna&quot;)#per rimuovere la vecchia colonnail_mio_dataset = dt.rimuovi_colonna(il_mio_dataset, &quot;colonna&quot;)```&amp;nbsp;**Normalizzare i dati**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import preprocessing as ppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#normalizza intero datatsetdataset_normalizzato = pp.normalizza(il_mio_dataset)#normalizza una specifica colonnail_mio_dataset[&quot;colonna&quot;] = pp.normalizza_colonne(il_mio_dataset,&quot;colonna&quot;)#standardizza intero datatsetdataset_standardizzato = pp.standardizza(il_mio_dataset)#standardizza una specifica colonnail_mio_dataset[&quot;colonna&quot;] = pp.standardizza_colonne(il_mio_dataset,&quot;colonna&quot;)# dividi i dati in test e trainX_train, X_test, y_train, y_test = pp.dividi_train_test(il_mio_dataset, &quot;target&quot;, 0.25 )```&amp;nbsp;**Scarica degli esempi pratici**- ##### [Esempio Completo modulo PreProcessing](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_a996ef902fca480da70b5cc5ed4b66bf.pdf)&amp;nbsp;#&amp;nbsp;## _Step 3.1 ---_  **Modulo Text-PreProcessing**Con questo modulo potrai pulire, manipolare, standardizzare e scalare i tuoi dati Testuali&amp;nbsp;**Pulizia di Base**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import textpreprocessing as tppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#pulire l'intera colonna con una rigail_mio_dataset[&quot;testo_email&quot;] = tpp.pulisci_testo(il_mio_dataset,&quot;testo_email&quot;)#trasforma in minuscolo il tetsoil_mio_dataset[&quot;testo_email&quot;] = tpp.trasforma_in_minuscolo(il_mio_dataset, &quot;testo_email&quot;)#rimuovi caratteri speciali e cifre !&quot;#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~0123456789il_mio_dataset[&quot;colonna&quot;] = tpp.rimuovi_caratteri_speciali_e_cifre(il_mio_dataset,&quot;colonna&quot;)#rimuovi caratteri speciali !&quot;#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~il_mio_dataset[&quot;colonna&quot;] = tpp.rimuovi_caratteri_speciali(il_mio_dataset,&quot;colonna&quot;)#rimuovi stopwordsil_mio_dataset[&quot;colonna&quot;] = tpp.rimuovi_stopwords(il_mio_dataset,&quot;colonna&quot;, &quot;english&quot;)```&amp;nbsp;**Tokenizzazione e vettorizzazione del testo**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import textpreprocessing as tppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#vettorizzare il testo (tfidf)il_mio_dataset[&quot;testo_vet&quot;] = tpp.vettorizza_testo(il_mio_dataset,&quot;testo_email&quot;)#analisi componenti principaliil_mio_dataset[&quot;pca&quot;] = tpp.componenti_principali(il_mio_dataset,&quot;testo_vet&quot;)#tokenizzare il testo il_mio_dataset[&quot;testo_tok&quot;] = tpp.tokenizza_testo(il_mio_dataset,&quot;testo_email&quot;)```&amp;nbsp;**Altre funzioni**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import textpreprocessing as tppil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)#Bag of wordsil_mio_dataset[&quot;wordbags&quot;] = tpp.bag_of_words(il_mio_dataset,&quot;testo_email&quot;)#genera grafico words cloudcrea_wordcloud(il_mio_dataset,&quot;testo_email&quot;)```&amp;nbsp;**Scarica degli esempi pratici**- ##### [Esempio Completo modulo Text-PreProcessing](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_1313f3bacdc1410e95f45511bbdf9d52.pdf)&amp;nbsp;#&amp;nbsp;## _Step 4 ---_  **Modulo Visualizzazione**Con questo modulo potrai visualizzare e creare grafici sui tuoi dati molto velocemente&amp;nbsp;**Creare Grafici**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import visualizzazione as vzil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)# grafico singola colonna vz.grafico_colonna(il_mio_dataset,&quot;prezzo&quot;)# grafico a punti di due colonnevz.grafico_scatter(il_mio_dataset,&quot;spesa&quot;,&quot;reddito&quot;)# grafico a linee di due colonnevz.grafico_line(il_mio_dataset,&quot;spesa&quot;,&quot;reddito&quot;)# grafico boxplot di due colonnevz.grafico_boxplot(il_mio_dataset,&quot;et√†&quot;,&quot;reddito&quot;)# histogramma di due colonnevz.grafico_hist(il_mio_dataset,&quot;acquisti_prodotto_A&quot;,&quot;acquisti_prodotto_B&quot;)```&amp;nbsp;**Grafici Automattizati**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import statistica as st# creare grafici in modo automaticost.report_dataset(il_mio_dataset)#apri il tuo dataset sul webst.apri_dataframe_nel_browser(il_mio_dataset)```&amp;nbsp;**Grafici 3d**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import visualizzazione as vzil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)# creare grafici tridimensionalivz.grafico_3d(il_mio_dataset, &quot;spesa&quot;, &quot;sesso&quot;, &quot;reddito&quot;)```&amp;nbsp;**Scarica degli esempi pratici**- ##### [Esempio Completo modulo Visualizzazione](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_28aae9fe099148f6a24c9eda42573878.pdf)&amp;nbsp;#&amp;nbsp;## _Step 5 ---_  **Modulo Apprendimento Automatico**Con questo modulo potrai :- Scoprire l'algoritmo pi√π performante sui tuoi dati- Implementare e allenare con una riga oltre 20 algoritmi- Valutare, spiegare, salvare e caricare il tuo modello- Fare previsioni su nuovi dati con il tuo modello- &amp; molto molto altro ancora&amp;nbsp;**Scoprire l'algoritmo pi√π performante**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import machinelearning as mlil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)colonne_x = [&quot;et√†&quot;,&quot;sesso&quot;,&quot;reddito&quot;,&quot;sconto&quot;,&quot;data&quot;]target_reg = &quot;spesa_effettata&quot;target_cla = &quot;ha_acquistato?&quot;# scoprire algoritmo di regressione pi√π performantemodello = ml.performance_modelli_regressione(il_mio_dataset, colonne_x, target_reg)# scoprire algoritmo di classificazione pi√π performantemodello = ml.performance_modelli_classificazione(il_mio_dataset, colonne_x, target_cla)```&amp;nbsp;**Creare il modelli di regressione [SEMPLICE]**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import machinelearning as mlil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)colonne_x = [&quot;et√†&quot;,&quot;sesso&quot;,&quot;reddito&quot;,&quot;sconto&quot;,&quot;data&quot;]target_reg = &quot;spesa_effettata&quot;# dopo aver scoperto l'algoritmo pi√π performante lo potrai implementare # in una sola rigamodello1 = ml.regressione_lineare(il_mio_dataset, colonne_x, target_reg)modello2 = ml.regressione_logistica(il_mio_dataset, colonne_x, target_reg)modello3 = ml.regressione_SVR(il_mio_dataset, colonne_x, target_reg)modello4 = ml.regressione_SVC(il_mio_dataset, colonne_x, target_reg)modello5 = ml.regressione_random_forest(il_mio_dataset, colonne_x, target_reg)modello6 = ml.regressione_gradient_boosting(il_mio_dataset, colonne_x, target_reg)modello7 = ml.regressione_decision_tree(il_mio_dataset, colonne_x, target_reg)modello8 = ml.regressione_knn(il_mio_dataset, colonne_x, target_reg)modello9 = ml.modello_elastic_net(il_mio_dataset, colonne_x, target_reg)modello10 = ml.modello_lasso(il_mio_dataset, colonne_x, target_reg)modello11 = ml.modello_ridge(il_mio_dataset, colonne_x, target_reg)```&amp;nbsp;**Creare il modelli di classificazione [SEMPLICE]**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import machinelearning as mlil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)colonne_x = [&quot;et√†&quot;,&quot;sesso&quot;,&quot;reddito&quot;,&quot;sconto&quot;,&quot;data&quot;]target_cla = &quot;ha_acquistato?&quot;# dopo aver scoperto l'algoritmo pi√π performante lo potrai implementare # in una sola rigamodello1 = ml.classificatore_random_forest(il_mio_dataset, colonne_x, target_cla)modello2 = ml.classificatore_gradient_boosting(il_mio_dataset, colonne_x, target_cla)modello3 = ml.classificatore_decision_tree(il_mio_dataset, colonne_x, target_cla)modello4 = ml.classificatore_knn(il_mio_dataset, colonne_x, target_cla)modello5 = ml.classificatore_logistico(il_mio_dataset, colonne_x, target_cla)modello6 = ml.classificatore_naivebayes(il_mio_dataset, colonne_x, target_cla)modello7 = ml.classificatore_svm(il_mio_dataset, colonne_x, target_cla)```&amp;nbsp;**Valutare, Prevedere, Salvare e Caricare un modello**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import machinelearning as mlil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)colonne_x = [&quot;et√†&quot;,&quot;sesso&quot;,&quot;reddito&quot;,&quot;sconto&quot;,&quot;data&quot;]target_reg = &quot;spesa_effettata&quot;modello1 = ml.regressione_lineare(il_mio_dataset, colonne_x, target_reg)# Valutare un modelloprint(ml.valutazione_modello(modello1,il_mio_dataset, colonne_x, target_reg))# Spiegare un modelloml.spiega_modello(modello1,il_mio_dataset, colonne_x, target_reg)# Previsione con un modellonuovo_dataset = dt.leggi_csv(&quot;nuovo.csv&quot;)previsioni = ml.predizione_y(modello1,nuovo_dataset)# Salvare e Caricare un modelloml.salva_modello(modello1,&quot;nome_modello&quot;)ml.carica_modello(&quot;nome_modello&quot;)```&amp;nbsp;**Creare modelli avanzati [AVANZATO]**```shfrom intelligenzaartificiale import dataset as dtfrom intelligenzaartificiale import machinelearning as mlil_mio_dataset = dt.leggi_csv(&quot;file_name.csv&quot;)colonne_x = [&quot;et√†&quot;,&quot;sesso&quot;,&quot;reddito&quot;,&quot;sconto&quot;,&quot;data&quot;]target_cla = &quot;ha_acquistato?&quot;target_reg = &quot;spesa_effettata&quot;##Tutti i Modelli Avanzatimodel1 = ml.regressione_lineare_avanzata(df, lista_colonne_x, colonna_y, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False, random_state=None)modello2 = regressione_logistica_avanzata(df, lista_colonne_x, colonna_y, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, C=1.0, class_weight=None, max_iter=100, multi_class='ovr', penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)modello = ml.regressione_SVR_avanzata(df, lista_colonne_x, colonna_y, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, C=1.0, epsilon=0.1, gamma='auto', kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)modello = ml.regressione_SVC_avanzata(df, lista_colonne_x, colonna_y, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)modello = ml.regressione_random_forest_avanzata(df, lista_colonne_x, colonna_y, n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)modello = ml.classificatore_logistico_avanzato(df, lista_colonne_x, colonna_y, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=None)modello = ml.classificatore_naivebayes_avanzato(df, lista_colonne_x, colonna_y, priors=None)modello = ml.classificatore_svm_avanzato(df, lista_colonne_x, colonna_y, C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)modello = ml.classificatore_random_forest_avanzato(df, lista_colonne_x, colonna_y, n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)modello = ml.regressione_gradient_boosting_avanzato(df, lista_colonne_x, colonna_y, n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)modello = ml.classificatore_gradient_boosting_avanzato(df, lista_colonne_x, colonna_y, n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)modello = ml.regressione_decision_tree_avanzato(df, lista_colonne_x, colonna_y, n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)modello = ml.classificatore_decision_tree_avanzato(df, lista_colonne_x, colonna_y, n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)modello = ml.regressione_knn_avanzato(df, lista_colonne_x, colonna_y, n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1, **kwargs)modello = ml.classificatore_knn_avanzato(df, lista_colonne_x, colonna_y, n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1, **kwargs)modello = ml.modello_elastic_net_avanzato(df, lista_colonne_x, colonna_y, alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')modello = ml.modello_ridge_avanzato(df, lista_colonne_x, colonna_y, alpha=1.0, fit_intercept=True, normalize=False, precompute='auto', copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')modello = ml.modello_lasso_avanzato(df, lista_colonne_x, colonna_y, alpha=1.0, fit_intercept=True, normalize=False, precompute='auto', copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')```&amp;nbsp;**Scarica degli esempi pratici**- ##### [Esempio Completo modulo Machine Learning](https://3c029f53-d5cb-4407-a287-e90c489e81e2.usrfiles.com/ugd/3c029f_574ed01c91a441d69b51da47209b8b1b.pdf)&amp;nbsp;#&amp;nbsp;## _Step 6 ---_  **Modulo Apprendimento Profondo**###### üöß Questa parte della libreria √® ancora in fase di SVILUPPO üöß&amp;nbsp;#&amp;nbsp;## _Step7 ---_  **Modulo NLP**###### üöß Questa parte della libreria √® ancora in fase di SVILUPPO üöß&amp;nbsp;#&amp;nbsp;# Licenza **MIT****¬© Copyright 2020-2022 [Intelligenza Artificiale Italia](intelligenzaartificialeitalia.net)**</longdescription>
</pkgmetadata>