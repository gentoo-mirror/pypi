<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># airflow-commonsA python package that contains common functionalities for airflow## InstallationUse the package manager pip to install airflow-commons.```bashpip install airflow-commons```## Modules* bigquery_operator: With this module you can manage your Google BigQuery operations.* mysql_operator: Using this module, you can connect to your MySQL data source and manage your data operations.* s3_operator: This operator connects to your s3 bucket and lets you manage your bucket.* glossary: This module consists of constants used across project* sql_resources: Template BigQuery and MySQL queries such as merge, delete, select etc. are located here.* utils: Generic methods like connection, querying etc. are implemented in this module.## Usage* Sample deduplication code works like:```pythonfrom airflow_commons import bigquery_operatorbigquery_operator.deduplicate(        service_account_file=&quot;path_to_file&quot;,        start_date=&quot;01-01-2020 14:00:00&quot;,        end_date=&quot;01-01-2020 15:00:00&quot;,        project_id=&quot;bigquery_project_id&quot;,        source_dataset=&quot;source_dataset&quot;,        source_table=&quot;source_table&quot;,        target_dataset=&quot;target_dataset&quot;,        target_table=&quot;target_table&quot;,        oldest_allowable_target_partition=&quot;01-01-2015 00:00:00&quot;,        primary_keys=[&quot;primary_keys&quot;],        time_columns=[&quot;time_columns&quot;],        allow_partition_pruning=True,    )```</longdescription>
</pkgmetadata>