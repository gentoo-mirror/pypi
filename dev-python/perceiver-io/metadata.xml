<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Perceiver, Perceiver IO and Perceiver ARThis repository is a PyTorch and PyTorch Lightning implementation of&lt;table&gt;  &lt;tr&gt;    &lt;td&gt;       &lt;b&gt;Perceiver&lt;/b&gt;: General Perception with Iterative Attention       (&lt;a href=&quot;https://arxiv.org/abs/2103.03206&quot;&gt;paper&lt;/a&gt;,        &lt;a href=&quot;https://www.youtube.com/watch?v=P_xeshTnPZg&quot;&gt;video&lt;/a&gt;)    &lt;/td&gt;    &lt;td&gt;&lt;img src=&quot;docs/images/small-perceiver.png&quot; alt=&quot;Perceiver&quot;/&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;      &lt;b&gt;Perceiver IO&lt;/b&gt;: A General Architecture for Structured Inputs &amp; Outputs      (&lt;a href=&quot;https://arxiv.org/abs/2107.14795&quot;&gt;paper&lt;/a&gt;,       &lt;a href=&quot;https://www.deepmind.com/blog/building-architectures-that-can-handle-the-worlds-data&quot;&gt;blog post&lt;/a&gt;)    &lt;/td&gt;    &lt;td&gt;&lt;img src=&quot;docs/images/small-perceiver-io.png&quot; alt=&quot;Perceiver IO&quot;/&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;      General-purpose, long-context autoregressive modeling with &lt;b&gt;Perceiver AR&lt;/b&gt;      (&lt;a href=&quot;https://arxiv.org/abs/2202.07765&quot;&gt;paper&lt;/a&gt;,       &lt;a href=&quot;https://www.deepmind.com/blog/perceiver-ar-general-purpose-long-context-autoregressive-generation&quot;&gt;blog post&lt;/a&gt;)    &lt;/td&gt;    &lt;td&gt;&lt;img src=&quot;docs/images/small-perceiver-ar.png&quot; alt=&quot;Perceiver AR&quot;/&gt;&lt;/td&gt;  &lt;/tr&gt;&lt;/table&gt;All model classes are written in plain PyTorch and can be wrapped into [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/stable/)modules for training at scale. The command line interface is implemented with the [Lightning CLI](https://pytorch-lightning.readthedocs.io/en/stable/cli/lightning_cli.html).[Pretrained weights](docs/pretrained-models.md) can be imported for [official models](docs/pretrained-models.md#official-models)from the ðŸ¤— Hub, [training checkpoints](docs/pretrained-models.md#training-checkpoints) from [training examples](docs/training-examples.md)are available for download too. Datasets used in the training examples are ðŸ¤— [datasets](https://huggingface.co/docs/datasets)wrapped into PyTorch Lightning [data modules](perceiver/data). For NLP tasks, this library supports all ðŸ¤—[fast tokenizers](https://huggingface.co/docs/transformers/fast_tokenizers) and the ðŸ¤— Perceiver UTF-8 bytes tokenizer.## Installation### Via pip```shellpip install perceiver-io[text,vision]```### From sourcesInstallation from sources requires a [Miniconda](https://docs.conda.io/en/latest/miniconda.html) and a[Poetry](https://python-poetry.org/docs/#installation) (1.2.0 or higher) installation.Create and activate the `perceiver-io` conda environment:```shellconda env create -f environment.ymlconda activate perceiver-io```Install main and test dependencies, including all extras:```shell# Without dependencies required for examplespoetry install --all-extras```If you want to run the [examples](examples) locally, additionally use `--with examples`:```shellpoetry install --all-extras --with examples```### Docker image```shelldocker pull ghcr.io/krasserm/perceiver-io:latest```See [Docker image](docs/docker-image.md) for details.## Documentation- [Getting started](docs/getting-started.md)- [Model construction](docs/model-construction.md)- [Pretrained models](docs/pretrained-models.md)- [Training examples](docs/training-examples.md)- [Inference examples](examples/inference.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/krasserm/perceiver-io/blob/0.8.1/examples/inference.ipynb)- [Building blocks](docs/building-blocks.md)## ArticlesArticles referencing this repository:- [Training compute-optimal Perceiver AR language models](https://krasserm.github.io/2023/01/23/scaling-perceiver-ar/)- [A gentle introduction to Rotary Position Embedding](https://krasserm.github.io/2022/12/13/rotary-position-embedding/)## Other implementations- [Perceiver](https://paperswithcode.com/paper/perceiver-general-perception-with-iterative#code)- [Perceiver IO](https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for#code)- [Perceiver AR](https://paperswithcode.com/paper/general-purpose-long-context-autoregressive#code)</longdescription>
</pkgmetadata>