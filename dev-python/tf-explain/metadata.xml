<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># tf-explain[![Pypi Version](https://img.shields.io/pypi/v/tf-explain.svg)](https://pypi.org/project/tf-explain/)[![Build Status](https://github.com/sicara/tf-explain/actions/workflows/ci.yml/badge.svg)](https://github.com/sicara/tf-explain/actions)[![Documentation Status](https://readthedocs.org/projects/tf-explain/badge/?version=latest)](https://tf-explain.readthedocs.io/en/latest/?badge=latest)![Python Versions](https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-%23EBBD68.svg)![Tensorflow Versions](https://img.shields.io/badge/tensorflow-2.x-blue.svg)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)__tf-explain__ implements interpretability methods as Tensorflow 2.x callbacks to __ease neural network's understanding__.See [Introducing tf-explain, Interpretability for Tensorflow 2.0](https://blog.sicara.com/tf-explain-interpretability-tensorflow-2-9438b5846e35)__Documentation__: https://tf-explain.readthedocs.io## Installation__tf-explain__ is available on PyPi as an alpha release. To install it:```bashvirtualenv venv -p python3.8pip install tf-explain```tf-explain is compatible with Tensorflow 2.x. It is not declared as a dependencyto let you choose between full and standalone-CPU versions. Additionally to the previous install, run:```bash# For CPU or GPUpip install tensorflow==2.6.0```Opencv is also a dependency. To install it, run:```bash# For CPU or GPUpip install opencv-python```## Quickstarttf-explain offers 2 ways to apply interpretability methods. The full list of methods is the [Available Methods](#available-methods) section.### On trained modelThe best option is probably to load a trained model and apply the methods on it.```python# Load pretrained model or your ownmodel = tf.keras.applications.vgg16.VGG16(weights=&quot;imagenet&quot;, include_top=True)# Load a sample image (or multiple ones)img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))img = tf.keras.preprocessing.image.img_to_array(img)data = ([img], None)# Start explainerexplainer = GradCAM()grid = explainer.explain(data, model, class_index=281)  # 281 is the tabby cat index in ImageNetexplainer.save(grid, &quot;.&quot;, &quot;grad_cam.png&quot;)```### During trainingIf you want to follow your model during the training, you can also use it as a Keras Callback,and see the results directly in [TensorBoard](https://www.tensorflow.org/tensorboard/).```pythonfrom tf_explain.callbacks.grad_cam import GradCAMCallbackmodel = [...]callbacks = [    GradCAMCallback(        validation_data=(x_val, y_val),        class_index=0,        output_dir=output_dir,    )]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```## Available Methods1. [Activations Visualization](#activations-visualization)1. [Vanilla Gradients](#vanilla-gradients)1. [Gradients*Inputs](#gradients-inputs)1. [Occlusion Sensitivity](#occlusion-sensitivity)1. [Grad CAM (Class Activation Maps)](#grad-cam)1. [SmoothGrad](#smoothgrad)1. [Integrated Gradients](#integrated-gradients)### Activations Visualization&gt; Visualize how a given input comes out of a specific activation layer```pythonfrom tf_explain.callbacks.activations_visualization import ActivationsVisualizationCallbackmodel = [...]callbacks = [    ActivationsVisualizationCallback(        validation_data=(x_val, y_val),        layers_name=[&quot;activation_1&quot;],        output_dir=output_dir,    ),]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/activations_visualisation.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;### Vanilla Gradients&gt; Visualize gradients importance on input image```pythonfrom tf_explain.callbacks.vanilla_gradients import VanillaGradientsCallbackmodel = [...]callbacks = [    VanillaGradientsCallback(        validation_data=(x_val, y_val),        class_index=0,        output_dir=output_dir,    ),]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/vanilla_gradients.png&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;### Gradients*Inputs&gt; Variant of [Vanilla Gradients](#vanilla-gradients) ponderating gradients with input values```pythonfrom tf_explain.callbacks.gradients_inputs import GradientsInputsCallbackmodel = [...]callbacks = [    GradientsInputsCallback(        validation_data=(x_val, y_val),        class_index=0,        output_dir=output_dir,    ),]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/gradients_inputs.png&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;### Occlusion Sensitivity&gt; Visualize how parts of the image affects neural network's confidence by occluding parts iteratively```pythonfrom tf_explain.callbacks.occlusion_sensitivity import OcclusionSensitivityCallbackmodel = [...]callbacks = [    OcclusionSensitivityCallback(        validation_data=(x_val, y_val),        class_index=0,        patch_size=4,        output_dir=output_dir,    ),]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/occlusion_sensitivity.png&quot; width=&quot;200&quot; /&gt;    &lt;p style=&quot;color: grey; font-size:small; width:350px;&quot;&gt;Occlusion Sensitivity for Tabby class (stripes differentiate tabby cat from other ImageNet cat classes)&lt;/p&gt;&lt;/div&gt;### Grad CAM&gt; Visualize how parts of the image affects neural network's output by looking into the activation mapsFrom [Grad-CAM: Visual Explanations from Deep Networksvia Gradient-based Localization](https://arxiv.org/abs/1610.02391)```pythonfrom tf_explain.callbacks.grad_cam import GradCAMCallbackmodel = [...]callbacks = [    GradCAMCallback(        validation_data=(x_val, y_val),        class_index=0,        output_dir=output_dir,    )]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/grad_cam.png&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;### SmoothGrad&gt; Visualize stabilized gradients on the inputs towards the decisionFrom [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825)```pythonfrom tf_explain.callbacks.smoothgrad import SmoothGradCallbackmodel = [...]callbacks = [    SmoothGradCallback(        validation_data=(x_val, y_val),        class_index=0,        num_samples=20,        noise=1.,        output_dir=output_dir,    )]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/smoothgrad.png&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;### Integrated Gradients&gt; Visualize an average of the gradients along the construction of the input towards the decisionFrom [Axiomatic Attribution for Deep Networks](https://arxiv.org/pdf/1703.01365.pdf)```pythonfrom tf_explain.callbacks.integrated_gradients import IntegratedGradientsCallbackmodel = [...]callbacks = [    IntegratedGradientsCallback(        validation_data=(x_val, y_val),        class_index=0,        n_steps=20,        output_dir=output_dir,    )]model.fit(x_train, y_train, batch_size=2, epochs=2, callbacks=callbacks)```&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;./docs/assets/integrated_gradients.png&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;## Roadmap- [ ] Subclassing API Support- [ ] Additional Methods  - [ ] [GradCAM++](https://arxiv.org/abs/1710.11063)  - [x] [Integrated Gradients](https://arxiv.org/abs/1703.01365)  - [x] [Guided SmoothGrad](https://arxiv.org/abs/1706.03825)  - [ ] [LRP](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)- [ ] Auto-generated API Documentation &amp; Documentation Testing## ContributingTo contribute to the project, please read the [dedicated section](./CONTRIBUTING.md).## CitationA [citation file](./CITATION.cff) is available for citing this work.</longdescription>
</pkgmetadata>