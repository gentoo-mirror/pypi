<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>  &lt;a href=&quot;https://github.com/kensho-technologies/pyctcdecode/actions?query=workflow%3A%22Tests+and+lint%22&quot;&gt;&lt;img src=&quot;https://github.com/kensho-technologies/pyctcdecode/workflows/Tests%20and%20lint/badge.svg&quot; /&gt;&lt;/a&gt;  &lt;a href=&quot;https://codecov.io/gh/kensho-technologies/pyctcdecode&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/kensho-technologies/pyctcdecode/branch/main/graph/badge.svg&quot; /&gt;&lt;/a&gt;  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; /&gt;&lt;/a&gt;  &lt;a href=&quot;http://www.repostatus.org/#active&quot;&gt;&lt;img src=&quot;http://www.repostatus.org/badges/latest/active.svg&quot; /&gt;&lt;/a&gt;  &lt;a href=&quot;https://github.com/psf/black&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot; /&gt;&lt;/a&gt;## pyctcdecodeA fast and feature-rich CTC beam search decoder for speech recognition written in Python, providing n-gram (kenlm) language model support similar to PaddlePaddle's decoder, but incorporating many new features such as byte pair encoding and real-time decoding to support models like Nvidia's [Conformer-CTC](tutorials/01_pipeline_nemo.ipynb) or Facebook's [Wav2Vec2](tutorials/02_pipeline_huggingface.ipynb).``` bashpip install pyctcdecode```### Main Features:- üî•‚ÄÄhotword boosting- ü§ñ‚ÄÄhandling of BPE vocabulary- üë•‚ÄÄmulti-LM support for 2+ models- üïí‚ÄÄstateful LM for real-time decoding- ‚ú®‚ÄÄnative frame index annotation of words- üí®‚ÄÄfast runtime, comparable to C++ implementation- üêç‚ÄÄeasy-to-modify Python code### Quick Start:``` pythonfrom pyctcdecode import build_ctcdecoder# specify alphabet labels as they appear in logitslabels = [    &quot; &quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;, &quot;i&quot;, &quot;j&quot;, &quot;k&quot;, &quot;l&quot;,    &quot;m&quot;, &quot;n&quot;, &quot;o&quot;, &quot;p&quot;, &quot;q&quot;, &quot;r&quot;, &quot;s&quot;, &quot;t&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;,]# prepare decoder and decode logits via shallow fusiondecoder = build_ctcdecoder(    labels,    kenlm_model_path=&quot;/my/dir/kenlm_model.arpa&quot;,  # either .arpa or .bin file    alpha=0.5,  # tuned on a val set    beta=1.0,  # tuned on a val set)text = decoder.decode(logits)```If the vocabulary is BPE-based, `pyctcdecode` will automatically recognize that and handled token merging automatically._(Note: the LM itself has no notion of this and is still word-based.)_``` pythonlabels = [&quot;&lt;unk&gt;&quot;, &quot;‚ñÅbug&quot;, &quot;s&quot;, &quot;‚ñÅbunny&quot;]decoder = build_ctcdecoder(    labels,    kenlm_model_path,)text = decoder.decode(logits)```Improve domain specificity by adding important contextual words (&quot;hotwords&quot;) during inference:``` pythonhotwords = [&quot;looney tunes&quot;, &quot;anthropomorphic&quot;]text = decoder.decode(    logits,    hotwords=hotwords,    hotword_weight=10.0,)```_(Note: `pyctcdecode` contains several free hyperparametersthat can strongly influence error rate and wall time.  Default valuesfor these parameters were (merely) chosen in order to yield goodperformance for one particular use case.  For best results, especiallywhen working with languages other than English, users are encouragedto perform a hyperparameter optimization study on their own data.)_Batch support via multiprocessing:``` pythonimport multiprocessingwith multiprocessing.get_context(&quot;fork&quot;).Pool() as pool:    text_list = decoder.decode_batch(pool, logits_list)```Use `pyctcdecode` for a pretrained Conformer-CTC model:``` pythonimport nemo.collections.asr as nemo_asrasr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(  model_name='stt_en_conformer_ctc_small')logits = asr_model.transcribe([&quot;my_file.wav&quot;], logprobs=True)[0]decoder = build_ctcdecoder(asr_model.decoder.vocabulary)decoder.decode(logits)```The tutorials folder contains many well documented notebook examples on how to run speech recognition using pretrained models from Nvidia's [NeMo](https://github.com/NVIDIA/NeMo) and Huggingface/Facebook's [Wav2Vec2](https://huggingface.co/transformers/model_doc/wav2vec2.html).For more details on how to use all of pyctcdecode's features, have a look at our [main tutorial](tutorials/00_basic_usage.ipynb).### Why pyctcdecode?In scientific computing, there‚Äôs often a tension between a language‚Äôs performance and its ease of use for prototyping and experimentation. Although C++ is the conventional choice for CTC decoders, we decided to try building one in Python. This choice allowed us to easily implement experimental features, while keeping runtime competitive through optimizations like caching and beam pruning. We compare the performance of `pyctcdecode` to an industry standard C++ decoder at various beam widths (shown as inline annotations), allowing us to visualize the trade-off of word error rate (y-axis) vs runtime (x-axis). For beam widths of 10 or greater, pyctcdecode yields strictly superior performance, with lower error rates in less time, see code [here](tutorials/03_eval_performance.ipynb).&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/images/performance.png&quot;&gt;&lt;/p&gt;The use of Python allows us to easily implement features like hotword support with only a few lines of code.&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;800px&quot; src=&quot;docs/images/hotwords.png&quot;&gt;&lt;/p&gt;`pyctcdecode` can return either a single transcript, or the full results of the beam search algorithm. The latter provides the language model state to enable real-time inference as well as word-based logit indices (frames) to enable word-based timing and confidence score calculations natively through the decoding process.&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;450px&quot; src=&quot;docs/images/beam_output.png&quot;&gt;&lt;/p&gt;Additional features such as BPE vocabulary, as well as examples of `pyctcdecode` as part of a full speech recognition pipeline, can be found in the [tutorials section](tutorials).### Resources:- [NeMo](https://github.com/NVIDIA/NeMo) and [Wav2Vec2](https://huggingface.co/transformers/model_doc/wav2vec2.html)- [CTC blog post](https://distill.pub/2017/ctc/)- [Beam search](https://www.youtube.com/watch?v=RLWuzLLSIgw) by Andrew Ng- Talks on beam search and pyctcdecode ([Longer talk](https://www.youtube.com/watch?v=CDuvVL0z_xk) and [Shorter talk](https://www.youtube.com/watch?v=mp7fHMTnK9A)) ### License:Licensed under the Apache 2.0 License. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.Copyright 2021-present Kensho Technologies, LLC. The present date is determined by the timestamp of the most recent commit in the repository.</longdescription>
</pkgmetadata>