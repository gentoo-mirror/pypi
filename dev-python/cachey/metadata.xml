<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Caching for Analytic Computations---------------------------------Humans repeat stuff.  Caching helps.Normal caching policies like LRU aren't well suited for analytic computationswhere both the cost of recomputation and the cost of storage routinely vary byone million or more.  Consider the following computations```python# Want thisnp.std(x)        # tiny result, costly to recompute# Don't want thisnp.transpose(x)  # huge result, cheap to recompute```Cachey tries to hold on to values that have the following characteristics1. Expensive to recompute (in seconds)2. Cheap to store (in bytes)3. Frequently used4. Recenty usedIt accomplishes this by adding the following to each items score on each access    score += compute_time / num_bytes * (1 + eps) ** tick_timeFor some small value of epsilon (which determines the memory halflife.) Thishas units of inverse bandwidth, has exponential decay of old results androughly linear amplification of repeated results.Example-------```python&gt;&gt;&gt; from cachey import Cache&gt;&gt;&gt; c = Cache(1e9, 1)  # 1 GB, cut off anything with cost 1 or less&gt;&gt;&gt; c.put('x', 'some value', cost=3)&gt;&gt;&gt; c.put('y', 'other value', cost=2)&gt;&gt;&gt; c.get('x')'some value'```This also has a `memoize` method```python&gt;&gt;&gt; memo_f = c.memoize(f)```Status------Cachey is new and not robust.</longdescription>
</pkgmetadata>