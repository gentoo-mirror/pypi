<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![Build Status](https://travis-ci.com/andhus/dirhash-python.svg?branch=master)](https://travis-ci.com/andhus/dirhash-python)[![codecov](https://codecov.io/gh/andhus/dirhash-python/branch/master/graph/badge.svg)](https://codecov.io/gh/andhus/dirhash-python)# dirhashA lightweight python module and CLI for computing the hash of anydirectory based on its files' structure and content.- Supports all hashing algorithms of Python's built-in `hashlib` module.- Glob/wildcard (&quot;.gitignore style&quot;) path matching for expressive filtering of files to include/exclude.- Multiprocessing for up to [6x speed-up](#performance)The hash is computed according to the [Dirhash Standard](https://github.com/andhus/dirhash), which is designed to allow for consistent and collision resistant generation/verification of directory hashes across implementations.## InstallationFrom PyPI:```commandlinepip install dirhash```Or directly from source:```commandlinegit clone git@github.com:andhus/dirhash-python.gitpip install dirhash/```## UsagePython module:```pythonfrom dirhash import dirhashdirpath = &quot;path/to/directory&quot;dir_md5 = dirhash(dirpath, &quot;md5&quot;)pyfiles_md5 = dirhash(dirpath, &quot;md5&quot;, match=[&quot;*.py&quot;])no_hidden_sha1 = dirhash(dirpath, &quot;sha1&quot;, ignore=[&quot;.*&quot;, &quot;.*/&quot;])```CLI:```commandlinedirhash path/to/directory -a md5dirhash path/to/directory -a md5 --match &quot;*.py&quot;dirhash path/to/directory -a sha1 --ignore &quot;.*&quot;  &quot;.*/&quot;```## Why?If you (or your application) need to verify the integrity of a set of files as wellas their name and location, you might find this useful. Use-cases range from verification of your image classification dataset (before spending GPU-$$$ on training your fancy Deep Learning model) to validation of generated files inregression-testing.There isn't really a standard way of doing this. There are plenty of recipes out there (see e.g. these SO-questions for [linux](https://stackoverflow.com/questions/545387/linux-compute-a-single-hash-for-a-given-folder-contents)and [python](https://stackoverflow.com/questions/24937495/how-can-i-calculate-a-hash-for-a-filesystem-directory-using-python))but I couldn't find one that is properly tested (there are some gotcha:s to cover!) and documented with a compelling user interface. `dirhash` was created with this as the goal.[checksumdir](https://github.com/cakepietoast/checksumdir) is another python module/tool with similar intent (that inspired this project) but it lacks much of thefunctionality offered here (most notably including file names/structure in the hash)and lacks tests.## PerformanceThe python `hashlib` implementation of common hashing algorithms are highlyoptimised. `dirhash` mainly parses the file tree, pipes data to `hashlib` and combines the output. Reasonable measures have been taken to minimize the overhead and for common use-cases, the majority of time is spent reading data from disk and executing `hashlib` code.The main effort to boost performance is support for multiprocessing, where thereading and hashing is parallelized over individual files.As a reference, let's compare the performance of the `dirhash` [CLI](https://github.com/andhus/dirhash-python/blob/master/src/dirhash/cli.py) with the shell command:`find path/to/folder -type f -print0 | sort -z | xargs -0 md5 | md5` which is the top answer for the SO-question: [Linux: compute a single hash for a given folder &amp; contents?](https://stackoverflow.com/questions/545387/linux-compute-a-single-hash-for-a-given-folder-contents)Results for two test cases are shown below. Both have 1 GiB of random data: in &quot;flat_1k_1MB&quot;, split into 1k files (1 MiB each) in a flat structure, and in &quot;nested_32k_32kB&quot;, into 32k files (32 KiB each) spread over the 256 leaf directories in a binary tree of depth 8.Implementation      | Test Case       | Time (s) | Speed up------------------- | --------------- | -------: | -------:shell reference     | flat_1k_1MB     | 2.29     | -&gt; 1.0`dirhash`           | flat_1k_1MB     | 1.67     | 1.36`dirhash`(8 workers)| flat_1k_1MB     | 0.48     | **4.73**shell reference     | nested_32k_32kB | 6.82     | -&gt; 1.0`dirhash`           | nested_32k_32kB | 3.43     | 2.00`dirhash`(8 workers)| nested_32k_32kB | 1.14     | **6.00**The benchmark was run a MacBook Pro (2018), further details and source code [here](https://github.com/andhus/dirhash-python/tree/master/benchmark).## DocumentationPlease refer to `dirhash -h`, the python [source code](https://github.com/andhus/dirhash-python/blob/master/src/dirhash/__init__.py) and the [Dirhash Standard](https://github.com/andhus/dirhash).</longdescription>
</pkgmetadata>