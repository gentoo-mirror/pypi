<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![ci](https://github.com/fidelity/jurity/actions/workflows/ci.yml/badge.svg?branch=master)](https://github.com/fidelity/jurity/actions/workflows/ci.yml) [![PyPI version fury.io](https://badge.fury.io/py/jurity.svg)](https://pypi.python.org/pypi/jurity/) [![PyPI license](https://img.shields.io/pypi/l/jurity.svg)](https://pypi.python.org/pypi/jurity/) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) [![Downloads](https://static.pepy.tech/personalized-badge/jurity?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=orange&amp;left_text=Downloads)](https://pepy.tech/project/jurity)# Jurity: Fairness &amp; Evaluation LibraryJurity is a research library that provides fairness metrics, recommender system evaluations, classification metrics and bias mitigation techniques. The library adheres to PEP-8 standards and is tested heavily.Jurity is developed by the Artificial Intelligence Center of Excellence at Fidelity Investments. Documentation is available at [fidelity.github.io/jurity](https://fidelity.github.io/jurity).## Fairness Metrics* [Average Odds](https://fidelity.github.io/jurity/about_fairness.html#average-odds)* [Disparate Impact](https://fidelity.github.io/jurity/about_fairness.html#disparate-impact)* [Equal Opportunity](https://fidelity.github.io/jurity/about_fairness.html#equal-opportunity)* [False Negative Rate (FNR) Difference](https://fidelity.github.io/jurity/about_fairness.html#fnr-difference)* [False Omission Rate (FOR) Difference](https://fidelity.github.io/jurity/about_fairness.html#for-difference)* [Generalized Entropy Index](https://fidelity.github.io/jurity/about_fairness.html#generalized-entropy-index)* [Predictive Equality](https://fidelity.github.io/jurity/about_fairness.html#predictive-equality)* [Statistical Parity](https://fidelity.github.io/jurity/about_fairness.html#statistical-parity)* [Theil Index](https://fidelity.github.io/jurity/about_fairness.html#theil-index)## Binary Bias Mitigation Techniques* [Equalized Odds](https://fidelity.github.io/jurity/about_fairness.html#equalized-odds)## Recommenders Metrics* [AUC: Area Under the Curve](https://fidelity.github.io/jurity/about_reco.html#auc-area-under-the-curve)* [CTR: Click-through rate](https://fidelity.github.io/jurity/about_reco.html#ctr-click-through-rate)* [DR: Doubly robust estimation](https://fidelity.github.io/jurity/about_reco.html#ctr-click-through-rate)* [IPS: Inverse propensity scoring](https://fidelity.github.io/jurity/about_reco.html#ctr-click-through-rate)* [MAP@K: Mean Average Precision](https://fidelity.github.io/jurity/about_reco.html#map-mean-average-precision)* [NDCG: Normalized discounted cumulative gain](https://fidelity.github.io/jurity/about_reco.html#ndcg-normalized-discounted-cumulative-gain)* [Precision@K](https://fidelity.github.io/jurity/about_reco.html#precision)* [Recall@K](https://fidelity.github.io/jurity/about_reco.html#recall)* [Inter-List Diversity@K](https://fidelity.github.io/jurity/about_reco.html#inter-list-diversity)* [Intra-List Diversity@K](https://fidelity.github.io/jurity/about_reco.html#intra-list-diversity)## Classification Metrics* [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)* [AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)* [F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)* [Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)* [Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)## Quick Start: Fairness Evaluation```python# Import binary and multi-class fairness metricsfrom jurity.fairness import BinaryFairnessMetrics, MultiClassFairnessMetrics# Databinary_predictions = [1, 1, 0, 1, 0, 0]multi_class_predictions = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;]multi_class_multi_label_predictions = [[&quot;a&quot;, &quot;b&quot;], [&quot;b&quot;, &quot;c&quot;], [&quot;b&quot;], [&quot;a&quot;, &quot;b&quot;], [&quot;c&quot;, &quot;a&quot;], [&quot;c&quot;]]is_member = [0, 0, 0, 1, 1, 1]classes = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]# Metrics (see also other available metrics)metric = BinaryFairnessMetrics.StatisticalParity()multi_metric = MultiClassFairnessMetrics.StatisticalParity(classes)# Scoresprint(&quot;Metric:&quot;, metric.description)print(&quot;Lower Bound: &quot;, metric.lower_bound)print(&quot;Upper Bound: &quot;, metric.upper_bound)print(&quot;Ideal Value: &quot;, metric.ideal_value)print(&quot;Binary Fairness score: &quot;, metric.get_score(binary_predictions, is_member))print(&quot;Multi-class Fairness scores: &quot;, multi_metric.get_scores(multi_class_predictions, is_member))print(&quot;Multi-class multi-label Fairness scores: &quot;, multi_metric.get_scores(multi_class_multi_label_predictions, is_member))```## Quick Start: Bias Mitigation```python# Import binary fairness and binary bias mitigationfrom jurity.mitigation import BinaryMitigationfrom jurity.fairness import BinaryFairnessMetrics# Datalabels = [1, 1, 0, 1, 0, 0, 1, 0]predictions = [0, 0, 0, 1, 1, 1, 1, 0]likelihoods = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.1]is_member = [0, 0, 0, 0, 1, 1, 1, 1]# Bias Mitigationmitigation = BinaryMitigation.EqualizedOdds()# Training: Learn mixing rates from the labeled datamitigation.fit(labels, predictions, likelihoods, is_member)# Testing: Mitigate bias in predictionsfair_predictions, fair_likelihoods = mitigation.transform(predictions, likelihoods, is_member)# Scores: Fairness before and afterprint(&quot;Fairness Metrics Before:&quot;, BinaryFairnessMetrics().get_all_scores(labels, predictions, is_member), '\n'+30*'-')print(&quot;Fairness Metrics After:&quot;, BinaryFairnessMetrics().get_all_scores(labels, fair_predictions, is_member))```## Quick Start: Recommenders Evaluation```python# Import recommenders metricsfrom jurity.recommenders import BinaryRecoMetrics, RankingRecoMetrics, DiversityRecoMetricsimport pandas as pd# Dataactual = pd.DataFrame({&quot;user_id&quot;: [1, 2, 3, 4], &quot;item_id&quot;: [1, 2, 0, 3], &quot;clicks&quot;: [0, 1, 0, 0]})predicted = pd.DataFrame({&quot;user_id&quot;: [1, 2, 3, 4], &quot;item_id&quot;: [1, 2, 2, 3], &quot;clicks&quot;: [0.8, 0.7, 0.8, 0.7]})item_features = pd.DataFrame({&quot;item_id&quot;: [0, 1, 2, 3], &quot;feature1&quot;: [1, 2, 2, 1], &quot;feature2&quot;: [0.8, 0.7, 0.8, 0.7]})# Metricsauc = BinaryRecoMetrics.AUC(click_column=&quot;clicks&quot;)ctr = BinaryRecoMetrics.CTR(click_column=&quot;clicks&quot;)dr = BinaryRecoMetrics.CTR(click_column=&quot;clicks&quot;, estimation='dr')ips = BinaryRecoMetrics.CTR(click_column=&quot;clicks&quot;, estimation='ips')map_k = RankingRecoMetrics.MAP(click_column=&quot;clicks&quot;, k=2)ncdg_k = RankingRecoMetrics.NDCG(click_column=&quot;clicks&quot;, k=3)precision_k = RankingRecoMetrics.Precision(click_column=&quot;clicks&quot;, k=2)recall_k = RankingRecoMetrics.Recall(click_column=&quot;clicks&quot;, k=2)interlist_diversity_k = DiversityRecoMetrics.InterListDiversity(click_column=&quot;clicks&quot;, k=2)intralist_diversity_k = DiversityRecoMetrics.IntraListDiversity(item_features, click_column=&quot;clicks&quot;, k=2)# Scoresprint(&quot;AUC:&quot;, auc.get_score(actual, predicted))print(&quot;CTR:&quot;, ctr.get_score(actual, predicted))print(&quot;Doubly Robust:&quot;, dr.get_score(actual, predicted))print(&quot;IPS:&quot;, ips.get_score(actual, predicted))print(&quot;MAP@K:&quot;, map_k.get_score(actual, predicted))print(&quot;NCDG:&quot;, ncdg_k.get_score(actual, predicted))print(&quot;Precision@K:&quot;, precision_k.get_score(actual, predicted))print(&quot;Recall@K:&quot;, recall_k.get_score(actual, predicted))print(&quot;Inter-List Diversity@K:&quot;, interlist_diversity_k.get_score(actual, predicted))print(&quot;Intra-List Diversity@K:&quot;, intralist_diversity_k.get_score(actual, predicted))```## Quick Start: Classification Evaluation```python# Import classification metricsfrom jurity.classification import BinaryClassificationMetrics# Datalabels = [1, 1, 0, 1, 0, 0, 1, 0]predictions = [0, 0, 0, 1, 1, 1, 1, 0]# Available: Accuracy, F1, Precision, Recall, and AUCf1_score = BinaryClassificationMetrics.F1()print('F1 score is', f1_score.get_score(predictions, labels))```## InstallationJurity requires **Python 3.7+** and can be installed from PyPI using ``pip install jurity`` or by building from source as shown in [installation instructions](https://fidelity.github.io/jurity/install.html).## SupportPlease submit bug reports and feature requests as [Issues](https://github.com/fidelity/jurity/issues).## LicenseJurity is licensed under the [Apache License 2.0.](https://github.com/fidelity/jurity/blob/master/LICENSE)</longdescription>
</pkgmetadata>