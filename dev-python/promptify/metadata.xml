<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;110px&quot; src=&quot;https://raw.githubusercontent.com/promptslab/Promptify/main/assets/logo.png&quot;&gt;&lt;h1&gt;Promptify&lt;/h1&gt;&lt;/div&gt;&lt;!-- &lt;h2 align=&quot;center&quot;&gt;Promptify&lt;/h2&gt; --&gt;&lt;p align=&quot;center&quot;&gt;  &lt;p align=&quot;center&quot;&gt;Prompt Engineering, Solve NLP Problems with LLM's &amp; Easily generate different NLP Task prompts for popular generative models like GPT, PaLM, and more with Promptify&lt;/p&gt;&lt;/p&gt; &lt;h4 align=&quot;center&quot;&gt;  &lt;a href=&quot;https://github.com/promptslab/Promptify/blob/main/LICENSE&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot; alt=&quot;Promptify is released under the Apache 2.0 license.&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;https://pypi.org/project/promptify/&quot;&gt;    &lt;img src=&quot;https://badge.fury.io/py/Promptify.svg&quot; alt=&quot;PyPI version&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;http://makeapullrequest.com&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;http://makeapullrequest.com&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;https://discord.gg/m88xfYMbK6&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/Discord-Community-orange&quot; alt=&quot;Community&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;#&quot;&gt;    &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;colab&quot; /&gt;  &lt;/a&gt;&lt;/h4&gt;&lt;img width=&quot;910px&quot; src=&quot;https://raw.githubusercontent.com/promptslab/Promptify/main/assets/dark.png&quot;&gt;## Installation### With pipThis repository is tested on Python 3.7+, openai 0.25+.You should install Promptify using Pip command```bashpip3 install promptify```or```bashpip3 install git+https://github.com/promptslab/Promptify.git```## Quick tourTo immediately use a LLM model for your NLP task, we provide the `Pipeline` API.```pythonfrom promptify import Prompter,OpenAI, Pipelinesentence     =  &quot;&quot;&quot;The patient is a 93-year-old female with a medical                   history of chronic right hip pain, osteoporosis,                hypertension, depression, and chronic atrial                fibrillation admitted for evaluation and management                of severe nausea and vomiting and urinary tract                infection&quot;&quot;&quot;model        = OpenAI(api_key) # or `HubModel()` for Huggingface-based inference or 'Azure' etcprompter     = Prompter('ner.jinja') # select a template or provide custom templatepipe         = Pipeline(prompter , model)result = pipe.fit(sentence, domain=&quot;medical&quot;, labels=None)### Output[    {&quot;E&quot;: &quot;93-year-old&quot;, &quot;T&quot;: &quot;Age&quot;},    {&quot;E&quot;: &quot;chronic right hip pain&quot;, &quot;T&quot;: &quot;Medical Condition&quot;},    {&quot;E&quot;: &quot;osteoporosis&quot;, &quot;T&quot;: &quot;Medical Condition&quot;},    {&quot;E&quot;: &quot;hypertension&quot;, &quot;T&quot;: &quot;Medical Condition&quot;},    {&quot;E&quot;: &quot;depression&quot;, &quot;T&quot;: &quot;Medical Condition&quot;},    {&quot;E&quot;: &quot;chronic atrial fibrillation&quot;, &quot;T&quot;: &quot;Medical Condition&quot;},    {&quot;E&quot;: &quot;severe nausea and vomiting&quot;, &quot;T&quot;: &quot;Symptom&quot;},    {&quot;E&quot;: &quot;urinary tract infection&quot;, &quot;T&quot;: &quot;Medical Condition&quot;},    {&quot;Branch&quot;: &quot;Internal Medicine&quot;, &quot;Group&quot;: &quot;Geriatrics&quot;},] ```&lt;p float=&quot;left&quot;&gt;  &lt;img src=&quot;https://raw.githubusercontent.com/promptslab/Promptify/main/assets/ner.png&quot; width=&quot;250&quot; /&gt;  &lt;img src=&quot;https://raw.githubusercontent.com/promptslab/Promptify/main/assets/multilabel.png&quot; width=&quot;250&quot; /&gt;   &lt;img src=&quot;https://raw.githubusercontent.com/promptslab/Promptify/main/assets/qa_gen.png&quot; width=&quot;250&quot; /&gt;&lt;/p&gt;&lt;h4 align=&quot;center&quot;&gt;GPT-3 Example with NER, MultiLabel, Question Generation Task&lt;/h3&gt;&lt;h2&gt;Features üéÆ &lt;/h2&gt;&lt;ul&gt;  &lt;li&gt; Perform NLP tasks (such as NER and classification) in just 2 lines of code, with no training data required&lt;/li&gt;  &lt;li&gt; Easily add one shot, two shot, or few shot examples to the prompt&lt;/li&gt;  &lt;li&gt; Handling out-of-bounds prediction from LLMS (GPT, t5, etc.)&lt;/li&gt;  &lt;li&gt; Output always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering. This is a major advantage over LLMs generated output, whose unstructured and raw output makes it difficult to use in business or other applications.&lt;/li&gt;  &lt;li&gt; Custom examples and samples can be easily added to the prompt&lt;/li&gt;  &lt;li&gt; ü§ó Run inference on any model stored on the Huggingface Hub (see &lt;a href=&quot;https://github.com/promptslab/Promptify/blob/main/notebooks/huggingface.ipynb&quot;&gt;notebook guide&lt;/a&gt;).&lt;/li&gt;  &lt;li&gt; Optimized prompts to reduce OpenAI token costs (coming soon)&lt;/li&gt;&lt;/ul&gt;### Supporting wide-range of Prompt-Based NLP tasks :| Task Name | Colab Notebook | Status ||-------------|-------|-------|| Named Entity Recognition | [NER Examples with GPT-3](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing) | ‚úÖ  || Multi-Label Text Classification | [Classification Examples with GPT-3](https://colab.research.google.com/drive/1gNqDxNyMMUO67DxigzRAOa7C_Tcr2g6M?usp=sharing) | ‚úÖ    || Multi-Class Text Classification | [Classification Examples with GPT-3](https://colab.research.google.com/drive/1gNqDxNyMMUO67DxigzRAOa7C_Tcr2g6M?usp=sharing) | ‚úÖ    || Binary Text Classification  | [Classification Examples with GPT-3](https://colab.research.google.com/drive/1gNqDxNyMMUO67DxigzRAOa7C_Tcr2g6M?usp=sharing) | ‚úÖ    || Question-Answering | [QA Task Examples with GPT-3](https://colab.research.google.com/drive/1Yhl7iFb7JF0x89r1L3aDuufydVWX_VrL?usp=sharing) | ‚úÖ    || Question-Answer Generation | [QA Task Examples with GPT-3](https://colab.research.google.com/drive/1Yhl7iFb7JF0x89r1L3aDuufydVWX_VrL?usp=sharing) | ‚úÖ    || Relation-Extraction | [Relation-Extraction Examples with GPT-3](https://colab.research.google.com/drive/1iW4QNjllc8ktaQBWh3_04340V-tap1co?usp=sharing) | ‚úÖ    || Summarization  | [Summarization Task Examples with GPT-3](https://colab.research.google.com/drive/1PlXIAMDtrK-RyVdDhiSZy6ztcDWsNPNw?usp=sharing) | ‚úÖ    || Explanation    | [Explanation Task Examples with GPT-3](https://colab.research.google.com/drive/1PlXIAMDtrK-RyVdDhiSZy6ztcDWsNPNw?usp=sharing) | ‚úÖ    || SQL Writer    | [SQL Writer Example with GPT-3](https://colab.research.google.com/drive/1JNUYCTdqkdeIAxiX-NzR-4dngdmWj0rV?usp=sharing) | ‚úÖ    || Tabular Data | |    || Image Data | |     || More Prompts | |     |## Docs[Promptify Docs](https://promptify.readthedocs.io/)## Community &lt;div align=&quot;center&quot;&gt;If you are interested in Prompt-Engineering, LLMs, ChatGPT and other latest research discussions, please consider joining &lt;a href=&quot;https://discord.gg/m88xfYMbK6&quot;&gt;PromptsLab&lt;/a&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;Join us on Discord&quot; src=&quot;https://img.shields.io/discord/1069129502472556587?color=5865F2&amp;logo=discord&amp;logoColor=white&quot;&gt;&lt;/div&gt;```@misc{Promptify2022,  title = {Promptify: Structured Output from LLMs},  author = {Pal, Ankit},  year = {2022},  howpublished = {\url{https://github.com/promptslab/Promptify}},  note = {Prompt-Engineering components for NLP tasks in Python}}```## üíÅ ContributingWe welcome any contributions to our open source project, including new features, improvements to infrastructure, and more comprehensive documentation. Please see the [contributing guidelines](contribute.md)</longdescription>
</pkgmetadata>