<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># pyspark_dbscanAn Implementation of DBSCAN onÂ PySpark```pythonimport dbscanfrom sklearn.datasets import make_blobsfrom pyspark.sql import types as T, SparkSessionfrom scipy.spatial import distancespark = SparkSession \        .builder \        .appName(&quot;DBSCAN&quot;) \        .config(&quot;spark.jars.packages&quot;, &quot;graphframes:graphframes:0.7.0-spark2.3-s_2.11&quot;) \        .config('spark.driver.host', '127.0.0.1') \        .getOrCreate()X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4, random_state=5)data = [(i, [float(item) for item in X[i]]) for i in range(X.shape[0])]schema = T.StructType([T.StructField(&quot;id&quot;, T.IntegerType(), False),                               T.StructField(&quot;value&quot;, T.ArrayType(T.FloatType()), False)])#please repartition appropriately                            df = spark.createDataFrame(data, schema=schema).repartition(10)df_clusters = dbscan.process(spark, df, .2, 10, distance.euclidean, 2, &quot;checkpoint&quot;)```</longdescription>
</pkgmetadata>