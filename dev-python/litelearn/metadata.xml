<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># litelearna python library for building models without fussingover the nitty gritty details for data munging## installation`pip install litelearn`## usageonce you have a `pandas` dataframe you can create a model for your dataset in 3 lines of code:### Regression```python# load some datasetimport seaborn as snsdataset = &quot;penguins&quot;target = &quot;body_mass_g&quot;df = sns.load_dataset(dataset).dropna(subset=[target])# just 3 lines of code to create and evaluate a modelimport litelearn as llmodel = ll.regress_df(df, target)model.display_evaluation() ```### Classification```python# load some datasetimport seaborn as snsdataset = &quot;penguins&quot;target = &quot;species&quot;df = sns.load_dataset(dataset).dropna(subset=[target])# just 3 lines of code to create and evaluate a modelimport litelearn as llmodel = ll.classify_df(df, target)model.display_evaluation()```### Predictionprediction is easy too, it will work on any data that resembles the training data.dtypes don't have to match, and you can even have extra columns in your prediction data.missing values and unknown categories will be imputed with the training data's values.```pythondf = ...  # load some dataframesplit = int(len(df) * 0.8)train_df, val_df = df[:split], df[split:] model = ...  # build some modelpred = model.predict(val)  # predict on unseen data```## features+ does all the data munging for you, including missing data, categorical data handling+ uses the robust [catboost](https://catboost.ai/) library for gradient boosting, which is known for generating  high quality models with little tuning+ supports [shap](https://github.com/slundberg/shap) for explainability.  call `model.display_shap()` or `model.get_shap()` to get the shap values for your model+ supports sklearn's [permutation importance](https://scikit-learn.org/stable/modules/permutation_importance.html)  call `model.display_permutation_importance()` or `model.get_permutation_importance()`   to get feature importances that are biased towards the model's performance on test data.+ supports easy pickling: to save your model simply call `model.save(&quot;path/to/model.pkl&quot;)`  and to load your model call `model.load(&quot;path/to/model.pkl&quot;)`+ for regression models, you can call `model.display_residuals()` to see the residuals of your model+ it also supports segmeents for your data using the `model.set_segments()` method.  this will create a new column in your dataframe called `segment` which you can use to  group your data. this is useful for seeing how your model performs on different segments of your data. </longdescription>
</pkgmetadata>