<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;    &lt;a href=&quot;https://badge.fury.io/py/balanced-loss&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/balanced-loss.svg&quot; alt=&quot;pypi version&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/34196005/180311379-1003da44-cdf9-46e8-af83-e65fbc3710cd.png&quot; width=&quot;350&quot;&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    Easy-to-use, class-balanced, cross-entropy and focal loss implementation for Pytorch.&lt;/p&gt;## TheoryWhen training dataset labels are imbalanced, one thing to do is to balance the loss across sample classes.- First, the effective number of samples are calculated for all classes as:![alt-text](https://user-images.githubusercontent.com/34196005/180266195-aa2e8696-cdeb-48ed-a85f-7ffb353942a4.png)- Then the class balanced loss function is defined as:![alt-text](https://user-images.githubusercontent.com/34196005/180266198-e27d8cba-f5e1-49ca-9f82-d8656333e3c4.png)## Installation```bashpip install balanced-loss```## Usage- Standard losses:```pythonimport torchfrom balanced_loss import Loss# outputs and labelslogits = torch.tensor([[0.78, 0.1, 0.05]]) # 1 batch, 3 classlabels = torch.tensor([0]) # 1 batch# focal lossfocal_loss = Loss(loss_type=&quot;focal_loss&quot;)loss = focal_loss(logits, labels)``````python# cross-entropy lossce_loss = Loss(loss_type=&quot;cross_entropy&quot;)loss = ce_loss(logits, labels)``````python# binary cross-entropy lossbce_loss = Loss(loss_type=&quot;binary_cross_entropy&quot;)loss = bce_loss(logits, labels)```- Class-balanced losses:```pythonimport torchfrom balanced_loss import Loss# outputs and labelslogits = torch.tensor([[0.78, 0.1, 0.05]]) # 1 batch, 3 classlabels = torch.tensor([0]) # 1 batch# number of samples per class in the training datasetsamples_per_class = [30, 100, 25] # 30, 100, 25 samples for labels 0, 1 and 2, respectively# class-balanced focal lossfocal_loss = Loss(    loss_type=&quot;focal_loss&quot;,    samples_per_class=samples_per_class,    class_balanced=True)loss = focal_loss(logits, labels)``````python# class-balanced cross-entropy lossce_loss = Loss(    loss_type=&quot;cross_entropy&quot;,    samples_per_class=samples_per_class,    class_balanced=True)loss = ce_loss(logits, labels)``````python# class-balanced binary cross-entropy lossbce_loss = Loss(    loss_type=&quot;binary_cross_entropy&quot;,    samples_per_class=samples_per_class,    class_balanced=True)loss = bce_loss(logits, labels)```- Customize parameters:```pythonimport torchfrom balanced_loss import Loss# outputs and labelslogits = torch.tensor([[0.78, 0.1, 0.05]]) # 1 batch, 3 classlabels = torch.tensor([0])# number of samples per class in the training datasetsamples_per_class = [30, 100, 25] # 30, 100, 25 samples for labels 0, 1 and 2, respectively# class-balanced focal lossfocal_loss = Loss(    loss_type=&quot;focal_loss&quot;,    beta=0.999, # class-balanced loss beta    fl_gamma=2, # focal loss gamma    samples_per_class=samples_per_class,    class_balanced=True)loss = focal_loss(logits, labels)```## ImprovementsWhat is the difference between this repo and vandit15's?- This repo is a pypi installable package- This repo implements loss functions as `torch.nn.Module`- In addition to class balanced losses, this repo also supports the standard versions of the cross entropy/focal loss etc. over the same API- All typos and errors in vandit15's source are fixed## Referenceshttps://arxiv.org/abs/1901.05555https://github.com/richardaecn/class-balanced-losshttps://github.com/vandit15/Class-balanced-loss-pytorch</longdescription>
</pkgmetadata>