<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># pypduThis module provides basic read-only access to the data contained in Prometheus on-disk files from Python.`pypdu` may be installed from pip (on linux and macOS):```pip install pypdu````pypdu` can optionally expose samples in a numpy array if `numpy` is installed.If you need this, you can either ensure `numpy` is installed, or have it pulled in by `pypdu` as a dependency with:```pip install pypdu[numpy]```Example usage:```#!/usr/bin/env python3import pypdudata = pypdu.load(&quot;/path/to/stats_data&quot;)for series in data:    print(series.name) # equivalent to series.labels[&quot;__name__&quot;]    print(series.labels)    print(len(series.samples)) # number of samples can be computed                               # without iterating all of them    for sample in series.samples:        print(f&quot;{sample.timestamp} : {sample.value}&quot;)``` Or the series and samples can be unpacked:```for name, labels, samples in data:    print(name)    print(labels)    print(len(samples))    for timestamp, value in samples:        print(f&quot;{timestamp} : {value}&quot;)```#### numpyIf numpy is installed, samples can additionally be accessed as a numpy array. This may avoid copying the samples around if your code expects numpy arrays. E.g.,```for name, labels, samples in data:    arr = samples.as_array()    print(arr.dtype)    print(arr[0])```prints:```dtype([('timestamp', '&lt;i8'), ('value', '&lt;f8')])(1653556688725, 0.)```If numpy is _not_ available at runtime, this will raise an exception:```RuntimeError: Accessing samples as a numpy array requires numpy to be installed```#### Filtering time seriesIf only a subset of the time series are desired, `pypdu` can filter them based on label values, and avoid parsing unneeded series at all:```for series in data.filter({&quot;__name__&quot;:&quot;sysproc_page_faults_raw&quot;}):```This will usually perform better than filtering &quot;manually&quot; in python after the fact.Multiple labels can be specified:```data.filter({&quot;__name__&quot;:&quot;sysproc_page_faults_raw&quot;, &quot;proc&quot;:&quot;memcached&quot;})```ECMAScript regexes can also be used:```data.filter({&quot;proc&quot;:pypdu.regex(&quot;^go.*&quot;)})```Or even arbitrary Python callbacks:```data.filter({&quot;proc&quot;:lambda x: x.startswith(&quot;go&quot;)})```As shorthand, when filtering on `__name__` alone, just a string may be provided.```data.filter(&quot;sysproc_page_faults_raw&quot;)```#### Single series lookupIf there is only one time series matching your filter, for convenience you can do:```foobar_series = data[{&quot;__name__&quot;:&quot;foobar&quot;}]```This is roughly equivalent to:```foobar_series = next(iter(data.filter({&quot;__name__&quot;:&quot;foobar&quot;})))```If there are multiple time series matching your filter, this will silently discard all but the lexicographically first (sorted by the key and value of all labels).If none match, a `KeyError` is raised.All types of filter demonstrated above with `.filter(...)` may be used in this manner also.#### CalculationsSimple operations `(+ - / *)` may be applied to `Series` objects, computing the result lazily.```a = data[&quot;foobar&quot;]b = data[&quot;bazqux&quot;]c = data[&quot;spam&quot;]expression = (a + b) * (c / 100)for timestamp, value in expression:    ...```Note: the resulting iterable will contain a sample at each timestamp seen in _any_ of the constituent series. Even if all series are scraped with the same interval, if they are offset from each other this can lead to a lot of values. To avoid this, the expression can be resampled at a given interval:```for timestamp, value in expression.resample(10000): # 10s in ms    ...```This will lead to one sample _exactly_ every 10000 milliseconds. No interpolation is performed - if a given series did not have a sample at a chosen instant, the most recent value will be used.###### IRate```pypdu.irate(expr)```Results in a `Expression` which computes the instantaneous rate of change based on the current and previous sample - roughly equivalent to Prometheus `irate`.e.g.,```a = data[&quot;foobar&quot;]b = data[&quot;bazqux&quot;]rate = pypdu.irate(a+b/100)for timestamp, rate_value in rate:    ....```###### SumAs `Expression` supports addition, the standard Python method `sum` can be used to add multiple series together.However, if working with a very large number of series, `pypdu.sum` may more efficiently construct the `Expression` result (computation of the summed `Samples` is identical, however).e.g.,```series_list = list(data)py_sum_expr = sum(series_list)pdu_sum_expr = pypdu.sum(series_list) # may be faster if len(series_list) is large# but the resulting samples are identicalassert(list(pdu_sum_expr) == list(py_sum_expr))```#### Histograms`PrometheusData(...).histograms` allows iterating all histograms represented by the time series in a data directory.The histograms are exposed as `HistogramTimeSeries`, grouping all the component `..._bucket` time series together. Indexing into this series provides access to the histogram at a single point in time.e.g.,```data = pypdu.load(&quot;&lt;...&gt;&quot;)for histSeries in data.histograms:    print(&quot;Labels: &quot;, histSeries.labels)    print(&quot;Number of samples: &quot;, len(histSeries))    for hist in histSeries:        print(&quot;TS: &quot;, hist.timestamp)        print(hist.buckets())```Iterates over every histogram found in the Prometheus data, then iterates over every sample contained in that time series.Example output:```Labels:  {'__name__': 'cm_http_requests_seconds', 'instance': 'ns_server', 'job': 'ns_server_high_cardinality'}Number of samples:  3826TS:  1621268098827[(0.001, 8.0), (0.01, 25.0), (0.1, 25.0), (1.0, 25.0), (10.0, 25.0), (inf, 25.0)]TS:  1621268158827[(0.001, 39.0), (0.01, 118.0), (0.1, 126.0), (1.0, 127.0), (10.0, 127.0), (inf, 127.0)]TS:  1621268218827[(0.001, 43.0), (0.01, 132.0), (0.1, 140.0), (1.0, 141.0), (10.0, 141.0), (inf, 141.0)]TS:  1621268278827[(0.001, 48.0), (0.01, 145.0), (0.1, 153.0), (1.0, 154.0), (10.0, 154.0), (inf, 154.0)]TS:  1621268338827[(0.001, 53.0), (0.01, 158.0), (0.1, 166.0), (1.0, 167.0), (10.0, 167.0), (inf, 167.0)]TS:  1621268398827[(0.001, 55.0), (0.01, 171.0), (0.1, 179.0), (1.0, 180.0), (10.0, 180.0), (inf, 180.0)]TS:  1621268458827[(0.001, 60.0), (0.01, 191.0), (0.1, 199.0), (1.0, 200.0), (10.0, 200.0), (inf, 200.0)]TS:  1621268518827[(0.001, 66.0), (0.01, 204.0), (0.1, 212.0), (1.0, 213.0), (10.0, 213.0), (inf, 213.0)]TS:  1621268578827[(0.001, 71.0), (0.01, 217.0), (0.1, 225.0), (1.0, 226.0), (10.0, 226.0), (inf, 226.0)]TS:  1621268638827[(0.001, 73.0), (0.01, 230.0), (0.1, 238.0), (1.0, 239.0), (10.0, 239.0), (inf, 239.0)]...Labels: ...````HistogramTimeSeries` (in the above example, this is `histSeries`), can be indexed into - currentlyonly by a sample index, but in the future, selecting the histogram closest to a given timestamp may be supported.E.g., the first and last point in time view available for a specific histogram can be found with:```first = histSeries[0]last = histSeries[-1]```From which the timestamp and buckets could be read:```&gt;&gt;&gt; print(last.timestamp) # time since epoch in ms1631007596974&gt;&gt;&gt; print(last.bucket_bounds()))[0.001, 0.01, 0.1, 1.0, 10.0, inf]&gt;&gt;&gt; print(last.bucket_values())[4279.0, 4371.0, 4666.0, 5044.0, 5044.0, 5044.0]&gt;&gt;&gt; print(last.buckets()) # convenience zip of (bounds, values)[(0.001, 4279.0), (0.01, 4371.0), (0.1, 4666.0), (1.0, 5044.0), (10.0, 5044.0), (inf, 5044.0)]```The difference between histograms at two points in time can also be calculated:```delta = last-first&gt;&gt;&gt; delta.time_delta60000&gt;&gt;&gt; delta.buckets()[(0.001, 653.0), (0.01, 653.0), (0.1, 653.0), (1.0, 653.0), (10.0, 653.0), (inf, 653.0)]```Or the summation of two histograms:```total = histA+histB&gt;&gt;&gt; total.buckets()[(0.001, 1985.0), (0.01, 1985.0), (0.1, 1985.0), (1.0, 1985.0), (10.0, 1985.0), (inf, 1985.0)]```For either of addition or subtraction, the bucket boundaries must exactly match.#### SerialisationTime series may be dumped individually to a file or bytes. This may be useful if you need to store some number of series (e.g., in a key-value store), but don't wish to retain the entire Prometheus data directory.`pypdu.dump`/`pypdu.load` take an `int` file descriptor or, for convenience, a file-like object supporting `fileLike.fileno() -&gt; int`.These methods be used to read/write data from/to a pipe or socket, not just a file on disk. Note, arbitrary file-like objects which are not backed by a file descriptor are not supported.If provided a file handle which actually refers to a file on disk, `load` will try to mmap the file. If this fails, it will fall back to reading it like a stream. If mmapping is not desired, it can be disabled with:```pypdu.load(fileDescriptor, allow_mmap=False)```When `load`ing many series from a _stream_ (socket, pipe, etc), the underlying data for all Series will be read into memory - this may be costly if there are many Series. `pypdu.load_lazy` can instead be used to consume Series from a stream, one at a time.```for series in pypdu.load_lazy(someSocket):    # series are read and deserialised on demand while iterating````pypdu.dumps` creates a `bytes` object, while `pypdu.loads` operates on a [buffer](https://docs.python.org/3/c-api/buffer.html). Anything supporting the buffer protocol exposing a contiguous buffer may be used. This includes `bytes` objects, but also `numpy` arrays and many other types.A [memoryview](https://docs.python.org/3/library/stdtypes.html#memoryview) may be used to slice a buffer, allowing deserialisation from _part_ of a buffer, without having to copy out the relevant bytes.```# fd : int or file-like object with .fileno() methodpypdu.dump(fd, series)pypdu.dump(fd, [series, series, ...])pypdu.dump(fd, PrometheusData)# note, dumps on a lot of series will consume a lot of memory building# a big bytes objectpypdu.dumps(series) -&gt; bytespypdu.dumps([series, series, ...]) -&gt; bytespypdu.dumps(PrometheusData) -&gt; bytes# result of load{,s} depends on what was written# Deserialised series are entirely in-memory, may consume a lot of# memory.pypdu.load(fd) -&gt; Seriespypdu.load(fd) -&gt; [Series, Series,...]pypdu.loads(buffer) -&gt; Seriespypdu.loads(buffer) -&gt; [Series, Series, ...]# when loading a lot of series, this is the advised way to avoid# holding them all in memory at the same timepypdu.load_lazy(fd) -&gt; Iterable```Example dumping and loading multiple series to/from a file:```to_serialise = []for series in pypdu.load(&quot;foobar/baz/stats_data&quot;):    if some_condition(series):        to_serialise.append(series)with open(&quot;somefile&quot;, &quot;wb&quot;) as f:    pypdu.dump(f, to_serialise)...with open(&quot;somefile&quot;, &quot;rb&quot;) as f:    for series in pypdu.load_lazy(f):        # do something with the loaded series```Example dumping and loading a single series to/from stdin/out:```data = pypdu.load(&quot;foobar/baz/stats_data&quot;)series = data[&quot;foobar_series_name&quot;]pypdu.dump(sys.stdout, series)...series = pypdu.load(sys.stdin)```#### Runtime version checkingThe `pypdu` version can be specified at install time (e.g., in `requirements.txt`), but you can also verify the correct version is available at runtime (maybe someone is building locally and forgot to update some dependencies!).```&gt;&gt;&gt; import pypdu&gt;&gt;&gt; pypdu.__version__'0.0.12a3'&gt;&gt;&gt; pypdu.__git_rev__'a096f0d'&gt;&gt;&gt; pypdu.__git_tag__''&gt;&gt;&gt; pypdu.require(0, 0, 0)&gt;&gt;&gt; pypdu.require(0, 0, 12)&gt;&gt;&gt; pypdu.require(0, 1, 0)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;RuntimeError: Current pypdu version 0.0.12a3 does not meet required 0.1.0&gt;&gt;&gt; pypdu.require(0, 0, 12, &quot;a3&quot;)&gt;&gt;&gt; pypdu.require(0, 0, 12, &quot;a4&quot;)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;RuntimeError: Current pypdu version 0.0.12a3 does not meet required 0.0.12a4```If using a feature introduced in version `X.Y.Z`, `pypdu.require(X, Y, Z)` will raise an exception if an older version is in use.This exception can be caught, if you want to provide a more specific error message (e.g., &quot;Remember to update dependencies by running ...&quot;).#### Alternative installation steps##### pip install from sourceIf a wheel is not available for your platform or architecture, `pypdu` can be built and installed with:```pip install git+https://github.com/jameseh96/pdu.git```or for a specific version:```pip install git+https://github.com/jameseh96/pdu.git@vX.Y.Ze.g.,pip install git+https://github.com/jameseh96/pdu.git@v0.0.19```Building `pypdu` will require the dependencies listed in the [installation instructions](https://github.com/jameseh96/pdu#installing).`pypdu` is relatively platform independent, but has not been tested on platforms/architectures that don't have a wheel built (e.g., Windows, MacOS+Apple Silicon) - be prepared for potential issues at build and runtime.##### setup.py`pypdu` may be installed without `pip`. To use, clone the repository as in the [installation instructions](https://github.com/jameseh96/pdu#installing).Then run:```python setup.py install```##### manual .soAlternatively, following the `cmake` steps in the [installation instructions](https://github.com/jameseh96/pdu#installing) to build the project produces a module with a platform-dependent name - for example on MacOS this may be `pypdu.cpython-39-darwin.so`.This can be found either in `&lt;build dir&gt;/src/pypdu` or in your chosen installation prefix. This can be used without installing with `setup.py`, simply ensure the containing directory is in your `PYTHONPATH`.</longdescription>
</pkgmetadata>