<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># asynkit: A toolkit for Python coroutines[![CI](https://github.com/kristjanvalur/py-asynkit/actions/workflows/ci.yml/badge.svg)](https://github.com/kristjanvalur/py-asynkit/actions/workflows/ci.yml)This module provides some handy tools for those wishing to have better control over theway Python's `asyncio` module does things.- Helper tools for controlling coroutine execution, such as `CoroStart` and `Monitor`- Utility classes such as `GeneratorObject`- Coroutine helpers such `coro_iter()` and the `awaitmethod()` decorator- Helpers to run _async_ code from _non-async_ code, such as `await_sync()` and `aiter_sync()` - Scheduling helpers for `asyncio`, and extended event-loop implementations- _eager_ execution of Tasks- Limited support for `anyio` and `trio`.# Installation```bash$ pip install asynkit```# Coroutine Tools## `eager()` - lower latency IODid you ever wish that your _coroutines_ started right away, and only returned control tothe caller once they become blocked?  Like the way the `async` and `await` keywords work in the __C#__ language?Now they can. Just decorate or convert them with `acynkit.eager`:```python@asynkit.eagerasync def get_slow_remote_data():    result = await execute_remote_request()    return result.important_dataasync def my_complex_thing():    # kick off the request as soon as possible    future = get_slow_remote_data()    # The remote execution may now already be in flight. Do some work taking time    intermediate_result = await some_local_computation()    # wait for the result of the request    return compute_result(intermediate_result, await future)```By decorating your function with `eager`, the coroutine will start executing __right away__ andcontrol will return to the calling function as soon as it _suspends_, _returns_, or _raises_an exception. In case it is suspended, a _Task_ is created and returned, ready to resumeexecution from that point.Notice how, in either case, control is returned __directly__ back to thecalling function, maintaining synchronous execution. In effect, conventional codecalling order is maintained as much as possible. We call this _depth-first-execution_.This allows you to prepare and dispatch long running operations __as soon as possible__ whilestill being able to asynchronously wait for the result.`asynkit.eager` can also be used directly on the returned coroutine:```pythonlog = []async def test():    log.append(1)    await asyncio.sleep(0.2)  # some long IO    log.append(2)async def caller(convert):    del log[:]    log.append(&quot;a&quot;)    future = convert(test())    log.append(&quot;b&quot;)    await asyncio.sleep(0.1)  # some other IO    log.append(&quot;c&quot;)    await future# do nothingasyncio.run(caller(lambda c: c))assert log == [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, 1, 2]# Create a Taskasyncio.run(caller(asyncio.create_task))assert log == [&quot;a&quot;, &quot;b&quot;, 1, &quot;c&quot;, 2]# eagerasyncio.run(caller(asynkit.eager))assert log == [&quot;a&quot;, 1, &quot;b&quot;, &quot;c&quot;, 2]````eager()` is actually a convenience function, invoking either `coro_eager()` or `func_eager()` (see below) depending on context.Decorating your function makes sense if you __always__ intendTo _await_ its result at some later point. Otherwise, just apply it at the pointof invocation in each such case. ## `coro_eager()`, `func_eager()``coro_eager()` is the magic coroutine wrapper providing the __eager__ behaviour:1. It copies the current _context_1. It initializes a `CoroStart()` object for the coroutine, starting it in the copied context.2. If it subsequently is `done()` It returns `CoroStart.as_future()`, ortherwise   it creates and returns a `Task` (using `asyncio.create_task` by default.)The result is an _awaitable_ which can be either directly awaited or passedto `asyncio.gather()`. The coroutine is executed in its own copy of the current context,just as would happen if it were directly turned into a `Task`.`func_eager()` is a decorator which automatically applies `coro_eager()` to the coroutine returned by an async function.## `await_sync(), aiter_sync()` - Running coroutines synchronouslyIf you are writing code which should work both synchronously and asynchronously,you can now write the code fully _async_ and then run it _synchronously_ in the absenceof an event loop.  As long as the code doesn't _block_ (await unfinished _futures_) and doesn't try to access the event loop, it can successfully be executed.  This helps avoid writing duplicate code.```pythonasync def async_get_processed_data(datagetter):    data = datagetter()  # an optionally async callback    data = await data if isawaitable(data) else data    return process_data(data)# raises SynchronousError if datagetter blocksdef sync_get_processed_data(datagetter):    return asynkit.await_sync(async_get_processed_data(datagetter))```This sort of code might previously have been written thus:```python# A hybrid function, _may_ return an _awaitable_def hybrid_get_processed_data(datagetter):    data = datagetter()    if isawaitable(data):        # return an awaitable helper closure        async def helper():            data = await data            return process_data(data)        return helper    return process_data(data)  # duplicationasync def async_get_processed_data(datagetter):    r = hybrid_get_processed_data(datagetter)    return await r if isawaitable(r) else rdef sync_get_processed_data(datagetter):    r = hybrid_get_processed_data(datagetter)    if isawaitable(r):        raise RuntimeError(&quot;callbacks failed to run synchronously&quot;)    return r```The above pattern, writing async methods as sync and returning async helpers,is common in library code which needs to work both in synchronous and asynchronouscontext.  Needless to say, it is very convoluted, hard to debug and contains a lotof code duplication where the same logic is repeated inside async helper closures.Using `await_sync()` it is possible to write the entire logic as `async` methods andthen simply fail if the code tries to invoke any truly async operations.If the invoked coroutine blocks, a `SynchronousError` is raised _from_ a `SynchronousAbort` exception whichcontains a traceback.  This makes it easy to pinpoint the location in the code where theasync code blocked.  If the code tries to access the event loop, e.g. by creating a `Task`, a `RuntimeError` will be raised.  The `syncfunction()` decorator can be used to automatically wrap an async functionso that it is executed using `await_sync()`:```pycon&gt;&gt;&gt; @asynkit.syncfunction... async def sync_function():...     async def async_function():...         return &quot;look, no async!&quot;...     return await async_function()...&gt;&gt;&gt; sync_function()'look, no async!'&gt;&gt;&gt;```the `asyncfunction()` utility can be used when passing synchronous callbacks to asynccode, to make them async.  This, along with `syncfunction()` and `await_sync()`,can be used to integrate synchronous code with async middleware:```python@asynkit.syncfunctionasync def sync_client(sync_callback):    middleware = AsyncMiddleware(asynkit.asyncfunction(sync_callback))    return await middleware.run()```Using this pattern, one can write the middleware completely async, make it also workfor synchronous code, while avoiding the hybrid function _antipattern._### `aiter_sync()`A helper function is provided, which turns an `AsyncIterable` intoa generator, leveraging the `await_sync()` method:```pythonasync def agen():    for v in range(3):        yield vassert list(aiter_sync(agen())) == [1, 2, 3]```This is useful if using patterns such as `GeneratorObject` in a synchronousapplication.## `CoroStart`This class manages the state of a partially run coroutine and is what what powers the `coro_eager()` and `await_sync()` functions. When initialized, it will _start_ the coroutine, running it until it either suspends, returns, or raisesan exception.  It can subsequently be _awaited_ to retreive the result.Similarly to a `Future`, it has these methods:- `done()` - returns `True` if the coroutine finished without blocking. In this case, the following two methods may be called to get the result.- `result()` - Returns the _return value_ of the coroutine or **raises** any _exception_ that it produced.- `exception()` - Returns any _exception_ raised, or `None` otherwise. But more importly it has these:- `__await__()` - A magic method making it directly _awaitable_. If it has already finished, awaiting this coroutine is the same as calling `result()`, otherwise it awaits the original coroutine's continued execution- `as_coroutine()` - A helper which returns a proper _coroutine_ object to await the `CoroStart`- `as_future()` - If `done()`, returns a `Future` holding its result, otherwise, a `RuntimeError`  is raised.- `as_awaitable()` - If `done()`, returns `as_future()`, else returns `self`.  This is a convenience method for use with functions such as `asyncio.gather()`, which would otherwise wrap a completed coroutine in a `Task`.In addition it has:- `aclose()` - If `not done()`, will throw a `GeneratorError` into the coroutine and wait for it to finish.  Otherwise does nothing.- `athrow(exc)` - If `not done()`, will throw the given error into the coroutine and wait for it to raise or return a value.- `close()` and `throw(exc)` - Synchronous versions of the above, will raise `RuntimeError` if the coroutine does not immediately exit.This means that a context manager such as `aclosing()` can be used to ensurethat the coroutine is cleaned up in case of errors before it is awaited:```python# start foo() and run until it blocksasync with aclosing(CoroStart(foo())) as coro:    ...  # do things, which may result in an error    return await coro```CoroStart can be provided with a `contextvars.Context` object, in which case the coroutine will be run using thatcontext.## Context helper`coro_await()` is a helper function to await a coroutine, optionally with a `contextvars.Context`object to activate:```pythonvar1 = contextvars.ContextVar(&quot;myvar&quot;)async def my_method():    var1.set(&quot;foo&quot;)async def main():    context = contextvars.copy_context()    var1.set(&quot;bar&quot;)    await asynkit.coro_await(my_method(), context=context)    # the coroutine didn't modify _our_ context    assert var1.get() == &quot;bar&quot;    # ... but it did modify the copied context    assert context.get(var1) == &quot;foo&quot;```This is similar to `contextvars.Context.run()` but works for async functions.  This function isimplemented using `CoroStart`## `awaitmethod` - decorator for `__await__` methodsThis decorator turns the decorated method into a `Generator` as required for`__await__` methods, which must only return `Iterator` objects.It does so by invoking the `coro_iter()` helper.This makes it simple to make a class _awaitable_ by decorating an `async``__await__()` method.```pythonclass Awaitable:    def __init__(self, cofunc):        self.cofunc = cofunc        self.count = 0    @asynkit.awaitmethod    async def __await__(self):        await self.cofunc()        return self.count        self.count += 1async def main():    async def sleeper():        await asyncio.sleep(1)    a = Awaitable(sleeper)    assert (await a) == 0  # sleep once    assert (await a) == 1  # sleep againasyncio.run(main())```Unlike a regular _coroutine_ (the result of calling a _coroutine function_), an object with an `__await__` method can potentially be awaited multiple times.## `Monitor`A `Monitor` object can be used to await a coroutine, while listening for _out of band_ messagesfrom the coroutine.  As the coroutine sends messages, it is suspended, until the caller resumesawaiting for it.```pythonasync def coro(monitor):    await monitor.oob(&quot;hello&quot;)    await asyncio.sleep(0)    await monitor.oob(&quot;dolly&quot;)    return &quot;done&quot;async def runner():    m = Monitor()    c = coro(m)    while True:        try:            print(await m.aawait(c))            break        except OOBData as oob:            print(oob.data)```which will result in the output```hellodollydone```For convenience, the `Monitor` can be _bound_ so that the caller does not haveto keep the coroutine around.  Calling the monitor with the coroutine returns a `BoundMonitor`:```pythonasync def coro(m):    await m.oob(&quot;foo&quot;)    return &quot;bar&quot;m = Monitor()b = m(coro(m))try:    await bexcept OOBData as oob:    assert oob.data == &quot;foo&quot;assert await b == &quot;bar&quot;```Notice how the `BoundMonitor` can be _awaited_ directly, which is the same as awaiting`b.aawait(None)`.The caller can pass in _data_ to the coroutine via the `aawait(data=None)` method andit will become the _return value_ of the `Monitor.oob()` call in the coroutine.`Monitor.athrow()` can similarly be used to raise an exception out of the `Montitor.oob()` call.Neither data nor an exception can be sent the first time the coroutine is awaited, only as a response to a previous `OOBData` exception.A `Monitor` can be used when a coroutine wants to suspend itself, maybe waiting for some extenalcondition, without resorting to the relatively heavy mechanism of creating, managing and synchronizing`Task` objects.  This can be useful if the coroutine needs to maintain state.  Additionally,this kind of messaging does not require an _event loop_ to be present and can can be drivenusing `await_sync()` (see below.)Consider the following scenario. A _parser_ wants to read a line from a buffer, but fails, signallingthis to the monitor:```pythonasync def readline(m, buffer):    l = buffer.readline()    while not l.endswith(&quot;\n&quot;):        await m.oob(None)  # ask for more data in the buffer        l += buffer.readline()    return lasync def manager(buffer, io):    m = Monitor()    a = m(readline(m, buffer))    while True:        try:            return await a        except OOBData:            try:                buffer.fill(await io.read())            except Exception as exc:                await a.athrow(exc)```In this example, `readline()` is trivial, but if it were a stateful parser with hierarchicalinvocation structure, then this pattern allows the decoupling of IO and the parsing of buffered data, maintaining the state of the parser while _the caller_ fills up the buffer.Any IO exception is sent to the coroutine in this example.  This ensures that it cleansup properly.  Alternatively, `aclose()` could have been used:```pythonm = Monitor()with aclosing(m(readline(m, buffer))) as a:    # the aclosing context manager ensures that the coroutine is closed    # with `await a.aclose()`    # even if we don't finish running it.    ...```A standalone parser can also be simply implemented by two helper methods, `start()` and`try_await()`.```pythonasync def stateful_parser(monitor, input_data):    while input_short(input_data):        input_data += await monitor.oob()  # request more    # continue parsing, maye requesting more data    return await parsed_data(monitor, input_data)m: Monitor[Tuple[Any, bytes]] = Monitor()initial_data = b&quot;&quot;p = m(stateful_parser(m, b&quot;&quot;))await p.start()  # set the parser running, calling oob()# feed data until a value is returnedwhile True:    parsed = await p.try_await(await get_more_data())    if parsed is not None:        break```This pattern can even be employed in non-async applications, by usingthe `await_sync()` method instead of the `await` keyword to drive the `Monitor`.For a more complete example, have a look at [example_resp.py](examples/example_resp.py)## `GeneratorObject`A `GeneratorObject` builds on top of the `Monitor` to create an `AsyncGenerator`.  It is in many wayssimilar to an _asynchronous generator_ constructed using the _generator function_ syntax.But wheras those return values using the `yield` _keyword_,a GeneratorObject has an `ayield()` _method_, which means that data can be sent to the generatorby anyone, and not just by using `yield`, which makes composing such generators much simpler.The `GeneratorObject` leverages the `Monitor.oob()` method to deliver the _ayielded_ data to whomever is iterating over it:```pythonasync def generator(gen_obj):    # yield directly to the generator    await gen_obj.ayield(1)    # have someone else yield to it    async def helper():        await gen_obj.ayield(2)    await asyncio.create_task(helper())async def runner():    gen_obj = GeneratorObject()    values = [val async for val in gen_obj(generator(gen_obj))]    assert values == [1, 2]```The `GeneratorObject`, when called, returns a `GeneratorObjectIterator` which behaves inthe same way as an `AsyncGenerator` object.  It can be iterated over and supports the`asend()`, `athrow()` and `aclose()` methods.A `GeneratorObject` is a flexible way to asynchronously generate results withoutresorting to `Task` and `Queue` objects.  What is more, it allows this sortof generating pattern to be used in non-async programs, via `aiter_sync()`:```pythondef sync_runner():    gen_obj = GeneratorObject()    values = [val for val in aiter_sync(gen_obj(generator(gen_obj)))]    assert values == [1, 2]```# Scheduling toolsA set of functions are provided to perform advanced scheduling of `Task` objectswith `asyncio`.  They work with the built-in event loop, and also with any eventloopimplementing the `AbstractSchedulingLoop` abstract base class, such as the `SchedulingMixin`class which can be used to extend the built-in event loops.## Scheduling functions### `sleep_insert(pos)`Similar to `asyncio.sleep()` but sleeps only for `pos` places in the runnable queue.Whereas `asyncio.sleep(0)` will place the executing task at the end of the queue, which isappropriate for fair scheduling, in some advanced cases you want to wake up sooner than that, perhapsafter a specific task.### `task_reinsert(task, pos)`Takes a _runnable_ task (for example just created with `asyncio.create_task()` or similar) andreinserts it at a given position in the queue. Similarly as for `sleep_insert()`, this can be useful to achievecertain scheduling goals.### `task_switch(task, *, insert_pos=None)`Immediately moves the given task to the head of the ready queue and switches to it, assuming it is runnable.If `insert_pos is not None`, the current task will beput to sleep at that position, using `sleep_insert()`. Otherwise the current task is put at the endof the ready queue.  If `insert_pos == 1` the current task will be inserted directly after the targettask, making it the next to be run.  If `insert_pos == 0`, the current task will execute _before_ the target.### `task_is_blocked(task)`Returns True if the task is waiting for some awaitable, such as a Future or another Task, and is thus noton the ready queue.### `task_is_runnable(task)`Roughly the opposite of `task_is_blocked()`, returns True if the task is neither `done()` nor __blocked__ andawaits execution.### `create_task_descend(coro)`Implements depth-first task scheduling.Similar to `asyncio.create_task()` this creates a task but starts it running right away, and positions the caller to be wokenup right after it blocks. The effect is similar to using `asynkit.eager()` butit achieves its goals solely by modifying the runnable queue. A `Task` is alwayscreated, unlike `eager`, which only creates a task if the target blocks.## Runnable task helpersA few functions are added to help working with tasks.The following identity applies:```pythonasyncio.all_tasks() = (    asynkit.runnable_tasks() | asynkit.blocked_tasks() | asyncio.current_task())```### `runnable_tasks(loop=None)`Returns a set of the tasks that are currently runnable in the given loop### `blocked_tasks(loop=None)`Returns a set of the tasks that are currently blocked on some future in the given loop.## Event Loop toolsAlso provided is a mixin for the built-in event loop implementations in python, providing some primitives for advanced scheduling of tasks.  These primitives are what is used by thescheduling functions above, and so custom event loop implementations can provide customimplementations of these methods.### `SchedulingMixin` mixin classThis class adds some handy scheduling functions to the event loop. They primarilywork with the _ready queue_, a queue of callbacks representing tasks readyto be executed.- `ready_len(self)` - returns the length of the ready queue- `ready_pop(self, pos=-1)` - pops an entry off the queue- `ready_insert(self, pos, element)` - inserts a previously popped element into the queue- `ready_rotate(self, n)` - rotates the queue- `call_insert(self, pos, ...)` - schedules a callback at position `pos` in the queue### Concrete event loop classesConcrete subclasses of Python's built-in event loop classes are provided.- `SchedulingSelectorEventLoop` is a subclass of `asyncio.SelectorEventLoop` with the `SchedulingMixin`- `SchedulingProactorEventLoop` is a subclass of `asyncio.ProactorEventLoop` with the `SchedulingMixin` on those platforms that support it.### Event Loop PolicyA policy class is provided to automatically create the appropriate event loops.- `SchedulingEventLoopPolicy` is a subclass of `asyncio.DefaultEventLoopPolicy` which instantiates either of the above event loop classes as appropriate.Use this either directly:```pythonasyncio.set_event_loop_policy(asynkit.SchedulingEventLoopPolicy())asyncio.run(myprogram())```or with a context manager:```pythonwith asynkit.event_loop_policy():    asyncio.run(myprogram())```# Coroutine helpersA couple of functions are provided to introspect the state of coroutine objects. Theywork on both regular __async__ coroutines, __classic__ coroutines (using `yield from`) and__async generators__.- `coro_is_new(coro)` -  Returns true if the object has just been created and hasn't started executing yet- `coro_is_suspended(coro)` - Returns true if the object is in a suspended state.- `coro_is_done(coro)` - Returns true if the object has finished executing, e.g. by returning or raising an exception.- `coro_get_frame(coro)` - Returns the current frame object of the coroutine, if it has one, or `None`.# `anyio` supportThe library has been tested to work with the `anyio`.  However, not everything is supported on the `trio` backend.Currently only the `asyncio` backend can be assumed to work reliably.When using the asyncio backend, the module `asynkit.experimental.anyio` can be used, to provide &quot;eager&quot;-likebehaviour to task creation.  It will return an `EagerTaskGroup` context manager:```pythonfrom asynkit.experimental.anyio import create_eager_task_groupfrom anyio import run, sleepasync def func(task_status):    print(&quot;hello&quot;)    task_status.started(&quot;world&quot;)    await sleep(0.01)    print(&quot;goodbye&quot;)async def main():    async with create_eager_task_group() as tg:        start = tg.start(func)        print(&quot;fine&quot;)        print(await start)    print(&quot;world&quot;)run(main, backend=&quot;asyncio&quot;)```This will result in the following output:```hellofineworldgoodbyeworld```The first part of the function `func` is run even before calling `await` on the result from `EagerTaskGroup.start()`Similarly, `EagerTaskGroup.start_soon()` will run the provided coroutine up to its first blocking point beforereturning.## `trio` limitations`trio` differs significantly from `asyncio` and therefore enjoys only limited support.- The event loop is completely different and proprietary and so the event loop extensions don't work  for `trio`.- `CoroStart` when used with `Task` objects, such as by using `EagerTaskGroup`,  does not work reliably with `trio`.  This is because the syncronization primitives  are not based on `Future` objects but rather perform `Task`-based actions both before going to sleep  and upon waking up.  If a `CoroStart` initially blocks on a primitive such as `Event.wait()` or  `sleep(x)` it will be surprised and throw an error when it wakes up on in a different  `Task` than when it was in when it fell asleep.`CoroStart` works by intercepting a `Future` being passed up via the `await` protocol to the event loop to perform the task scheduling.  If any part of the task scheduling has happenedbefore this, and the _continuation_ happens on a different `Task` then things may breakin various ways.   For `asyncio`, the event loop never sees the `Future` object until`as_coroutine()` has been called and awaited, and so if this happens in a new task, all is good.</longdescription>
</pkgmetadata>