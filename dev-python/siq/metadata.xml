<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># SIQ - super-resolution image quantification## deep perceptual resampling and super-resolution for (medical) imaginginstall by calling (within the source directory):```python setup.py install```or install via `pip install siq`# what this will dofacilitates:* creating training and testing data for deep networks* generating and testing perceptual losses in 2D and 3D* general training and inference functions for deep networks* intuitive weighting of multiple losses* anisotropic super-resolution* evaluation strategies for the above# first time setup```pythonimport antspyt1wantspyt1w.get_data( force_download=True )# import siq     # FIXME - for later# siq.get_data( force_download=True )```NOTE: `get_data` has a `force_download` option to make sure the latestpackage data is installed.# example processing```pythonimport osimport siqimport globimport antsfns=glob.glob( os.path.expanduser( &quot;~/.antspyt1w/2*T1w*gz&quot; ) )import tensorflow as tfofn = os.path.expanduser(&quot;~/code/DPR/models/dsr3d_2up_64_256_6_3_v0.0zzz.h5&quot;)if os.path.exists( ofn ):    print(&quot;existing model&quot;) # should always initialize with pre-trained model    mdl = tf.keras.models.load_model( ofn, compile=False )else:    print(&quot;default model - initialized with random weights&quot;)    mdl = siq.default_dbpn( [2,2,2] ) # should match ratio of high to low size patchesmyoutprefix = '/tmp/XXX'training_path = siq.train(    mdl,     fns[0:3],     fns[0:3],     output_prefix=myoutprefix,    target_patch_size=[32,32,32],    target_patch_size_low=[16,16,16],    n_test=2,     learning_rate=5e-05,     feature_layer=6,     feature=2,     tv=0.1,    max_iterations=2,     verbose=True)training_path.to_csv( myoutprefix + &quot;_training.csv&quot; )image = ants.image_read( fns[0] )image = ants.resample_image( image, [48,48,48] ) # downsample for speed in testingtest = siq.inference( image, mdl )```see also: the training scripts in `tests`.## todo1. numpy read/write2. test/fix 2D## your compute environment```bashexport TF_ENABLE_ONEDNN_OPTS=1 # for CPUtotal_cpu_cores=$(nproc)number_sockets=$(($(grep &quot;^physical id&quot; /proc/cpuinfo | awk '{print $4}' | sort -un | tail -1)+1))number_cpu_cores=$(( (total_cpu_cores/2) / number_sockets))echo &quot;number of CPU cores per socket: $number_cpu_cores&quot;;echo &quot;number of socket: $number_sockets&quot;;echo &quot;Physical cores:&quot;egrep '^core id' /proc/cpuinfo | sort -u | wc -lecho &quot;Logical cores:&quot;egrep '^processor' /proc/cpuinfo | sort -u | wc -lecho &quot;Physical cpus (separate chips):&quot;egrep '^physical id' /proc/cpuinfo | sort -u | wc -l```## to publish a release```rm -r -f build/ antspymm.egg-info/ dist/python3 setup.py sdist bdist_wheelpython3 -m twine upload -u username -p password  dist/*```## notes on cpu environment```# dd=/home/ubuntu/miniconda3/condabin/conda# conda update -n base -c defaults conda# conda init bash# conda create -n ai3 python=3.9# conda activate ai3 # pip3 install --upgrade pippy=python3 # &quot;sudo /opt/parallelcluster/pyenv/versions/3.7.10/envs/awsbatch_virtualenv/bin/python3.7&quot;$py -m pip install --upgrade pip# python3.7 -m pip uninstall tensorflow antspynet dipy patsy tensorboard tensorflow-probability -y$py -m pip install nibabel PyNomaly scipy $py -m pip install antspyx $py -m pip install dipy $py -m pip install antspyt1w $py -m pip install antspymm $py -m pip install antspynet$py -m pip install siq$py -m pip uninstall tensorflow -y$py -m pip install intel-tensorflow # -avx512==2.9.1$py -m pip install tensorflow_probability$py -m pip install keras```</longdescription>
</pkgmetadata>