<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Dask-Snowflake[![Tests](https://github.com/coiled/dask-snowflake/actions/workflows/tests.yml/badge.svg)](https://github.com/coiled/dask-snowflake/actions/workflows/tests.yml)[![Linting](https://github.com/coiled/dask-snowflake/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/coiled/dask-snowflake/actions/workflows/pre-commit.yml)This connector is in an early experimental/testing phase.[Reach out to us](https://coiled.io/contact-us/) if you are interested in tryingit out!## Installation`dask-snowflake` can be installed with `pip`:```shellpip install dask-snowflake```or with `conda`:```shellconda install -c conda-forge dask-snowflake```## Usage`dask-snowflake` provides `read_snowflake` and `to_snowflake` methodsfor parallel IO from Snowflake with Dask.```python&gt;&gt;&gt; from dask_snowflake import read_snowflake&gt;&gt;&gt; example_query = '''...    SELECT *...    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER;... '''&gt;&gt;&gt; ddf = read_snowflake(...     query=example_query,...     connection_kwargs={...         &quot;user&quot;: &quot;...&quot;,...         &quot;password&quot;: &quot;...&quot;,...         &quot;account&quot;: &quot;...&quot;,...     },... )``````python&gt;&gt;&gt; from dask_snowflake import to_snowflake&gt;&gt;&gt; to_snowflake(...     ddf,...     name=&quot;my_table&quot;,...     connection_kwargs={...         &quot;user&quot;: &quot;...&quot;,...         &quot;password&quot;: &quot;...&quot;,...         &quot;account&quot;: &quot;...&quot;,...     },... )```See their docstrings for further API information.## TestsRunning tests requires a Snowflake account and access to a database.The test suite will automatically look for specific `SNOWFLAKE_*`environment variables (listed below) that must be set.It's recommended (though not required) to store these environment variablesin a local `.env` file in the root of the `dask-snowflake` repository.This file will be automatically ignored by `git`, reducing the risk of accidentallycommiting it.Here's what an example `.env` file looks like:```envSNOWFLAKE_USER=&quot;&lt;test user name&gt;&quot;SNOWFLAKE_PASSWORD=&quot;&lt;test_user_password&gt;&quot;SNOWFLAKE_ACCOUNT=&quot;&lt;account&gt;.&lt;region&gt;.aws&quot;SNOWFLAKE_WAREHOUSE=&quot;&lt;test warehouse&gt;&quot;SNOWFLAKE_ROLE=&quot;&lt;test role&gt;&quot;SNOWFLAKE_DATABASE=&quot;&lt;test database&gt;&quot;SNOWFLAKE_SCHEMA=&quot;&lt;test schema&gt;&quot;```You may then `source .env` or install [`pytest-dotenv`](https://github.com/quiqua/pytest-dotenv)to automatically set these environment variables.&gt; **_Note:_**&gt; If you run the tests and get an `MemoryError` mentioning&gt; &quot;write+execute memory for ffi.callback()&quot;, you probably have stale&gt; build of `cffi` from conda-forge. Remove it and install the version&gt; using `pip`:&gt;&gt; ```shell&gt; conda remove cffi --force&gt; pip install cffi&gt; ```## License[BSD-3](LICENSE)</longdescription>
</pkgmetadata>