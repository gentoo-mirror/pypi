<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Anthropic Python API Library[![PyPI version](https://img.shields.io/pypi/v/anthropic.svg)](https://pypi.org/project/anthropic/)The Anthropic Python library provides convenient access to the Anthropic REST API from any Python 3.7+application. It includes type definitions for all request params and response fields,and offers both synchronous and asynchronous clients powered by [httpx](https://github.com/encode/httpx).## Migration from v0.2.x and belowIn `v0.3.0`, we introduced a fully rewritten SDK.The new version uses separate sync and async clients, unified streaming, typed params and structured response objects, and resource-oriented methods:**Sync before/after:**```diff- client = anthropic.Client(os.environ[&quot;ANTHROPIC_API_KEY&quot;])+ client = anthropic.Anthropic(api_key=os.environ[&quot;ANTHROPIC_API_KEY&quot;])  # or, simply provide an ANTHROPIC_API_KEY environment variable:+ client = anthropic.Anthropic();- rsp = client.completion(**params)- rsp[&quot;completion&quot;]+ rsp = client.completions.create(**params)+ rsp.completion```**Async before/after:**```diff- client = anthropic.Client(os.environ[&quot;ANTHROPIC_API_KEY&quot;])+ client = anthropic.AsyncAnthropic(api_key=os.environ[&quot;ANTHROPIC_API_KEY&quot;])- await client.acompletion(**params)+ await client.completions.create(**params)```The `.completion_stream()` and `.acompletion_stream()` methods have been removed;simply pass `stream=True`to `.completions.create()`.Streaming responses are now incremental; the full text is not sent in each message,as v0.3 sends the `Anthropic-Version: 2023-06-01` header.&lt;details&gt;&lt;summary&gt;Example streaming diff&lt;/summary&gt;```diff py  import anthropic- client = anthropic.Client(os.environ[&quot;ANTHROPIC_API_KEY&quot;])+ client = anthropic.Anthropic()  # Streams are now incremental diffs of text  # rather than sending the whole message every time:  text = &quot;- stream = client.completion_stream(**params)- for data in stream:-     diff = data[&quot;completion&quot;].replace(text, &quot;&quot;)-     text = data[&quot;completion&quot;]+ stream = client.completions.create(**params, stream=True)+ for data in stream:+     diff = data.completion # incremental text+     text += data.completion      print(diff, end=&quot;&quot;)  print(&quot;Done. Final text is:&quot;)  print(text)```&lt;/details&gt;## DocumentationThe API documentation can be found [here](https://docs.anthropic.com/claude/reference/).## Installation```shpip install anthropic```## Usage```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = Anthropic(    # defaults to os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)    api_key=&quot;my api key&quot;,)completion = anthropic.completions.create(    model=&quot;claude-1&quot;,    max_tokens_to_sample=300,    prompt=f&quot;{HUMAN_PROMPT} how does a court case get to the Supreme Court? {AI_PROMPT}&quot;,)print(completion.completion)```While you can provide an `api_key` keyword argument, we recommend using [python-dotenv](https://pypi.org/project/python-dotenv/)and adding `ANTHROPIC_API_KEY=&quot;my api key&quot;` to your `.env` file so that your API Key is not stored in source control.## Async UsageSimply import `AsyncAnthropic` instead of `Anthropic` and use `await` with each API call:```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = AsyncAnthropic(    # defaults to os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)    api_key=&quot;my api key&quot;,)async def main():    completion = await anthropic.completions.create(        model=&quot;claude-1&quot;,        max_tokens_to_sample=300,        prompt=f&quot;{HUMAN_PROMPT} how does a court case get to the Supreme Court? {AI_PROMPT}&quot;,    )    print(completion.completion)asyncio.run(main())```Functionality between the synchronous and asynchronous clients is otherwise identical.## Streaming ResponsesWe provide support for streaming responses using Server Side Events (SSE).```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = Anthropic()stream = anthropic.completions.create(    prompt=f&quot;{HUMAN_PROMPT} Your prompt here {AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-1&quot;,    stream=True,)for completion in stream:    print(completion.completion)```The async client uses the exact same interface.```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = AsyncAnthropic()stream = await anthropic.completions.create(    prompt=f&quot;{HUMAN_PROMPT} Your prompt here {AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-1&quot;,    stream=True,)async for completion in stream:    print(completion.completion)```## Using TypesNested request parameters are [TypedDicts](https://docs.python.org/3/library/typing.html#typing.TypedDict), while responses are [Pydantic](https://pydantic-docs.helpmanual.io/) models. This helps provide autocomplete and documentation within your editor.If you would like to see type errors in VS Code to help catch bugs earlier, set `python.analysis.typeCheckingMode` to `&quot;basic&quot;`.## Handling errorsWhen the library is unable to connect to the API (e.g., due to network connection problems or a timeout), a subclass of `anthropic.APIConnectionError` is raised.When the API returns a non-success status code (i.e., 4xx or 5xxresponse), a subclass of `anthropic.APIStatusError` will be raised, containing `status_code` and `response` properties.All errors inherit from `anthropic.APIError`.```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = Anthropic()try:    anthropic.completions.create(        prompt=f&quot;{HUMAN_PROMPT} Your prompt here {AI_PROMPT}&quot;,        max_tokens_to_sample=300,        model=&quot;claude-1&quot;,    )except anthropic.APIConnectionError as e:    print(&quot;The server could not be reached&quot;)    print(e.__cause__)  # an underlying Exception, likely raised within httpx.except anthropic.RateLimitError as e:    print(&quot;A 429 status code was received; we should back off a bit.&quot;)except anthropic.APIStatusError as e:    print(&quot;Another non-200-range status code was received&quot;)    print(e.status_code)    print(e.response)```Error codes are as followed:| Status Code | Error Type                 || ----------- | -------------------------- || 400         | `BadRequestError`          || 401         | `AuthenticationError`      || 403         | `PermissionDeniedError`    || 404         | `NotFoundError`            || 422         | `UnprocessableEntityError` || 429         | `RateLimitError`           || &gt;=500       | `InternalServerError`      || N/A         | `APIConnectionError`       |### RetriesCertain errors will be automatically retried 2 times by default, with a short exponential backoff.Connection errors (for example, due to a network connectivity problem), 409 Conflict, 429 Rate Limit,and &gt;=500 Internal errors will all be retried by default.You can use the `max_retries` option to configure or disable this:```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT# Configure the default for all requests:anthropic = Anthropic(    # default is 2    max_retries=0,)# Or, configure per-request:anthropic.with_options(max_retries=5).completions.create(    prompt=f&quot;{HUMAN_PROMPT} Can you help me effectively ask for a raise at work? {AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-1&quot;,)```### TimeoutsRequests time out after 60 seconds by default. You can configure this with a `timeout` option,which accepts a float or an [`httpx.Timeout`](https://www.python-httpx.org/advanced/#fine-tuning-the-configuration):```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT# Configure the default for all requests:anthropic = Anthropic(    # default is 60s    timeout=20.0,)# More granular control:anthropic = Anthropic(    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),)# Override per-request:anthropic.with_options(timeout=5 * 1000).completions.create(    prompt=f&quot;{HUMAN_PROMPT} Where can I get a good coffee in my neighbourhood? {AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-1&quot;,)```On timeout, an `APITimeoutError` is thrown.Note that requests which time out will be [retried twice by default](#retries).## Default HeadersWe automatically send the `anthropic-version` header set to `2023-06-01`.If you need to, you can override it by setting default headers per-request or on the client object.Be aware that doing so may result in incorrect types and other unexpected or undefined behavior in the SDK.```pythonfrom anthropic import Anthropicanthropic = Anthropic(    default_headers={&quot;anthropic-version&quot;: &quot;My-Custom-Value&quot;},)```## Advanced: Configuring custom URLs, proxies, and transportsYou can configure the following keyword arguments when instantiating the client:```pythonimport httpxfrom anthropic import Anthropicanthropic = Anthropic(    # Use a custom base URL    base_url=&quot;http://my.test.server.example.com:8083&quot;,    proxies=&quot;http://my.test.proxy.example.com&quot;,    transport=httpx.HTTPTransport(local_address=&quot;0.0.0.0&quot;),)```See the httpx documentation for information about the [`proxies`](https://www.python-httpx.org/advanced/#http-proxying) and [`transport`](https://www.python-httpx.org/advanced/#custom-transports) keyword arguments.## StatusThis package is in beta. Its internals and interfaces are not stable and subject to change without a major semver bump;please reach out if you rely on any undocumented behavior.We are keen for your feedback; please open an [issue](https://www.github.com/anthropics/anthropic-sdk-python/issues) with questions, bugs, or suggestions.## RequirementsPython 3.7 or higher.</longdescription>
</pkgmetadata>