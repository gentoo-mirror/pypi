<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;img src=&quot;images/logo.png&quot; width=&quot;70%&quot; height=&quot;70%&quot;/&gt;[![PyPI - Python](https://img.shields.io/badge/python-3.6%20|%203.7%20|%203.8-blue.svg)](https://pypi.org/project/keybert/)[![PyPI - License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/MaartenGr/keybert/blob/master/LICENSE)[![PyPI - PyPi](https://img.shields.io/pypi/v/polyfuzz)](https://pypi.org/project/polyfuzz/)[![Build](https://img.shields.io/github/workflow/status/MaartenGr/polyfuzz/Code%20Checks/master)](https://pypi.org/project/polyfuzz/)[![docs](https://img.shields.io/badge/docs-Passing-green.svg)](https://maartengr.github.io/PolyFuzz/)  **`PolyFuzz`** performs fuzzy string matching, string grouping, and contains extensive evaluation functions. PolyFuzz is meant to bring fuzzy string matching techniques together within a single framework.Currently, methods include a variety of edit distance measures, a character-based n-gram TF-IDF, word embeddingtechniques such as FastText and GloVe, and ðŸ¤— transformers embeddings.  Corresponding medium post can be found [here](https://towardsdatascience.com/string-matching-with-bert-tf-idf-and-more-274bb3a95136?source=friends_link&amp;sk=0f765b76ceaba49363829c13dfdc9d98).&lt;a name=&quot;installation&quot;/&gt;&lt;/a&gt;## InstallationYou can install **`PolyFuzz`** via pip: ```bashpip install polyfuzz```You may want to install more depending on the transformers and language backends that you will be using. The possible installations are:```pythonpip install polyfuzz[sbert]pip install polyfuzz[flair]pip install polyfuzz[gensim]pip install polyfuzz[spacy]pip install polyfuzz[use]```If you want to speed up the cosine similarity comparison and decrease memory usage when using embedding models, you can use `sparse_dot_topn` which is installed via:```bashpip install polyfuzz[fast]```&lt;details&gt;&lt;summary&gt;Installation Issues&lt;/summary&gt;You might run into installation issues with `sparse_dot_topn`. If so, one solution that has worked for many is by installing it via conda first before installing PolyFuzz:```bashconda install -c conda-forge sparse_dot_topn```If that does not work, I would advise you to look through their issues](https://github.com/ing-bank/sparse_dot_topn/issues) page or continue to use PolyFuzz without `sparse_dot_topn`. &lt;/details&gt;  &lt;a name=&quot;gettingstarted&quot;/&gt;&lt;/a&gt;## Getting StartedFor an in-depth overview of the possibilities of `PolyFuzz` you can check the full documentation [here](https://maartengr.github.io/PolyFuzz/) or you can follow along with the notebook [here](https://github.com/MaartenGr/PolyFuzz/blob/master/notebooks/Overview.ipynb).### Quick StartThe main goal of `PolyFuzz` is to allow the user to perform different methods for matching strings. We start by defining two lists, one to map from and one to map to. We are going to be using `TF-IDF` to create n-grams on a character level in order to compare similarity between strings. Then, we calculate the similarity between strings by calculating the cosine similarity between vector representations. We only have to instantiate `PolyFuzz` with `TF-IDF` and match the lists:```pythonfrom polyfuzz import PolyFuzzfrom_list = [&quot;apple&quot;, &quot;apples&quot;, &quot;appl&quot;, &quot;recal&quot;, &quot;house&quot;, &quot;similarity&quot;]to_list = [&quot;apple&quot;, &quot;apples&quot;, &quot;mouse&quot;]model = PolyFuzz(&quot;TF-IDF&quot;)model.match(from_list, to_list)```  The resulting matches can be accessed through `model.get_matches()`:```python&gt;&gt;&gt; model.get_matches()         From      To    Similarity0       apple   apple    1.0000001      apples  apples    1.0000002        appl   apple    0.7837513       recal    None    0.0000004       house   mouse    0.5879275  similarity    None    0.000000``` **NOTE 1**: If you want to compare distances within a single list, you can simply pass that list as such: `model.match(from_list)`**NOTE 2**: When instantiating `PolyFuzz` we also could have used &quot;EditDistance&quot; or &quot;Embeddings&quot; to quickly access Levenshtein and FastText (English) respectively. ### ProductionThe `.match` function allows you to quickly extract similar strings. However, after selecting the right models to be used, you may want to use PolyFuzz in production to match incoming strings. To do so, we can make use of the familiar `fit`, `transform`, and `fit_transform` functions. Let's say that we have a list of words that we know to be correct called `train_words`. We want to any incoming word to mapped to one of the words in `train_words`. In other words, we `fit` on `train_words` and we use `transform` on any incoming words:```pythonfrom sklearn.datasets import fetch_20newsgroupsfrom sklearn.feature_extraction.text import CountVectorizerfrom polyfuzz import PolyFuzztrain_words = [&quot;apple&quot;, &quot;apples&quot;, &quot;appl&quot;, &quot;recal&quot;, &quot;house&quot;, &quot;similarity&quot;]unseen_words = [&quot;apple&quot;, &quot;apples&quot;, &quot;mouse&quot;]# Fitmodel = PolyFuzz(&quot;TF-IDF&quot;)model.fit(train_words)# Transformresults = model.transform(unseen_words)```In the above example, we are using `fit` on `train_words` to calculate the TF-IDF representation of those words which are saved to be used again in `transform`. This speeds up `transform` quite a bit since all TF-IDF representations are stored when applying `fit`. Then, we apply save and load the model as follows to be used in production:```python# Save the modelmodel.save(&quot;my_model&quot;)# Load the modelloaded_model = PolyFuzz.load(&quot;my_model&quot;)```### Group MatchesWe can group the matches `To` as there might be significant overlap in strings in our to_list. To do this, we calculate the similarity within strings in to_list and use `single linkage` to then group the strings with a high similarity.When we extract the new matches, we can see an additional column `Group` in which all the `To` matches were grouped to:```python&gt;&gt;&gt; model.group(link_min_similarity=0.75)&gt;&gt;&gt; model.get_matches()      FromToSimilarityGroup0     appleapple1.000000apples1    applesapples1.000000apples2      applapple0.783751apples3     recalNone0.000000None4     housemouse0.587927mouse5similarityNone0.000000None```As can be seen above, we grouped apple and apples together to `apple` such that when a string is mapped to `apple` it will fall in the cluster of `[apples, apple]` and will be mapped to the first instance in the cluster which is `apples`.### Precision-Recall Curve  Next, we would like to see how well our model is doing on our data. We express our results as **`precision`** and **`recall`** where precision is defined as the minimum similarity score before a match is correct and recall the percentage of matches found at a certain minimum similarity score.  Creating the visualizations is as simple as:```model.visualize_precision_recall()```&lt;img src=&quot;images/tfidf.png&quot; width=&quot;100%&quot; height=&quot;100%&quot;/&gt; ## ModelsCurrently, the following models are implemented in PolyFuzz:* TF-IDF* EditDistance (you can use any distance measure, see [documentation](https://maartengr.github.io/PolyFuzz/tutorial/models/#EditDistance))* FastText and GloVe* ðŸ¤— TransformersWith `Flair`, we can use all ðŸ¤— Transformers [models](https://huggingface.co/transformers/pretrained_models.html). We simply have to instantiate any Flair WordEmbedding method and pass it through PolyFuzzy.All models listed above can be found in `polyfuzz.models` and can be used to create and compare different models:```pythonfrom polyfuzz.models import EditDistance, TFIDF, Embeddingsfrom flair.embeddings import TransformerWordEmbeddingsembeddings = TransformerWordEmbeddings('bert-base-multilingual-cased')bert = Embeddings(embeddings, min_similarity=0, model_id=&quot;BERT&quot;)tfidf = TFIDF(min_similarity=0)edit = EditDistance()string_models = [bert, tfidf, edit]model = PolyFuzz(string_models)model.match(from_list, to_list)```To access the results, we again can call `get_matches` but since we have multiple models we get back a dictionary of dataframes back. In order to access the results of a specific model, call `get_matches` with the correct id: ```python&gt;&gt;&gt; model.get_matches(&quot;BERT&quot;)        From    To          Similarity0apple    apple1.0000001apples    apples1.0000002appl    apple0.9280453recal    apples0.8252684house    mouse0.8875245similarity  mouse0.791548``` Finally, visualize the results to compare the models:```pythonmodel.visualize_precision_recall(kde=True)```&lt;img src=&quot;images/multiple_models.png&quot; width=&quot;100%&quot; height=&quot;100%&quot;/&gt;## Custom GrouperWe can even use one of the `polyfuzz.models` to be used as the grouper in case you would like to use something else than the standard TF-IDF model:```pythonmodel = PolyFuzz(&quot;TF-IDF&quot;)model.match(from_list, to_list)edit_grouper = EditDistance(n_jobs=1)model.group(edit_grouper)```## Custom ModelsAlthough the options above are a great solution for comparing different models, what if you have developed your own? If you follow the structure of PolyFuzz's `BaseMatcher`  you can quickly implement any model you would like.Below, we are implementing the ratio similarity measure from RapidFuzz.```pythonimport numpy as npimport pandas as pdfrom rapidfuzz import fuzzfrom polyfuzz.models import BaseMatcherclass MyModel(BaseMatcher):    def match(self, from_list, to_list, **kwargs):        # Calculate distances        matches = [[fuzz.ratio(from_string, to_string) / 100 for to_string in to_list]                     for from_string in from_list]                # Get best matches        mappings = [to_list[index] for index in np.argmax(matches, axis=1)]        scores = np.max(matches, axis=1)                # Prepare dataframe        matches = pd.DataFrame({'From': from_list,'To': mappings, 'Similarity': scores})        return matches```Then, we can simply create an instance of MyModel and pass it through PolyFuzz:```pythoncustom_model = MyModel()model = PolyFuzz(custom_model)```## CitationTo cite PolyFuzz in your work, please use the following bibtex reference:```bibtex@misc{grootendorst2020polyfuzz,  author       = {Maarten Grootendorst},  title        = {PolyFuzz: Fuzzy string matching, grouping, and evaluation.},  year         = 2020,  publisher    = {Zenodo},  version      = {v0.2.2},  doi          = {10.5281/zenodo.4461050},  url          = {https://doi.org/10.5281/zenodo.4461050}}```## ReferencesBelow, you can find several resources that were used for or inspired by when developing PolyFuzz:    **Edit distance algorithms**:  These algorithms focus primarily on edit distance measures and can be used in `polyfuzz.models.EditDistance`:* https://github.com/jamesturk/jellyfish* https://github.com/ztane/python-Levenshtein* https://github.com/seatgeek/fuzzywuzzy* https://github.com/maxbachmann/rapidfuzz* https://github.com/roy-ht/editdistance**Other interesting repos**:* https://github.com/ing-bank/sparse_dot_topn    * Used in PolyFuzz for fast cosine similarity between sparse matrices</longdescription>
</pkgmetadata>