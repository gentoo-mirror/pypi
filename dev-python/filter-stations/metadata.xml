<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>## Documentationhttps://filterstations.netlify.app/## Water Level Pipeline - A series of functions to be added to the filter-stations module in pypi to evalute which TAHMO stations to use that corroborates with the water level- All begins with the coordinates of the gauging station(location of the monitoring sensor)```pythonimport osfrom pathlib import Pathimport haversine as hsimport pandas as pdimport numpy as npimport datetimeimport statsmodels.api as smfrom matplotlib.dates import DateFormatterimport matplotlib.pyplot as plt# config_pathconfig_path = os.path.join(Path(os.getcwd()).parent.absolute(), 'config.json')``````pythonfrom filter_stations import retreive_data, Interactive_maps, Filterimport json# Authenticationwith open(config_path) as f:    conf = json.load(f)apiKey = conf['apiKey']apiSecret = conf['apiSecret']fs = retreive_data(apiKey, apiSecret)``````python# given the radius and the longitude and latitude of the gauging station, return the stations withindef stations_within_radius(radius, latitude, longitude, df=False):    stations  = fs.get_stations_info()    stations['distance'] = stations.apply(lambda row: hs.haversine((latitude, longitude), (row['location.latitude'], row['location.longitude'])), axis=1)    infostations = stations[['code', 'location.latitude','location.longitude', 'distance']].sort_values('distance')    if df:        return infostations[infostations['distance'] &lt;= radius]    else:        return infostations[infostations['distance'] &lt;= radius].code.values``````pythonewaso = stations_within_radius(100, -0.406689, 36.96301)ewaso```    API request: services/assets/v2/stations        array(['TA00283', 'TA00378', 'TA00754', 'TA00074', 'TA00196', 'TA00073',           'TA00056', 'TA00029', 'TA00416', 'TA00719', 'TA00258', 'TA00622',           'TA00028', 'TA00414', 'TA00190', 'TA00078', 'TA00024', 'TA00080',           'TA00166', 'TA00108', 'TA00026', 'TA00189', 'TA00250', 'TA00182',           'TA00715', 'TA00377', 'TA00027', 'TA00057', 'TA00134', 'TA00448',           'TA00774', 'TA00773', 'TA00772', 'TA00775', 'TA00771', 'TA00679',           'TA00770'], dtype=object)The assumption here is one can have credential but not the data- From the list of stations get the precipitation data with a certain data completeness check provided- Additionally the start and end date if the data is not provided- The default start date is the day the sensors were set up at DSAIL- Chck the documentation on the types of variables available```pythondef stations_data_check(stations_list, percentage=1, start_date=None, end_date=None, data=None, variables=['pr'], csv_file=None):    if data is None:        data = fs.multiple_measurements(stations_list, startDate=start_date, endDate=end_date, variables=variables, csv_file=csv_file)    # Check the percentage of missing data and return the stations with less than the percentage of missing data    data.index = data.index.astype('datetime64[ns]')    data = data.dropna(axis=1, thresh=int(len(data) * percentage))    data.to_csv(f'{csv_file}.csv')    return data``````pythonstations_df = stations_data_check(list(ewaso), start_date='2022-12-01', end_date='2022-12-31', variables=['pr'], csv_file='ewaso2.csv')```Apart from the completeness another method of validation by eliminating unusable sensors is checking for a positive correlation and lag- The default lag is 3 days between a particular station and the gauging station- The required format is a timeseries data - Provide the column names for evaluation format = [Date, data]- with the change in parameters one can choose above or below threshold ```pythondef stations_lag(weather_stations_df, gauging_stations_df, gauging_station_columns, date=None, lag=3, above=False, below=False):            # set the date as axis    # weather_station_df = weather_stations_df.set_index('Date')    # weather_stations_df.Date= weather_stations_df.Date.apply(pd.to_datetime,dayfirst = True)    # weather_stations_df = weather_stations_df.set_index('Date')    # get the starting date of the gauging station the first value    if date is None:        date = gauging_stations_df.loc[0, gauging_station_columns[0]]    start_date = datetime.datetime.strptime(date, &quot;%d/%m/%Y&quot;)    end_date = start_date + datetime.timedelta(len(gauging_stations_df)-1)    # get the ddataframe from start date to end date    df_fit = weather_stations_df[start_date:end_date]    # get the water data list    water_list = list(gauging_stations_df[f'{gauging_station_columns[1]}'])    above_thresh_lag = dict()    below_thresh_lag = dict()    # get the lag for every column against the water data     for cols in df_fit.columns:        select_list = list(df_fit[cols])        coefficient_list = list(sm.tsa.stattools.ccf(select_list,water_list, adjusted=False))        a = np.argmax(coefficient_list)        b = coefficient_list[a]        if a &gt; lag:            above_thresh_lag[cols] = {                'lag': a,                'coefficient': b,                'coefficient_list': coefficient_list,                'select_list': select_list,                'water_list' : water_list            }        else:            below_thresh_lag[cols] = {                'lag': a,                'coefficient': b,                'coefficient_list': coefficient_list,                'select_list': select_list,                'water_list' : water_list            }    if above and below:        return above_thresh_lag, below_thresh_lag    elif above:        return above_thresh_lag    elif below:        return below_thresh_lag``````pythonwater_six = pd.read_csv('./water-level-data-ewaso/1E2020.csv')water_six```&lt;div&gt;&lt;style scoped&gt;    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }&lt;/style&gt;&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;  &lt;thead&gt;    &lt;tr style=&quot;text-align: right;&quot;&gt;      &lt;th&gt;&lt;/th&gt;      &lt;th&gt;time&lt;/th&gt;      &lt;th&gt;water_level(m)&lt;/th&gt;    &lt;/tr&gt;  &lt;/thead&gt;  &lt;tbody&gt;    &lt;tr&gt;      &lt;th&gt;0&lt;/th&gt;      &lt;td&gt;12/05/2020&lt;/td&gt;      &lt;td&gt;2.618646&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;1&lt;/th&gt;      &lt;td&gt;13/05/2020&lt;/td&gt;      &lt;td&gt;2.551392&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;2&lt;/th&gt;      &lt;td&gt;14/05/2020&lt;/td&gt;      &lt;td&gt;2.507711&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;3&lt;/th&gt;      &lt;td&gt;15/05/2020&lt;/td&gt;      &lt;td&gt;2.491130&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;4&lt;/th&gt;      &lt;td&gt;16/05/2020&lt;/td&gt;      &lt;td&gt;2.434761&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;...&lt;/th&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;259&lt;/th&gt;      &lt;td&gt;26/01/2021&lt;/td&gt;      &lt;td&gt;0.947099&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;260&lt;/th&gt;      &lt;td&gt;27/01/2021&lt;/td&gt;      &lt;td&gt;0.929186&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;261&lt;/th&gt;      &lt;td&gt;28/01/2021&lt;/td&gt;      &lt;td&gt;0.911274&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;262&lt;/th&gt;      &lt;td&gt;29/01/2021&lt;/td&gt;      &lt;td&gt;0.910711&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;263&lt;/th&gt;      &lt;td&gt;30/01/2021&lt;/td&gt;      &lt;td&gt;0.939971&lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;264 rows Ã— 2 columns&lt;/p&gt;&lt;/div&gt;```pythonlag_ = stations_lag(stations_df, water_six, ['time', 'water_level(m)'], lag=3,below=True)lag_```#### Plotting Provides visuals of the data- An option to save the- An option of choosing the dpi - provide the startDate based on the water collection starting date```pythonlag_[list(lag_.keys())[0]]['water_list']``````pythonimport warningswarnings. filterwarnings('ignore')``````pythondef plot_figs(weather_stations, water_list, threshold_list, save=False, dpi=500, date='11-02-2021'):    start_date = datetime.datetime.strptime(date, &quot;%d-%m-%Y&quot;)    end_date = start_date + datetime.timedelta(len(water_list)-1)    # weather_stations = weather_stations.set_index('Date')    df_plot = weather_stations[start_date:end_date]    df_plot = df_plot[threshold_list].reset_index()    df_plot.rename(columns={'index':'Date'}, inplace=True)            plt.rcParams['figure.figsize'] = (15, 9)    print('Begin plotting!')        for cols in df_plot.columns[1:]:        fig, ax1 = plt.subplots()        color = 'tab:blue'        ax1.set_xlabel(f'Time', fontsize=24, weight='bold')        ax1.set_ylabel(f'Rainfall {cols} (mm)', color=color, fontsize=24, weight='bold')        ax1.bar(pd.to_datetime(df_plot['Date'], format=&quot;%d/%m/%Y&quot;), df_plot[f'{cols}'], color=color, width=4, alpha=1.0)        ax1.tick_params(axis='y', labelcolor=color, labelsize=24)        ax1.tick_params(axis='x')        ax1.set_xticklabels(df_plot['Date'], fontsize=21, weight='bold')        ax1.grid(color='gray', linestyle='--', linewidth=0.8)        ax1.set(facecolor=&quot;white&quot;)        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis        color = 'tab:red'        ax2.set_ylabel('Water level/Stage (m)', color=color, fontsize=24, weight='bold')        ax2.plot(pd.to_datetime(df_plot['Date'], format=&quot;%d/%m/%Y&quot;), water_list, color=color, linewidth=4)        ax2.tick_params(axis='y', labelcolor=color, labelsize=24)        ax2.set(facecolor=&quot;white&quot;)        plt.title('Stage and Rainfall against Time', fontsize=22, weight='bold')        date_form = DateFormatter(&quot;%m-%y&quot;)        ax1.xaxis.set_major_formatter(date_form)        fig.tight_layout()        if save:            fig.savefig(f'{cols}.png', dpi=dpi)``````pythonplot_figs(stations_df, lag_[list(lag_.keys())[0]]['water_list'], list(lag_.keys()), save=True, date='12-05-2020')```    Begin plotting!        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_1.png) --&gt;![water_level_pipeline_16_1](https://github.com/kaburia/Packaging/assets/88529649/cd20fb19-3011-4064-ae09-2901f0076c76)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_2.png) --&gt;![water_level_pipeline_16_2](https://github.com/kaburia/Packaging/assets/88529649/1a1960cb-43ac-42ab-b543-fe6b2a59d562)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_3.png) --&gt;![water_level_pipeline_16_3](https://github.com/kaburia/Packaging/assets/88529649/463f839c-7f19-43c0-9ffc-1b51b643ee5d)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_4.png) --&gt;![water_level_pipeline_16_4](https://github.com/kaburia/Packaging/assets/88529649/95d594b6-2191-4312-a597-1b3caa2b84b1)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_5.png) --&gt;![water_level_pipeline_16_5](https://github.com/kaburia/Packaging/assets/88529649/92939c65-9825-48e7-8042-32a0b365cb60)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_6.png) --&gt;![water_level_pipeline_16_6](https://github.com/kaburia/Packaging/assets/88529649/cce3140d-8340-46be-9a00-68611d0f85e4)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_7.png) --&gt;![water_level_pipeline_16_7](https://github.com/kaburia/Packaging/assets/88529649/cd41b3fa-a2a7-4274-bf81-a82ead887c98)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_8.png) --&gt;![water_level_pipeline_16_8](https://github.com/kaburia/Packaging/assets/88529649/335cac65-8981-44d0-b83e-c14e5077a312)        &lt;!-- ![png](water_level_pipeline_files/water_level_pipeline_16_9.png) --&gt;![water_level_pipeline_16_9](https://github.com/kaburia/Packaging/assets/88529649/35ecc08c-a2bd-4034-88ef-6044e5850793)    Format to get the stations maetadata```pythondef filter_metadata(lag_keys):    captured_list = [i.split('_')[0] for i in list(lag_keys)]    return fs.get_stations_info(multipleStations=captured_list)``````pythonfilter_metadata(list(lag_.keys()))```    API request: services/assets/v2/stations    &lt;div&gt;&lt;style scoped&gt;    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }&lt;/style&gt;&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;  &lt;thead&gt;    &lt;tr style=&quot;text-align: right;&quot;&gt;      &lt;th&gt;&lt;/th&gt;      &lt;th&gt;code&lt;/th&gt;      &lt;th&gt;status&lt;/th&gt;      &lt;th&gt;installationdate&lt;/th&gt;      &lt;th&gt;elevationground&lt;/th&gt;      &lt;th&gt;sensorinstallations&lt;/th&gt;      &lt;th&gt;dataloggerinstallations&lt;/th&gt;      &lt;th&gt;creatorid&lt;/th&gt;      &lt;th&gt;created&lt;/th&gt;      &lt;th&gt;updaterid&lt;/th&gt;      &lt;th&gt;updated&lt;/th&gt;      &lt;th&gt;...&lt;/th&gt;      &lt;th&gt;location.countrycode&lt;/th&gt;      &lt;th&gt;location.zipcode&lt;/th&gt;      &lt;th&gt;location.latitude&lt;/th&gt;      &lt;th&gt;location.longitude&lt;/th&gt;      &lt;th&gt;location.elevationmsl&lt;/th&gt;      &lt;th&gt;location.note&lt;/th&gt;      &lt;th&gt;location.creatorid&lt;/th&gt;      &lt;th&gt;location.created&lt;/th&gt;      &lt;th&gt;location.updaterid&lt;/th&gt;      &lt;th&gt;location.updated&lt;/th&gt;    &lt;/tr&gt;  &lt;/thead&gt;  &lt;tbody&gt;    &lt;tr&gt;      &lt;th&gt;26&lt;/th&gt;      &lt;td&gt;TA00028&lt;/td&gt;      &lt;td&gt;1&lt;/td&gt;      &lt;td&gt;2015-08-31T00:00:00Z&lt;/td&gt;      &lt;td&gt;9.0&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T08:35:17.888233Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T08:35:17.888233Z&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;KE&lt;/td&gt;      &lt;td&gt;&lt;/td&gt;      &lt;td&gt;0.055219&lt;/td&gt;      &lt;td&gt;37.136747&lt;/td&gt;      &lt;td&gt;2003.6&lt;/td&gt;      &lt;td&gt;{}&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-10-26T13:32:16.15537Z&lt;/td&gt;      &lt;td&gt;37&lt;/td&gt;      &lt;td&gt;2022-06-30T11:11:50.27135Z&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;27&lt;/th&gt;      &lt;td&gt;TA00029&lt;/td&gt;      &lt;td&gt;1&lt;/td&gt;      &lt;td&gt;2015-09-02T00:00:00Z&lt;/td&gt;      &lt;td&gt;2.0&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T08:36:19.30342Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T08:36:19.30342Z&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;KE&lt;/td&gt;      &lt;td&gt;&lt;/td&gt;      &lt;td&gt;-0.500776&lt;/td&gt;      &lt;td&gt;36.587511&lt;/td&gt;      &lt;td&gt;2545.8&lt;/td&gt;      &lt;td&gt;{}&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-10-26T13:33:31.451613Z&lt;/td&gt;      &lt;td&gt;37&lt;/td&gt;      &lt;td&gt;2022-02-28T12:25:09.578242Z&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;53&lt;/th&gt;      &lt;td&gt;TA00057&lt;/td&gt;      &lt;td&gt;1&lt;/td&gt;      &lt;td&gt;2015-10-08T00:00:00Z&lt;/td&gt;      &lt;td&gt;2.0&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T09:21:29.092833Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T09:21:29.092833Z&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;KE&lt;/td&gt;      &lt;td&gt;&lt;/td&gt;      &lt;td&gt;-1.253030&lt;/td&gt;      &lt;td&gt;36.856487&lt;/td&gt;      &lt;td&gt;1645.3&lt;/td&gt;      &lt;td&gt;{}&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-10-29T09:13:33.768613Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2022-07-26T07:34:06.603938Z&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;68&lt;/th&gt;      &lt;td&gt;TA00074&lt;/td&gt;      &lt;td&gt;1&lt;/td&gt;      &lt;td&gt;2015-11-19T00:00:00Z&lt;/td&gt;      &lt;td&gt;2.0&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T09:38:25.742397Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T09:38:25.742397Z&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;KE&lt;/td&gt;      &lt;td&gt;&lt;/td&gt;      &lt;td&gt;-0.566080&lt;/td&gt;      &lt;td&gt;37.074412&lt;/td&gt;      &lt;td&gt;1726.8&lt;/td&gt;      &lt;td&gt;{}&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-10-29T10:35:28.49617Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2022-07-26T07:38:42.100985Z&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;74&lt;/th&gt;      &lt;td&gt;TA00080&lt;/td&gt;      &lt;td&gt;1&lt;/td&gt;      &lt;td&gt;2016-01-28T00:00:00Z&lt;/td&gt;      &lt;td&gt;2.0&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T09:43:10.523398Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-11T09:43:10.523398Z&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;KE&lt;/td&gt;      &lt;td&gt;&lt;/td&gt;      &lt;td&gt;-1.087589&lt;/td&gt;      &lt;td&gt;36.818402&lt;/td&gt;      &lt;td&gt;1777.3&lt;/td&gt;      &lt;td&gt;{}&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-10-29T10:53:47.845042Z&lt;/td&gt;      &lt;td&gt;37&lt;/td&gt;      &lt;td&gt;2022-02-28T13:07:04.709903Z&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;150&lt;/th&gt;      &lt;td&gt;TA00166&lt;/td&gt;      &lt;td&gt;1&lt;/td&gt;      &lt;td&gt;2017-05-11T00:00:00Z&lt;/td&gt;      &lt;td&gt;2.0&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;None&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-12T08:29:28.10697Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-12-12T08:29:28.10697Z&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;KE&lt;/td&gt;      &lt;td&gt;&lt;/td&gt;      &lt;td&gt;-0.319508&lt;/td&gt;      &lt;td&gt;37.659139&lt;/td&gt;      &lt;td&gt;1404.0&lt;/td&gt;      &lt;td&gt;{}&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-11-10T08:47:37.949135Z&lt;/td&gt;      &lt;td&gt;2&lt;/td&gt;      &lt;td&gt;2018-11-10T08:47:37.949135Z&lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;6 rows Ã— 28 columns&lt;/p&gt;&lt;/div&gt;```python```</longdescription>
</pkgmetadata>