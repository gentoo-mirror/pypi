<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;h1 align=&quot;center&quot;&gt;🏃♀️ Runhouse 🏠&lt;/h1&gt;[//]: # (&lt;p align=&quot;center&quot;&gt;)[//]: # (  &lt;a href=&quot;https://discord.gg/RnhB6589Hs&quot;&gt; )[//]: # (    &lt;img alt=&quot;Join Discord&quot; src=&quot;https://img.shields.io/discord/1065833240625172600?label=Discord&amp;style=for-the-badge&quot;&gt;)[//]: # (  &lt;/a&gt;)[//]: # (&lt;/p&gt;)## 👵 Welcome Home!Runhouse is a unified interface into *existing* compute and data systems, built to reclaimthe 50-75% of ML practitioners' time lost to debugging, adapting, or repackaging codefor different environments.### 🤨 Who is this for?* 🦸♀️ **OSS maintainers** who want to improve the accessibility, reproducibility, and reach of their code,without having to build support or examples for every cloud or compute system (e.g. Kubernetes) one by one.   * See this in action in 🤗 Hugging Face ([Transformers](https://github.com/huggingface/transformers/blob/main/examples/README.md#running-the-examples-on-remote-hardware-with-auto-setup), [Accelerate](https://github.com/huggingface/accelerate/blob/main/examples/README.md#simple-multi-gpu-hardware-launcher)) and 🦜🔗 [Langchain](https://python.langchain.com/en/latest/modules/models/llms/integrations/runhouse.html)* 👩🔬 **ML Researchers and Data Scientists** who don't want to spend or wait 3-6 months translating and packagingtheir work for production.* 👩🏭 **ML Engineers** who want to be able to update and improve production services, pipelines, and artifacts with aPythonic, debuggable devX.* 👩🔧 **ML Platform teams** who want a versioned, shared, maintainable stack of services and data artifacts thatresearch and production pipelines both depend on.### 🦾 How does it work?_&quot;Learn once, run anywhere&quot;_Runhouse is like **PyTorch + Terraform + Google Drive.**1. Just as **PyTorch** lets you send a model or tensor `.to(device)`, Runhouse OSSlets you do `my_fn.to('gcp_a100')` or `my_table.to('s3')`: send functions and data to any of your compute ordata infra, all in Python, and continue to interact with them eagerly (there's no DAG) from your existing code andenvironment. Think of it as an expansion pack to Python that lets it take detours to remotemachines or manipulate remote data.2. Just as **Terraform** is a unified language for creation and destruction of infra, theRunhouse APIs are a unified interface into existing compute and data systems.See what we already support and what's on the [roadmap, below](#supported-infra).3. Runhouse resources can be shared across environments or teams, providing a **Google Drive**-likelayer for accessibility, visibility, and management across all your infra and providers.This allows you to:* Call your preprocessing, training, and inference each on different hardware frominside a single notebook or script* Slot that script into a single orchestrator node rather than translate it into an ML pipeline DAG of docker images* Share any of those services or data artifacts with your team instantly, and update them over time![img.png](https://raw.githubusercontent.com/run-house/runhouse/main/docs/assets/img.png)![img.png](https://raw.githubusercontent.com/run-house/runhouse/main/docs/assets/img_1.png)It wraps industry-standard tooling like Ray and the Cloud SDKs (boto, gsutil, etc. via [SkyPilot](https://github.com/skypilot-org/skypilot/))to give you production-quality features like queuing, distributed, async, logging,low latency, hardware efficiency, auto-launching, and auto-termination out of the box.### 👩💻 Enough chitchat, just show me the codeHere is **all the code you need** to stand up a stable diffusion inference service ona fresh cloud GPU.```pythonimport runhouse as rhfrom diffusers import StableDiffusionPipelinedef sd_generate(prompt):    model = StableDiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-2-base&quot;).to(&quot;cuda&quot;)    return model(prompt).images[0]gpu = rh.cluster(name=&quot;my-a100&quot;, instance_type=&quot;A100:1&quot;).up_if_not()sd_generate = rh.function(sd_generate).to(gpu, env=[&quot;torch&quot;, &quot;diffusers&quot;])# the following runs on our remote A100 gpusd_generate(&quot;An oil painting of Keanu Reeves eating a sandwich.&quot;).show()sd_generate.save(name=&quot;sd_generate&quot;)```On the data side, sync folders, tables, or blobs between local, clusters, and file storage. Allthis is done without bouncing off the laptop.```pythonimport runhouse as rhfolder_on_gpu = rh.folder(path=&quot;./instance_images&quot;).to(gpu, path=&quot;dreambooth/instance_images&quot;)folder_on_s3 = folder_on_gpu.to(&quot;s3&quot;, path=&quot;dreambooth/instance_images&quot;)folder_on_s3.save(&quot;dreambooth_outputs&quot;)```Reuse your saved compute and data resources from anywhere, with a single line of Python.```pythonsd_generate = rh.function(name=&quot;sd_generate&quot;)image = sd_generate(&quot;A hot dog made of matcha.&quot;)folder_on_s3 = rh.folder(name=&quot;dreambooth_outputs&quot;)folder_on_local = folder_on_s3.to(&quot;here&quot;)```These APIs work from anywhere with a Python interpreter and an internet connection.Notebooks, scripts, pipeline nodes, etc. are all fair game.### 🙅♀️ Runhouse is not* An orchestrator / scheduler (Airflow, Prefect, Metaflow)* A distributed compute DSL (Ray, Spark, Dask)* An ML Platform (Sagemaker, Vertex, Azure ML)* A model registry / experiment manager / MLOps framework (MLFlow, WNB, Kubeflow)* Hosted compute (Modal, Banana, Replicate)## 🐣 Getting StartedPlease see the [Getting Started guide](https://runhouse-docs.readthedocs-hosted.com/en/latest/installation.html#).tldr;```commandlinepip install runhouse# Or &quot;runhouse[aws]&quot;, &quot;runhouse[gcp]&quot;, &quot;runhouse[azure]&quot;, &quot;runhouse[all]&quot;# [optional] to set up cloud provider secrets:sky check# [optional] login for portability:runhouse login```## 🔒 Creating a Runhouse Account for Secrets and PortabilityYou can unlock some unique portability features by creating an (always free)[account](https://www.run.house) and saving your secrets and resource metadata there.Log in from anywhere to access all previously saved secrets and resources, ready to be used with withno additional setup.To log in, run `runhouse login` from the command line, or`rh.login()` from Python.&gt; **Note**:Secrets are stored in Hashicorp Vault (an industry standard for secrets management), and our APIs simply call Vault's APIs. We only ever store light metadata about your resources(e.g. my_folder_name -&gt; [provider, bucket, path]) on our API servers, while all actual data and computestays inside your own cloud account and never hits our servers. We plan toadd support for BYO secrets management shortly. Let us know if you need it and which system you use.## &lt;h2 id=&quot;supported-infra&quot;&gt; 🏗️ Supported Infra &lt;/h2&gt;Runhouse is an ambitious project to provide a unified API into many paradigms and providers forvarious types of infra. You can find our currently support systems and high-level roadmap below.Please reach out (first name at run.house) to contribute or share feedback!- Compute  - On-prem    - Single instance - **Supported**    - Ray cluster - **Supported**    - Kubernetes - Planned    - Slurm - Exploratory  - Cloud VMs    - AWS - **Supported**    - GCP - **Supported**    - Azure - **Supported**    - Lambda - **Supported**  - Serverless - Planned- Data  - Blob storage    - AWS - **Supported**    - GCP - **Supported**    - R2 - Planned    - Azure - Exploratory  - Tables    - Arrow-based (Pandas, Hugging Face, PyArrow, Ray.data, Dask, CuDF) - **Supported**    - SQL-style - Planned    - Lakehouse - Exploratory  - KVStores - Exploratory- Management  - Secrets    - Runhouse Den (via Hashicorp Vault) - **Supported**    - Custom (Vault, AWS, GCP, Azure) - Planned  - RBAC - Planned  - Telemetry - Planned## 👨🏫 Learn More[**Docs**](https://runhouse-docs.readthedocs-hosted.com/en/latest/index.html):High-level overviews of the architecture, detailed API references, and basic API examples.[**Tutorials Repo**](https://github.com/run-house/tutorials): A comprehensive walkthrough of Runhouse APIs through some popular ML examples, think Stable Diffusion, Dreambooth, BERT.[**Funhouse Repo**](https://github.com/run-house/funhouse): Standalone Runhouse apps to try out fun ML ideas,think the latest Stable Diffusion models, text generation models, launching Gradio spaces, and even more![**Comparisons Repo**](https://github.com/run-house/comparisons): Comparisons of Runhouse with other ML solutions, with working code examples.## 🙋♂️ Getting HelpMessage us on [Discord](https://discord.gg/RnhB6589Hs), email us (first name at run.house), or create an issue.## 👷♀️ ContributingWe welcome contributions! Please check out [contributing](CONTRIBUTING.md) if you're interested.</longdescription>
</pkgmetadata>