<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;  &lt;h1&gt;Cherche&lt;/h1&gt;  &lt;p&gt;Neural search&lt;/p&gt;&lt;/div&gt;&lt;br&gt;&lt;div align=&quot;center&quot;&gt;  &lt;!-- Documentation --&gt;  &lt;a href=&quot;https://raphaelsty.github.io/cherche/&quot;&gt;&lt;img src=&quot;https://img.shields.io/website?label=docs&amp;style=flat-square&amp;url=https%3A%2F%2Fraphaelsty.github.io/cherche/%2F&quot; alt=&quot;documentation&quot;&gt;&lt;/a&gt;  &lt;!-- Demo --&gt;  &lt;a href=&quot;https://huggingface.co/spaces/raphaelsty/games&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/demo-running-blueviolet?style=flat-square&quot; alt=&quot;Demo&quot;&gt;&lt;/a&gt;  &lt;!-- License --&gt;  &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&quot; alt=&quot;license&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;br&gt;Cherche allows the creation of efficient neural search pipelines using retrievers and pre-trained language models as rankers. Cherche's main strength is its ability to build diverse and end-to-end pipelines from lexical matching, semantic matching, and collaborative filtering-based models.![Alt text](docs/img/explain.png)## Installation ü§ñ```shpip install cherche --upgrade```To install the development version:```shpip install git+https://github.com/raphaelsty/cherche```## [Documentation](https://raphaelsty.github.io/cherche/) üìúDocumentation is available [here](https://raphaelsty.github.io/cherche/). It provides detailsabout retrievers, rankers, pipelines, question answering, summarization, and examples.## QuickStart üí®### Documents üìëCherche allows findings the right document within a list of objects. Here is an example of a corpus.```pythonfrom cherche import datadocuments = data.load_towns()documents[:3][{'id': 0,  'title': 'Paris',  'url': 'https://en.wikipedia.org/wiki/Paris',  'article': 'Paris is the capital and most populous city of France.'}, {'id': 1,  'title': 'Paris',  'url': 'https://en.wikipedia.org/wiki/Paris',  'article': &quot;Since the 17th century, Paris has been one of Europe's major centres of science, and arts.&quot;}, {'id': 2,  'title': 'Paris',  'url': 'https://en.wikipedia.org/wiki/Paris',  'article': 'The City of Paris is the centre and seat of government of the region and province of √éle-de-France.'  }]```### Retriever ranker üîçHere is an example of a neural search pipeline composed of a TF-IDF that quickly retrieves documents, followed by a ranking model. The ranking model sorts the documents produced by the retriever based on the semantic similarity between the query and the documents.```pythonfrom cherche import data, retrieve, rankfrom sentence_transformers import SentenceTransformer# List of dictsdocuments = data.load_towns()# Retrieve on fields title and articleretriever = retrieve.TfIdf(key=&quot;id&quot;, on=[&quot;title&quot;, &quot;article&quot;], documents=documents, k=30)# Rank on fields title and articleranker = rank.Encoder(    key = &quot;id&quot;,    on = [&quot;title&quot;, &quot;article&quot;],    encoder = SentenceTransformer(&quot;sentence-transformers/all-mpnet-base-v2&quot;).encode,    k = 3,)# Pipeline creationsearch = retriever + rankersearch.add(documents=documents)search(&quot;Bordeaux&quot;)[{'id': 57, 'similarity': 0.69513476}, {'id': 63, 'similarity': 0.6214991}, {'id': 65, 'similarity': 0.61809057}]```Map the index to the documents to access their contents.```pythonsearch += documentssearch(&quot;Bordeaux&quot;)[{'id': 57,  'title': 'Bordeaux',  'url': 'https://en.wikipedia.org/wiki/Bordeaux',  'article': 'Bordeaux ( bor-DOH, French: [b…î Ådo] (listen); Gascon Occitan: Bord√®u [bu…æÀà√∞…õw]) is a port city on the river Garonne in the Gironde department, Southwestern France.',  'similarity': 0.69513476}, {'id': 63,  'title': 'Bordeaux',  'url': 'https://en.wikipedia.org/wiki/Bordeaux',  'article': 'The term &quot;Bordelais&quot; may also refer to the city and its surrounding region.',  'similarity': 0.6214991}, {'id': 65,  'title': 'Bordeaux',  'url': 'https://en.wikipedia.org/wiki/Bordeaux',  'article': &quot;Bordeaux is a world capital of wine, with its castles and vineyards of the Bordeaux region that stand on the hillsides of the Gironde and is home to the world's main wine fair, Vinexpo.&quot;,  'similarity': 0.61809057}]```## Retrieve üëªCherche provides different [retrievers](https://raphaelsty.github.io/cherche/retrieve/retrieve/) that filter input documents based on a query.- retrieve.Elastic- retrieve.TfIdf- retrieve.Lunr- retrieve.BM25Okapi- retrieve.BM25L- retrieve.Flash- retrieve.Encoder- retrieve.DPR- retrieve.Fuzz- retrieve.Meilisearch- retrieve.TypeSense- retrieve.Recommend## Rank ü§óCherche rankers are compatible with [SentenceTransformers](https://www.sbert.net/docs/pretrained_models.html) models, [Hugging Face sentence similarity](https://huggingface.co/models?pipeline_tag=zero-shot-classification&amp;sort=downloads) models, [Hugging Face zero shot classification](https://huggingface.co/models?pipeline_tag=zero-shot-classification&amp;sort=downloads) models, and of course with your own models.## Summarization and question answeringCherche provides modules dedicated to summarization and question answering. These modules are compatible with Hugging Face's pre-trained models and fully integrated into neural search pipelines.## TranslationHugging Face's translation models can be fully integrated into the neural search pipeline to translate queries, documents, or answers.## Collaborative filteringSearch is fully compatible with the collaborative filtering library [Implicit](https://github.com/benfred/implicit). It is advantageous if you have a history associated with users and you want to retrieve / re-rank documents based on user preferences.|            | **Document 1** | **Document 2** | **Document 3** | **Document 4** ||:----------:|:--------------:|:--------------:|:--------------:|:--------------:|| **User 1** |        1       |        0       |        0       |        1       || **User 2** |        0       |        1       |        0       |        0       || **User 3** |        0       |        4       |        1       |        0       |## DeployWe provide a minimalist API to deploy our neural search pipeline with FastAPI and Docker; information is available in the [documentation](https://raphaelsty.github.io/cherche/deployment/deployment/).## Hugging Face SpaceA running demo is available on [Hugging Face](https://huggingface.co/spaces/raphaelsty/games).## Contributors ü§ùCherche was created for/by Renault and is now available to all.We welcome all contributions.&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/img/renault.jpg&quot;/&gt;&lt;/p&gt;## Acknowledgements üëèThe BM25 models available in Cherche are wrappers around [rank_bm25](https://github.com/dorianbrown/rank_bm25). Elastic retriever is a wrapper around [Python Elasticsearch Client](https://elasticsearch-py.readthedocs.io/en/v7.15.2/). TfIdf retriever is a wrapper around [scikit-learn's TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Lunr retriever is a wrapper around [Lunr.py](https://github.com/yeraydiazdiaz/lunr.py). Flash retriever is a wrapper around [FlashText](https://github.com/vi3k6i5/flashtext). DPR and Encode rankers are wrappers dedicated to the use of the pre-trained models of [SentenceTransformers](https://www.sbert.net/docs/pretrained_models.html) in a neural search pipeline. ZeroShot ranker is a wrapper dedicated to the use of the zero-shot sequence classifiers of [Hugging Face](https://huggingface.co/models?pipeline_tag=zero-shot-classification&amp;sort=downloads) in a neural search pipeline.## See also üëÄCherche is a minimalist solution and meets a need for modularity. Cherche is the way to go if we start with a list of documents as JSON with multiple fields to search on and create pipelines. Also, Cherche is well suited for middle-sized corpora.Do not hesitate to look at Jina, Haystack, or TxtAi, which offer advanced neural search solutions.- [Haystack](https://github.com/deepset-ai/haystack)- [Jina](https://github.com/jina-ai/jina)- [txtai](https://github.com/neuml/txtai)## CitationsIf you use cherche to produce results for your scientific publication, please refer to our SIGIR paper:```@inproceedings{Sourty2022sigir,    author = {Raphael Sourty and Jose G. Moreno and Lynda Tamine and Francois-Paul Servant},    title = {CHERCHE: A new tool to rapidly implement pipelines in information retrieval},    booktitle = {Proceedings of SIGIR 2022},    year = {2022}}```## Dev Team üíæThe Cherche dev team is made up of [Rapha√´l Sourty](https://github.com/raphaelsty), [Fran√ßois-Paul Servant](https://github.com/fpservant), [Nicolas Bizzozzero](https://github.com/NicolasBizzozzero), [Jose G Moreno](https://scholar.google.com/citations?user=4BZFUw8AAAAJ&amp;hl=fr). ü•≥</longdescription>
</pkgmetadata>