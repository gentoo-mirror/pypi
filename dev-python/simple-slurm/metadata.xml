<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;h1 align=&quot;center&quot;&gt;Simple Slurm&lt;/h1&gt;&lt;p align=&quot;center&quot;&gt;A simple Python wrapper for Slurm with flexibility in mind&lt;p&gt;&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/amq92/simple_slurm/actions/workflows/python-publish-pypi.yml&quot;&gt;    &lt;img src=&quot;https://github.com/amq92/simple_slurm/actions/workflows/python-publish-pypi.yml/badge.svg&quot; alt=&quot;Publish to PyPI&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/amq92/simple_slurm/actions/workflows/python-package-conda.yml&quot;&gt;    &lt;img src=&quot;https://github.com/amq92/simple_slurm/actions/workflows/python-package-conda.yml/badge.svg&quot; alt=&quot;Publish to Conda&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/amq92/simple_slurm/actions/workflows/python-run-tests.yml&quot;&gt;    &lt;img src=&quot;https://github.com/amq92/simple_slurm/actions/workflows/python-run-tests.yml/badge.svg&quot; alt=&quot;Run Python Tests&quot; /&gt;&lt;/a&gt;&lt;/p&gt;```pythonimport datetimefrom simple_slurm import Slurmslurm = Slurm(    array=range(3, 12),    cpus_per_task=15,    dependency=dict(after=65541, afterok=34987),    gres=['gpu:kepler:2', 'gpu:tesla:2', 'mps:400'],    ignore_pbs=True,    job_name='name',    output=f'{Slurm.JOB_ARRAY_MASTER_ID}_{Slurm.JOB_ARRAY_ID}.out',    time=datetime.timedelta(days=1, hours=2, minutes=3, seconds=4),)slurm.sbatch('python demo.py ' + Slurm.SLURM_ARRAY_TASK_ID)```The above snippet is equivalent to running the following command:```bashsbatch &lt;&lt; EOF#!/bin/sh#SBATCH --array               3-11#SBATCH --cpus-per-task       15#SBATCH --dependency          after:65541,afterok:34987#SBATCH --gres                gpu:kepler:2,gpu:tesla:2,mps:400#SBATCH --ignore-pbs#SBATCH --job-name            name#SBATCH --output              %A_%a.out#SBATCH --time                1-02:03:04python demo.py \$SLURM_ARRAY_TASK_IDEOF```## Contents+ [Introduction](#introduction)+ [Installation instructions](#installation-instructions)+ [Many syntaxes available](#many-syntaxes-available)    - [Using configuration files](#using-configuration-files)    - [Using the command line](#using-the-command-line)+ [Job dependencies](#job-dependencies)+ [Additional features](#additional-features)    - [Filename Patterns](#filename-patterns)    - [Output Environment Variables](#output-environment-variables)## IntroductionThe [`sbatch`](https://slurm.schedmd.com/sbatch.html) and [`srun`](https://slurm.schedmd.com/srun.html) commands in [Slurm](https://slurm.schedmd.com/overview.html) allow submitting parallel jobs into a Linux cluster in the form of batch scripts that follow a certain structure.The goal of this library is to provide a simple wrapper for these functions (`sbatch` and `srun`) so that Python code can be used for constructing and launching the aforementioned batch script.Indeed, the generated batch script can be shown by printing the `Slurm` object:```pythonfrom simple_slurm import Slurmslurm = Slurm(array=range(3, 12), job_name='name')print(slurm)``````bash&gt;&gt; #!/bin/sh&gt;&gt; &gt;&gt; #SBATCH --array               3-11&gt;&gt; #SBATCH --job-name            name```Then, the job can be launched with either command:```pythonslurm.srun('echo hello!')slurm.sbatch('echo hello!')``````bash&gt;&gt; Submitted batch job 34987```While both commands are quite similar, [`srun`](https://slurm.schedmd.com/srun.html) will wait for the job completion, while [`sbatch`](https://slurm.schedmd.com/sbatch.html) will launch and disconnect from the jobs.&gt; More information can be found in [Slurm's Quick Start Guide](https://slurm.schedmd.com/quickstart.html) and in [here](https://stackoverflow.com/questions/43767866/slurm-srun-vs-sbatch-and-their-parameters).## Installation instructionsFrom PyPI```bashpip install simple_slurm```From Conda```bashconda install -c conda-forge simple_slurm```From git```bashpip install git+https://github.com/amq92/simple_slurm.git```## Many syntaxes available```pythonslurm = Slurm('-a', '3-11')slurm = Slurm('--array', '3-11')slurm = Slurm('array', '3-11')slurm = Slurm(array='3-11')slurm = Slurm(array=range(3, 12))slurm.add_arguments(array=range(3, 12))slurm.set_array(range(3, 12))```All these arguments are equivalent!It's up to you to choose the one(s) that best suits you needs.&gt; *&quot;With great flexibility comes great responsability&quot;*You can either keep a command-line-like syntax or a more Python-like one```pythonslurm = Slurm()slurm.set_dependency('after:65541,afterok:34987')slurm.set_dependency(['after:65541', 'afterok:34987'])slurm.set_dependency(dict(after=65541, afterok=34987))```All the possible arguments have their own setter methods(ex. `set_array`, `set_dependency`, `set_job_name`).Please note that hyphenated arguments, such as `--job-name`, need to be underscored(so to comply with Python syntax and be coherent).```pythonslurm = Slurm('--job_name', 'name')slurm = Slurm(job_name='name')# slurm = Slurm('--job-name', 'name')  # NOT VALID# slurm = Slurm(job-name='name')       # NOT VALID```Moreover, boolean arguments such as `--contiguous`, `--ignore_pbs` or `--overcommit` can be activated with `True` or an empty string.```pythonslurm = Slurm('--contiguous', True)slurm.add_arguments(ignore_pbs='')slurm.set_wait(False)print(slurm)``````bash#!/bin/sh#SBATCH --contiguous#SBATCH --ignore-pbs```### Using configuration filesLet's define the *static* components of a job definition in a YAML file `default.slurm````yamlcpus_per_task: 15job_name: 'name'output: '%A_%a.out'```Including these options with the using the `yaml` package is very *simple*```pythonimport yamlfrom simple_slurm import Slurmslurm = Slurm(**yaml.load(open('default.slurm')))...slurm.set_array(range(NUMBER_OF_SIMULATIONS))```The job can be updated according to the *dynamic* project needs (ex. `NUMBER_OF_SIMULATIONS`).### Using the command lineFor simpler dispatch jobs, a comand line entry point is also made available.```bashsimple_slurm [OPTIONS] &quot;COMMAND_TO_RUN_WITH_SBATCH&quot;```As such, both of these `python` and `bash` calls are equivalent.```pythonslurm = Slurm(partition='compute.p', output='slurm.log', ignore_pbs=True)slurm.sbatch('echo \$HOSTNAME')``````bashsimple_slurm --partition=compute.p --output slurm.log --ignore_pbs &quot;echo \$HOSTNAME&quot;```## Job dependenciesThe `sbatch` call prints a message if successful and returns the corresponding `job_id` ```pythonjob_id = slurm.sbatch('python demo.py ' + Slurm.SLURM_ARRAY_TAKSK_ID)```If the job submission was successful, it prints:```Submitted batch job 34987```And returns the variable `job_id = 34987`, which can be used for setting dependencies on subsequent jobs```pythonslurm_after = Slurm(dependency=dict(afterok=job_id)))```## Additional featuresFor convenience, Filename Patterns and Output Environment Variables are available as attributes of the Simple Slurm object.See [https://slurm.schedmd.com/sbatch.html](https://slurm.schedmd.com/sbatch.html#lbAH) for details on the commands.```pythonfrom slurm import Slurmslurm = Slurm(output=('{}_{}.out'.format(    Slurm.JOB_ARRAY_MASTER_ID,    Slurm.JOB_ARRAY_ID))slurm.sbatch('python demo.py ' + slurm.SLURM_ARRAY_JOB_ID)```This example would result in output files of the form `65541_15.out`.Here the job submission ID is `65541`, and this output file corresponds to the submission number `15` in the job array. Moreover, this index is passed to the Python code `demo.py` as an argument.&gt; Note that they can be accessed either as `Slurm.&lt;name&gt;` or `slurm.&lt;name&gt;`, here `slurm` is an instance of the `Slurm` class.### Filename Patterns`sbatch` allows for a filename pattern to contain one or more replacement symbols.They can be accessed with `Slurm.&lt;name&gt;`name                | value | description:-------------------|------:|:-----------JOB_ARRAY_MASTER_ID | %A    |  job array's master job allocation numberJOB_ARRAY_ID        | %a    |  job array id (index) numberJOB_ID_STEP_ID      | %J    |  jobid.stepid of the running job. (e.g. &quot;128.0&quot;)JOB_ID              | %j    |  jobid of the running jobHOSTNAME            | %N    |  short hostname. this will create a separate io file per nodeNODE_IDENTIFIER     | %n    |  node identifier relative to current job (e.g. &quot;0&quot; is the first node of the running job) this will create a separate io file per nodeSTEP_ID             | %s    |  stepid of the running jobTASK_IDENTIFIER     | %t    |  task identifier (rank) relative to current job. this will create a separate io file per taskUSER_NAME           | %u    |  user nameJOB_NAME            | %x    |  job namePERCENTAGE          | %%    |  the character &quot;%&quot;DO_NOT_PROCESS      | \\\\  |  do not process any of the replacement symbols### Output Environment VariablesThe Slurm controller will set the following variables in the environment of the batch script.They can be accessed with `Slurm.&lt;name&gt;`.name                   | description:----------------------|:-----------SLURM_ARRAY_TASK_COUNT | total number of tasks in a job arraySLURM_ARRAY_TASK_ID    | job array id (index) numberSLURM_ARRAY_TASK_MAX   | job array's maximum id (index) numberSLURM_ARRAY_TASK_MIN   | job array's minimum id (index) numberSLURM_ARRAY_TASK_STEP  | job array's index step sizeSLURM_ARRAY_JOB_ID     | job array's master job id number...                    | ...See [https://slurm.schedmd.com/sbatch.html](https://slurm.schedmd.com/sbatch.html#lbAK) for a complete list.</longdescription>
</pkgmetadata>