<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>*********# fastapi_crawler_scheduler*********## 使用*********```pythonfrom fastapi import FastAPIfrom fastapi_crawler_scheduler import TaskSchedulerapp = FastAPI()task_scheduler = TaskScheduler(    app=app,    ssl=False,    project_name=&quot;project_name&quot;,    server_name=&quot;server_name&quot;,    redis_username='redis_username',    redis_password='redis_password',    redis_host=&quot;127.0.0.1&quot;,    redis_port=6379,    thread_pool_size=50,)```### 添加|更新任务 - add_task#### interval类型```pythondef add_spider(**crawler_info):    print(f&quot;add_spider = {crawler_info}&quot;)    print(&quot;add_spider&quot;)trigger = 'interval'crawler_info = {    &quot;topic&quot;: &quot;interval insert_task&quot;,    &quot;title_handler_name&quot;: &quot;interval insert_task&quot;,    &quot;seconds&quot;: 4,}job_id = 'job_1'task_scheduler.add_task(    func=add_spider,    job_id=job_id,    trigger=trigger,    crawler_info=crawler_info,    seconds=4)```#### date类型```pythondef add_spider(**crawler_info):    print(f&quot;add_spider = {crawler_info}&quot;)    print(&quot;add_spider&quot;)trigger = 'date'crawler_info = {    &quot;topic&quot;: &quot;date insert_task&quot;,    &quot;title_handler_name&quot;: &quot;date insert_task&quot;,    &quot;run_date&quot;: &quot;2022-10-03 11:30:00&quot;,}job_id = 'job_1'run_date = '2022-10-03 11:30:00'task_scheduler.add_task(    func=add_spider,    job_id=job_id,    trigger=trigger,    crawler_info=crawler_info,    run_date=run_date,)```#### cron类型```pythondef add_spider(**crawler_info):    print(f&quot;add_spider = {crawler_info}&quot;)    print(&quot;add_spider&quot;)job_id = 'job_1'trigger = 'cron'minute = '*/2'crawler_info = {    &quot;topic&quot;: &quot;cron update_task&quot;,    &quot;title_handler_name&quot;: &quot;cron update_task&quot;,    &quot;minute&quot;: minute,}task_scheduler.add_task(    func=add_spider,    job_id=job_id,    trigger=trigger,    crawler_info=crawler_info,    minute=minute,)```### 删除任务 - delete_task```pythonjob_id = 'job_1'task_scheduler.delete_task(job_id=job_id)```### 查看任务```python# 查看该项目的所有键task_scheduler.show_all_redis_key()# 查看该项目的所进程task_scheduler.show_all_redis_nodes()# 查看该项目的所有加载过的任务task_scheduler.show_all_redis_tasks()# 查看该项目使用的apscheduler.get_jobs()方法获得的所有任务task_scheduler.show_all_scheduler_get_jobs()# 查看该项目的apscheduler存储redis的所有任务task_scheduler.show_all_apscheduler_stores_jobs()# 查看该项目的的apscheduler存储redis的所有任务的run_ttimestask_scheduler.show_all_redis_apscheduler_run_times()# 查看该项目的所有任务不存在apscheduler存储redis的所有任务task_scheduler.show_all_task_not_in_stores_jobs()# 查看该项目的任务没有执行的项目（不包含只执行过一次的项目）task_scheduler.show_all_task_not_in_stores_run_times()task_scheduler.clear_project_keys()```### 请求redis 脏数据   慎用```pythontask_scheduler.clear_project_keys()```安装============Pypi----    $ pip install fastapi-crawler-scheduler</longdescription>
</pkgmetadata>