<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># celery-heimdall[![codecov](https://codecov.io/gh/TkTech/celery-heimdall/branch/main/graph/badge.svg?token=1A2CVHQ25Q)](https://codecov.io/gh/TkTech/celery-heimdall)![GitHub](https://img.shields.io/github/license/tktech/celery-heimdall)![PyPI - Python Version](https://img.shields.io/pypi/pyversions/celery-heimdall)Celery Heimdall is a set of common utilities useful for the Celery backgroundworker framework, built on top of Redis. It's not trying to handle every usecase, but to be an easy, modern, and maintainable drop-in solution for 90% ofprojects.## Features- Globally unique tasks, allowing only 1 copy of a task to execute at a time, or  within a time period (ex: &quot;Don't allow queuing until an hour has passed&quot;)- Global rate limiting. Celery has built-in rate limiting, but it's a rate limit  _per worker_, making it unsuitable for purposes such as limiting requests to  an API.## Installation`pip install celery-heimdall`## Usage### Unique TasksImagine you have a task that starts when a user presses a button. This tasktakes a long time and a lot of resources to generate a report. You don't wantthe user to press the button 10 times and start 10 tasks. In this case, youwant what Heimdall calls a unique task:```pythonfrom celery import shared_taskfrom celery_heimdall import HeimdallTask@shared_task(base=HeimdallTask, heimdall={'unique': True})def generate_report(customer_id):    pass```All we've done here is change the base Task class that Celery will use to runthe task, and passed in some options for Heimdall to use. This task is nowunique - for the given arguments, only 1 will ever run at the same time.#### ExpiryWhat happens if our task dies, or something goes wrong? We might end up in asituation where our lock never gets cleared, called [deadlock][]. To work aroundthis, we add a maximum time before the task is allowed to be queued again:```pythonfrom celery import shared_taskfrom celery_heimdall import HeimdallTask@shared_task(  base=HeimdallTask,  heimdall={    'unique': True,    'unique_timeout': 60 * 60  })def generate_report(customer_id):  pass```Now, `generate_report` will be allowed to run again in an hour even if thetask got stuck, the worker ran out of memory, the machine burst into flames,etc...#### Custom KeysBy default, a hash of the task name and its arguments is used as the lock key.But this often might not be what you want. What if you only want one report ata time, even for different customers? Ex:```pythonfrom celery import shared_taskfrom celery_heimdall import HeimdallTask@shared_task(  base=HeimdallTask,  heimdall={    'unique': True,    'key': lambda args, kwargs: 'generate_report'  })def generate_report(customer_id):  pass```By specifying our own key function, we can completely customize how we determineif a task is unique.#### The Existing TaskBy default, if you try to queue up a unique task that is already running,Heimdall will return the existing task's `AsyncResult`. This lets you writesimple code that doesn't need to care if a task is unique or not. Imagine asimple API endpoint that starts a report when it's hit, but we only want itto run one at a time. The below is all you need:```pythonimport timefrom celery import shared_taskfrom celery_heimdall import HeimdallTask@shared_task(base=HeimdallTask, heimdall={'unique': True})def generate_report(customer_id):  time.sleep(10)def my_api_call(customer_id: int):  return {    'status': 'RUNNING',    'task_id': generate_report.delay(customer_id).id  }```Everytime `my_api_call` is called with the same `customer_id`, the same`task_id` will be returned by `generate_report.delay()` until the original taskhas completed.Sometimes you'll want to catch that the task was already running when you triedto queue it again. We can tell Heimdall to raise an exception in this case:```pythonimport timefrom celery import shared_taskfrom celery_heimdall import HeimdallTask, AlreadyQueuedError@shared_task(  base=HeimdallTask,  heimdall={    'unique': True,    'unique_raises': True  })def generate_report(customer_id):  time.sleep(10)def my_api_call(customer_id: int):  try:    task = generate_report.delay(customer_id)    return {'status': 'STARTED', 'task_id': task.id}  except AlreadyQueuedError as exc:    return {'status': 'ALREADY_RUNNING', 'task_id': exc.likely_culprit}```By setting `unique_raises` to `True` when we define our task, an`AlreadyQueuedError` will be raised when you try to queue up a unique tasktwice. The `AlreadyQueuedError` has two properties:- `likely_culprit`, which contains the task ID of the already-running task,- `expires_in`, which is the time remaining (in seconds) before the   already-running task is considered to be expired.#### Unique Interval TaskWhat if we want the task to only run once in an hour, even if it's finished?In those cases, we want it to run, but not clear the lock when it's finished:```pythonfrom celery import shared_taskfrom celery_heimdall import HeimdallTask@shared_task(  base=HeimdallTask,  heimdall={    'unique': True,    'unique_timeout': 60 * 60,    'unique_wait_for_expiry': True  })def generate_report(customer_id):  pass```By setting `unique_wait_for_expiry` to `True`, the task will finish, and won'tallow another `generate_report()` to be queued until `unique_timeout` haspassed.### Rate LimitingCelery offers rate limiting out of the box. However, this rate limiting applieson a per-worker basis. There's no reliable way to rate limit a task across allyour workers. Heimdall makes this easy:```pythonfrom celery import shared_taskfrom celery_heimdall import HeimdallTask, RateLimit@shared_task(  base=HeimdallTask,  heimdall={    'rate_limit': RateLimit((2, 60))  })def download_report_from_amazon(customer_id):  pass```This says &quot;every 60 seconds, only allow this task to run 2 times&quot;. If a taskcan't be run because it would violate the rate limit, it'll be rescheduled.It's important to note this does not guarantee that your task will run _exactly_twice a second, just that it won't run _more_ than twice a second. Tasks arerescheduled with a random jitter to prevent the [thundering herd][] problem.#### Dynamic Rate LimitingJust like you can dynamically provide a key for a task, you can alsodynamically provide a rate limit based off that key.```pythonfrom celery import shared_taskfrom celery_heimdall import HeimdallTask, RateLimit@shared_task(  base=HeimdallTask,  heimdall={    # Provide a lower rate limit for the customer with the ID 10, for everyone    # else provide a higher rate limit.    'rate_limit': RateLimit(lambda args: (1, 30) if args[0] == 10 else (2, 30)),    'key': lambda args, kwargs: f'customer_{args[0]}'  })def download_report_from_amazon(customer_id):  pass```## InspirationsThese are more mature projects which inspired this library, and which maysupport older versions of Celery &amp; Python then this project.- [celery_once][], which is unfortunately abandoned and the reason this project  exists.- [celery_singleton][]- [This snippet][snip] by Vigrond, and subsequent improvements by various  contributors.[celery_once]: https://github.com/cameronmaske/celery-once[celery_singleton]: https://github.com/steinitzu/celery-singleton[deadlock]: https://en.wikipedia.org/wiki/Deadlock[thundering herd]: https://en.wikipedia.org/wiki/Thundering_herd_problem[snip]: https://gist.github.com/Vigrond/2bbea9be6413415e5479998e79a1b11a</longdescription>
</pkgmetadata>