<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Google Search Results in Python[![Package](https://badge.fury.io/py/google-search-results.svg)](https://badge.fury.io/py/google-search-results)[![Build](https://github.com/serpapi/google-search-results-python/actions/workflows/python-package.yml/badge.svg)](https://github.com/serpapi/google-search-results-python/actions/workflows/python-package.yml)This Python package is meant to scrape and parse search results from Google, Bing, Baidu, Yandex, Yahoo, Home Depot, eBay and more, using [SerpApi](https://serpapi.com). The following services are provided:- [Search API](https://serpapi.com/search-api)- [Search Archive API](https://serpapi.com/search-archive-api)- [Account API](https://serpapi.com/account-api)- [Location API](https://serpapi.com/locations-api) (Google Only)SerpApi provides a [script builder](https://serpapi.com/demo) to get you started quickly.## InstallationPython 3.7+```bashpip install google-search-results```[Link to the python package page](https://pypi.org/project/google-search-results/)## Quick start```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({    &quot;q&quot;: &quot;coffee&quot;,     &quot;location&quot;: &quot;Austin,Texas&quot;,    &quot;api_key&quot;: &quot;&lt;your secret api key&gt;&quot;  })result = search.get_dict()```This example runs a search for &quot;coffee&quot; using your secret API key.The SerpApi service (backend)- Searches Google using the search: q = &quot;coffee&quot;- Parses the messy HTML responses- Returns a standardized JSON responseThe GoogleSearch class- Formats the request- Executes a GET http request against SerpApi service- Parses the JSON response into a dictionaryEt voil√†...Alternatively, you can search:- Bing using BingSearch class- Baidu using BaiduSearch class- Yahoo using YahooSearch class- DuckDuckGo using DuckDuckGoSearch class- eBay using EbaySearch class- Yandex using YandexSearch class- HomeDepot using HomeDepotSearch class- GoogleScholar using GoogleScholarSearch class- Youtube using YoutubeSearch class- Walmart using WalmartSearch- Apple App Store using AppleAppStoreSearch class- Naver using NaverSearch classSee the [playground to generate your code.](https://serpapi.com/playground)## Summary- [Google Search Results in Python](#google-search-results-in-python)  - [Installation](#installation)  - [Quick start](#quick-start)  - [Summary](#summary)    - [Google Search API capability](#google-search-api-capability)    - [How to set SERP API key](#how-to-set-serp-api-key)    - [Example by specification](#example-by-specification)    - [Location API](#location-api)    - [Search Archive API](#search-archive-api)    - [Account API](#account-api)    - [Search Bing](#search-bing)    - [Search Baidu](#search-baidu)    - [Search Yandex](#search-yandex)    - [Search Yahoo](#search-yahoo)    - [Search Ebay](#search-ebay)    - [Search Home depot](#search-home-depot)    - [Search Youtube](#search-youtube)    - [Search Google Scholar](#search-google-scholar)    - [Generic search with SerpApiClient](#generic-search-with-serpapiclient)    - [Search Google Images](#search-google-images)    - [Search Google News](#search-google-news)    - [Search Google Shopping](#search-google-shopping)    - [Google Search By Location](#google-search-by-location)    - [Batch Asynchronous Searches](#batch-asynchronous-searches)    - [Python object as a result](#python-object-as-a-result)    - [Python paginate using iterator](#pagination-using-iterator)    - [Error management](#error-management)  - [Change log](#change-log)  - [Conclusion](#conclusion)### Google Search API capabilitySource code.```pythonparams = {  &quot;q&quot;: &quot;coffee&quot;,  &quot;location&quot;: &quot;Location Requested&quot;,   &quot;device&quot;: &quot;desktop|mobile|tablet&quot;,  &quot;hl&quot;: &quot;Google UI Language&quot;,  &quot;gl&quot;: &quot;Google Country&quot;,  &quot;safe&quot;: &quot;Safe Search Flag&quot;,  &quot;num&quot;: &quot;Number of Results&quot;,  &quot;start&quot;: &quot;Pagination Offset&quot;,  &quot;api_key&quot;: &quot;Your SERP API Key&quot;,   # To be match  &quot;tbm&quot;: &quot;nws|isch|shop&quot;,   # To be search  &quot;tbs&quot;: &quot;custom to be search criteria&quot;,  # allow async request  &quot;async&quot;: &quot;true|false&quot;,  # output format  &quot;output&quot;: &quot;json|html&quot;}# define the search searchsearch = GoogleSearch(params)# override an existing parametersearch.params_dict[&quot;location&quot;] = &quot;Portland&quot;# search format return as raw htmlhtml_results = search.get_html()# parse results#  as python Dictionarydict_results = search.get_dict()#  as JSON using json packagejson_results = search.get_json()#  as dynamic Python objectobject_result = search.get_object()```[Link to the full documentation](https://serpapi.com/search-api)See below for more hands-on examples.### How to set SERP API keyYou can get an API key here if you don't already have one: https://serpapi.com/users/sign_upThe SerpApi `api_key` can be set globally:```pythonGoogleSearch.SERP_API_KEY = &quot;Your Private Key&quot;```The SerpApi `api_key` can be provided for each search:```pythonquery = GoogleSearch({&quot;q&quot;: &quot;coffee&quot;, &quot;serp_api_key&quot;: &quot;Your Private Key&quot;})```### Example by specificationWe love true open source, continuous integration and Test Driven Development (TDD).  We are using RSpec to test [our infrastructure around the clock](https://travis-ci.org/serpapi/google-search-results-python) to achieve the best Quality of Service (QoS). The directory test/ includes specification/examples.Set your API key.```bashexport API_KEY=&quot;your secret key&quot;```Run test```pythonmake test```### Location API```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({})location_list = search.get_location(&quot;Austin&quot;, 3)print(location_list)```This prints the first 3 locations matching Austin (Texas, Texas, Rochester).```python[   {   'canonical_name': 'Austin,TX,Texas,United States',        'country_code': 'US',        'google_id': 200635,        'google_parent_id': 21176,        'gps': [-97.7430608, 30.267153],        'id': '585069bdee19ad271e9bc072',        'keys': ['austin', 'tx', 'texas', 'united', 'states'],        'name': 'Austin, TX',        'reach': 5560000,        'target_type': 'DMA Region'},        ...]```### Search Archive APIThe search results are stored in a temporary cache.The previous search can be retrieved from the cache for free.```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({&quot;q&quot;: &quot;Coffee&quot;, &quot;location&quot;: &quot;Austin,Texas&quot;})search_result = search.get_dictionary()assert search_result.get(&quot;error&quot;) == Nonesearch_id = search_result.get(&quot;search_metadata&quot;).get(&quot;id&quot;)print(search_id)```Now let's retrieve the previous search from the archive.```pythonarchived_search_result = GoogleSearch({}).get_search_archive(search_id, 'json')print(archived_search_result.get(&quot;search_metadata&quot;).get(&quot;id&quot;))```This prints the search result from the archive.### Account API```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({})account = search.get_account()```This prints your account information.### Search Bing```pythonfrom serpapi import BingSearchsearch = BingSearch({&quot;q&quot;: &quot;Coffee&quot;, &quot;location&quot;: &quot;Austin,Texas&quot;})data = search.get_dict()```This code prints Bing search results for coffee as a Dictionary. https://serpapi.com/bing-search-api### Search Baidu```pythonfrom serpapi import BaiduSearchsearch = BaiduSearch({&quot;q&quot;: &quot;Coffee&quot;})data = search.get_dict()```This code prints Baidu search results for coffee as a Dictionary. https://serpapi.com/baidu-search-api### Search Yandex```pythonfrom serpapi import YandexSearchsearch = YandexSearch({&quot;text&quot;: &quot;Coffee&quot;})data = search.get_dict()```This code prints Yandex search results for coffee as a Dictionary. https://serpapi.com/yandex-search-api### Search Yahoo```pythonfrom serpapi import YahooSearchsearch = YahooSearch({&quot;p&quot;: &quot;Coffee&quot;})data = search.get_dict()```This code prints Yahoo search results for coffee as a Dictionary. https://serpapi.com/yahoo-search-api### Search eBay```pythonfrom serpapi import EbaySearchsearch = EbaySearch({&quot;_nkw&quot;: &quot;Coffee&quot;})data = search.get_dict()```This code prints eBay search results for coffee as a Dictionary. https://serpapi.com/ebay-search-api### Search Home Depot```pythonfrom serpapi import HomeDepotSearchsearch = HomeDepotSearch({&quot;q&quot;: &quot;chair&quot;})data = search.get_dict()```This code prints Home Depot search results for chair as Dictionary. https://serpapi.com/home-depot-search-api### Search Youtube```pythonfrom serpapi import HomeDepotSearchsearch = YoutubeSearch({&quot;q&quot;: &quot;chair&quot;})data = search.get_dict()```This code prints Youtube search results for chair as Dictionary. https://serpapi.com/youtube-search-api### Search Google Scholar```pythonfrom serpapi import GoogleScholarSearchsearch = GoogleScholarSearch({&quot;q&quot;: &quot;Coffee&quot;})data = search.get_dict()```This code prints Google Scholar search results.### Search Walmart```pythonfrom serpapi import WalmartSearchsearch = WalmartSearch({&quot;query&quot;: &quot;chair&quot;})data = search.get_dict()```This code prints Walmart search results.### Search Youtube```pythonfrom serpapi import YoutubeSearchsearch = YoutubeSearch({&quot;search_query&quot;: &quot;chair&quot;})data = search.get_dict()```This code prints Youtube search results.### Search Apple App Store```pythonfrom serpapi import AppleAppStoreSearchsearch = AppleAppStoreSearch({&quot;term&quot;: &quot;Coffee&quot;})data = search.get_dict()```This code prints Apple App Store search results.### Search Naver```pythonfrom serpapi import NaverSearchsearch = NaverSearch({&quot;query&quot;: &quot;chair&quot;})data = search.get_dict()```This code prints Naver search results.### Generic search with SerpApiClient```pythonfrom serpapi import SerpApiClientquery = {&quot;q&quot;: &quot;Coffee&quot;, &quot;location&quot;: &quot;Austin,Texas&quot;, &quot;engine&quot;: &quot;google&quot;}search = SerpApiClient(query)data = search.get_dict()```This class enables interaction with any search engine supported by SerpApi.com ### Search Google Images```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({&quot;q&quot;: &quot;coffe&quot;, &quot;tbm&quot;: &quot;isch&quot;})for image_result in search.get_dict()['images_results']:    link = image_result[&quot;original&quot;]    try:        print(&quot;link: &quot; + link)        # wget.download(link, '.')    except:        pass```This code prints all the image links,  and downloads the images if you un-comment the line with wget (Linux/OS X tool to download files).This tutorial covers more ground on this topic.https://github.com/serpapi/showcase-serpapi-tensorflow-keras-image-training### Search Google News```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({    &quot;q&quot;: &quot;coffe&quot;,   # search search    &quot;tbm&quot;: &quot;nws&quot;,  # news    &quot;tbs&quot;: &quot;qdr:d&quot;, # last 24h    &quot;num&quot;: 10})for offset in [0,1,2]:    search.params_dict[&quot;start&quot;] = offset * 10    data = search.get_dict()    for news_result in data['news_results']:        print(str(news_result['position'] + offset * 10) + &quot; - &quot; + news_result['title'])```This script prints the first 3 pages of the news headlines for the last 24 hours.### Search Google Shopping```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({    &quot;q&quot;: &quot;coffe&quot;,   # search search    &quot;tbm&quot;: &quot;shop&quot;,  # news    &quot;tbs&quot;: &quot;p_ord:rv&quot;, # last 24h    &quot;num&quot;: 100})data = search.get_dict()for shopping_result in data['shopping_results']:    print(shopping_result['position']) + &quot; - &quot; + shopping_result['title'])```This script prints all the shopping results, ordered by review order.### Google Search By LocationWith SerpApi, we can build a Google search from anywhere in the world.This code looks for the best coffee shop for the given cities.```pythonfrom serpapi import GoogleSearchfor city in [&quot;new york&quot;, &quot;paris&quot;, &quot;berlin&quot;]:  location = GoogleSearch({}).get_location(city, 1)[0][&quot;canonical_name&quot;]  search = GoogleSearch({      &quot;q&quot;: &quot;best coffee shop&quot;,   # search search      &quot;location&quot;: location,      &quot;num&quot;: 1,      &quot;start&quot;: 0  })  data = search.get_dict()  top_result = data[&quot;organic_results&quot;][0][&quot;title&quot;]```### Batch Asynchronous SearchesWe offer two ways to boost your searches thanks to the`async` parameter. - Blocking - async=false - more compute intensive because the search needs to maintain many connections. (default) - Non-blocking - async=true - the way to go for large batches of queries  (recommended)```python# Operating systemimport os# regular expression libraryimport re# safe queue (named Queue in python2)from queue import Queue# Time utilityimport time# SerpApi searchfrom serpapi import GoogleSearch# store searchessearch_queue = Queue()# SerpApi searchsearch = GoogleSearch({    &quot;location&quot;: &quot;Austin,Texas&quot;,    &quot;async&quot;: True,    &quot;api_key&quot;: os.getenv(&quot;API_KEY&quot;)})# loop through a list of companiesfor company in ['amd', 'nvidia', 'intel']:    print(&quot;execute async search: q = &quot; + company)    search.params_dict[&quot;q&quot;] = company    result = search.get_dict()    if &quot;error&quot; in result:        print(&quot;oops error: &quot;, result[&quot;error&quot;])        continue    print(&quot;add search to the queue where id: &quot;, result['search_metadata'])    # add search to the search_queue    search_queue.put(result)print(&quot;wait until all search statuses are cached or success&quot;)# Create regular searchwhile not search_queue.empty():    result = search_queue.get()    search_id = result['search_metadata']['id']    # retrieve search from the archive - blocker    print(search_id + &quot;: get search from archive&quot;)    search_archived = search.get_search_archive(search_id)    print(search_id + &quot;: status = &quot; +          search_archived['search_metadata']['status'])    # check status    if re.search('Cached|Success',                 search_archived['search_metadata']['status']):        print(search_id + &quot;: search done with q = &quot; +              search_archived['search_parameters']['q'])    else:        # requeue search_queue        print(search_id + &quot;: requeue search&quot;)        search_queue.put(result)        # wait 1s        time.sleep(1)print('all searches completed')```This code shows how to run searches asynchronously.The search parameters must have {async: True}. This indicates that the client shouldn't wait for the search to be completed.The current thread that executes the search is now non-blocking, which allows it to execute thousands of searches in seconds. The SerpApi backend will do the processing work.The actual search result is deferred to a later call from the search archive using get_search_archive(search_id).In this example the non-blocking searches are persisted in a queue: search_queue.A loop through the search_queue allows it to fetch individual search results.This process can easily be multithreaded to allow a large number of concurrent search requests.To keep things simple, this example only explores search results one at a time (single threaded).[See example.](https://github.com/serpapi/google-search-results-python/blob/master/tests/test_example.py)### Python object as a resultThe search results can be automatically wrapped in dynamically generated Python object.This solution offers a more dynamic, fully Oriented Object Programming approach over the regular Dictionary / JSON data structure.```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({&quot;q&quot;: &quot;Coffee&quot;, &quot;location&quot;: &quot;Austin,Texas&quot;})r = search.get_object()assert type(r.organic_results), listassert r.organic_results[0].titleassert r.search_metadata.idassert r.search_metadata.google_urlassert r.search_parameters.q, &quot;Coffee&quot;assert r.search_parameters.engine, &quot;google&quot;```### Pagination using iteratorLet's collect links across multiple search results pages.```python# to get 2 pagesstart = 0end = 40page_size = 10# basic search parametersparameter = {  &quot;q&quot;: &quot;coca cola&quot;,  &quot;tbm&quot;: &quot;nws&quot;,  &quot;api_key&quot;: os.getenv(&quot;API_KEY&quot;),  # optional pagination parameter  #  the pagination method can take argument directly  &quot;start&quot;: start,  &quot;end&quot;: end,  &quot;num&quot;: page_size}# as proof of concept # urls collectsurls = []# initialize a searchsearch = GoogleSearch(parameter)# create a python generator using parameterpages = search.pagination()# or set custom parameterpages = search.pagination(start, end, page_size)# fetch one search result per iteration # using a basic python for loop # which invokes python iterator under the hood.for page in pages:  print(f&quot;Current page: {page['serpapi_pagination']['current']}&quot;)  for news_result in page[&quot;news_results&quot;]:    print(f&quot;Title: {news_result['title']}\nLink: {news_result['link']}\n&quot;)    urls.append(news_result['link'])  # check if the total number pages is as expected# note: the exact number if variable depending on the search engine backendif len(urls) == (end - start):  print(&quot;all search results count match!&quot;)if len(urls) == len(set(urls)):  print(&quot;all search results are unique!&quot;)```Examples to fetch links with pagination: [test file](https://github.com/serpapi/google-search-results-python/blob/master/tests/test_example_paginate.py), [online IDE](https://replit.com/@DimitryZub1/Scrape-Google-News-with-Pagination-python-serpapi)### Error managementSerpApi keeps error management simple. - backend service error or search fail - client errorIf it's a backend error, a simple error message is returned as string in the server response.```pythonfrom serpapi import GoogleSearchsearch = GoogleSearch({&quot;q&quot;: &quot;Coffee&quot;, &quot;location&quot;: &quot;Austin,Texas&quot;, &quot;api_key&quot;: &quot;&lt;secret_key&gt;&quot;})data = search.get_json()assert data[&quot;error&quot;] == None```In some cases, there are more details available in the data object.If it's a client error, then a SerpApiClientException is raised.## Change log2023-03-10 @ 2.4.2 - Change long description to README.md2021-12-22 @ 2.4.1 - add more search engine    - youtube   - walmart   - apple_app_store   - naver  - raise SerpApiClientException instead of raw string in order to follow Python guideline 3.5+ - add more unit error tests for serp_api_client2021-07-26 @ 2.4.0 - add page size support using num parameter - add youtube search engine2021-06-05 @ 2.3.0 - add pagination support2021-04-28 @ 2.2.0 - add get_response method to provide raw requests.Response object2021-04-04 @ 2.1.0 - Add home depot search engine - get_object() returns dynamic Python object 2020-10-26 @ 2.0.0 - Reduce class name to &lt;engine&gt;Search - Add get_raw_json2020-06-30 @ 1.8.3 - simplify import - improve package for python 3.5+ - add support for python 3.5 and 3.62020-03-25 @ 1.8 - add support for Yandex, Yahoo, Ebay - clean-up test2019-11-10 @ 1.7.1 - increase engine parameter priority over engine value set in the class2019-09-12 @ 1.7 - Change  namespace &quot;from lib.&quot; instead: &quot;from serpapi import GoogleSearch&quot; - Support for Bing and Baidu2019-06-25 @ 1.6 - New search engine supported: Baidu and Bing## ConclusionSerpApi supports all the major search engines. Google has the more advance support with all the major services available: Images, News, Shopping and more..To enable a type of search, the field tbm (to be matched) must be set to: * isch: Google Images API. * nws: Google News API. * shop: Google Shopping API. * any other Google service should work out of the box. * (no tbm parameter): regular Google search.The field `tbs` allows to customize the search even more.[The full documentation is available here.](https://serpapi.com/search-api)</longdescription>
</pkgmetadata>