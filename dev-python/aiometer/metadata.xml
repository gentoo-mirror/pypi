<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># aiometer[![Build Status](https://dev.azure.com/florimondmanca/public/_apis/build/status/florimondmanca.aiometer?branchName=master)](https://dev.azure.com/florimondmanca/public/_build/latest?definitionId=4&amp;branchName=master)[![Coverage](https://codecov.io/gh/florimondmanca/aiometer/branch/master/graph/badge.svg)](https://codecov.io/gh/florimondmanca/aiometer)![Python versions](https://img.shields.io/pypi/pyversions/aiometer.svg)[![Package version](https://badge.fury.io/py/aiometer.svg)](https://pypi.org/project/aiometer)`aiometer` is a Python 3.7+ concurrency scheduling library compatible with `asyncio` and `trio` and inspired by [Trimeter](https://github.com/python-trio/trimeter). It makes it easier to execute lots of tasks concurrently while controlling concurrency limits (i.e. applying _[backpressure](https://lucumr.pocoo.org/2020/1/1/async-pressure/)_) and collecting results in a predictable manner.**Content**- [Example](#example)- [Features](#features)- [Installation](#installation)- [Usage](#usage)  - [Flow control](#flow-control)  - [Running tasks](#running-tasks)- [How To](#how-to)- [API Reference](#api-reference)- [Contributing](#contributing)- [License](#license)## ExampleLet's use [HTTPX](https://github.com/encode/httpx) to make web requests concurrently..._Try this code interactively using [IPython](https://ipython.org/install.html)._```python&gt;&gt;&gt; import asyncio&gt;&gt;&gt; import functools&gt;&gt;&gt; import random&gt;&gt;&gt; import aiometer&gt;&gt;&gt; import httpx&gt;&gt;&gt;&gt;&gt;&gt; client = httpx.AsyncClient()&gt;&gt;&gt;&gt;&gt;&gt; async def fetch(client, request):...     response = await client.send(request)...     # Simulate extra processing......     await asyncio.sleep(2 * random.random())...     return response.json()[&quot;json&quot;]...&gt;&gt;&gt; requests = [...     httpx.Request(&quot;POST&quot;, &quot;https://httpbin.org/anything&quot;, json={&quot;index&quot;: index})...     for index in range(100)... ]...&gt;&gt;&gt; # Send requests, and process responses as they're made available:&gt;&gt;&gt; async with aiometer.amap(...     functools.partial(fetch, client),...     requests,...     max_at_once=10, # Limit maximum number of concurrently running tasks....     max_per_second=5,  # Limit request rate to not overload the server.... ) as results:...     async for data in results:...         print(data)...{'index': 3}{'index': 4}{'index': 1}{'index': 2}{'index': 0}...&gt;&gt;&gt; # Alternatively, fetch and aggregate responses into an (ordered) list...&gt;&gt;&gt; jobs = [functools.partial(fetch, client, request) for request in requests]&gt;&gt;&gt; results = await aiometer.run_all(jobs, max_at_once=10, max_per_second=5)&gt;&gt;&gt; results[{'index': 0}, {'index': 1}, {'index': 2}, {'index': 3}, {'index': 4}, ...]```## Installation_This project is in beta and maturing. Be sure to pin any dependencies to the latest minor._```bashpip install &quot;aiometer==0.3.*&quot;```## Features- Concurrency management and throttling helpers.- `asyncio` and `trio` support.- Fully type annotated.- 100% test coverage.## Usage### Flow controlThe key highlight of `aiometer` is allowing you to apply flow control strategies in order to limit the degree of concurrency of your programs.There are two knobs you can play with to fine-tune concurrency:- `max_at_once`: this is used to limit the maximum number of concurrently running tasks at any given time. (If you have 100 tasks and set `max_at_once=10`, then `aiometer` will ensure that no more than 10 run at the same time.)- `max_per_second`: this option limits the number of tasks spawned per second. This is useful to not overload I/O resources, such as servers that may have a rate limiting policy in place.Example usage:```python&gt;&gt;&gt; import asyncio&gt;&gt;&gt; import aiometer&gt;&gt;&gt; async def make_query(query):...     await asyncio.sleep(0.05)  # Simulate a database request....&gt;&gt;&gt; queries = ['SELECT * from authors'] * 1000&gt;&gt;&gt; # Allow at most 5 queries to run concurrently at any given time:&gt;&gt;&gt; await aiometer.run_on_each(make_query, queries, max_at_once=5)...&gt;&gt;&gt; # Make at most 10 queries per second:&gt;&gt;&gt; await aiometer.run_on_each(make_query, queries, max_per_second=10)...&gt;&gt;&gt; # Run at most 10 concurrent jobs, spawning new ones at least every 5 seconds:&gt;&gt;&gt; async def job(id):...     await asyncio.sleep(10)  # A very long task....&gt;&gt;&gt; await aiometer.run_on_each(job, range(100),  max_at_once=10, max_per_second=0.2)```### Running tasks`aiometer` provides 4 different ways to run tasks concurrently in the form of 4 different run functions. Each function accepts all the options documented in [Flow control](#flow-control), and runs tasks in a slightly different way, allowing to address a variety of use cases. Here's a handy table for reference (see also the [API Reference](#api-reference)):| Entrypoint      | Use case                                       || --------------- | ---------------------------------------------- || `run_on_each()` | Execute async callbacks in any order.          || `run_all()`     | Return results as an ordered list.             || `amap()`        | Iterate over results as they become available. || `run_any()`     | Return result of first completed function.     |To illustrate the behavior of each run function, let's first setup a hello world async program:```python&gt;&gt;&gt; import asyncio&gt;&gt;&gt; import random&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; import aiometer&gt;&gt;&gt;&gt;&gt;&gt; async def get_greeting(name):...     await asyncio.sleep(random.random())  # Simulate I/O...     return f&quot;Hello, {name}&quot;...&gt;&gt;&gt; async def greet(name):...     greeting = await get_greeting(name)...     print(greeting)...&gt;&gt;&gt; names = [&quot;Robert&quot;, &quot;Carmen&quot;, &quot;Lucas&quot;]```Let's start with `run_on_each()`. It executes an async function once for each item in a list passed as argument:```python&gt;&gt;&gt; await aiometer.run_on_each(greet, names)'Hello, Robert!''Hello, Lucas!''Hello, Carmen!'```If we'd like to get the list of greetings in the same order as `names`, in a fashion similar to [`Promise.all()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all), we can use `run_all()`:```python&gt;&gt;&gt; await aiometer.run_all([partial(get_greeting, name) for name in names])['Hello, Robert', 'Hello, Carmen!', 'Hello, Lucas!']````amap()` allows us to process each greeting as it becomes available (which means maintaining order is not guaranteed):```python&gt;&gt;&gt; async with aiometer.amap(get_greeting, names) as greetings:...     async for greeting in greetings:...         print(greeting)'Hello, Lucas!''Hello, Robert!''Hello, Carmen!'```Lastly, `run_any()` can be used to run async functions until the first one completes, similarly to [`Promise.any()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/any):```python&gt;&gt;&gt; await aiometer.run_any([partial(get_greeting, name) for name in names])'Hello, Carmen!'```As a last fun example, let's use `amap()` to implement a no-threads async version of [sleep sort](https://rosettacode.org/wiki/Sorting_algorithms/Sleep_sort):```python&gt;&gt;&gt; import asyncio&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; import aiometer&gt;&gt;&gt; numbers = [0.3, 0.1, 0.6, 0.2, 0.7, 0.5, 0.5, 0.2]&gt;&gt;&gt; async def process(n):...     await asyncio.sleep(n)...     return n...&gt;&gt;&gt; async with aiometer.amap(process, numbers) as results:...     sorted_numbers = [n async for n in results]...&gt;&gt;&gt; sorted_numbers[0.1, 0.2, 0.2, 0.3, 0.5, 0.5, 0.6, 0.7]```## How To### Multiple parametrized values in `run_on_each` and `amap``run_on_each` and `amap` only accept functions that accept a single positional argument (i.e. `(Any) -&gt; Awaitable`).So if you have a function that is parametrized by multiple values, you should refactor it to match this form.This can generally be achieved like this:1. Build a proxy container type (eg. a `namedtuple`), eg `T`.2. Refactor your function so that its signature is now `(T) -&gt; Awaitable`.3. Build a list of these proxy containers, and pass it to `aiometer`.For example, assuming you have a function that processes X/Y coordinates...```pythonasync def process(x: float, y: float) -&gt; None:    passxs = list(range(100))ys = list(range(100))for x, y in zip(xs, ys):    await process(x, y)```You could use it with `amap` by refactoring it like this:```pythonfrom typing import NamedTuple# Proxy container type:class Point(NamedTuple):    x: float    y: float# Rewrite to accept a proxy as a single positional argument:async def process(point: Point) -&gt; None:    x = point.x    y = point.y    ...xs = list(range(100))ys = list(range(100))# Build a list of proxy containers:points = [Point(x, y) for x, y in zip(x, y)]# Use it:async with aiometer.amap(process, points) as results:    ...```## API Reference### Common options* `max_at_once` (_Optional_, `int`): the maximum number of concurrently running tasks at any given time.* `max_per_second` (_Optional_, `int`): the maximum number of tasks spawned per second.### `aiometer.run_on_each()`**Signature**: _async_ aiometer.run_on_each(*async_fn*, *args*, *, *max_at_once=None*, *max_per_second=None*) -&gt; *None*Concurrently run the equivalent of `async_fn(arg) for arg in args`. Does not return any value. To get return values back, use [`aiometer.run_all()`](#aiometerrun_all).### `aiometer.run_all()`**Signature**: _async_ aiometer.run_all(*async_fns*, *max_at_once=None*, *max_per_second=None*) -&gt; *list*Concurrently run the `async_fns` functions, and return the list of results in the same order.### `aiometer.amap()`**Signature**: _async_ aiometer.amap(*async_fn*, *args*, *max_at_once=None*, *max_per_second=None*) -&gt; *async iterator*Concurrently run the equivalent of `async_fn(arg) for arg in args`, and return an async iterator that yields results as they become available.### `aiometer.run_any()`**Signature**: _async_ aiometer.run_any(*async_fns*, *max_at_once=None*, *max_per_second=None*) -&gt; *Any*Concurrently run the `async_fns` functions, and return the first available result.## ContributingSee [CONTRIBUTING.md](./CONTRIBUTING.md).## LicenseMIT# ChangelogAll notable changes to this project will be documented in this file.The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).## 0.4.0 - 2023-01-18### Removed- Drop support for Python 3.6, which has reached EOL. (Pull #38)### Added- Add official support for Python 3.10 and 3.11. (Pull #38)### Fixed- Relax version requirements for `typing_extensions` and address `mypy&gt;=0.981` strict optional changes. (Pull #38)## 0.3.0 - 2021-07-06### Changed- Update `anyio` dependency to v3 (previously v1). (Pull #25)  - _NB: no API change, but dependency mismatches may occur. Be sure to port your codebase to anyio v3 before upgrading `aiometer`._### Added- Add support for Python 3.6 (installs the `contextlib2` backport library there). (Pull #26)- Officialize support for Python 3.9. (Pull #26)## 0.2.1 - 2020-03-26### Fixed- Improve robustness of the `max_per_second` implementation by using the generic cell rate algorithm (GCRA) instead of leaky bucket. (Pull #5)## 0.2.0 - 2020-03-22### Added- Add support for Python 3.7. (Pull #3)## 0.1.0 - 2020-03-21### Added- Add `run_on_each()`, `run_all()`, `amap()` and `run_any()`, with `max_at_once` and `max_per_second` options. (Pull #1)</longdescription>
</pkgmetadata>