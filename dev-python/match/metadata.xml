<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>match=====|Build Status||Latest Conda Version|\ |Latest PyPI Version|\ |Python Versions|The purpose of the module ``Match`` is to get the offsets (as well asthe string between those offsets, for debugging) of a cleaned-up,tokenized string from its original, untokenized source. “Big deal,” youmight say, but this is actually a pretty difficult task if the originaltext is sufficiently messy, not to mention rife with Unicode characters.Consider some text, stored in a variable ``original_text``, like:::   I   am writing a letter !  Sometimes,I forget to put spaces (and do weird stuff with punctuation)  ?  J'aurai une pomme, s'il vous plâit !This will/should/might be properly tokenized as:.. code:: python   [['I', 'am', 'writing', 'a', 'letter', '!'],    ['Sometimes', ',', 'I', 'forget', 'to', 'put', 'spaces', '-LRB-', 'and', 'do', 'weird', 'stuff', 'with', 'punctuation', '-RRB-', '?'],    [&quot;J'aurai&quot;, 'une', 'pomme', ',', &quot;s'il&quot;, 'vous', 'plâit', '!']]Now:.. code:: python   In [2]: import match   In [3]: match.match(original_text, ['-LRB-', 'and', 'do', 'weird', 'stuff', 'with', 'punctuation', '-RRB-'])   Out[3]: [(60, 97, '(and do weird stuff with punctuation)')]   In [4]: match.match(original_text, ['I', 'am', 'writing', 'a', 'letter', '!'])   Out[4]: [(0, 25, 'I   am writing a letter !')]   In [5]: match.match(original_text, [&quot;s'il&quot;, 'vous', 'plâit', '!'])   Out[5]: [(121, 138, &quot;s'il vous plâit !&quot;)]The return type from ``match()`` is a ``list`` because it will return*all* occurrences of the argument, be it a ``list`` of tokens or asingle ``string`` (word):.. code:: python   In [6]: match.match(original_text, &quot;I&quot;)   Out[6]: [(0, 1, 'I'), (37, 38, 'I')]When passing in a single ``string``, ``match()`` is expecting that``string`` to be a single word or token. Thus:.. code:: python   In [7]: match.match(&quot;****because,the****&quot;, &quot;because , the&quot;)   Out[7]: []Try passing in ``&quot;because , the&quot;.split(' ')`` instead, or better yet,the output from a proper tokenizer.For convenience, a function called ``match_lines()`` is provided:.. code:: python   In [8]: match.match_lines(original_text, [      ...: ['-LRB-', 'and', 'do', 'weird', 'stuff', 'with', 'punctuation', '-RRB-'],      ...: ['I', 'am', 'writing', 'a', 'letter', '!'],      ...: &quot;I&quot;      ...: ])   Out[8]:   [(0, 1, 'I'),    (0, 25, 'I   am writing a letter !'),    (37, 38, 'I'),    (60, 97, '(and do weird stuff with punctuation)')]The values returned will always be sorted by their offsets.Installation------------``pip install match`` or ``conda install -c ets match``Requirements-------------  Python &gt;= 3.8-  `nltk &lt;http://www.nltk.org&gt;`__-  `regex &lt;https://pypi.python.org/pypi/regex&gt;`__Documentation-------------`Here! &lt;match&gt;`__... |Build Status| image:: https://github.com/EducationalTestingService/match/actions/workflows/python-test.yml/badge.svg   :target: https://github.com/EducationalTestingService/match/actions/workflows/python-test.yml/.. |Latest Conda Version| image:: https://img.shields.io/conda/v/ets/match   :target: https://anaconda.org/ets/match.. |Latest PyPI Version| image:: https://img.shields.io/pypi/v/match   :target: https://pypi.org/project/match/.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/match   :target: https://pypi.python.org/pypi/match/</longdescription>
</pkgmetadata>