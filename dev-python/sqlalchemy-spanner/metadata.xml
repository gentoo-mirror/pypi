<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Spanner dialect for SQLAlchemy==============================Spanner dialect for SQLAlchemy represents an interface API designed tomake it possible to control Cloud Spanner databases with SQLAlchemy API.The dialect is built on top of `the Spanner DBAPI &lt;https://github.com/googleapis/python-spanner/tree/master/google/cloud/spanner_dbapi&gt;`__,which is designed in accordance with`PEP-249 &lt;https://www.python.org/dev/peps/pep-0249/&gt;`__.Known limitations are listed `here &lt;#features-and-limitations&gt;`__. Allsupported features have been tested and verified to work with the testconfigurations. There may be configurations and/or data model variationsthat have not yet been covered by the tests and that show unexpectedbehavior. Please report any problems that you might encounter by`creating a newissue &lt;https://github.com/googleapis/python-spanner-sqlalchemy/issues/new&gt;`__.-  `Cloud Spanner product   documentation &lt;https://cloud.google.com/spanner/docs&gt;`__-  `SQLAlchemy product documentation &lt;https://www.sqlalchemy.org/&gt;`__Quick Start-----------In order to use this package, you first need to go through the followingsteps:1. `Select or create a Cloud Platform   project. &lt;https://console.cloud.google.com/project&gt;`__2. `Enable billing for your   project. &lt;https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project&gt;`__3. `Enable the Google Cloud Spanner   API. &lt;https://cloud.google.com/spanner&gt;`__4. `Setup   Authentication. &lt;https://googleapis.dev/python/google-api-core/latest/auth.html&gt;`__Installation------------Stable released version of the package is available on PyPi:::   pip install sqlalchemy-spannerTo install an in-development version of the package, clone itsGit-repository:::   git clone https://github.com/googleapis/python-spanner-sqlalchemy.gitNext install the package from the package ``setup.py`` file:::   python setup.py installDuring setup the dialect will be registered with entry points.A Minimal App-------------Database URL~~~~~~~~~~~~In order to connect to a database one have to use its URL on connectioncreation step. SQLAlchemy 1.3 and 1.4 versions have a bit of differenceon this step in a dialect prefix part:.. code:: python   # for SQLAlchemy 1.3:   spanner:///projects/project-id/instances/instance-id/databases/database-id   # for SQLAlchemy 1.4:   spanner+spanner:///projects/project-id/instances/instance-id/databases/database-idTo pass your custom client object directly to be be used, create engine as following:.. code:: python    engine = create_engine(        &quot;spanner+spanner:///projects/project-id/instances/instance-id/databases/database-id&quot;,        connect_args={'client': spanner.Client(project=&quot;project-id&quot;)}    )Create a table~~~~~~~~~~~~~~.. code:: python   from sqlalchemy import (       Column,       Integer,       MetaData,       String,       Table,       create_engine,   )   engine = create_engine(       &quot;spanner:///projects/project-id/instances/instance-id/databases/database-id&quot;   )   metadata = MetaData(bind=engine)   user = Table(       &quot;users&quot;,       metadata,       Column(&quot;user_id&quot;, Integer, primary_key=True),       Column(&quot;user_name&quot;, String(16), nullable=False),   )   metadata.create_all(engine)Insert a row~~~~~~~~~~~~.. code:: python   import uuid   from sqlalchemy import (       MetaData,       Table,       create_engine,   )   engine = create_engine(       &quot;spanner:///projects/project-id/instances/instance-id/databases/database-id&quot;   )   user = Table(&quot;users&quot;, MetaData(bind=engine), autoload=True)   user_id = uuid.uuid4().hex[:6].lower()   with engine.begin() as connection:       connection.execute(user.insert(), {&quot;user_id&quot;: user_id, &quot;user_name&quot;: &quot;Full Name&quot;})Read~~~~.. code:: python   from sqlalchemy import MetaData, Table, create_engine, select   engine = create_engine(       &quot;spanner:///projects/project-id/instances/instance-id/databases/database-id&quot;   )   table = Table(&quot;users&quot;, MetaData(bind=engine), autoload=True)   with engine.begin() as connection:       for row in connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall():           print(row)Migration---------SQLAlchemy uses `Alembic &lt;https://alembic.sqlalchemy.org/en/latest/#&gt;`__tool to organize database migrations.Spanner dialect doesn't provide a default migration environment, it's upto user to write it. One thing to be noted here - one should explicitlyset ``alembic_version`` table not to use migration revision id as aprimary key:.. code:: python   with connectable.connect() as connection:       context.configure(           connection=connection,           target_metadata=target_metadata,           version_table_pk=False,  # don't use primary key in the versions table       )As Spanner restricts changing a primary key value, not setting the ``version_table_pk`` flagto ``False`` can cause migration problems. If ``alembic_versions`` table was already created with a primary key, setting the flag to ``False`` will not work, because the flag is only applied on table creation.    Notice that DDL statements in Spanner are not transactional. They will not be automatically reverted in case of a migration fail. Also Spanner encourage use of the `autocommit_block() &lt;https://alembic.sqlalchemy.org/en/latest/api/runtime.html#alembic.runtime.migration.MigrationContext.autocommit_block&gt;`__ for migrations in order to prevent DDLs from aborting migration transactions with schema modifications.| **Warning!**| A migration script can produce a lot of DDL statements. If each of the  statements is executed separately, performance issues can occur. To  avoid it, it's highly recommended to use the `Alembic batch  context &lt;https://alembic.sqlalchemy.org/en/latest/batch.html&gt;`__  feature to pack DDL statements into groups of statements.Features and limitations------------------------Interleaved tables~~~~~~~~~~~~~~~~~~| Cloud Spanner dialect includes two dialect-specific arguments for  ``Table`` constructor, which help to define interleave relations:  ``spanner_interleave_in`` - a parent table name  ``spanner_inverleave_on_delete_cascade`` - a flag specifying if  ``ON DELETE CASCADE`` statement must be used for the interleave  relation| An example of interleave relations definition:.. code:: python   team = Table(       &quot;team&quot;,       metadata,       Column(&quot;team_id&quot;, Integer, primary_key=True),       Column(&quot;team_name&quot;, String(16), nullable=False),   )   team.create(engine)   client = Table(       &quot;client&quot;,       metadata,       Column(&quot;team_id&quot;, Integer, primary_key=True),       Column(&quot;client_id&quot;, Integer, primary_key=True),       Column(&quot;client_name&quot;, String(16), nullable=False),       spanner_interleave_in=&quot;team&quot;,       spanner_interleave_on_delete_cascade=True,   )   client.add_is_dependent_on(team)   client.create(engine)**Note**: Interleaved tables have a dependency between them, so theparent table must be created before the child table. When creatingtables with this feature, make sure to call ``add_is_dependent_on()`` onthe child table to request SQLAlchemy to create the parent table beforethe child table.Unique constraints~~~~~~~~~~~~~~~~~~Cloud Spanner doesn't support direct UNIQUE constraints creation. Inorder to achieve column values uniqueness UNIQUE indexes should be used.Instead of direct UNIQUE constraint creation:.. code:: python   Table(       'table',       metadata,       Column('col1', Integer),       UniqueConstraint('col1', name='uix_1')   )Create a UNIQUE index:.. code:: python   Table(       'table',       metadata,       Column('col1', Integer),       Index(&quot;uix_1&quot;, &quot;col1&quot;, unique=True),   )Autocommit mode~~~~~~~~~~~~~~~Spanner dialect supports both ``SERIALIZABLE`` and ``AUTOCOMMIT``isolation levels. ``SERIALIZABLE`` is the default one, wheretransactions need to be committed manually. ``AUTOCOMMIT`` modecorresponds to automatically committing of a query right in itsexecution time.Isolation level change example:.. code:: python   from sqlalchemy import create_engine   eng = create_engine(&quot;spanner:///projects/project-id/instances/instance-id/databases/database-id&quot;)   autocommit_engine = eng.execution_options(isolation_level=&quot;AUTOCOMMIT&quot;)Automatic transactions retry~~~~~~~~~~~~~~~~~~~~~~~~~~~~In the default ``SERIALIZABLE`` mode transactions may fail with ``Aborted`` exception. This is a transient kind of errors, which mostly happen to prevent data corruption by concurrent modifications. Though the original transaction becomes non operational, a simple retry of the queries solves the issue.This, however, may require to manually repeat a long list of operations, executed in the failed transaction. To simplify it, Spanner Connection API tracks all the operations, executed inside current transaction, and their result checksums. If the transaction failed with ``Aborted`` exception, the Connection API will automatically start a new transaction and will re-run all the tracked operations, checking if their results are the same as they were in the original transaction. In case data changed, and results differ, the transaction is dropped, as there is no way to automatically retry it.In ``AUTOCOMMIT`` mode automatic transactions retry mechanism is disabled, as every operation is committed just in time, and there is no way an ``Aborted`` exception can happen.Autoincremented IDs~~~~~~~~~~~~~~~~~~~Cloud Spanner doesn't support autoincremented IDs mechanism due toperformance reasons (`see for moredetails &lt;https://cloud.google.com/spanner/docs/schema-design#primary-key-prevent-hotspots&gt;`__).We recommend that you use the Python`uuid &lt;https://docs.python.org/3/library/uuid.html&gt;`__ module togenerate primary key fields to avoid creating monotonically increasingkeys.Though it's not encouraged to do so, in case you *need* the feature, youcan simulate it manually as follows:.. code:: python   with engine.begin() as connection:       top_id = connection.execute(           select([user.c.user_id]).order_by(user.c.user_id.desc()).limit(1)       ).fetchone()       next_id = top_id[0] + 1 if top_id else 1       connection.execute(user.insert(), {&quot;user_id&quot;: next_id})Query hints~~~~~~~~~~~Spanner dialect supports `queryhints &lt;https://cloud.google.com/spanner/docs/query-syntax#table_hints&gt;`__,which give the ability to set additional query execution parameters.Usage example:.. code:: python   session = Session(engine)   Base = declarative_base()   class User(Base):       &quot;&quot;&quot;Data model.&quot;&quot;&quot;       __tablename__ = &quot;users&quot;       id = Column(Integer, primary_key=True)       name = Column(String(50))   query = session.query(User)   query = query.with_hint(       selectable=User, text=&quot;@{FORCE_INDEX=index_name}&quot;   )   query = query.filter(User.name.in_([&quot;val1&quot;, &quot;val2&quot;]))   query.statement.compile(session.bind)ReadOnly transactions~~~~~~~~~~~~~~~~~~~~~By default, transactions produced by a Spanner connection are inReadWrite mode. However, some applications require an ability to grantReadOnly access to users/methods; for these cases Spanner dialectsupports the ``read_only`` execution option, which switches a connectioninto ReadOnly mode:.. code:: python   with engine.connect().execution_options(read_only=True) as connection:       connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall()Note that execution options are applied lazily - on the ``execute()``method call, right before it.ReadOnly/ReadWrite mode of a connection can't be changed while atransaction is in progress - first you must commit or rollback it.Stale reads~~~~~~~~~~~To use the Spanner `StaleReads &lt;https://cloud.google.com/spanner/docs/reads#perform-stale-read&gt;`__with SQLAlchemy you can tweak the connection execution options with awanted staleness value. For example:.. code:: python   # maximum staleness   with engine.connect().execution_options(       read_only=True,       staleness={&quot;max_staleness&quot;: datetime.timedelta(seconds=5)}   ) as connection:       connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall().. code:: python   # exact staleness   with engine.connect().execution_options(       read_only=True,       staleness={&quot;exact_staleness&quot;: datetime.timedelta(seconds=5)}   ) as connection:       connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall().. code:: python   # min read timestamp   with engine.connect().execution_options(       read_only=True,       staleness={&quot;min_read_timestamp&quot;: datetime.datetime(2021, 11, 17, 12, 55, 30)}   ) as connection:       connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall().. code:: python   # read timestamp   with engine.connect().execution_options(       read_only=True,       staleness={&quot;read_timestamp&quot;: datetime.datetime(2021, 11, 17, 12, 55, 30)}   ) as connection:       connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall()Note that the set option will be dropped when the connection is returnedback to the pool.Request priority~~~~~~~~~~~~~~~~~~~~~In order to use Request Priorities feature in Cloud Spanner, SQLAlchemy provides an ``execution_options`` parameter:.. code:: python   from google.cloud.spanner_v1 import RequestOptions   with engine.connect().execution_options(       request_priority=RequestOptions.Priority.PRIORITY_MEDIUM   ) as connection:       connection.execute(select([&quot;*&quot;], from_obj=table)).fetchall()DDL and transactions~~~~~~~~~~~~~~~~~~~~DDL statements are executed outside the regular transactions mechanism,which means DDL statements will not be rolled back on normal transactionrollback.Dropping a table~~~~~~~~~~~~~~~~Cloud Spanner, by default, doesn't drop tables, which have secondaryindexes and/or foreign key constraints. In Spanner dialect forSQLAlchemy, however, this restriction is omitted - if a table you aretrying to delete has indexes/foreign keys, they will be droppedautomatically right before dropping the table.Data types~~~~~~~~~~Data types table mapping SQLAlchemy types to Cloud Spanner types:========== =========SQLAlchemy Spanner========== =========INTEGER    INT64BIGINT     INT64DECIMAL    NUMERICFLOAT      FLOAT64TEXT       STRINGARRAY      ARRAYBINARY     BYTESVARCHAR    STRINGCHAR       STRINGBOOLEAN    BOOLDATETIME   TIMESTAMPNUMERIC    NUMERIC========== =========Other limitations~~~~~~~~~~~~~~~~~-  WITH RECURSIVE statement is not supported.-  Named schemas are not supported.-  Temporary tables are not supported.-  Numeric type dimensions (scale and precision) are constant. See the   `docs &lt;https://cloud.google.com/spanner/docs/data-types#numeric_types&gt;`__.Best practices--------------When a SQLAlchemy function is called, a new connection to a database isestablished and a Spanner session object is fetched. In case ofconnectionless execution these fetches are done for every ``execute()``call, which can cause a significant latency. To avoid initiating aSpanner session on every ``execute()`` call it's recommended to writecode in connection-bounded fashion. Once a ``Connection()`` object isexplicitly initiated, it fetches a Spanner session object and uses itfor all the following calls made on this ``Connection()`` object.Non-optimal connectionless use:.. code:: python   # execute() is called on object, which is not a Connection() object   insert(user).values(user_id=1, user_name=&quot;Full Name&quot;).execute()Optimal connection-bounded use:.. code:: python   with engine.begin() as connection:       # execute() is called on a Connection() object       connection.execute(user.insert(), {&quot;user_id&quot;: 1, &quot;user_name&quot;: &quot;Full Name&quot;})Connectionless way of use is also deprecated since SQLAlchemy 2.0 andsoon will be removed (see in `SQLAlchemydocs &lt;https://docs.sqlalchemy.org/en/14/core/connections.html#connectionless-execution-implicit-execution&gt;`__).Running tests-------------Spanner dialect includes a compliance, migration and unit test suite. Torun the tests the ``nox`` package commands can be used:::   # Run the whole suite   $ nox   # Run a particular test session   $ nox -s migration_testRunning tests on Spanner emulator~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~The dialect test suite can be runned on `Spanneremulator &lt;https://cloud.google.com/spanner/docs/emulator&gt;`__. Severaltests, relating to ``NULL`` values of data types, are skipped whenexecuted on emulator.Contributing------------Contributions to this library are welcome and encouraged. Please reportissues, file feature requests, and send pull requests. See`CONTRIBUTING &lt;https://github.com/googleapis/python-spanner-sqlalchemy/blob/main/contributing.md&gt;`__for more information on how to get started.**Note that this project is not officially supported by Google as partof the Cloud Spanner product.**Please note that this project is released with a Contributor Code ofConduct. By participating in this project you agree to abide by itsterms. See the `Code ofConduct &lt;https://github.com/googleapis/python-spanner-sqlalchemy/blob/main/code-of-conduct.md&gt;`__for more information.</longdescription>
</pkgmetadata>