<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># object-store-python[![CI][ci-img]][ci-link][![code style: black][black-img]][black-link]![PyPI](https://img.shields.io/pypi/v/object-store-python)[![PyPI - Downloads][pypi-img]][pypi-link]Python bindings and integrations for the excellent [`object_store`][object-store] crate.The main idea is to provide a common interface to various storage backends including theobjects stores from most major cloud providers. The APIs are very focussed and tayloredtowards modern cloud native applications by hiding away many features (and complexities)encountered in full fledges file systems.Among the included backend are:- Amazon S3 and S3 compliant APIs- Google Cloud Storage Buckets- Azure Blob Gen1 and Gen2 accounts (including ADLS Gen2)- local storage- in-memory store## InstallationThe `object-store-python` package is available on PyPI and can be installed via```shpoetry add object-store-python```or using pip```shpip install object-store-python```## UsageThe main [`ObjectStore`](#object-store-python) API mirrors the native [`object_store`][object-store]implementation, with some slight adjustments for ease of use in python programs.### `ObjectStore` api```pyfrom object_store import ObjectStore, ObjectMeta# we use an in-memory store for demonstration purposes.# data will not be persisted and is not shared across store instancesstore = ObjectStore(&quot;memory://&quot;)store.put(&quot;data&quot;, b&quot;some data&quot;)data = store.get(&quot;data&quot;)assert data == b&quot;some data&quot;blobs = store.list()meta: ObjectMeta = store.head(&quot;data&quot;)range = store.get_range(&quot;data&quot;, start=0, length=4)assert range == b&quot;some&quot;store.copy(&quot;data&quot;, &quot;copied&quot;)copied = store.get(&quot;copied&quot;)assert copied == data```### ConfigurationAs much as possible we aim to make access to various storage backends dependentonly on runtime configuration. The kind of service is always derived from theurl used to specifiy the storage location. Some basic configuration can also bederived from the url string, dependent on the chosen url format.```pyfrom object_store import ObjectStorestorage_options = {    &quot;azure_storage_account_name&quot;: &quot;&lt;my-account-name&gt;&quot;,    &quot;azure_client_id&quot;: &quot;&lt;my-client-id&gt;&quot;,    &quot;azure_client_secret&quot;: &quot;&lt;my-client-secret&gt;&quot;,    &quot;azure_tenant_id&quot;: &quot;&lt;my-tenant-id&gt;&quot;}store = ObjectStore(&quot;az://&lt;container-name&gt;&quot;, storage_options)```We can provide the same configuration via the environment.```pyimport osfrom object_store import ObjectStoreos.environ[&quot;AZURE_STORAGE_ACCOUNT_NAME&quot;] = &quot;&lt;my-account-name&gt;&quot;os.environ[&quot;AZURE_CLIENT_ID&quot;] = &quot;&lt;my-client-id&gt;&quot;os.environ[&quot;AZURE_CLIENT_SECRET&quot;] = &quot;&lt;my-client-secret&gt;&quot;os.environ[&quot;AZURE_TENANT_ID&quot;] = &quot;&lt;my-tenant-id&gt;&quot;store = ObjectStore(&quot;az://&lt;container-name&gt;&quot;)```#### AzureThe recommended url format is `az://&lt;container&gt;/&lt;path&gt;` and Azure always requieres`azure_storage_account_name` to be configured.- [shared key][azure-key]  - `azure_storage_account_key`- [service principal][azure-ad]  - `azure_client_id`  - `azure_client_secret`  - `azure_tenant_id`- [shared access signature][azure-sas]  - `azure_storage_sas_key` (as provided by StorageExplorer)- bearer token  - `azure_storage_token`- [managed identity][azure-managed]  - if using user assigned identity one of `azure_client_id`, `azure_object_id`, `azure_msi_resource_id`  - if no other credential can be created, managed identity will be tried- [workload identity][azure-workload]  - `azure_client_id`  - `azure_tenant_id`  - `azure_federated_token_file`#### S3The recommended url format is `s3://&lt;bucket&gt;/&lt;path&gt;` S3 storage always requires aregion to be specified via one of `aws_region` or `aws_default_region`.- [access key][aws-key]  - `aws_access_key_id`  - `aws_secret_access_key`- [session token][aws-sts]  - `aws_session_token`- [imds instance metadata][aws-imds]  - `aws_metadata_endpoint`- [profile][aws-profile]  - `aws_profile`AWS supports [virtual hosting of buckets][aws-virtual], which can be configured by setting`aws_virtual_hosted_style_request` to &quot;true&quot;.When an alternative implementation or a mocked service like localstack is used, the serviceendpoint needs to be explicitly specified via `aws_endpoint`.#### GCSThe recommended url format is `gs://&lt;bucket&gt;/&lt;path&gt;`.- service account  - `google_service_account`### with `pyarrow````pyfrom pathlib import Pathimport numpy as npimport pyarrow as paimport pyarrow.fs as fsimport pyarrow.dataset as dsimport pyarrow.parquet as pqfrom object_store import ArrowFileSystemHandlertable = pa.table({&quot;a&quot;: range(10), &quot;b&quot;: np.random.randn(10), &quot;c&quot;: [1, 2] * 5})base = Path.cwd()store = fs.PyFileSystem(ArrowFileSystemHandler(str(base.absolute())))pq.write_table(table.slice(0, 5), &quot;data/data1.parquet&quot;, filesystem=store)pq.write_table(table.slice(5, 10), &quot;data/data2.parquet&quot;, filesystem=store)dataset = ds.dataset(&quot;data&quot;, format=&quot;parquet&quot;, filesystem=store)```## Development### Prerequisites- [poetry](https://python-poetry.org/docs/)- [Rust toolchain](https://www.rust-lang.org/tools/install)- [just](https://github.com/casey/just#readme)### Running testsIf you do not have [`just`](&lt;(https://github.com/casey/just#readme)&gt;) installed and do not wish to install it,have a look at the [`justfile`](https://github.com/roeap/object-store-python/blob/main/justfile) to see the raw commands.To set up the development environment, and install a dev version of the native package just run:```shjust init```This will also configure [`pre-commit`](https://pre-commit.com/) hooks in the repository.To run the rust as well as python tests:```shjust test```[object-store]: https://crates.io/crates/object_store[pypi-img]: https://img.shields.io/pypi/dm/object-store-python[pypi-link]: https://pypi.org/project/object-store-python/[ci-img]: https://github.com/roeap/object-store-python/actions/workflows/ci.yaml/badge.svg[ci-link]: https://github.com/roeap/object-store-python/actions/workflows/ci.yaml[black-img]: https://img.shields.io/badge/code%20style-black-000000.svg[black-link]: https://github.com/psf/black[aws-virtual]: https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html[azure-managed]: https://learn.microsoft.com/en-gb/azure/app-service/overview-managed-identity[azure-sas]: https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview[azure-ad]: https://learn.microsoft.com/en-us/azure/storage/blobs/authorize-access-azure-active-directory[azure-key]: https://learn.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key[azure-workload]: https://learn.microsoft.com/en-us/azure/aks/workload-identity-overview[aws-imds]: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html[aws-profile]: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html[aws-sts]: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html[aws-key]: https://docs.aws.amazon.com/accounts/latest/reference/credentials-access-keys-best-practices.html</longdescription>
</pkgmetadata>