<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Hazm====Python library for digesting Persian text.+ Text cleaning+ Sentence and word tokenizer+ Word lemmatizer+ POS tagger+ Shallow parser+ Dependency parser+ Interfaces for Persian corpora+ [NLTK](http://nltk.org/) compatible+ Python 2.7, 3.4, 3.5 and 3.6 support+ [![Build Status](https://travis-ci.org/sobhe/hazm.png)](https://travis-ci.org/sobhe/hazm)## Usage```python&gt;&gt;&gt; from __future__ import unicode_literals&gt;&gt;&gt; from hazm import *&gt;&gt;&gt; normalizer = Normalizer()&gt;&gt;&gt; normalizer.normalize('اصلاح نويسه ها و استفاده از نیمفاصله پردازش را آسان مي كند')'اصلاح نویسهها و استفاده از نیمفاصله پردازش را آسان میکند'&gt;&gt;&gt; sent_tokenize('ما هم برای وصل کردن آمدیم! ولی برای پردازش، جدا بهتر نیست؟')['ما هم برای وصل کردن آمدیم!', 'ولی برای پردازش، جدا بهتر نیست؟']&gt;&gt;&gt; word_tokenize('ولی برای پردازش، جدا بهتر نیست؟')['ولی', 'برای', 'پردازش', '،', 'جدا', 'بهتر', 'نیست', '؟']&gt;&gt;&gt; stemmer = Stemmer()&gt;&gt;&gt; stemmer.stem('کتابها')'کتاب'&gt;&gt;&gt; lemmatizer = Lemmatizer()&gt;&gt;&gt; lemmatizer.lemmatize('میروم')'رفت#رو'&gt;&gt;&gt; tagger = POSTagger(model='resources/postagger.model')&gt;&gt;&gt; tagger.tag(word_tokenize('ما بسیار کتاب میخوانیم'))[('ما', 'PRO'), ('بسیار', 'ADV'), ('کتاب', 'N'), ('میخوانیم', 'V')]&gt;&gt;&gt; chunker = Chunker(model='resources/chunker.model')&gt;&gt;&gt; tagged = tagger.tag(word_tokenize('کتاب خواندن را دوست داریم'))&gt;&gt;&gt; tree2brackets(chunker.parse(tagged))'[کتاب خواندن NP] [را POSTP] [دوست داریم VP]'&gt;&gt;&gt; parser = DependencyParser(tagger=tagger, lemmatizer=lemmatizer)&gt;&gt;&gt; parser.parse(word_tokenize('زنگها برای که به صدا درمیآید؟'))&lt;DependencyGraph with 8 nodes&gt;```## InstallationThe latest stabe verson of Hazm can be installed through `pip`:pip install hazmBut for testing or using Hazm with the latest updates you may use:pip install https://github.com/sobhe/hazm/archive/master.zip --upgradeWe have also trained [tagger and parser models](https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip). You may put these models in the `resources` folder of your project.## ExtensionsNote: These are not official versions of hazm, not uptodate on functionality and are not supported by Sobhe.+ [**JHazm**](https://github.com/mojtaba-khallash/JHazm): A Java port of Hazm+ [**NHazm**](https://github.com/mojtaba-khallash/NHazm): A C# port of Hazm## Thanks+ to constributors: [Mojtaba Khallash](https://github.com/mojtaba-khallash) and [Mohsen Imany](https://github.com/imani).+ to [Virastyar](http://virastyar.ir/) project for persian word list.</longdescription>
</pkgmetadata>