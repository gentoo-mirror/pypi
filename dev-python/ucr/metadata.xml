<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;br&gt; &lt;br&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/static/images/VectorU.svg&quot; alt=&quot;Github Runner Covergae Status&quot; height=&quot;100&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;img src=&quot;docs/static/images/VectorC.svg&quot; alt=&quot;Github Runner Covergae Status&quot; height=&quot;100&quot;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;img src=&quot;docs/static/images/VectorR.svg&quot; alt=&quot;Github Runner Covergae Status&quot; height=&quot;100&quot;&gt;&lt;/p&gt;&lt;br&gt; &lt;br&gt;&lt;p align=&quot;center&quot;&gt;Universal Character Recognizer (UCR) is an &lt;u&gt;Open Source&lt;/u&gt;, &lt;u&gt;Easy to use&lt;/u&gt; Python library to build &lt;u&gt;Production Ready&lt;/u&gt; OCR applications with its highly Intuitive,  Modular &amp; Extensible API design and off-the-shelf &lt;a href=&quot;docs/modelzoo.md&quot;&gt;Pretrained Models&lt;/a&gt; for over &lt;b&gt;25 languages&lt;/b&gt;.&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;  Read UCR Documentation on &lt;u&gt;&lt;a href=&quot;https://ucr.docyard.ai/&quot;&gt;ucr.docyard.ai&lt;/a&gt;&lt;/u&gt;  &lt;br&gt; &lt;br&gt;  &lt;a href=&quot;#about&quot;&gt;Features&lt;/a&gt; •  &lt;a href=&quot;#setup&quot;&gt;Setup&lt;/a&gt; •  &lt;a href=&quot;#usage&quot;&gt;Usage&lt;/a&gt; •  &lt;a href=&quot;#acknowledgement&quot;&gt;Acknowledgement&lt;/a&gt;  &lt;br&gt; &lt;br&gt;  &lt;img alt=&quot;PyPI - Python Version&quot; src=&quot;https://img.shields.io/pypi/pyversions/ucr&quot;&gt;  &lt;a href=&quot;https://badge.fury.io/py/ucr&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/ucr.svg&quot; alt=&quot;PyPI version&quot;&gt;&lt;/a&gt;&lt;/p&gt;## Demo#### For details, click [here](https://ucr.docyard.ai/demo)!&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/static/images/demo.gif&quot;/&gt;&lt;/p&gt;## Features- Supports SOTA Text Detection and Recognition models- Built on top of Pytorch and Pytorch Lightning- Supports over 25 languages- Model Zoo contains 27 Pretrained Models across 25 languages- Modular Design Language allows Pick and Choose of different components- Easily extensible with Custom Components and attributes- Hydra config enables Rapid Prototyping with multiple configurations- Support for Packaging, Logging and Deployment tools straight out of the box*Note: Some features are still in active development and might not be available.*## Setup### Installation**Require python version &gt;= 3.6.2, install with `pip` (recommended)**1. &lt;b&gt;Prerequisites:&lt;/b&gt; Install compatible version of Pytorch and torchvision from [official repository](https://pytorch.org/get-started/locally/).2. &lt;b&gt;Installation:&lt;/b&gt; Install the latest stable version of UCR:```shellpip install -U ucr```#### &lt;span style=&quot;color:#FF8856&quot;&gt;[Optional]&lt;/span&gt; Test InstallationRun dummy tests!```pythonucr test# Optional: Add -l/--lang='language_id' to test on particular language!ucr test -l='en_number'```  ## Usage### Workflow&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;docs/static/images/workflow.png&quot;/&gt;&lt;/p&gt;Execution flow of UCR is displayed above. Broadly it can be divided into 4 sub-parts:1. Input (image/folder path or web address) is fed into the &lt;u&gt;Detection&lt;/u&gt; model which outputs bounding box coordinates of all the text boxes.2. The detected boxes are then checked for &lt;u&gt;Orientation&lt;/u&gt; and corrected accordingly.3. Next, &lt;u&gt;Recognition&lt;/u&gt; model runs on the corrected text boxes. It returns bounding box information and OCR output.4. Lastly, an optional &lt;u&gt;Post Processing&lt;/u&gt; module is executed to improve/modify the results.### Quick StartThe following code snippet shows how to get started with UCR library.```pythonfrom ucr import UCR# initializationocr = UCR(lang=&quot;en_number&quot;, device=&quot;cpu&quot;)# run predictionresult = ocr.predict('input_path', output='output_path')# for saving annotated imageresult = ocr.predict('input_path', output='output_path', save_image=True)```For complete list of arguments, refer &lt;a href=&quot;docs/tldr.md/#argument-list&quot;&gt;Argument List&lt;/a&gt;## Model ZooA collection of pretrained models for detection, classification and recognition processes is present &lt;a href=&quot;ucr.docyard.ai/modelzoo&quot;&gt;here&lt;/a&gt; !  These models can be useful for out-of-the-box inference on over 25 languages.## AcknowledgementSubstantial part of the UCR library is either inspired or inherited from the [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) library. Wherever possible the repository has been ported from PaddlePaddle to PyTorch framework including the direct translation of model parameters.Also, a big thanks to [Clova AI](https://clova.ai/en/research/research-areas.html), for open sourcing their testing script and pretrained models ([CRAFT](https://github.com/clovaai/CRAFT-pytorch)).  ## License[Apache License 2.0](LICENSE)</longdescription>
</pkgmetadata>