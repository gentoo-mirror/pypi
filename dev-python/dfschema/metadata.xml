<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># DFS (aka Dataframe_Schema)**DFS** is a lightweight validator for `pandas.DataFrame`. You can think of it as a `jsonschema` for dataframe. Key features:1. **Lightweight**: only dependent on `pandas`  and `pydantic` (which depends only on `typing_extensions`)2. **Explicit**: inspired by `JsonSchema`, all schemas are stored as json (or yaml) files and can be generated or changed on the fly.3. **Simple**: Easy to use, no need to change your workflow and dive into the implementation details. 4. **Comprehensive**: Summarizes all errors in a single summary exception, checks for distributions, works on subsets of the dataframe 5. **Rapid**: base schemas can be generated from given dataframe or sql query (using `pd.read_sql`).6. **Handy**: Supports command line interface (with `[cli]` extra).7. **Extendable**: Core idea is to validate *dataframes* of any type. While now supports only pandas, we'll add abstractions to run same checks on different types of dataframes (CuDF, Dask, SparkDF, etc )## QuickStart### 1. Validate DataFrameVia wrapper```pythonimport pandas as pdimport dfschema as dfsdf = pd.DataFrame({  &quot;a&quot;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],  &quot;b&quot;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})schema_pass = {  &quot;shape&quot;: {&quot;min_rows&quot;: 10}}schema_raise = {  &quot;shape&quot;: {&quot;min_rows&quot;: 20}}dfs.validate(df, schema_pass)  # won't raise any issuesdfs.validate(df, schema_raise) # will Raise DataFrameSchemaError```Alternatively (v2 optional), you can use the root class, `DfSchema`:```pythondfs.DfSchema.from_dict(schema_pass).validate(df)  # won't raise any issuesdfs.DfSchema.from_dict(schema_raise).validate(df)  # will Raise DataFrameSchemaError```### 2. Generate Schema```pythondfs.DfSchema.from_df(df)```### 3. Read and Write Schemas  ```pythonschema = dfs.DfSchema.from_file('schema.json')schema.to_file(&quot;schema.yml&quot;)```### 4. Using CLI&gt; Note: requires [cli] extra as relies on `Typer` and `click`#### Validate via CLI```shelldfschema validate --read_kwargs_json '{delimiter=&quot;|&quot;}' FILEPATH SCHEMA_FILEPATH```Supports- csv- xlsx- parquet- feather#### Generate via CLI```shelldfs generate --format 'yaml' DATA_PATH &gt; schema.yaml```## InstallationWIP## Alternatives- [TableScheme](https://pypi.org/project/tableschema/)- [GreatExpectations](https://greatexpectations.io/). Large and complex package with Html reports, Airflow Operator, connectors, etc. an work on out-of-memory data, SQL databases, parquet, etc- [Pandera](https://pandera.readthedocs.io/en/stable/) - awesome package, great and suitable for type hinting, compatible with `hypothesis`  - [great talk](https://www.youtube.com/watch?v=PI5UmKi14cM)- [Tensorflow validate](https://www.tensorflow.org/tfx/guide/tfdv)- [DTF expectations](https://github.com/calogica/dbt-expectations)## Changes- [[changelog]]## Roadmap- [ ] Add tutorial Notebook- [ ] Support tableschema- [ ] Support Modin models- [ ] Support SQLAlchemy ORM models- [ ] Built-in Airflow Operator?- [ ] Interactive CLI/jupyter for schema generation</longdescription>
</pkgmetadata>