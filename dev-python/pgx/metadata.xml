<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![ci](https://github.com/sotetsuk/pgx/actions/workflows/ci.yml/badge.svg)](https://github.com/sotetsuk/pgx/actions/workflows/ci.yml)&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;docs/assets/logo.svg&quot; width=&quot;40%&quot;&gt;&lt;/div&gt;A collection of GPU/TPU-accelerated parallel game simulators for reinforcement learning (RL)&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;docs/assets/go_dark.gif#gh-dark-mode-only&quot; width=&quot;30%&quot;&gt;&lt;img src=&quot;docs/assets/go_dark.gif#gh-dark-mode-only&quot; width=&quot;30%&quot; style=&quot;transform:rotate(270deg);&quot;&gt;&lt;img src=&quot;docs/assets/go_dark.gif#gh-dark-mode-only&quot; width=&quot;30%&quot; style=&quot;transform:rotate(90deg);&quot;&gt;&lt;img src=&quot;docs/assets/go_light.gif#gh-light-mode-only&quot; width=&quot;30%&quot;&gt;&lt;img src=&quot;docs/assets/go_light.gif#gh-light-mode-only&quot; width=&quot;30%&quot; style=&quot;transform:rotate(270deg);&quot;&gt;&lt;img src=&quot;docs/assets/go_light.gif#gh-light-mode-only&quot; width=&quot;30%&quot; style=&quot;transform:rotate(90deg);&quot;&gt;&lt;/div&gt;## Why Pgx?&lt;!--- throughput: https://colab.research.google.com/drive/1gIWHYLKBxE2XKDhAlEYKVecz3WG4czdz#scrollTo=V1QZhRXoGL8K---&gt;[Brax](https://github.com/google/brax), a [JAX](https://github.com/google/jax)-native physics engine, provides extremely high-speed parallel simulation for RL in *continuous* state space.Then, what about RL in *discrete* state spaces like Chess, Shogi, and Go? **Pgx** provides a wide variety of JAX-native game simulators! Highlighted features include:- **JAX-native.** All `step` functions are *JIT-able*- **Super fast** in parallel execution on accelerators- **Various game support** including **Backgammon**, **Chess**, **Shogi**, and **Go**- **Beautiful visualization** in SVG format## Install```shpip install pgx```## Usage&lt;a href=&quot;https://colab.research.google.com/github/sotetsuk/pgx/blob/main/colab/pgx_hello_world.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;&lt;/a&gt;```pyimport jaximport pgxenv = pgx.make(&quot;go-19x19&quot;)init = jax.jit(jax.vmap(env.init))  # vectorize and JIT-compilestep = jax.jit(jax.vmap(env.step))batch_size = 1024keys = jax.random.split(jax.random.PRNGKey(42), batch_size)state = init(keys)  # vectorized stateswhile not state.terminated.all():    action = model(state.current_player, state.observation, state.legal_action_mask)    state = step(state, action)  # state.reward (2,)```&lt;!---### Limitations (for the simplicity)* Does **NOT** support agent death and creation, which dynmically changes the array size. It does not well suit to GPU-accelerated computation.* Does **NOT** support Chance player (Nature player) with action selection.* Does **NOT** support OpenAI Gym API.    * OpenAI Gym is for single-agent environment. Most of Pgx environments are multi-player games. Just defining opponents is not enough for converting multi-agent environemnts to OpenAI Gym environment. E.g., in the game of go, the next state s' is defined as the state just after placing a stone in AlhaGo paper. However, s' becomes the state after the opponents' play. This changes the definition of V(s').* Does **NOT** support PettingZoo API.    * PettingZoo is *Gym for multi-agent RL*. As far as we know, PettingZoo does not support vectorized environments (like VectorEnv in OpenAI Gym). As Pgx's main feature is highly vectorized environment via GPU/TPU support, We do not currently support PettingZoo API. ### `skip_chance`* We prepare skip_chance=True option for some environments. This makes it possible to consider value function for &quot;post-decision states&quot; (See AlgoRL book). However, we do not allow chance agent to choose action like OpenSpiel. This is because the action space of chance agent and usual agent are different. Thus, when the chance player is chosen (`current_player=-1`), `action=-1` must be returned to step function. Use `shuffle` to make `step` stochastic.### truncatation and auto_reset* supported by `make(env_id=&quot;...&quot;, auto_reset=True, max_episode_length=64)`* `auto_reset` will replace the terminal state by initial state (but `is_terminal=True` is set)* `is_truncated=True` is also set to state---&gt;## Supported games and road map&gt; :warning: Pgx is currently in the beta version. Therefore, API is subject to change without notice. We aim to release v1.0.0 in April 2023. Opinions and comments are more than welcome!Use `pgx.available_games()` to see the list of currently available games.&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;fig/svgs/2048_dark.png#gh-dark-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/backgammon_dark.png#gh-dark-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/go-9x9_dark.png#gh-dark-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/kuhn_poker_dark.png#gh-dark-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/shogi_dark.png#gh-dark-mode-only&quot; height=&quot;120px&quot;&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;fig/svgs/2048_light.png#gh-light-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/backgammon_light.png#gh-light-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/go-9x9_light.png#gh-light-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/kuhn_poker_light.png#gh-light-mode-only&quot; height=&quot;120px&quot;&gt;&lt;img src=&quot;fig/svgs/shogi_light.png#gh-light-mode-only&quot; height=&quot;120px&quot;&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;table&gt;&lt;tr&gt;  &lt;th&gt;Game&lt;/th&gt;  &lt;th&gt;Environment&lt;/th&gt;  &lt;th&gt;Visualization&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/2048_(video_game)&quot;&gt;2048&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/D%C5%8Dbutsu_sh%C5%8Dgi&quot;&gt;Animal Shogi&lt;/a&gt; &lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Backgammon&quot;&gt;Backgammon&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Contract_bridge&quot;&gt;Bridge Bidding&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:construction:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Chess&quot;&gt;Chess&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Connect_Four&quot;&gt;Connect Four&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Go_(game)&quot;&gt;Go&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hex_(board_game)&quot;&gt;Hex&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kuhn_poker&quot;&gt;Kuhn Poker&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1207.1411&quot;&gt;Leduc hold'em&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Japanese_mahjong&quot;&gt;Mahjong&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:construction:&lt;/td&gt; &lt;td&gt;:construction:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://github.com/kenjyoung/MinAtar&quot;&gt;MinAtar/Asterix&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://github.com/kenjyoung/MinAtar&quot;&gt;MinAtar/Breakout&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://github.com/kenjyoung/MinAtar&quot;&gt;MinAtar/Freeway&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://github.com/kenjyoung/MinAtar&quot;&gt;MinAtar/Seaquest&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://github.com/kenjyoung/MinAtar&quot;&gt;MinAtar/SpaceInvaders&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Reversi&quot;&gt;Othello&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Shogi&quot;&gt;Shogi&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://sugorokuya.jp/p/suzume-jong&quot;&gt;Sparrow Mahjong&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Tic-tac-toe&quot;&gt;Tic-tac-toe&lt;/a&gt;&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt; &lt;td&gt;:white_check_mark:&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;## See alsoPgx is intended to complement these **JAX-native environments** with (classic) board game suits:- [RobertTLange/gymnax](https://github.com/RobertTLange/gymnax): JAX implementation of popular RL environments ([classic control](https://gymnasium.farama.org/environments/classic_control), [bsuite](https://github.com/deepmind/bsuite), MinAtar, etc) and meta RL tasks- [google/brax](https://github.com/google/brax): Rigidbody physics simulation in JAX and continuous-space RL tasks (ant, fetch, humanoid, etc)- [instadeepai/jumanji](https://github.com/instadeepai/jumanji): A suite of diverse and challenging    RL environments in JAX (bin-packing, routing problems, etc)Combining Pgx with these **JAX-native algorithms/implementations** might be an interesting direction:- [Anakin framework](https://arxiv.org/abs/2104.06272): Highly efficient RL framework that works with JAX-native environments on TPUs- [deepmind/mctx](https://github.com/deepmind/mctx): JAX-native MCTS implementations, including AlphaZero and MuZero- [deepmind/rlax](https://github.com/deepmind/rlax): JAX-native RL components- [google/evojax](https://github.com/google/evojax): Hardware-Accelerated neuroevolution- [RobertTLange/evosax](https://github.com/RobertTLange/evosax): JAX-native evolution strategy (ES) implementations- [adaptive-intelligent-robotics/QDax](https://github.com/adaptive-intelligent-robotics/QDax): JAX-native Quality-Diversity (QD) algorithms## Citation```@article{koyamada2023pgx,  title={Pgx: Hardware-accelerated parallel game simulation for reinforcement learning},  author={Koyamada, Sotetsu and Okano, Shinri and Nishimori, Soichiro and Murata, Yu and Habara, Keigo and Kita, Haruka and Ishii, Shin},  journal={arXiv preprint arXiv:2303.17503},  year={2023}}```## LICENSEApache-2.0</longdescription>
</pkgmetadata>