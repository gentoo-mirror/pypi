<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>.. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/async_logo.png    :target: https://github.com/hyriver/HyRiver|.. image:: https://joss.theoj.org/papers/b0df2f6192f0a18b9e622a3edff52e77/status.svg    :target: https://joss.theoj.org/papers/b0df2f6192f0a18b9e622a3edff52e77    :alt: JOSS|.. |pygeohydro| image:: https://github.com/hyriver/pygeohydro/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pygeohydro/actions/workflows/test.yml    :alt: Github Actions.. |pygeoogc| image:: https://github.com/hyriver/pygeoogc/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pygeoogc/actions/workflows/test.yml    :alt: Github Actions.. |pygeoutils| image:: https://github.com/hyriver/pygeoutils/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pygeoutils/actions/workflows/test.yml    :alt: Github Actions.. |pynhd| image:: https://github.com/hyriver/pynhd/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pynhd/actions/workflows/test.yml    :alt: Github Actions.. |py3dep| image:: https://github.com/hyriver/py3dep/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/py3dep/actions/workflows/test.yml    :alt: Github Actions.. |pydaymet| image:: https://github.com/hyriver/pydaymet/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pydaymet/actions/workflows/test.yml    :alt: Github Actions.. |pynldas2| image:: https://github.com/hyriver/pynldas2/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pynldas2/actions/workflows/test.yml    :alt: Github Actions.. |async| image:: https://github.com/hyriver/async-retriever/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/async-retriever/actions/workflows/test.yml    :alt: Github Actions.. |signatures| image:: https://github.com/hyriver/hydrosignatures/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/hydrosignatures/actions/workflows/test.yml    :alt: Github Actions================ ==================================================================== ============Package          Description                                                          Status================ ==================================================================== ============PyNHD_           Navigate and subset NHDPlus (MR and HR) using web services           |pynhd|Py3DEP_          Access topographic data through National Map's 3DEP web service      |py3dep|PyGeoHydro_      Access NWIS, NID, WQP, HCDN 2009, NLCD, CAMELS, and SSEBop databases |pygeohydro|PyDaymet_        Access daily, monthly, and annual climate data via Daymet            |pydaymet|PyNLDAS2_        Access hourly NLDAS-2 data via web services                          |pynldas2|HydroSignatures_ A collection of tools for computing hydrological signatures          |signatures|AsyncRetriever_  High-level API for asynchronous requests with persistent caching     |async|PyGeoOGC_        Send queries to any ArcGIS RESTful-, WMS-, and WFS-based services    |pygeoogc|PyGeoUtils_      Utilities for manipulating geospatial, (Geo)JSON, and (Geo)TIFF data |pygeoutils|================ ==================================================================== ============.. _PyGeoHydro: https://github.com/hyriver/pygeohydro.. _AsyncRetriever: https://github.com/hyriver/async-retriever.. _PyGeoOGC: https://github.com/hyriver/pygeoogc.. _PyGeoUtils: https://github.com/hyriver/pygeoutils.. _PyNHD: https://github.com/hyriver/pynhd.. _Py3DEP: https://github.com/hyriver/py3dep.. _PyDaymet: https://github.com/hyriver/pydaymet.. _PyNLDAS2: https://github.com/hyriver/pynldas2.. _HydroSignatures: https://github.com/hyriver/hydrosignaturesAsyncRetriever: Asynchronous requests with persistent caching-------------------------------------------------------------.. image:: https://img.shields.io/pypi/v/async-retriever.svg    :target: https://pypi.python.org/pypi/async-retriever    :alt: PyPi.. image:: https://img.shields.io/conda/vn/conda-forge/async-retriever.svg    :target: https://anaconda.org/conda-forge/async-retriever    :alt: Conda Version.. image:: https://codecov.io/gh/hyriver/async-retriever/branch/main/graph/badge.svg    :target: https://codecov.io/gh/hyriver/async-retriever    :alt: CodeCov.. image:: https://img.shields.io/pypi/pyversions/async-retriever.svg    :target: https://pypi.python.org/pypi/async-retriever    :alt: Python Versions.. image:: https://github.com/hyriver/async-retriever/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/async-retriever/actions/workflows/test.yml    :alt: Github Actions|.. image:: https://img.shields.io/badge/security-bandit-green.svg    :target: https://github.com/PyCQA/bandit    :alt: Security Status.. image:: https://www.codefactor.io/repository/github/hyriver/async-retriever/badge   :target: https://www.codefactor.io/repository/github/hyriver/async-retriever   :alt: CodeFactor.. image:: https://img.shields.io/badge/code%20style-black-000000.svg    :target: https://github.com/psf/black    :alt: black.. image:: https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;logoColor=white    :target: https://github.com/pre-commit/pre-commit    :alt: pre-commit|Features--------AsyncRetriever is a part of `HyRiver &lt;https://github.com/hyriver/HyRiver&gt;`__ software stack thatis designed to aid in hydroclimate analysis through web services. This package serves as HyRiver'sengine for asynchronously sending requests and retrieving responses as ``text``, ``binary``, or``json`` objects. It uses persistent caching using`aiohttp-client-cache &lt;https://aiohttp-client-cache.readthedocs.io&gt;`__ to speed up the retrievaleven further. Moreover, thanks to `nest_asyncio &lt;https://github.com/erdewit/nest_asyncio&gt;`__you can use this package in Jupyter notebooks. Although this package is part of the HyRiversoftware stack, it can be used for any web calls. There are three functions that you canuse to make web calls:* ``retrieve_text``: Get responses as ``text`` objects.* ``retrieve_binary``: Get responses as ``binary`` objects.* ``retrieve_json``: Get responses as ``json`` objects.* ``stream_write``: Stream responses and write them to disk in chunks.You can also use the general-purpose ``retrieve`` function to get responses as anyof the three types. All responses are returned as a list that has the same order as theinput list of requests. Moreover, there is another function called ``delete_url_cache``for removing all requests from a cache file that contains a given URL.You can control the request/response caching behavior and verbosity of the packageby setting the following environment variables:* ``HYRIVER_CACHE_NAME``: Path to the caching SQLite database. It defaults to  ``./cache/aiohttp_cache.sqlite``* ``HYRIVER_CACHE_EXPIRE``: Expiration time for cached requests in seconds. It defaults to  one week.* ``HYRIVER_CACHE_DISABLE``: Disable reading/writing from/to the cache. The default is false.For example, in your code before making any requests you can do:.. code-block:: python    import os    os.environ[&quot;HYRIVER_CACHE_NAME&quot;] = &quot;path/to/file.sqlite&quot;    os.environ[&quot;HYRIVER_CACHE_EXPIRE&quot;] = &quot;3600&quot;    os.environ[&quot;HYRIVER_CACHE_DISABLE&quot;] = &quot;true&quot;You can find some example notebooks `here &lt;https://github.com/hyriver/HyRiver-examples&gt;`__.You can also try using AsyncRetriever without installingit on your system by clicking on the binder badge. A Jupyter Labinstance with the HyRiver stack pre-installed will be launched in your web browser, and youcan start coding!Moreover, requests for additional functionalities can be submitted via`issue tracker &lt;https://github.com/hyriver/async-retriever/issues&gt;`__.Citation--------If you use any of HyRiver packages in your research, we appreciate citations:.. code-block:: bibtex    @article{Chegini_2021,        author = {Chegini, Taher and Li, Hong-Yi and Leung, L. Ruby},        doi = {10.21105/joss.03175},        journal = {Journal of Open Source Software},        month = {10},        number = {66},        pages = {1--3},        title = {{HyRiver: Hydroclimate Data Retriever}},        volume = {6},        year = {2021}    }Installation------------You can install ``async-retriever`` using ``pip``:.. code-block:: console    $ pip install async-retrieverAlternatively, ``async-retriever`` can be installed from the ``conda-forge`` repositoryusing `Conda &lt;https://docs.conda.io/en/latest/&gt;`__:.. code-block:: console    $ conda install -c conda-forge async-retrieverQuick start-----------AsyncRetriever by default creates and/or uses ``./cache/aiohttp_cache.sqlite`` as the cachethat you can customize by the ``cache_name`` argument. Also, by default, the cache doesn'thave any expiration date and the ``delete_url_cache`` function should be used if you knowthat a database on a server was updated, and you want to retrieve the latest data.Alternatively, you can use the ``expire_after`` to set the expiration date for the cache.As an example for retrieving a ``binary`` response, let's use the DAAC server to get`NDVI &lt;https://daac.ornl.gov/VEGETATION/guides/US_MODIS_NDVI.html&gt;`_.The responses can be directly passed to ``xarray.open_mfdataset`` to get the data asa ``xarray`` Dataset. We can also disable SSL certificate verification by setting``ssl=False``... code-block:: python    import io    import xarray as xr    import async_retriever as ar    from datetime import datetime    west, south, east, north = (-69.77, 45.07, -69.31, 45.45)    base_url = &quot;https://thredds.daac.ornl.gov/thredds/ncss/ornldaac/1299&quot;    dates_itr = ((datetime(y, 1, 1), datetime(y, 1, 31)) for y in range(2000, 2005))    urls, kwds = zip(        *[            (                f&quot;{base_url}/MCD13.A{s.year}.unaccum.nc4&quot;,                {                    &quot;params&quot;: {                        &quot;var&quot;: &quot;NDVI&quot;,                        &quot;north&quot;: f&quot;{north}&quot;,                        &quot;west&quot;: f&quot;{west}&quot;,                        &quot;east&quot;: f&quot;{east}&quot;,                        &quot;south&quot;: f&quot;{south}&quot;,                        &quot;disableProjSubset&quot;: &quot;on&quot;,                        &quot;horizStride&quot;: &quot;1&quot;,                        &quot;time_start&quot;: s.strftime(&quot;%Y-%m-%dT%H:%M:%SZ&quot;),                        &quot;time_end&quot;: e.strftime(&quot;%Y-%m-%dT%H:%M:%SZ&quot;),                        &quot;timeStride&quot;: &quot;1&quot;,                        &quot;addLatLon&quot;: &quot;true&quot;,                        &quot;accept&quot;: &quot;netcdf&quot;,                    }                },            )            for s, e in dates_itr        ]    )    resp = ar.retrieve_binary(urls, kwds, max_workers=8, ssl=False)    data = xr.open_mfdataset(io.BytesIO(r) for r in resp)We can remove these requests and their responses from the cache like so:.. code-block:: python    ar.delete_url_cache(base_url).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/ndvi.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/async.ipynbFor a ``json`` response example, let's get water level recordings of an NOAA's water level station,8534720 (Atlantic City, NJ), during 2012, using CO-OPS API. Note that this CO-OPS product has a31-day limit for a single request, so we have to break the request down accordingly... code-block:: python    import pandas as pd    station_id = &quot;8534720&quot;    start = pd.to_datetime(&quot;2012-01-01&quot;)    end = pd.to_datetime(&quot;2012-12-31&quot;)    s = start    dates = []    for e in pd.date_range(start, end, freq=&quot;m&quot;):        dates.append((s.date(), e.date()))        s = e + pd.offsets.MonthBegin()    url = &quot;https://api.tidesandcurrents.noaa.gov/api/prod/datagetter&quot;    urls, kwds = zip(        *[            (                url,                {                    &quot;params&quot;: {                        &quot;product&quot;: &quot;water_level&quot;,                        &quot;application&quot;: &quot;web_services&quot;,                        &quot;begin_date&quot;: f'{s.strftime(&quot;%Y%m%d&quot;)}',                        &quot;end_date&quot;: f'{e.strftime(&quot;%Y%m%d&quot;)}',                        &quot;datum&quot;: &quot;MSL&quot;,                        &quot;station&quot;: f&quot;{station_id}&quot;,                        &quot;time_zone&quot;: &quot;GMT&quot;,                        &quot;units&quot;: &quot;metric&quot;,                        &quot;format&quot;: &quot;json&quot;,                    }                },            )            for s, e in dates        ]    )    resp = ar.retrieve_json(urls, kwds)    wl_list = []    for rjson in resp:        wl = pd.DataFrame.from_dict(rjson[&quot;data&quot;])        wl[&quot;t&quot;] = pd.to_datetime(wl.t)        wl = wl.set_index(wl.t).drop(columns=&quot;t&quot;)        wl[&quot;v&quot;] = pd.to_numeric(wl.v, errors=&quot;coerce&quot;)        wl_list.append(wl)    water_level = pd.concat(wl_list).sort_index()    water_level.attrs = rjson[&quot;metadata&quot;].. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/water_level.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/async.ipynbNow, let's see an example without any payload or headers. Here's how we can retrieveharmonic constituents of several NOAA stations from CO-OPS:.. code-block:: python    stations = [        &quot;8410140&quot;,        &quot;8411060&quot;,        &quot;8413320&quot;,        &quot;8418150&quot;,        &quot;8419317&quot;,        &quot;8419870&quot;,        &quot;8443970&quot;,        &quot;8447386&quot;,    ]    base_url = &quot;https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations&quot;    urls = [f&quot;{base_url}/{i}/harcon.json?units=metric&quot; for i in stations]    resp = ar.retrieve_json(urls)    amp_list = []    phs_list = []    for rjson in resp:        sid = rjson[&quot;self&quot;].rsplit(&quot;/&quot;, 2)[1]        const = pd.DataFrame.from_dict(rjson[&quot;HarmonicConstituents&quot;]).set_index(&quot;name&quot;)        amp = const.rename(columns={&quot;amplitude&quot;: sid})[sid]        phase = const.rename(columns={&quot;phase_GMT&quot;: sid})[sid]        amp_list.append(amp)        phs_list.append(phase)    amp = pd.concat(amp_list, axis=1)    phs = pd.concat(phs_list, axis=1).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/tides.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/async.ipynbContributing------------Contributions are appreciated and very welcomed. Please read`CONTRIBUTING.rst &lt;https://github.com/hyriver/async-retriever/blob/main/CONTRIBUTING.rst&gt;`__for instructions.</longdescription>
</pkgmetadata>