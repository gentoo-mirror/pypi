<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>sk-dist: Distributed scikit-learn meta-estimators in PySpark============================================================|License| |Build Status| |PyPI Package| |Downloads| |Python Versions|What is it?-----------``sk-dist`` is a Python package for machine learning built on top of`scikit-learn &lt;https://scikit-learn.org/stable/index.html&gt;`__ and isdistributed under the `Apache 2.0 softwarelicense &lt;https://github.com/Ibotta/sk-dist/blob/master/LICENSE&gt;`__. The``sk-dist`` module can be thought of as &quot;distributed scikit-learn&quot; asits core functionality is to extend the ``scikit-learn`` built-in``joblib`` parallelization of meta-estimator training to`spark &lt;https://spark.apache.org/&gt;`__. A popular use case is the parallelization of grid search as shown here:Check out the `blog post &lt;https://medium.com/building-ibotta/train-sklearn-100x-faster-bec530fc1f45&gt;`__ for more information on the motivation and use cases of ``sk-dist``.Main Features--------------  **Distributed Training** - ``sk-dist`` parallelizes the training of   ``scikit-learn`` meta-estimators with PySpark. This allows   distributed training of these estimators without any constraint on   the physical resources of any one machine. In all cases, spark   artifacts are automatically stripped from the fitted estimator. These   estimators can then be pickled and un-pickled for prediction tasks,   operating identically at predict time to their ``scikit-learn``   counterparts. Supported tasks are:   -  *Grid Search*: `Hyperparameter optimization      techniques &lt;https://scikit-learn.org/stable/modules/grid_search.html&gt;`__,      particularly      `GridSearchCV &lt;https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV&gt;`__      and      `RandomizedSeachCV &lt;https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV&gt;`__,      are distributed such that each parameter set candidate is trained      in parallel.   -  *Multiclass Strategies*: `Multiclass classification      strategies &lt;https://scikit-learn.org/stable/modules/multiclass.html&gt;`__,      particularly      `OneVsRestClassifier &lt;https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier&gt;`__      and      `OneVsOneClassifier &lt;https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier&gt;`__,      are distributed such that each binary probelm is trained in      parallel.   -  *Tree Ensembles*: `Decision tree      ensembles &lt;https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees&gt;`__      for classification and regression, particularly      `RandomForest &lt;https://scikit-learn.org/stable/modules/ensemble.html#random-forests&gt;`__      and      `ExtraTrees &lt;https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees&gt;`__,      are distributed such that each tree is trained in parallel.-  **Distributed Prediction** - ``sk-dist`` provides a prediction module   which builds `vectorized   UDFs &lt;https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs&gt;`__   for   `PySpark &lt;https://spark.apache.org/docs/latest/api/python/index.html&gt;`__   `DataFrames &lt;https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame&gt;`__   using fitted ``scikit-learn`` estimators. This distributes the   ``predict`` and ``predict_proba`` methods of ``scikit-learn``   estimators, enabling large scale prediction with ``scikit-learn``.-  **Feature Encoding** - ``sk-dist`` provides a flexible feature   encoding utility called ``Encoderizer`` which encodes mix-typed   feature spaces using either default behavior or user defined   customizable settings. It is particularly aimed at text features, but   it additionally handles numeric and dictionary type feature spaces.Installation------------Dependencies~~~~~~~~~~~~``sk-dist`` requires:-  `Python &lt;https://www.python.org/&gt;`__ (&gt;= 3.5)-  `scikit-learn &lt;https://scikit-learn.org/stable/&gt;`__ (&gt;=0.20.0)-  `pandas &lt;https://pandas.pydata.org/&gt;`__ (&gt;=0.17.0)-  `numpy &lt;https://www.numpy.org/&gt;`__ -  `scipy &lt;https://www.scipy.org/&gt;`__ -  `joblib &lt;https://joblib.readthedocs.io/en/latest/&gt;`__ Dependency Notes~~~~~~~~~~~~~~~~-  versions of ``numpy``, ``scipy`` and ``joblib`` that are compatible with any supported version of ``scikit-learn`` should be sufficient for ``sk-dist``- ``sk-dist`` is not supported with Python 2Spark Dependencies~~~~~~~~~~~~~~~~~~Most ``sk-dist`` functionality requires a spark installation as well asPySpark. Some functionality can run without spark, so spark relateddependencies are not required. The connection between sk-dist and sparkrelies solely on a ``sparkContext`` as an argument to various``sk-dist`` classes upon instantiation.A variety of spark configurations and setups will work. It is left up tothe user to configure their own spark setup. The testing suite runs``spark 2.3`` and ``spark 2.4``, though any ``spark 2.0+`` versions are expected to work.Additional spark related dependecies are ``pyarrow``, which is used onlyfor ``skdist.predict`` functions. This uses vectorized pandas UDFs whichrequire ``pyarrow&gt;=0.8.0``, tested with ``pyarrow==0.15.0``. Depending on the spark version, it may be necessary to set``spark.conf.set(&quot;spark.sql.execution.arrow.enabled&quot;, &quot;true&quot;)`` in thespark configuration.User Installation~~~~~~~~~~~~~~~~~The easiest way to install ``sk-dist`` is with ``pip``:::    pip install --upgrade sk-distYou can also download the source code:::    git clone https://github.com/Ibotta/sk-dist.gitTesting~~~~~~~With ``pytest`` installed, you can run tests locally:::    pytest sk-distExamples--------The package contains numerous `examples &lt;https://github.com/Ibotta/sk-dist/tree/master/examples&gt;`__ on how to use ``sk-dist`` in practice. Examples of note are:-  `Grid Search with XGBoost &lt;https://github.com/Ibotta/sk-dist/blob/master/examples/search/xgb.py&gt;`__-  `Spark ML Benchmark Comparison &lt;https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py&gt;`__-  `Encoderizer with 20 Newsgroups &lt;https://github.com/Ibotta/sk-dist/blob/master/examples/encoder/basic_usage.py&gt;`__-  `One-Vs-Rest vs One-Vs-One &lt;https://github.com/Ibotta/sk-dist/blob/master/examples/multiclass/basic_usage.py&gt;`__-  `Large Scale Sklearn Prediction with PySpark UDFs &lt;https://github.com/Ibotta/sk-dist/blob/master/examples/predict/basic_usage.py&gt;`_Gradient Boosting-----------------``sk-dist`` has been tested with a number of popular gradient boosting packages that conform to the ``scikit-learn`` API. This includes ``xgboost`` and ``catboost``. These will need to be installed in addition to ``sk-dist`` on all nodes of the spark cluster via a node bootstrap script. Version compatibility is left up to the user.Support for ``lightgbm`` is not guaranteed, as it requires `additional installations &lt;https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#linux&gt;`__ on all nodes of the spark cluster. This may work given proper installation but has not beed tested with ``sk-dist``.Background----------The project was started at `IbottaInc. &lt;https://medium.com/building-ibotta&gt;`__ on the machine learningteam and open sourced in 2019.It is currently maintained by the machine learning team at Ibotta. Specialthanks to those who contributed to ``sk-dist`` while it was initiallyin development at Ibotta:-  `Evan Harris &lt;https://github.com/denver1117&gt;`__-  `Nicole Woytarowicz &lt;https://github.com/nicolele&gt;`__-  `Mike Lewis &lt;https://github.com/Mikelew88&gt;`__-  `Bobby Crimi &lt;https://github.com/rpcrimi&gt;`__Thanks to `James Foley &lt;https://github.com/chadfoley36&gt;`__ for logo artwork... |License| image:: https://img.shields.io/badge/License-Apache%202.0-blue.svg   :target: https://opensource.org/licenses/Apache-2.0.. |Build Status| image:: https://travis-ci.org/Ibotta/sk-dist.png?branch=master   :target: https://travis-ci.org/Ibotta/sk-dist.. |PyPI Package| image:: https://badge.fury.io/py/sk-dist.svg   :target: https://pypi.org/project/sk-dist/.. |Downloads| image:: https://img.shields.io/pypi/dm/sk-dist   :target: https://pypistats.org/packages/sk-dist.. |Python Versions| image:: https://img.shields.io/pypi/pyversions/sk-dist   :target: https://pypi.org/project/sk-dist/</longdescription>
</pkgmetadata>