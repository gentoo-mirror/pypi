<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># ChatLab**Chat Experiments, Simplified**üí¨üî¨ChatLab is a Python package that makes it easy to experiment with OpenAI's chat models. It provides a simple interface for chatting with the models and a way to register functions that can be called from the chat model.Best yet, it's interactive in the notebook!## Introduction```pythonimport chatlabimport randomdef flip_a_coin():    '''Returns heads or tails'''    return random.choice(['heads', 'tails'])conversation = chatlab.Conversation()conversation.register(flip_a_coin)conversation.submit(&quot;Please flip a coin for me&quot;)```&lt;details style=&quot;background:#DDE6ED;color:#27374D;padding:.5rem 1rem;borderRadius:5px&quot;&gt;&lt;summary&gt;&amp;nbsp;ùëì&amp;nbsp; Ran `flip_a_coin`&lt;/summary&gt;&lt;br /&gt;Input:```json{}```Output:```json&quot;tails&quot;```&lt;/details&gt;```markdownIt landed on tails!```In the notebook, text will stream into a Markdown output and function inputs and outputs are a nice collapsible display, like with ChatGPT Plugins.&lt;details class=&quot;details-reset border rounded-2&quot; open=&quot;&quot;&gt;  &lt;summary class=&quot;px-3 py-2&quot;&gt;    &lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-device-camera-video&quot;&gt;    &lt;path d=&quot;M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;    &lt;span aria-label=&quot;Video description flip-a-coin-chatlab.mp4&quot; class=&quot;m-1&quot;&gt;flip-a-coin-chatlab.mp4&lt;/span&gt;    &lt;span class=&quot;dropdown-caret&quot;&gt;&lt;/span&gt;  &lt;/summary&gt;  &lt;video src=&quot;https://user-images.githubusercontent.com/836375/248335062-fdc523b1-ca31-4506-b3ed-c73be9eb0d88.mp4&quot; data-canonical-src=&quot;https://user-images.githubusercontent.com/836375/248335062-fdc523b1-ca31-4506-b3ed-c73be9eb0d88.mp4&quot; controls=&quot;controls&quot; muted=&quot;muted&quot; class=&quot;d-block rounded-bottom-2 border-top width-fit&quot; style=&quot;max-height:640px; min-height: 200px&quot;&gt;  &lt;/video&gt;&lt;/details&gt;### Installation```bashpip install chatlab```### ConfigurationYou'll need to set your `OPENAI_API_KEY` environment variable. You can find your API key on your [OpenAI account page](https://platform.openai.com/account/api-keys). I recommend setting it in an `.env` file when working locally.On hosted environments like Noteable, set it in your Secrets to keep it safe from prying LLM eyes.## What can `Conversation`s enable _you_ to do?üí¨Where `Conversation`s take it next level is with _Chat Functions_. You can-   declare a function-   register the function in your `Conversation`-   watch as Chat Models call your functions!You may recall this kind of behavior from [ChatGPT Plugins](https://noteable.io/chatgpt-plugin-for-notebook/). Now, you can take this even further with your own custom code.As an example, let's give the large language models the ability to tell time.```pythonfrom datetime import datetimefrom pytz import timezone, all_timezones, utcfrom typing import Optionalfrom pydantic import BaseModeldef what_time(tz: Optional[str] = None):    '''Current time, defaulting to UTC'''    if tz is None:        pass    elif tz in all_timezones:        tz = timezone(tz)    else:        return 'Invalid timezone'    return datetime.now(tz).strftime('%I:%M %p')class WhatTime(BaseModel):    tz: Optional[str] = None```Let's break this down.`what_time` is the function we're going to provide access to. Its docstring forms the `description` for the model while the schema comes from the pydantic `BaseModel` called `WhatTime`.```pythonimport chatlabconversation = chatlab.Conversation()# Register our functionconversation.register(what_time, WhatTime)# Pluck the submit off for easy access as chatchat = conversation.submit```After that, we can call `chat` with direct strings (which are turned into user messages) or using simple message makers from `chatlab` named `user` and `system`.```pythonchat(&quot;What time is it?&quot;)```&lt;details style=&quot;background:#DDE6ED;color:#27374D;padding:.5rem 1rem;borderRadius:5px&quot;&gt;&lt;summary&gt;&amp;nbsp;ùëì&amp;nbsp; Ran `what_time`&lt;/summary&gt;&lt;br /&gt;Input:```json{}```Output:```json&quot;11:19 AM&quot;```&lt;/details&gt;```markdownThe current time is 11:19 AM.```## InterfaceThe `chatlab` package exports### `Conversation`The `Conversation` class is the main way to chat using OpenAI's models. It keeps a history of your chat in `Conversation.messages`.#### `Conversation.submit`When you call `submit`, you're sending over messages to the chat model and getting back an updating `Markdown` display live as well as a interactive details area for any function calls.```pythonconversation.submit('What would a parent who says &quot;I have to play zone defense&quot; mean? ')# Markdown response inlineconversation.messages``````js[{'role': 'user',  'content': 'What does a parent of three kids mean by &quot;I have to play zone defense&quot;?'}, {'role': 'assistant',  'content': 'When a parent of three kids says &quot;I have to play zone defense,&quot; it means that they...```#### `Conversation.register`You can register functions with `Conversation.register` to make them available to the chat model. The function's docstring becomes the description of the function while the schema is derived from the `pydantic.BaseModel` passed in.```pythonfrom pydantic import BaseModelclass WhatTime(BaseModel):    tz: Optional[str] = Nonedef what_time(tz: Optional[str] = None):    '''Current time, defaulting to UTC'''    if tz is None:        pass    elif tz in all_timezones:        tz = timezone(tz)    else:        return 'Invalid timezone'    return datetime.now(tz).strftime('%I:%M %p')conversation.register(what_time, WhatTime)```#### `Conversation.messages`The raw messages sent and received to OpenAI. If you hit a token limit, you can remove old messages from the list to make room for more.```pythonconversation.messages = conversation.messages[-100:]```### Messaging#### `human`/`user`These functions create a message from the user to the chat model.```pythonfrom chatlab import humanhuman(&quot;How are you?&quot;)``````json{ &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How are you?&quot; }```#### `narrate`/`system``system` messages, also called `narrate` in `chatlab`, allow you to steer the model in a direction. You can use these to provide context without being seen by the user. One common use is to include it as initial context for the conversation.```pythonfrom chatlab import narratenarrate(&quot;You are a large bird&quot;)``````json{ &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a large bird&quot; }```## DevelopmentThis project uses poetry for dependency management. To get started, clone the repo and run```bashpoetry install -E dev -E test```We use `black`, `isort`, and `mypy`.## ContributingPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.</longdescription>
</pkgmetadata>