<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># mecab-ko-dicThis is a Korean dictionary for the MeCab tokenizer, packaged for use in Pythonwith [mecab-python3](https://github.com/SamuraiT/mecab-python3) or[fugashi](https://github.com/polm/fugashi). ## Should you use this?We (at Luminoso) think this is probably a better way to find tokens in Koreanwords than just splitting the text on spaces would be. We also know that MeCabwasn't designed for Korean. But it gives us the kind of tokens we need betterthan other things we've tried.One reason we're packaging this is to use it in [wordfreq][], which needs tohave a reasonable set of consistent tokens so it can look up their frequencies,and already uses MeCab for Japanese.[wordfreq]: https://github.com/LuminosoInsight/wordfreqIf interoperability with things that already use MeCab is not your goal, youprobably have better options for Korean NLP than this.## CreditsThe dictionary data was created by Yongwoon Lee and Yungho Yu. We've included itas part of this package under the terms of the Apache License 2.0. The originaldictionary can be found [here][original-dict].The idea to package a MeCab dictionary as a Python repository, as well as thecode structure for doing so, come from [Paul McCann's ipadic package][ipadic-py].[original-dict]: https://bitbucket.org/eunjeon/mecab-ko-dic/[ipadic-py]: https://github.com/polm/ipadic-py## UsageTo install:    pip install mecab-ko-dicTo initialize with mecab-python3:    import MeCab    import mecab_ko_dic    tagger = MeCab.Tagger(mecab_ko_dic.MECAB_ARGS)    print(tagger.parse(&quot;안녕하세요세계.&quot;))## LicenseThe data we use, and this code repository itself, are released under the ApacheLicense 2.0. See the LICENSE.txt file included in this distribution.</longdescription>
</pkgmetadata>