<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>daml-dit-api====API definitions for DIT packages to be hosted in Daml Hub. This mainlycontains the [type definitions](daml_dit_api/package_metadata.py)for the format of the `dabl-meta.yaml` file at the root of each DIT file.DIT files are also used to contain integrations loaded and run by DamlHub. This repository also contains documentation (in this `README`)describing the runtime environment that Daml Hub provides tointegrations.# Package MetadataAt their core, DIT files are [ZIP archives](https://en.wikipedia.org/wiki/Zip_(file_format))that follow a specific set of conventions regarding their content. Themost important of these conventions is the presence of a YAML metadatafile at the root of the archive and named `dabl-meta.yaml`. Thismetadata file contains catalog information describing the contents ofthe DIT, as well as any packaging details needed to successfullydeploy a DIT file into Daml Hub. An example of a deployment instruction isa _subdeployment_. A subdeployment instructs Daml Hub to deploy a specificsubfile within the DIT file. A DIT file that contains an embedded DARfile could use a subdeployment to ensure that the embedded DAR file isdeployed to the ledger when the DIT is deployed. In this way, a DITfile composed of multiple artifacts (DARs, Bots, UI's, etc.) can beconstructed to deploy a set of artifacts to a single ledger in asingle action.# IntegrationsIntegrations are a special case of DIT file that are augmented withthe ability to run as an executable within a Daml Hub cluster. This isdone by packaging Python [DAZL bot](https://github.com/digital-asset/dazl-client)code into an [executable ZIP](https://docs.python.org/3/library/zipapp.html)using [PEX](https://github.com/pantsbuild/pex) and augmenting tharesulting file with the metadata and other resources needed to make ita correctly formed DIT file.Logically speaking, Daml Hub integrations are DAZL bots packaged withinformation needed to fit them into the Daml Hub runtime and userinterface. The major functional contrast between a Daml Hub integrationand a Python Bot is that the integration has the external networkaccess needed to connect to an outside system and the Python Bot doesnot. Due to the security implications of running within Daml Hub withexternal network access, integrations can only be deployed with theapproval of DA staff.## Developing IntegrationsThe easiest way to develop an integration for Daml Hub is to use the[framework library](https://github.com/digital-asset/daml-dit-if)and [`ddit` build tool](https://github.com/digital-asset/daml-dit-ddit).The integration framework presents a Python API closely related to theDAZL bot api and ensures that integrations follow the conventionsrequired to integrate into Daml Hub._Unless you know exactly what you are doing and why you are doing it,use the framework._## The Integration Runtime EnvironmentBy convention, integrations accept a number of environment variablesthat specify key paramaters.  Integrations built with the frameworkuse defaults for these variables that connect to a default locallyconfigured sandbox instance.Variables provided by Daml Hub include the following:| Variable | Default | Purpose ||----------|---------|---------|| `DAML_LEDGER_URL` | `http://localhost:6865` | Address of local ledger gRPC API || `DABL_HEALTH_PORT` | 8089 | Port for HTTP endpoint. (Used for both liveness/readiness and webhooks) || `DABL_JWKS_URL` | | HTTP URL for JWKS Repository || `DABL_INTEGRATION_METADATA_PATH` | 'int_args.yaml' | Path to local metadata file || `DABL_INTEGRATION_TYPE_ID` | | Type ID for the specific integration within the DIT to run || `DABL_LEDGER_PARTY` | | Party identifier for network connection || `DABL_LOG_LEVEL` | 0 | Log verbosity level - 0 up to 50, inclusive. |(Note that for legacy reasons, the ledger URL is also available underthe `DABL_LEDGER_URL` environment variable.)## LoggingDABL integrations use the default Python logging package, and theframework provides specific support for controlling log level atruntime. To integrate properly with this logic, it is important thatintegrations use the `integration` logger. This logger is switched from`INFO` level to `DEBUG` level at a `DABL_LOG_LEVEL` setting of 10 or above.The preferred way of creating an integration logger is via the`getIntegrationLogger` function in the API package.</longdescription>
</pkgmetadata>