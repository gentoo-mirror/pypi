<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;h1 style=&quot;text-align: center&quot;&gt;TensorNeko&lt;/h1&gt; &lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://img.shields.io/github/stars/ControlNet/tensorneko?style=flat-square&quot;&gt;    &lt;img src=&quot;https://img.shields.io/github/forks/ControlNet/tensorneko?style=flat-square&quot;&gt;    &lt;a href=&quot;https://github.com/ControlNet/tensorneko/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/ControlNet/tensorneko?style=flat-square&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/tensorneko/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/tensorneko?style=flat-square&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/tensorneko/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dm/tensorneko?style=flat-square&quot;&gt;&lt;/a&gt;    &lt;img src=&quot;https://img.shields.io/github/license/ControlNet/tensorneko?style=flat-square&quot;&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;        &lt;a href=&quot;https://www.python.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/tensorneko?style=flat-square&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://pytorch.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PyTorch-%3E%3D1.9.0-EE4C2C?style=flat-square&amp;logo=pytorch&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://www.pytorchlightning.ai/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Pytorch%20Lightning-1.7.*-792EE5?style=flat-square&amp;logo=pytorch-lightning&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;    &lt;a href=&quot;https://github.com/ControlNet/tensorneko/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/ControlNet/tensorneko/unittest.yml?branch=dev&amp;label=unittest&amp;style=flat-square&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/ControlNet/tensorneko/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/ControlNet/tensorneko/release.yml?branch=master&amp;label=release&amp;style=flat-square&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://coveralls.io/github/ControlNet/tensorneko&quot;&gt;&lt;img src=&quot;https://img.shields.io/coverallsCoverage/github/ControlNet/tensorneko?style=flat-square&quot;&gt;&lt;/a&gt;&lt;/div&gt;Tensor Neural Engine Kompanion. An util library based on PyTorch and PyTorch Lightning.## Install```shellpip install tensorneko```To use the library without PyTorch and PyTorch Lightning, you can install the util library (support Python 3.7 ~ 3.10 with limited features) with following command.```shellpip install tensorneko_util```## Neko Layers, Modules and ArchitecturesBuild an MLP with linear layers. The activation and normalization will be placed in the hidden layers.784 -&gt; 1024 -&gt; 512 -&gt; 10```pythonimport tensorneko as nekoimport torch.nnmlp = neko.module.MLP(    neurons=[784, 1024, 512, 10],    build_activation=torch.nn.ReLU,    build_normalization=[        lambda: torch.nn.BatchNorm1d(1024),        lambda: torch.nn.BatchNorm1d(512)    ],    dropout_rate=0.5)```Build a Conv2d with activation and normalization.```pythonimport tensorneko as nekoimport torch.nnconv2d = neko.layer.Conv2d(    in_channels=256,    out_channels=1024,    kernel_size=(3, 3),    padding=(1, 1),    build_activation=torch.nn.ReLU,    build_normalization=lambda: torch.nn.BatchNorm2d(256),    normalization_after_activation=False)```#### All architectures, modules and layersLayers:- `Aggregation`- `Concatenate`- `Conv`, `Conv1d`, `Conv2d`, `Conv3d`- `GaussianNoise`- `ImageAttention`, `SeqAttention`- `MaskedConv2d`, `MaskedConv2dA`, `MaskedConv2dB`- `Linear`- `Log`- `PatchEmbedding2d`- `PositionalEmbedding`- `Reshape`- `Stack`- `VectorQuantizer`Modules:- `DenseBlock`- `InceptionModule`- `MLP`- `ResidualBlock` and `ResidualModule`- `AttentionModule`, `TransformerEncoderBlock` and `TransformerEncoder`- `GatedConv`Architectures:- `AutoEncoder`- `GAN`- `WGAN`- `VQVAE`## Neko modulesAll `tensorneko.layer` and `tensorneko.module` are `NekoModule`. They can be used in [fn.py](https://github.com/kachayev/fn.py) pipe operation.```pythonfrom tensorneko.layer import Linearfrom torch.nn import ReLUimport torchlinear0 = Linear(16, 128, build_activation=ReLU)linear1 = Linear(128, 1)f = linear0 &gt;&gt; linear1print(f(torch.rand(16)).shape)# torch.Size([1])```## Neko IOEasily load and save different modal data.```pythonimport tensorneko as nekofrom tensorneko.io import json_datafrom typing import List# read video (Temporal, Channel, Height, Width)video_tensor, audio_tensor, video_info = neko.io.read.video(&quot;path/to/video.mp4&quot;)# write videoneko.io.write.video(&quot;path/to/video.mp4&quot;,     video_tensor, video_info.video_fps,    audio_tensor, video_info.audio_fps)# read audio (Channel, Temporal)audio_tensor, sample_rate = neko.io.read.audio(&quot;path/to/audio.wav&quot;)# write audioneko.io.write.audio(&quot;path/to/audio.wav&quot;, audio_tensor, sample_rate)# read image (Channel, Height, Width) with float value in range [0, 1]image_tensor = neko.io.read.image(&quot;path/to/image.png&quot;)# write imageneko.io.write.image(&quot;path/to/image.png&quot;, image_tensor)neko.io.write.image(&quot;path/to/image.jpg&quot;, image_tensor)# read plain texttext_string = neko.io.read.text(&quot;path/to/text.txt&quot;)# write plain textneko.io.write.text(&quot;path/to/text.txt&quot;, text_string)# read json as python dict or listjson_dict = neko.io.read.json(&quot;path/to/json.json&quot;)# read json as an object@json_dataclass JsonData:    x: int    y: intjson_obj: List[JsonData] = neko.io.read.json(&quot;path/to/json.json&quot;, cls=List[JsonData])# write json from python dict/list or json_data decorated objectneko.io.write.json(&quot;path/to/json.json&quot;, json_dict)neko.io.write.json(&quot;path/to/json.json&quot;, json_obj)```Besides, the read/write for `mat` and `pickle` files is also supported.## Neko preprocessing```pythonimport tensorneko as neko# A video tensor with (120, 3, 720, 1280)video = neko.io.read.video(&quot;example/video.mp4&quot;).video# Get a resized tensor with (120, 3, 256, 256)resized_video = neko.preprocess.resize_video(video, (256, 256))```#### All preprocessing utils- `resize_video`- `resize_image`- `padding_video`- `padding_audio`- `crop_with_padding`- `frames2video`if `ffmpeg` is available, you can use below ffmpeg wrappers.- `video2frames`- `merge_video_audio`- `resample_video_fps`- `mp32wav`## Neko Visualization### Variable Web WatcherStart a web server to watch the variable status when the program (e.g. training, inference, data preprocessing) is running.```pythonimport timefrom tensorneko.visualization.watcher import *data_list = ... # a list of datadef preprocessing(d): ...# initialize the componentspb = ProgressBar(&quot;Processing&quot;, total=len(data_list))logger = Logger(&quot;Log message&quot;)var = Variable(&quot;Some Value&quot;, 0)line_chart = LineChart(&quot;Line Chart&quot;, x_label=&quot;x&quot;, y_label=&quot;y&quot;)view = View(&quot;Data preprocessing&quot;).add_all()t0 = time.time()# open server when the code block in running.with Server(view, port=8000):    for i, data in enumerate(data_list):        preprocessing(data) # do some processing here                x = time.time() - t0  # time since the start of the program        y = i # processed number of data        line_chart.add(x, y)  # add to the line chart        logger.log(&quot;Some messages&quot;)  # log messages to the server        var.value = ...  # keep tracking a variable        pb.add(1)  # update the progress bar by add 1```When the script is running, go to `127.0.0.1:8000` to keep tracking the status.### Tensorboard ServerSimply run tensorboard server in Python script.```pythonimport tensorneko as nekowith neko.visualization.tensorboard.Server(port=6006):    trainer.fit(model, dm)```### Matplotlib wrappersDisplay an image of (C, H, W) shape by `plt.imshow` wrapper.```pythonimport tensorneko as nekoimport matplotlib.pyplot as pltimage_tensor = ...  # an image tensor with shape (C, H, W)neko.visualization.matplotlib.imshow(image_tensor)plt.show()```### Predefined colorsSeveral aesthetic colors are predefined.```pythonimport tensorneko as nekoimport matplotlib.pyplot as plt# use with matplotlibplt.plot(..., color=neko.visualization.Colors.RED)# the palette for seaborn is also availablefrom tensorneko_util.visualization.seaborn import paletteimport seaborn as snssns.set_palette(palette)```## Neko ModelBuild and train a simple model for classifying MNIST with MLP.```pythonfrom typing import Optional, Union, Sequence, Dict, Listimport torch.nnfrom torch import Tensorfrom torch.optim import Adamfrom torchmetrics import Accuracyfrom pytorch_lightning.callbacks import ModelCheckpointimport tensorneko as nekofrom tensorneko.util import get_activation, get_lossclass MnistClassifier(neko.NekoModel):    def __init__(self, name: str, mlp_neurons: List[int], activation: str, dropout_rate: float, loss: str,        learning_rate: float, weight_decay: float    ):        super().__init__(name)        self.weight_decay = weight_decay        self.learning_rate = learning_rate        self.flatten = torch.nn.Flatten()        self.mlp = neko.module.MLP(            neurons=mlp_neurons,            build_activation=get_activation(activation),            dropout_rate=dropout_rate        )        self.loss_func = get_loss(loss)()        self.acc_func = Accuracy()    def forward(self, x):        # (batch, 28, 28)        x = self.flatten(x)        # (batch, 768)        x = self.mlp(x)        # (batch, 10)        return x    def training_step(self, batch: Optional[Union[Tensor, Sequence[Tensor]]] = None, batch_idx: Optional[int] = None,        optimizer_idx: Optional[int] = None, hiddens: Optional[Tensor] = None    ) -&gt; Dict[str, Tensor]:        x, y = batch        logit = self(x)        prob = logit.sigmoid()        loss = self.loss_func(logit, y)        acc = self.acc_func(prob.max(dim=1)[1], y)        return {&quot;loss&quot;: loss, &quot;acc&quot;: acc}    def validation_step(self, batch: Optional[Union[Tensor, Sequence[Tensor]]] = None, batch_idx: Optional[int] = None,        dataloader_idx: Optional[int] = None    ) -&gt; Dict[str, Tensor]:        x, y = batch        logit = self(x)        prob = logit.sigmoid()        loss = self.loss_func(logit, y)        acc = self.acc_func(prob.max(dim=1)[1], y)        return {&quot;loss&quot;: loss, &quot;acc&quot;: acc}    def configure_optimizers(self):        optimizer = Adam(self.parameters(), lr=self.learning_rate, betas=(0.5, 0.9), weight_decay=self.weight_decay)        return {            &quot;optimizer&quot;: optimizer        }model = MnistClassifier(&quot;mnist_mlp_classifier&quot;, [784, 1024, 512, 10], &quot;ReLU&quot;, 0.5, &quot;CrossEntropyLoss&quot;, 1e-4, 1e-4)dm = ...  # The MNIST datamodule from PyTorch Lightningtrainer = neko.NekoTrainer(log_every_n_steps=100, gpus=1, logger=model.name, precision=32,    callbacks=[ModelCheckpoint(dirpath=&quot;./ckpt&quot;,        save_last=True, filename=model.name + &quot;-{epoch}-{val_acc:.3f}&quot;, monitor=&quot;val_acc&quot;, mode=&quot;max&quot;    )])trainer.fit(model, dm)```## Neko CallbacksSome simple but useful pytorch-lightning callbacks are provided.- `DisplayMetricsCallback`- `EarlyStoppingLR`: Early stop training when learning rate reaches threshold.## Neko Notebook HelpersHere are some helper functions to better interact with Jupyter Notebook.```pythonimport tensorneko as neko# display a videoneko.notebook.display.video(&quot;path/to/video.mp4&quot;)# display an audioneko.notebook.display.audio(&quot;path/to/audio.wav&quot;)# display a code fileneko.notebook.display.code(&quot;path/to/code.java&quot;)```## Neko Debug ToolsGet the default values from `ArgumentParser` args. It's convenient to use this in the notebook.```pythonfrom argparse import ArgumentParserfrom tensorneko.debug import get_parser_default_argsparser = ArgumentParser()parser.add_argument(&quot;integers&quot;, type=int, nargs=&quot;+&quot;, default=[1, 2, 3])parser.add_argument(&quot;--sum&quot;, dest=&quot;accumulate&quot;, action=&quot;store_const&quot;, const=sum, default=max)args = get_parser_default_args(parser)print(args.integers)  # [1, 2, 3]print(args.accumulate)  # &lt;function sum at ...&gt;```## Neko EvaluationSome metrics function for evaluation are provided.- `iou_1d`- `iou_2d`- `psnr_video`- `psnr_image`- `ssim_video`- `ssim_image`## Neko Utilities### Misc functions`__`: The arguments to pipe operator. (Inspired from [fn.py](https://github.com/kachayev/fn.py))```pythonfrom tensorneko.util import __, _result = __(20) &gt;&gt; (_ + 1) &gt;&gt; (_ * 2) &gt;&gt; __.getprint(result)# 42````Seq` and `Stream`: A collection wrapper for method chaining with concurrent supporting.```pythonfrom tensorneko.util import Seq, Stream, _from tensorneko_util.backend.parallel import ParallelType# using method chainingseq = Seq.of(1, 2, 3).map(_ + 1).filter(_ % 2 == 0).map(_ * 2).take(2).to_list()# return [4, 8]# using bit shift operator to chain the sequenceseq = Seq.of(1, 2, 3) &lt;&lt; Seq.of(2, 3, 4) &lt;&lt; [3, 4, 5]# return Seq(1, 2, 3, 2, 3, 4, 3, 4, 5)# run concurrent with `for_each` for Streamif __name__ == '__main__':    Stream.of(1, 2, 3, 4).for_each(print, progress_bar=True, parallel_type=ParallelType.PROCESS)````Option`: A monad for dealing with data.```pythonfrom tensorneko.util import return_option@return_optiondef get_data():    if some_condition:        return 1    else:        return Nonedef process_data(n: int):    if condition(n):        return n    else:        return None    data = get_data()data = data.map(process_data).get_or_else(-1)  # if the response is None, return -1````Eval`: A monad for lazy evaluation.```pythonfrom tensorneko.util import Eval@Eval.alwaysdef call_by_name_var():    return 42@Eval.laterdef call_by_need_var():    return 43@Eval.nowdef call_by_value_var():    return 44print(call_by_name_var.value)  # 42```### ReactiveThis library provides event bus based reactive tools. The API integrates the Python type annotation syntax.```python# useful decorators for default event busfrom tensorneko.util import (    subscribe, # run in the main thread    subscribe_thread, # run in a new thread    subscribe_async, # run async    subscribe_process # run in a new process)# Event base typefrom tensorneko.util import Eventclass LogEvent(Event):    def __init__(self, message: str):        self.message = message# the event argument should be annotated correctly@subscribedef log_information(event: LogEvent):    print(event.message)@subscribe_threaddef log_information_thread(event: LogEvent):    print(event.message, &quot;in another thread&quot;)if __name__ == '__main__':    # emit an event, and then the event handler will be invoked    # The sequential order is not guaranteed    LogEvent(&quot;Hello world!&quot;)    # one possible output:    # Hello world! in another thread    # Hello world!```### Multiple Dispatch`dispatch`: Multi-dispatch implementation for Python. To my knowledge, 3 popular multi-dispatch libraries still have critical limitations. [plum](https://github.com/wesselb/plum) doesn't support static methods, [mutipledispatch](https://github.com/mrocklin/multipledispatch) doesn't support Python type annotation syntax and [multimethod](https://github.com/coady/multimethod) doesn't support default argument. TensorNeko can do it all.```pythonfrom tensorneko.util import dispatchclass DispatchExample:    @staticmethod    @dispatch    def go() -&gt; None:        print(&quot;Go0&quot;)    @staticmethod    @dispatch    def go(x: int) -&gt; None:        print(&quot;Go1&quot;)    @staticmethod    @dispatch    def go(x: float, y: float = 1.0) -&gt; None:        print(&quot;Go2&quot;)@dispatchdef come(x: int) -&gt; str:    return &quot;Come1&quot;@dispatch.of(str)def come(x) -&gt; str:    return &quot;Come2&quot;```### Miscellaneous`StringGetter`: Get PyTorch class from string.```pythonimport tensorneko as nekoactivation = neko.util.get_activation(&quot;leakyRelu&quot;)()````Seed`: The universal seed for `numpy`, `torch` and Python `random`.```pythonfrom tensorneko.util import Seedfrom torch.utils.data import DataLoader# set seed to 42 for all numpy, torch and python randomSeed.set(42)# Apply seed to parallel workers of DataLoaderDataLoader(    train_dataset,    batch_size=batch_size,    num_workers=num_workers,    worker_init_fn=Seed.get_loader_worker_init(),    generator=Seed.get_torch_generator())````Timer`: A timer for measuring the time.```pythonfrom tensorneko.util import Timerimport time# use as a context manager with single timewith Timer():    time.sleep(1)# use as a context manager with multiple segmentswith Timer() as t:    time.sleep(1)    t.time(&quot;sleep A&quot;)    time.sleep(1)    t.time(&quot;sleep B&quot;)    time.sleep(1)# use as a decorator@Timer()def f():    time.sleep(1)    print(&quot;f&quot;)````Singleton`: A decorator to make a class as a singleton. Inspired from Scala/Kotlin.```pythonfrom tensorneko.util import Singleton@Singletonclass MyObject:    def __init__(self):        self.value = 0    def add(self, value):        self.value += value        return self.valueprint(MyObject.value)  # 0MyObject.add(1)print(MyObject.value)  # 1```Besides, many miscellaneous functions are also provided.Functions list (in `tensorneko_util`):- `generate_inf_seq`- `compose`- `listdir`- `with_printed`- `ifelse`- `dict_add`- `as_list`- `identity`- `list_to_dict`- `get_tensorneko_util_path`Functions list (in `tensorneko`):- `reduce_dict_by`- `summarize_dict_by`- `with_printed_shape`- `is_bad_num`- `count_parameters`</longdescription>
</pkgmetadata>