<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://raw.githubusercontent.com/dbt-labs/dbt/ec7dee39f793aa4f7dd3dae37282cc87664813e4/etc/dbt-logo-full.svg&quot; alt=&quot;dbt logo&quot; width=&quot;500&quot;/&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;  &lt;a href=&quot;https://github.com/dbt-labs/dbt-redshift/actions/workflows/main.yml&quot;&gt;    &lt;img src=&quot;https://github.com/dbt-labs/dbt-redshift/actions/workflows/main.yml/badge.svg?event=push&quot; alt=&quot;Unit Tests Badge&quot;/&gt;  &lt;/a&gt;  &lt;a href=&quot;https://github.com/dbt-labs/dbt-redshift/actions/workflows/integration.yml&quot;&gt;    &lt;img src=&quot;https://github.com/dbt-labs/dbt-redshift/actions/workflows/integration.yml/badge.svg?event=push&quot; alt=&quot;Integration Tests Badge&quot;/&gt;  &lt;/a&gt;&lt;/p&gt;**[dbt](https://www.getdbt.com/)** enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.dbt is the T in ELT. Organize, cleanse, denormalize, filter, rename, and pre-aggregate the raw data in your warehouse so that it's ready for analysis.## dbt-greenplumThe `dbt-greenplum` package contains the code enabling dbt to work with Greenplum. This adapter based on [postgres-adapter](https://github.com/dbt-labs/dbt-core/blob/main/plugins/postgres/dbt/include/postgres/profile_template.yml) with a bit difference for a greenplum specific features## InstallationEasiest way to start use dbt-greenplum is to install it using pip`pip install dbt-greenplum==&lt;version&gt;`Where `&lt;version&gt;` is same as your dbt versionAvailable versions: - 0.19.2 - 1.0.4 - 1.2.0 - 1.4.0 - 1.5.0## Supported FeaturesYou can specify following settings: - Storage type   - heap   - appendoptimized - Distribution   - `distributed randomly` by defaut   - `distributed by (column, [ ... ] )` by setting up `distributed_by` parameter in the model config   - `distributed replicated` by setting up `distributed_replicated=true` parameter in the model config - Table orientation   - `orientation=colum` by default   - `orientation=row` by setting up `orientation` parameter in `row` in the model config - Compress type, level and blocksize with default values   ```bash    compresstype=ZLIB,    compresslevel=1,    blocksize=32768   ```     You can also specify `blocksize`, `compresstype`, `compresslevel` in the model config - `appendoptimized` preference by default is `true`, also you can override it by setting up `appendoptimized` field in the model config - Partitions (see &quot;Partition&quot; chapter below)### Heap table exampleTo create heap table set `appendoptimized` parameter value to `false` ```SQL{{   config(      ...      materialized='table',      appendoptimized=false      ...   )}}select 1 as &quot;id&quot;```will produce following SQL code```SQLcreate  table &quot;&lt;db_name&gt;&quot;.&quot;&lt;schema_name&gt;&quot;.&quot;&lt;table_name&gt;&quot;with (   appendoptimized=false) as (   select 1 as &quot;id&quot;)DISTRIBUTED RANDOMLY;```### Appendoptimized table exampleYou can use `appendopimized` or `appendonly`(legacy) to create appendoptimized tableSuch model definition```SQL{{    config(        materialized='table',        distributed_by='id',        appendoptimized=true,        orientation='column',        compresstype='ZLIB',        compresslevel=1,        blocksize=32768    )}}with source_data as (    select 1 as id    union all    select null as id)select *from source_data```will produce following sql code```SQLcreate  table &quot;dvault&quot;.&quot;dv&quot;.&quot;my_first_dbt_model__dbt_tmp&quot;with (    appendoptimized=true,    blocksize=32768,    orientation=column,    compresstype=ZLIB,    compresslevel=1)as (  with source_data as (      select 1 as id      union all      select null as id    )  select *  from source_data)  distributed by (id);  alter table &quot;dvault&quot;.&quot;dv&quot;.&quot;my_first_dbt_model__dbt_tmp&quot; rename to &quot;my_first_dbt_model&quot;;```### PartitionsGreenplum does not support partitions with `create table as` [construction](https://gpdb.docs.pivotal.io/6-9/ref_guide/sql_commands/CREATE_TABLE_AS.html), so you need to build model in two steps - create table schema - insert dataTo implement partitions into you dbt-model you need to specify on of the following config parameters: - `fields_string` - definition of columns name, type and constraints - one of following way to configure partitions   - `raw_partition` by default   - `partition_type`, `partition_column`, `partition_spec`   - `partition_type`, `partition_column`, `partition_start`, `partition_end`, `partition_every`   - `partition_type`, `partition_column`, `partition_values` - `default_partition_name` - name of default partition 'other' by defaultLet consider examples of definition model with partitions - using `raw_partition` parameter   ```SQL   {% set fields_string %}        id int4 null,        incomingdate timestamp NULL   {% endset %}   {% set raw_partition %}       PARTITION BY RANGE (incomingdate)       (           START ('2021-01-01'::timestamp) INCLUSIVE           END ('2023-01-01'::timestamp) EXCLUSIVE           EVERY (INTERVAL '1 day'),           DEFAULT PARTITION extra       );   {% endset %}   {{       config(           materialized='table',           distributed_by='id',           appendoptimized=true,           orientation='column',           compresstype='ZLIB',           compresslevel=1,           blocksize=32768,           fields_string=fields_string,           raw_partition=raw_partition,           default_partition_name='other_data'       )   }}      with source_data as (          select           1 as id,           '2022-02-22'::timestamp as incomingdate       union all       select           null as id,           '2022-02-25'::timestamp as incomingdate   )   select *   from source_data   ```   will produce following sql code   ```SQL   create table if not exists &quot;database&quot;.&quot;schema&quot;.&quot;my_first_dbt_model__dbt_tmp&quot; (       id int4 null,       incomingdate timestamp NULL   )   with (       appendoptimized=true,       blocksize=32768,       orientation=column,       compresstype=ZLIB,       compresslevel=1   )   DISTRIBUTED BY (id)   PARTITION BY RANGE (incomingdate)   (       START ('2021-01-01'::timestamp) INCLUSIVE       END ('2023-01-01'::timestamp) EXCLUSIVE       EVERY (INTERVAL '1 day'),       DEFAULT PARTITION extra   );      insert into &quot;database&quot;.&quot;schema&quot;.&quot;my_first_dbt_model__dbt_tmp&quot; (       with source_data as (              select               1 as id,               '2022-02-22'::timestamp as incomingdate           union all           select               null as id,               '2022-02-25'::timestamp as incomingdate       )       select *       from source_data   );   alter table &quot;dvault&quot;.&quot;dv&quot;.&quot;my_first_dbt_model&quot; rename to &quot;my_first_dbt_model__dbt_backup&quot;;   drop table if exists &quot;dvault&quot;.&quot;dv&quot;.&quot;my_first_dbt_model__dbt_backup&quot; cascade;   alter table &quot;database&quot;.&quot;schema&quot;.&quot;my_first_dbt_model__dbt_tmp&quot; rename to &quot;my_first_dbt_model&quot;;   ``` - Same result you can get using `partition_type`, `partition_column`, `partition_spec` parameters   ```SQL   {% set fields_string %}       id int4 null,       incomingdate timestamp NULL   {% endset %}   {%- set partition_type = 'RANGE' -%}   {%- set partition_column = 'incomingdate' -%}   {% set partition_spec %}       START ('2021-01-01'::timestamp) INCLUSIVE       END ('2023-01-01'::timestamp) EXCLUSIVE       EVERY (INTERVAL '1 day'),       DEFAULT PARTITION extra   {% endset %}      {{       config(           materialized='table',           distributed_by='id',           appendoptimized=true,           orientation='column',           compresstype='ZLIB',           compresslevel=1,           blocksize=32768,           fields_string=fields_string,           partition_type=partition_type,           partition_column=partition_column,           partition_spec=partition_spec,           default_partition_name='other_data'       )   }}      with source_data as (          select           1 as id,           '2022-02-22'::timestamp as incomingdate       union all       select           null as id,           '2022-02-25'::timestamp as incomingdate   )   select *   from source_data   ``` - also, you can use third way   ```SQL   {% set fields_string %}       id int4 null,       incomingdate timestamp NULL   {% endset %}         {%- set partition_type = 'RANGE' -%}   {%- set partition_column = 'incomingdate' -%}   {%- set partition_start = &quot;'2021-01-01'::timestamp&quot; -%}   {%- set partition_end = &quot;'2022-01-01'::timestamp&quot; -%}   {%- set partition_every = '1 day' -%}         {{       config(           materialized='table',           distributed_by='id',           appendoptimized=true,           orientation='column',           compresstype='ZLIB',           compresslevel=1,           blocksize=32768,           fields_string=fields_string,           partition_type=partition_type,           partition_column=partition_column,           partition_start=partition_start,           partition_end=partition_end,           partition_every=partition_every,           default_partition_name='other_data'       )   }}      with source_data as (          select           1 as id,           '2022-02-22'::timestamp as incomingdate       union all       select           null as id,           '2022-02-25'::timestamp as incomingdate   )   select *   from source_data   ``` - example of partition_type `LIST` is coming soon#### Table partition hintsToo check generate sql script use `-d` option:`dbt -d run &lt;...&gt; -m &lt;models&gt;`If you want implement complex partition logic with subpartition or something else use `raw_partition` parameter## Getting started- [Install dbt](https://docs.getdbt.com/docs/installation)- Read the [introduction](https://docs.getdbt.com/docs/introduction/) and [viewpoint](https://docs.getdbt.com/docs/about/viewpoint/)## Join the dbt Community- Be part of the conversation in the [dbt Community Slack](http://community.getdbt.com/)- Read more on the [dbt Community Discourse](https://discourse.getdbt.com)## Reporting bugs and contributing code- Want to report a bug or request a feature? Let us know on [Slack](http://community.getdbt.com/), or open [an issue](https://github.com/markporoshin/dbt-greenplum/issues/new)- Want to help us build dbt? Check out the [Contributing Guide](https://github.com/dbt-labs/dbt/blob/HEAD/CONTRIBUTING.md)## Code of ConductEveryone interacting in the dbt project's codebases, issue trackers, chat rooms, and mailing lists is expected to follow the [dbt Code of Conduct](https://community.getdbt.com/code-of-conduct).</longdescription>
</pkgmetadata>