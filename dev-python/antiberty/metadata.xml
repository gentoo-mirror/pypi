<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># AntiBERTyOfficial repository for AntiBERTy, an antibody-specific transformer language model pre-trained on 558M natural antibody sequences, as described in [Deciphering antibody affinity maturation with language models and weakly supervised learning](https://arxiv.org/abs/2112.07782).## SetupTo use AntiBERTy, install via pip:```bashpip install antiberty```Alternatively, you can clone this repository and install the package locally:```bash$ git clone git@github.com:jeffreyruffolo/AntiBERTy.git $ pip install AntiBERTy```## Usage### EmbeddingsTo use AntiBERTy to generate sequence embeddings, use the `embed` function. The output is a list of embedding tensors, where each tensor is the embedding for the corresponding sequence. Each embedding has dimension `[(Length + 2) x 512]`.```pythonfrom antiberty import AntiBERTyRunnerantiberty = AntiBERTyRunner()sequences = [    &quot;EVQLVQSGPEVKKPGTSVKVSCKASGFTFMSSAVQWVRQARGQRLEWIGWIVIGSGNTNYAQKFQERVTITRDMSTSTAYMELSSLRSEDTAVYYCAAPYCSSISCNDGFDIWGQGTMVTVS&quot;,    &quot;DVVMTQTPFSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPGQSPKLLIYKVSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGVYFCSQSTHVPYTFGGGTKLEIK&quot;,]embeddings = antiberty.embed(sequences)```To access the attention matrices, pass the `return_attention` flag to the `embed` function. The output is a list of attention matrices, where each matrix is the attention matrix for the corresponding sequence. Each attention matrix has dimension `[Layer x Heads x (Length + 2) x (Length + 2)]`.```pythonfrom antiberty import AntiBERTyRunnerantiberty = AntiBERTyRunner()sequences = [    &quot;EVQLVQSGPEVKKPGTSVKVSCKASGFTFMSSAVQWVRQARGQRLEWIGWIVIGSGNTNYAQKFQERVTITRDMSTSTAYMELSSLRSEDTAVYYCAAPYCSSISCNDGFDIWGQGTMVTVS&quot;,    &quot;DVVMTQTPFSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPGQSPKLLIYKVSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGVYFCSQSTHVPYTFGGGTKLEIK&quot;,]embeddings, attentions = antiberty.embed(sequences, return_attention=True)```The `embed` function can also be used with masked sequences. Masked residues should be indicated with underscores.### ClassificationTo use AntiBERTy to predict the species and chain type of sequences, use the `classify` function. The output is two lists of classifications for each sequences.```pythonfrom antiberty import AntiBERTyRunnerantiberty = AntiBERTyRunner()sequences = [    &quot;EVQLVQSGPEVKKPGTSVKVSCKASGFTFMSSAVQWVRQARGQRLEWIGWIVIGSGNTNYAQKFQERVTITRDMSTSTAYMELSSLRSEDTAVYYCAAPYCSSISCNDGFDIWGQGTMVTVS&quot;,    &quot;DVVMTQTPFSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPGQSPKLLIYKVSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGVYFCSQSTHVPYTFGGGTKLEIK&quot;,]species_preds, chain_preds = antiberty.classify(sequences)```The `classify` function can also be used with masked sequences. Masked residues should be indicated with underscores.### Mask predictionTo use AntiBERTy to predict the identity of masked residues, use the `fill_masks` function. Masked residues should be indicated with underscores. The output is a list of filled sequences, corresponding to the input masked sequences.```pythonfrom antiberty import AntiBERTyRunnerantiberty = AntiBERTyRunner()sequences = [    &quot;____VQSGPEVKKPGTSVKVSCKASGFTFMSSAVQWVRQARGQRLEWIGWIVIGSGN_NYAQKFQERVTITRDM__STAYMELSSLRSEDTAVYYCAAPYCSSISCNDGFD____GTMVTVS&quot;,    &quot;DVVMTQTPFSLPV__GDQASISCRSSQSLVHSNGNTY_HWYLQKPGQSPKLLIYKVSNRFSGVPDRFSG_GSGTDFTLKISRVEAEDLGVYFCSQSTHVPYTFGG__KLEIK&quot;,]filled_sequences = antiberty.fill_masks(sequences)```## Citing this work```bibtex@article{ruffolo2021deciphering,    title = {Deciphering antibody affinity maturation with language models and weakly supervised learning},    author = {Ruffolo, Jeffrey A and Gray, Jeffrey J and Sulam, Jeremias},    journal = {arXiv preprint arXiv:2112.07782},    year= {2021}}```</longdescription>
</pkgmetadata>