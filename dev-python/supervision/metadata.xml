<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;  &lt;p&gt;    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;_blank&quot;&gt;      &lt;img        width=&quot;100%&quot;        src=&quot;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&quot;      &gt;    &lt;/a&gt;  &lt;/p&gt;  &lt;br&gt;[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb)&lt;/div&gt;## üëã hello**We write your reusable computer vision tools.** Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù## üíª installPip install the supervision package in a[**3.11&gt;=Python&gt;=3.7**](https://www.python.org/) environment.```bashpip install supervision```&lt;details close&gt;&lt;summary&gt;üëâ install from source&lt;/summary&gt;```bash# clone repository and navigate to root directorygit clone https://github.com/roboflow/supervision.gitcd supervision# setup python environment and activate itpython3 -m venv venvsource venv/bin/activate# installpip install -e &quot;.[dev]&quot;```&lt;/details&gt;## üî• quickstart### [detections processing](https://roboflow.github.io/supervision/detection/core/)```python&gt;&gt;&gt; import supervision as sv&gt;&gt;&gt; from ultralytics import YOLO&gt;&gt;&gt; model = YOLO('yolov8s.pt')&gt;&gt;&gt; result = model(IMAGE)[0]&gt;&gt;&gt; detections = sv.Detections.from_yolov8(result)&gt;&gt;&gt; len(detections)5```&lt;details close&gt;&lt;summary&gt;üëâ more detections utils&lt;/summary&gt;  - Easily switch inference pipeline between supported object detection / instance segmentation models      ```python    &gt;&gt;&gt; import supervision as sv    &gt;&gt;&gt; from segment_anything import sam_model_registry, SamAutomaticMaskGenerator    &gt;&gt;&gt; sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)    &gt;&gt;&gt; mask_generator = SamAutomaticMaskGenerator(sam)    &gt;&gt;&gt; sam_result = mask_generator.generate(IMAGE)    &gt;&gt;&gt; detections = sv.Detections.from_sam(sam_result=sam_result)    ``` - [Advanced filtering](https://roboflow.github.io/supervision/quickstart/detections/)      ```python    &gt;&gt;&gt; detections = detections[detections.class_id == 0]    &gt;&gt;&gt; detections = detections[detections.confidence &gt; 0.5]    &gt;&gt;&gt; detections = detections[detections.area &gt; 1000]    ```  - Image annotation      ```python    &gt;&gt;&gt; import supervision as sv    &gt;&gt;&gt; box_annotator = sv.BoxAnnotator()    &gt;&gt;&gt; annotated_frame = box_annotator.annotate(    ...     scene=IMAGE,    ...     detections=detections    ... )    ```  &lt;/details&gt;### [datasets processing](https://roboflow.github.io/supervision/dataset/core/)```python&gt;&gt;&gt; import supervision as sv&gt;&gt;&gt; dataset = sv.DetectionDataset.from_yolo(...     images_directory_path='...',...     annotations_directory_path='...',...     data_yaml_path='...'... )&gt;&gt;&gt; dataset.classes['dog', 'person']&gt;&gt;&gt; len(dataset)1000```&lt;details close&gt;&lt;summary&gt;üëâ more dataset utils&lt;/summary&gt;- Load object detection / instance segmentation datasets in one of supported formats    ```python    &gt;&gt;&gt; dataset = sv.DetectionDataset.from_yolo(    ...     images_directory_path='...',    ...     annotations_directory_path='...',    ...     data_yaml_path='...'    ... )    &gt;&gt;&gt; dataset = sv.DetectionDataset.from_pascal_voc(    ...     images_directory_path='...',    ...     annotations_directory_path='...'    ... )    ```  - Loop over dataset entries    ```python    &gt;&gt;&gt; for name, image, labels in dataset:    ...     print(labels.xyxy)    array([[404.      , 719.      , 538.      , 884.5     ],           [155.      , 497.      , 404.      , 833.5     ],           [ 20.154999, 347.825   , 416.125   , 915.895   ]], dtype=float32)    ```  - Split dataset for training, testing and validation      ```python    &gt;&gt;&gt; train_dataset, test_dataset = dataset.split(split_ratio=0.7)    &gt;&gt;&gt; test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)      &gt;&gt;&gt; len(train_dataset), len(test_dataset), len(valid_dataset)    (700, 150, 150)    ```  - Save object detection / instance segmentation datasets in one of supported formats      ```python    &gt;&gt;&gt; dataset.as_yolo(    ...     images_directory_path='...',    ...     annotations_directory_path='...',    ...     data_yaml_path='...'    ... )    &gt;&gt;&gt; dataset.as_pascal_voc(    ...     images_directory_path='...',    ...     annotations_directory_path='...'    ... )    ```  - Convert labels between suppoted formats      ```python    &gt;&gt;&gt; sv.DetectionDataset.from_yolo(    ...     images_directory_path='...',    ...     annotations_directory_path='...',    ...     data_yaml_path='...'    ... ).as_pascal_voc(    ...     images_directory_path='...',    ...     annotations_directory_path='...'    ... )    ```  - Load classification datasets in one of supported formats    ```python    &gt;&gt;&gt; cs = sv.ClassificationDataset.from_folder_structure(    ...     root_directory_path='...'    ... )    ```- Save classification datasets in one of supported formats    ```python    &gt;&gt;&gt; cs.as_folder_structure(    ...     root_directory_path='...'    ... )    ```&lt;/details&gt;## üé¨ tutorials&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;https://youtu.be/oEQYStnF2l8&quot; title=&quot;Accelerate Image Annotation with SAM and Grounding DINO&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/ae1ca38e-40b7-4b35-8582-e8ea5de3806e&quot; alt=&quot;Accelerate Image Annotation with SAM and Grounding DINO&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://youtu.be/oEQYStnF2l8&quot; title=&quot;Accelerate Image Annotation with SAM and Grounding DINO&quot;&gt;&lt;strong&gt;Accelerate Image Annotation with SAM and Grounding DINO&lt;/strong&gt;&lt;/a&gt;&lt;div&gt;&lt;strong&gt;Created: 20 Apr 2023&lt;/strong&gt; | &lt;strong&gt;Updated: 20 Apr 2023&lt;/strong&gt;&lt;/div&gt;&lt;br/&gt; Discover how to speed up your image annotation process using Grounding DINO and Segment Anything Model (SAM). Learn how to convert object detection datasets into instance segmentation datasets, and see the potential of using these models to automatically annotate your datasets for real-time detectors like YOLOv8... &lt;/p&gt; &lt;br/&gt; &lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;https://youtu.be/oEQYStnF2l8&quot; title=&quot;SAM - Segment Anything Model by Meta AI: Complete Guide&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/6913ff11-53c6-4341-8d90-eaff3023c3fd&quot; alt=&quot;SAM - Segment Anything Model by Meta AI: Complete Guide&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://youtu.be/oEQYStnF2l8&quot; title=&quot;SAM - Segment Anything Model by Meta AI: Complete Guide&quot;&gt;&lt;strong&gt;SAM - Segment Anything Model by Meta AI: Complete Guide&lt;/strong&gt;&lt;/a&gt;&lt;div&gt;&lt;strong&gt;Created: 11 Apr 2023&lt;/strong&gt; | &lt;strong&gt;Updated: 11 Apr 2023&lt;/strong&gt;&lt;/div&gt;&lt;br/&gt; Discover the incredible potential of Meta AI's Segment Anything Model (SAM)! We dive into SAM, an efficient and promptable model for image segmentation, which has revolutionized computer vision tasks. With over 1 billion masks on 11M licensed and privacy-respecting images, SAM's zero-shot performance is often competitive with or even superior to prior fully supervised results... &lt;/p&gt;## üìö documentationCurious how Supervision can help you solve problems on your project? Visit our [documentation](https://roboflow.github.io/supervision) page!## üíú built with supervisionYou built something cool using supervision? [Let us know!](https://github.com/roboflow/supervision/discussions/categories/built-with-supervision)## üèÜ contributionWe love your input! Please see our [contributing guide](https://github.com/roboflow/supervision/blob/main/CONTRIBUTING.md) to get started. Thank you üôè to all our contributors!&lt;br&gt;&lt;div align=&quot;center&quot;&gt;  &lt;div align=&quot;center&quot;&gt;      &lt;a href=&quot;https://youtube.com/roboflow&quot;&gt;          &lt;img            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634652&quot;            width=&quot;3%&quot;          /&gt;      &lt;/a&gt;      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;      &lt;a href=&quot;https://roboflow.com&quot;&gt;          &lt;img            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949746649&quot;            width=&quot;3%&quot;          /&gt;      &lt;/a&gt;      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;      &lt;a href=&quot;https://www.linkedin.com/company/roboflow-ai/&quot;&gt;          &lt;img            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633691&quot;            width=&quot;3%&quot;          /&gt;      &lt;/a&gt;      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;      &lt;a href=&quot;https://docs.roboflow.com&quot;&gt;          &lt;img            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634511&quot;            width=&quot;3%&quot;          /&gt;      &lt;/a&gt;      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;      &lt;a href=&quot;https://disuss.roboflow.com&quot;&gt;          &lt;img            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633584&quot;            width=&quot;3%&quot;          /&gt;      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;      &lt;a href=&quot;https://blog.roboflow.com&quot;&gt;          &lt;img            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633605&quot;            width=&quot;3%&quot;          /&gt;      &lt;/a&gt;      &lt;/a&gt;  &lt;/div&gt;&lt;/div&gt;</longdescription>
</pkgmetadata>