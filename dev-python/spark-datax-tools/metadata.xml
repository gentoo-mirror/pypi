<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># spark_datax_tools[![Github License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)[![Updates](https://pyup.io/repos/github/woctezuma/google-colab-transfer/shield.svg)](pyup)[![Python 3](https://pyup.io/repos/github/woctezuma/google-colab-transfer/python-3-shield.svg)](pyup)[![Code coverage](https://codecov.io/gh/woctezuma/google-colab-transfer/branch/master/graph/badge.svg)](codecov)spark_datax_tools is a Python library that implements for dataX schemas## InstallationThe code is packaged for PyPI, so that the installation consists in running:```shpip install spark-datax-tools ```## Usagewrapper take DataX```shNomenclature Datax================================table_name = &quot;t_pmfi_lcl_suppliers_purchases&quot;origen = &quot;host&quot;destination = &quot;hdfs&quot;datax_generated_nomenclature(table_name=table_name,                              origen=origen,                              destination=destination,                              output=True)List of adaptaders================================datax_list_adapters()Generated Ticket Adapter============================================================adapter_id = &quot;ADAPTER_HDFS_OUTSTAGING&quot;parameter = {&quot;uuaa&quot;:&quot;na8z&quot;}datax_generated_ticket_adapter(adapter_id=adapter_id,                                parameter=parameter,                                is_dev=True)                                                                                             Generated Ticket Transfer============================================================folder=&quot;CR-PEMFIMEN-T02&quot;job_name=&quot;PMFITP4012&quot;crq=&quot;CRQ100000&quot;periodicity=&quot;mensual&quot;hour=&quot;10AM&quot;weight=&quot;50MB&quot;origen=&quot;host&quot;destination=&quot;hdfs&quot;datax_generated_ticket_transfer(    folder=folder,        job_name=job_name,        crq=crq,    periodicity=periodicity,        hour=hour,        weight=weight,        table_name=table_name,        origen=origen,    destination=destination,    is_dev=True)                                                                   Generated Schema JSON Artifactory============================================================path_json = &quot;lclsupplierspurchases.output.schema&quot;is_schema_origen_in = Trueschema_type = &quot;host&quot;convert_string = Falsedatax_generated_schema_artifactory(     path_json=path_json,    is_schema_origen_in=schema_type,    schema_type=schema_type,    convert_string=convert_string)                    Generated Schema Json Datum============================================================spark = SparkSession.builder.master(&quot;local[*]&quot;).appName(&quot;SparkAPP&quot;).getOrCreate()path=&quot;fields_pe_datum2.csv&quot;table_name=&quot;t_pmfi_lcl_suppliers_purchases&quot;origen=&quot;host&quot;destination=&quot;hdfs&quot;storage_zone=&quot;master&quot;datax_generated_schema_datum(    spark=spark,    path=path,    table_name=table_name,    origen=origen,    destination=destination,    storage_zone=storage_zone,    convert_string=False)  ```## License[Apache License 2.0](https://www.dropbox.com/s/8t6xtgk06o3ij61/LICENSE?dl=0).## New features v1.0 ## BugFix- choco install visualcpp-build-tools## Reference - Jonathan Quiza [github](https://github.com/jonaqp). - Jonathan Quiza [RumiMLSpark](http://rumi-ml.herokuapp.com/). - Jonathan Quiza [linkedin](https://www.linkedin.com/in/jonaqp/).</longdescription>
</pkgmetadata>