<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![PyPi version](https://badgen.net/pypi/v/proxiflow/)](https://pypi.org/project/proxiflow)[![Documentation Status](https://readthedocs.org/projects/proxiflow/badge/?version=latest)](https://proxiflow.readthedocs.io/en/latest/?badge=latest)[![PyPI download month](https://img.shields.io/pypi/dm/proxiflow.svg)](https://pypi.python.org/pypi/proxiflow/)[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/tomesm/proxiflow/graphs/commit-activity)[![PyPI license](https://img.shields.io/pypi/l/proxiflow.svg)](https://pypi.python.org/pypi/proxiflow/)[![tests](https://github.com/tomesm/proxiflow/actions/workflows/tests.yml/badge.svg)](https://github.com/tomesm/proxiflow/actions/workflows/tests.yml)# ProxiFlowProxiFlow is a data preprocessig tool for machine learning that performsdata cleaning, normalization, and feature engineering.The biggest advantage if this library (which is basically a wrapper over [polars](https://github.com/pola-rs/polars) data frame) is that it is configurable via YAML configuration file which makes it suitable for MLOps pipelines or for building API requests over it.## DocumentationRead the full documentation [here](http://proxiflow.readthedocs.io/).## UsageTo use ProxiFlow, install it via pip:``` bashpip install proxiflow```You can then call it from the command line:``` bashproxiflow --config-file myconfig.yaml --input-file mydata.csv --output-file cleaned_data.csv```Here\'s an example of a YAML configuration file:``` yamlinput_format: csvoutput_format: csvdata_cleaning: #mandatory  # NOTE: Not handling missing values can cause errors during data normalization  handle_missing_values:    drop: false    mean: true # Only Int and Float columns are handled     # mode: true # Turned off for now.   handle_outliers: true # Only Float columns are handled  remove_duplicates: truedata_normalization: # mandatory  min_max: #mandatory but values are not mandatory. It can be left empty    # Specify columns:    - Age # not mandatory  z_score:     - Price   log:    - Floorsfeature_engineering:  one_hot_encoding: # mandatory    - Bedrooms      # not mandatory  feature_scaling:  # mandatory    degree: 2       # not mandatory. It specifies the polynominal degree    columns:        # not mandatory      - Floors      # not mandatory```The above configuration specifies that duplicate rows should be removedand missing values should be dropped.## APIProxiFlow can also be used as a Python library. Here\'s an example:``` pythonimport polars as plfrom proxiflow.config import Configfrom proxiflow.core import Cleaner# Load the datadf = pl.read_csv(&quot;mydata.csv&quot;)# Load the configurationconfig = Config(&quot;myconfig.yaml&quot;)# Clean the datacleaner = Cleaner(config)cleaned_data = cleaner.clean_data(data)# Perform data normalizationnormalizer = Normalizer(config)normalized_data = normalizer.normalize(cleaned_data)# Perform feature engineeringengineer = Engineer(config)engineered_data = engineer.execute(normalized_data)# Write the output dataengineered_data.write_csv(&quot;cleaned_data.csv&quot;)```## Log-   \[x\] Data cleaning-   \[x\] Data normalization-   \[x\] Feature engineering</longdescription>
</pkgmetadata>