<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># ASRP: Automatic Speech Recognition Preprocessing UtilityASRP is a python package that offers a set of tools to preprocess and evaluate ASR (Automatic Speech Recognition) text.The package also provides a speech-to-text transcription tool and a text-to-speech conversion tool. The code isopen-source and can be installed using pip.Key Features- [Preprocess ASR text with ease](#preprocess)- [Evaluate ASR output quality](#Evaluation)- [Transcribe speech to Hubert code](#speech-to-discrete-unit)- [Convert unit code to speech](#discrete-unit-to-speech)- [Enhance speech quality with a noise reduction tool](#speech-enhancement)- [LiveASR tool for real-time speech recognition](#liveasr---huggingfaces-model)- [Speaker Embedding Extraction (x-vector/d-vector)](#speaker-embedding-extraction---x-vector)## install`pip install asrp`## PreprocessASRP offers an easy-to-use set of functions to preprocess ASR text data.   The input data is a dictionary with the key 'sentence', and the output is the preprocessed text.     You can either use the fun_en function or use dynamic loading. Here's how to use it:```pythonimport asrpbatch_data = {    'sentence': &quot;I'm fine, thanks.&quot;}asrp.fun_en(batch_data)```dynamic loading```pythonimport asrpbatch_data = {    'sentence': &quot;I'm fine, thanks.&quot;}preprocessor = getattr(asrp, 'fun_en')preprocessor(batch_data)```## EvaluationASRP provides functions to evaluate the output quality of ASR systems using     the Word Error Rate (WER) and Character Error Rate (CER) metrics.   Here's how to use it:```pythonimport asrptargets = ['HuggingFace is great!', 'Love Transformers!', 'Let\'s wav2vec!']preds = ['HuggingFace is awesome!', 'Transformers is powerful.', 'Let\'s finetune wav2vec!']print(&quot;chunk size WER: {:2f}&quot;.format(100 * asrp.chunked_wer(targets, preds, chunk_size=None)))print(&quot;chunk size CER: {:2f}&quot;.format(100 * asrp.chunked_cer(targets, preds, chunk_size=None)))```## Speech to Discrete Unit```pythonimport asrpimport nlp2# https://github.com/facebookresearch/fairseq/blob/ust/examples/speech_to_speech/docs/textless_s2st_real_data.md# https://github.com/facebookresearch/fairseq/tree/main/examples/textless_nlp/gslm/ulmnlp2.download_file(    'https://huggingface.co/voidful/mhubert-base/resolve/main/mhubert_base_vp_en_es_fr_it3_L11_km1000.bin', './')hc = asrp.HubertCode(&quot;voidful/mhubert-base&quot;, './mhubert_base_vp_en_es_fr_it3_L11_km1000.bin', 11,                     chunk_sec=30,                     worker=20)hc('voice file path')```## Discrete Unit to speech```pythonimport asrpcode = []  # discrete unit# https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/gslm/unit2speech# https://github.com/facebookresearch/fairseq/blob/ust/examples/speech_to_speech/docs/textless_s2st_real_data.mdcs = asrp.Code2Speech(tts_checkpoint='./tts_checkpoint_best.pt', waveglow_checkpint='waveglow_256channels_new.pt')cs(code)# play on notebookimport IPython.display as ipdipd.Audio(data=cs(code), autoplay=False, rate=cs.sample_rate)```mhubert English hifigan vocoder example```pythonimport asrpimport nlp2import IPython.display as ipdfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLMnlp2.download_file(    'https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/g_00500000',    './')tokenizer = AutoTokenizer.from_pretrained(&quot;voidful/mhubert-unit-tts&quot;)model = AutoModelForSeq2SeqLM.from_pretrained(&quot;voidful/mhubert-unit-tts&quot;)model.eval()cs = asrp.Code2Speech(tts_checkpoint='./g_00500000', vocoder='hifigan')inputs = tokenizer([&quot;The quick brown fox jumps over the lazy dog.&quot;], return_tensors=&quot;pt&quot;)code = tokenizer.batch_decode(model.generate(**inputs,max_length=1024))[0]code = [int(i) for i in code.replace(&quot;&lt;/s&gt;&quot;,&quot;&quot;).replace(&quot;&lt;s&gt;&quot;,&quot;&quot;).split(&quot;v_tok_&quot;)[1:]]print(code)ipd.Audio(data=cs(code), autoplay=False, rate=cs.sample_rate)```## Speech EnhancementASRP also provides a tool to enhance speech quality with a noise reduction tool.  from https://github.com/facebookresearch/fairseq/tree/main/examples/speech_synthesis/preprocessing/denoiser```pythonfrom asrp import SpeechEnhancerase = SpeechEnhancer()print(ase('./test/xxx.wav'))```## LiveASR - huggingface's model* modify from https://github.com/oliverguhr/wav2vec2-live```pythonfrom asrp.live import LiveSpeechenglish_model = &quot;voidful/wav2vec2-xlsr-multilingual-56&quot;asr = LiveSpeech(english_model, device_name=&quot;default&quot;)asr.start()try:    while True:        text, sample_length, inference_time = asr.get_last_text()        print(f&quot;{sample_length:.3f}s&quot;              + f&quot;\t{inference_time:.3f}s&quot;              + f&quot;\t{text}&quot;)except KeyboardInterrupt:    asr.stop()```## LiveASR - whisper's model```pythonfrom asrp.live import LiveSpeechwhisper_model = &quot;tiny&quot;asr = LiveSpeech(whisper_model, vad_mode=2, language='zh')asr.start()last_text = &quot;&quot;while True:    asr_text = &quot;&quot;    try:        asr_text, sample_length, inference_time = asr.get_last_text()        if len(asr_text) &gt; 0:            print(asr_text, sample_length, inference_time)    except KeyboardInterrupt:        asr.stop()        break```## Speaker Embedding Extraction - x vectorfrom https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lobes.models.Xvector.html```pythonfrom asrp.speaker_embedding import extract_x_vectorextract_x_vector('./test/xxx.wav')```## Speaker Embedding Extraction - d vectorfrom https://github.com/yistLin/dvector```pythonfrom asrp.speaker_embedding import extract_d_vectorextract_d_vector('./test/xxx.wav')```</longdescription>
</pkgmetadata>