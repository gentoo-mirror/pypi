<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;&lt;h1&gt;  pywhisper&lt;/h1&gt;&lt;h4&gt;  &lt;a href=&quot;https://github.com/openai/whisper/tree/9f70a352f9f8630ab3aa0d06af5cb9532bd8c21d&quot;&gt;openai/whisper&lt;/a&gt; + extra features&lt;/h4&gt;&lt;div&gt;    &lt;a href=&quot;https://badge.fury.io/py/pywhisper&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/pywhisper.svg&quot; alt=&quot;pypi version&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://pepy.tech/project/pywhisper&quot;&gt;&lt;img src=&quot;https://pepy.tech/badge/pywhisper&quot; alt=&quot;downloads&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/fcakyon/pywhisper/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/fcakyon/yolov5-pip/actions/workflows/ci.yml/badge.svg&quot; alt=&quot;ci testing&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/fcakyon/pywhisper/actions/workflows/package_testing.yml&quot;&gt;&lt;img src=&quot;https://github.com/fcakyon/yolov5-pip/actions/workflows/package_testing.yml/badge.svg&quot; alt=&quot;package testing&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://twitter.com/fcakyon&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/fcakyon?color=blue&amp;logo=twitter&amp;style=flat&quot; alt=&quot;fcakyon twitter&quot;&gt;&lt;/a&gt;    &lt;br&gt;    &lt;br&gt;    &lt;/div&gt;&lt;/div&gt;## extra features- easy installation from pypi- no need for ffmpeg cli installation, pip install is enough- continious integration and package testing via github actions## setup```bashpip install pywhisper```You may need [`rust`](http://rust-lang.org) installed as well, in case [tokenizers](https://pypi.org/project/tokenizers/) does not provide a pre-built wheel for your platform. If you see installation errors during the `pip install` command above, please follow the [Getting started page](https://www.rust-lang.org/learn/get-started) to install Rust development environment. Additionally, you may need to configure the `PATH` environment variable, e.g. `export PATH=&quot;$HOME/.cargo/bin:$PATH&quot;`. If the installation fails with `No module named 'setuptools_rust'`, you need to install `setuptools_rust`, e.g. by running:```bashpip install setuptools-rust```## command-line usageThe following command will transcribe speech in audio files, using the `medium` model:    pywhisper audio.flac audio.mp3 audio.wav --model mediumThe default setting (which selects the `small` model) works well for transcribing English. To transcribe an audio file containing non-English speech, you can specify the language using the `--language` option:    pywhisper japanese.wav --language JapaneseAdding `--task translate` will translate the speech into English:    pywhisper japanese.wav --language Japanese --task translateRun the following to view all available options:    pywhisper --helpSee [tokenizer.py](pywhisper/tokenizer.py) for the list of all available languages.## python usageTranscription can also be performed within Python: ```pythonimport pywhispermodel = pywhisper.load_model(&quot;base&quot;)result = model.transcribe(&quot;audio.mp3&quot;)print(result[&quot;text&quot;])```Internally, the `transcribe()` method reads the entire file and processes the audio with a sliding 30-second window, performing autoregressive sequence-to-sequence predictions on each window.Below is an example usage of `pywhisper.detect_language()` and `pywhisper.decode()` which provide lower-level access to the model.```pythonimport pywhispermodel = pywhisper.load_model(&quot;base&quot;)# load audio and pad/trim it to fit 30 secondsaudio = pywhisper.load_audio(&quot;audio.mp3&quot;)audio = pywhisper.pad_or_trim(audio)# make log-Mel spectrogram and move to the same device as the modelmel = pywhisper.log_mel_spectrogram(audio).to(model.device)# detect the spoken language_, probs = model.detect_language(mel)print(f&quot;Detected language: {max(probs, key=probs.get)}&quot;)# decode the audiooptions = pywhisper.DecodingOptions()result = pywhisper.decode(model, mel, options)# print the recognized textprint(result.text)```</longdescription>
</pkgmetadata>