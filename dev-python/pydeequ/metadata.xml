<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># PyDeequPyDeequ is a Python API for [Deequ](https://github.com/awslabs/deequ), a library built on top of Apache Spark for defining &quot;unit tests for data&quot;, which measure data quality in large datasets. PyDeequ is written to support usage of Deequ in Python.[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) ![Coverage](https://img.shields.io/badge/coverage-90%25-green)There are 4 main components of Deequ, and they are:- Metrics Computation:    - `Profiles` leverages Analyzers to analyze each column of a dataset.    - `Analyzers` serve here as a foundational module that computes metrics for data profiling and validation at scale.- Constraint Suggestion:    - Specify rules for various groups of Analyzers to be run over a dataset to return back a collection of constraints suggested to run in a Verification Suite.- Constraint Verification:    - Perform data validation on a dataset with respect to various constraints set by you.   - Metrics Repository    - Allows for persistence and tracking of Deequ runs over time.![](imgs/pydeequ_architecture.jpg)## ðŸŽ‰ Announcements ðŸŽ‰- **NEW!!!** As of 06/19, 1.1.0rc0 of Python Deequ is published https://github.com/awslabs/python-deequ/releases/tag/v1.1.0rc0. We will bake for around 2 weeks. Any feedbacks are welcome through github issues.- With PyDeequ v0.1.8+, we now officially support Spark3 ! Just make sure you have an environment variable `SPARK_VERSION` to specify your Spark version! - We've release a blogpost on integrating PyDeequ onto AWS leveraging services such as AWS Glue, Athena, and SageMaker! Check it out: [Monitor data quality in your data lake using PyDeequ and AWS Glue](https://aws.amazon.com/blogs/big-data/monitor-data-quality-in-your-data-lake-using-pydeequ-and-aws-glue/).- Check out the [PyDeequ Release Announcement Blogpost](https://aws.amazon.com/blogs/big-data/testing-data-quality-at-scale-with-pydeequ/) with a tutorial walkthrough the Amazon Reviews dataset!- Join the PyDeequ community on [PyDeequ Slack](https://join.slack.com/t/pydeequ/shared_invite/zt-te6bntpu-yaqPy7bhiN8Lu0NxpZs47Q) to chat with the devs!## QuickstartThe following will quickstart you with some basic usage. For more in-depth examples, take a look in the [`tutorials/`](tutorials/) directory for executable Jupyter notebooks of each module. For documentation on supported interfaces, view the [`documentation`](https://pydeequ.readthedocs.io/).### InstallationYou can install [PyDeequ via pip](https://pypi.org/project/pydeequ/).```pip install pydeequ```### Set up a PySpark session```pythonfrom pyspark.sql import SparkSession, Rowimport pydeequspark = (SparkSession    .builder    .config(&quot;spark.jars.packages&quot;, pydeequ.deequ_maven_coord)    .config(&quot;spark.jars.excludes&quot;, pydeequ.f2j_maven_coord)    .getOrCreate())df = spark.sparkContext.parallelize([            Row(a=&quot;foo&quot;, b=1, c=5),            Row(a=&quot;bar&quot;, b=2, c=6),            Row(a=&quot;baz&quot;, b=3, c=None)]).toDF()```### Analyzers```pythonfrom pydeequ.analyzers import *analysisResult = AnalysisRunner(spark) \                    .onData(df) \                    .addAnalyzer(Size()) \                    .addAnalyzer(Completeness(&quot;b&quot;)) \                    .run()analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)analysisResult_df.show()```### Profile```pythonfrom pydeequ.profiles import *result = ColumnProfilerRunner(spark) \    .onData(df) \    .run()for col, profile in result.profiles.items():    print(profile)```### Constraint Suggestions```pythonfrom pydeequ.suggestions import *suggestionResult = ConstraintSuggestionRunner(spark) \             .onData(df) \             .addConstraintRule(DEFAULT()) \             .run()# Constraint Suggestions in JSON formatprint(suggestionResult)```### Constraint Verification```pythonfrom pydeequ.checks import *from pydeequ.verification import *check = Check(spark, CheckLevel.Warning, &quot;Review Check&quot;)checkResult = VerificationSuite(spark) \    .onData(df) \    .addCheck(        check.hasSize(lambda x: x &gt;= 3) \        .hasMin(&quot;b&quot;, lambda x: x == 0) \        .isComplete(&quot;c&quot;)  \        .isUnique(&quot;a&quot;)  \        .isContainedIn(&quot;a&quot;, [&quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;]) \        .isNonNegative(&quot;b&quot;)) \    .run()checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)checkResult_df.show()```### RepositorySave to a Metrics Repository by adding the `useRepository()` and `saveOrAppendResult()` calls to your Analysis Runner.```pythonfrom pydeequ.repository import *from pydeequ.analyzers import *metrics_file = FileSystemMetricsRepository.helper_metrics_file(spark, 'metrics.json')repository = FileSystemMetricsRepository(spark, metrics_file)key_tags = {'tag': 'pydeequ hello world'}resultKey = ResultKey(spark, ResultKey.current_milli_time(), key_tags)analysisResult = AnalysisRunner(spark) \    .onData(df) \    .addAnalyzer(ApproxCountDistinct('b')) \    .useRepository(repository) \    .saveOrAppendResult(resultKey) \    .run()```To load previous runs, use the `repository` object to load previous results back in.```pythonresult_metrep_df = repository.load() \    .before(ResultKey.current_milli_time()) \    .forAnalyzers([ApproxCountDistinct('b')]) \    .getSuccessMetricsAsDataFrame()```### Wrapping upAfter you've ran your jobs with PyDeequ, be sure to shut down your Spark session to prevent any hanging processes. ```pythonspark.sparkContext._gateway.shutdown_callback_server()spark.stop()```## [Contributing](https://github.com/awslabs/python-deequ/blob/master/CONTRIBUTING.md)Please refer to the [contributing doc](https://github.com/awslabs/python-deequ/blob/master/CONTRIBUTING.md) for how to contribute to PyDeequ.## [License](https://github.com/awslabs/python-deequ/blob/master/LICENSE)This library is licensed under the Apache 2.0 License.******## Contributing Developer Setup1. Setup [SDKMAN](#setup-sdkman)1. Setup [Java](#setup-java)1. Setup [Apache Spark](#setup-apache-spark)1. Install [Poetry](#poetry)1. Run [tests locally](#running-tests-locally)### Setup SDKMANSDKMAN is a tool for managing parallel Versions of multiple Software Development Kits on any Unix basedsystem. It provides a convenient command line interface for installing, switching, removing and listingCandidates. SDKMAN! installs smoothly on Mac OSX, Linux, WSL, Cygwin, etc... Support Bash and ZSH shells. Seedocumentation on the [SDKMAN! website](https://sdkman.io).Open your favourite terminal and enter the following:```bash$ curl -s https://get.sdkman.io | bashIf the environment needs tweaking for SDKMAN to be installed,the installer will prompt you accordingly and ask you to restart.Next, open a new terminal or enter:$ source &quot;$HOME/.sdkman/bin/sdkman-init.sh&quot;Lastly, run the following code snippet to ensure that installation succeeded:$ sdk version```### Setup JavaInstall Java Now open favourite terminal and enter the following:```bashList the AdoptOpenJDK OpenJDK versions$ sdk list javaTo install For Java 11$ sdk install java 11.0.10.hs-adptTo install For Java 11$ sdk install java 8.0.292.hs-adpt```### Setup Apache SparkInstall Java Now open favourite terminal and enter the following:```bashList the Apache Spark versions:$ sdk list sparkTo install For Spark 3$ sdk install spark 3.0.2```### PoetryPoetry [Commands](https://python-poetry.org/docs/cli/#search)```bashpoetry installpoetry update# --tree: List the dependencies as a tree.# --latest (-l): Show the latest version.# --outdated (-o): Show the latest version but only for packages that are outdated.poetry show -o```## Running Tests LocallyTake a look at tests in `tests/dataquality` and `tests/jobs````bash$ poetry run pytest```</longdescription>
</pkgmetadata>