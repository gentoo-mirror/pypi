<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># üìù nlplotnlplot: Analysis and visualization module for Natural Language Processing üìà## DescriptionFacilitates the visualization of natural language processing and provides quicker analysisYou can draw the following graph1. [N-gram bar chart](https://htmlpreview.github.io/?https://github.com/takapy0210/takapy_blog/blob/master/nlp/twitter_analytics_using_nlplot/2020-05-17_uni-gram.html)2. [N-gram tree Map](https://htmlpreview.github.io/?https://github.com/takapy0210/takapy_blog/blob/master/nlp/twitter_analytics_using_nlplot/2020-05-17_Tree%20of%20Most%20Common%20Words.html)3. [Histogram of the word count](https://htmlpreview.github.io/?https://github.com/takapy0210/takapy_blog/blob/master/nlp/twitter_analytics_using_nlplot/2020-05-17_number%20of%20words%20distribution.html)4. [wordcloud](https://github.com/takapy0210/takapy_blog/blob/master/nlp/twitter_analytics_using_nlplot/wordcloud.png)5. [co-occurrence networks](https://htmlpreview.github.io/?https://github.com/takapy0210/takapy_blog/blob/master/nlp/twitter_analytics_using_nlplot/2020-05-17_Co-occurrence%20network.html)6. [sunburst chart](https://htmlpreview.github.io/?https://github.com/takapy0210/takapy_blog/blob/master/nlp/twitter_analytics_using_nlplot/2020-05-17_sunburst%20chart.html)ÔºàTested in English and JapaneseÔºâ## Requirement- [python package](https://github.com/takapy0210/nlplot/blob/master/requirements.txt)## Installation```shpip install nlplot```I've posted on [this blog](https://www.takapy.work/entry/2020/05/17/192947) about the specific use. (Japanese)And, The sample code is also available [in the kernel of kaggle](https://www.kaggle.com/takanobu0210/twitter-sentiment-eda-using-nlplot). (English)## Quick start - Data PreparationThe column to be analyzed must be a space-delimited string```python# sample datatarget_col = &quot;text&quot;texts = [    &quot;Think rich look poor&quot;,    &quot;When you come to a roadblock, take a detour&quot;,    &quot;When it is dark enough, you can see the stars&quot;,    &quot;Never let your memories be greater than your dreams&quot;,    &quot;Victory is sweetest when you‚Äôve known defeat&quot;    ]df = pd.DataFrame({target_col: texts})df.head()```|    |  text  || ---- | ---- ||  0  |  Think rich look poor ||  1  |  When you come to a roadblock, take a detour ||  2  |  When it is dark enough, you can see the stars ||  3  |  Never let your memories be greater than your dreams  ||  4  |  Victory is sweetest when you‚Äôve known defeat  |## Quick start - Python API```pythonimport nlplotimport pandas as pdimport plotlyfrom plotly.subplots import make_subplotsfrom plotly.offline import iplotimport matplotlib.pyplot as plt%matplotlib inline# target_col as a list type or a string separated by a space.npt = nlplot.NLPlot(df, target_col='text')# Stopword calculations can be performed.stopwords = npt.get_stopword(top_n=30, min_freq=0)# 1. N-gram bar chartfig_unigram = npt.bar_ngram(    title='uni-gram',    xaxis_label='word_count',    yaxis_label='word',    ngram=1,    top_n=50,    width=800,    height=1100,    color=None,    horizon=True,    stopwords=stopwords,    verbose=False,    save=False,)fig_unigram.show()fig_bigram = npt.bar_ngram(    title='bi-gram',    xaxis_label='word_count',    yaxis_label='word',    ngram=2,    top_n=50,    width=800,    height=1100,    color=None,    horizon=True,    stopwords=stopwords,    verbose=False,    save=False,)fig_bigram.show()# 2. N-gram tree Mapfig_treemap = npt.treemap(    title='Tree map',    ngram=1,    top_n=50,    width=1300,    height=600,    stopwords=stopwords,    verbose=False,    save=False)fig_treemap.show()# 3. Histogram of the word countfig_histgram = npt.word_distribution(    title='word distribution',    xaxis_label='count',    yaxis_label='',    width=1000,    height=500,    color=None,    template='plotly',    bins=None,    save=False,)fig_histgram.show()# 4. wordcloudfig_wc = npt.wordcloud(    width=1000,    height=600,    max_words=100,    max_font_size=100,    colormap='tab20_r',    stopwords=stopwords,    mask_file=None,    save=False)plt.figure(figsize=(15, 25))plt.imshow(fig_wc, interpolation=&quot;bilinear&quot;)plt.axis(&quot;off&quot;)plt.show()# 5. co-occurrence networksnpt.build_graph(stopwords=stopwords, min_edge_frequency=10)# The number of nodes and edges to which this output is plotted.# If this number is too large, plotting will take a long time, so adjust the [min_edge_frequency] well.# &gt;&gt; node_size:70, edge_size:166fig_co_network = npt.co_network(    title='Co-occurrence network',    sizing=100,    node_size='adjacency_frequency',    color_palette='hls',    width=1100,    height=700,    save=False)iplot(fig_co_network)# 6. sunburst chartfig_sunburst = npt.sunburst(    title='sunburst chart',    colorscale=True,    color_continuous_scale='Oryel',    width=1000,    height=800,    save=False)fig_sunburst.show()# other# The original data frame of the co-occurrence network can also be accesseddisplay(    npt.node_df.head(), npt.node_df.shape,    npt.edge_df.head(), npt.edge_df.shape)```## DocumentTBD## Test```shcd testspytest```## Other- Plotly is used to plot the figure    - https://plotly.com/python/- co-occurrence networks is used to calculate the co-occurrence network    - https://networkx.github.io/documentation/stable/tutorial.html- wordcloud uses the following fonts    - https://mplus-fonts.osdn.jp/about.html</longdescription>
</pkgmetadata>