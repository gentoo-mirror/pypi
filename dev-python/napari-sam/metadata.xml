<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Segment Anything Model (SAM) in Napari[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-sam.svg?color=green)](https://github.com/MIC-DKFZ/napari-sam/raw/main/LICENSE)[![PyPI](https://img.shields.io/pypi/v/napari-sam.svg?color=green)](https://pypi.org/project/napari-sam)[![Python Version](https://img.shields.io/pypi/pyversions/napari-sam.svg?color=green)](https://python.org)[![tests](https://github.com/MIC-DKFZ/napari-sam/workflows/tests/badge.svg)](https://github.com/MIC-DKFZ/napari-sam/actions)[![codecov](https://codecov.io/gh/MIC-DKFZ/napari-sam/branch/main/graph/badge.svg)](https://codecov.io/gh/MIC-DKFZ/napari-sam)[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sam)](https://napari-hub.org/plugins/napari-sam)Segment anything with our **Napari** integration of Meta AI's new **Segment Anything Model (SAM)**!SAM is the new segmentation system from Meta AI capable of **one-click segmentation of any object**, and now, our plugin neatly integrates this into Napari.We have already **extended** SAM's click-based foreground separation to full **click-based semantic segmentation and instance segmentation**!At last, our SAM integration supports both **2D and 3D images**!----------------------------------Everything mode             |  Click-based semantic segmentation mode |  Click-based instance segmentation mode:-------------------------:|:-------------------------:|:-------------------------:![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_everything.png)  |  ![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_semantic.png)  |  ![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_instance.png)----------------------------------&lt;h2 align=&quot;center&quot;&gt;SAM in Napari demo&lt;/h2&gt;&lt;div align=&quot;center&quot;&gt;https://user-images.githubusercontent.com/3471895/236152620-0de983db-954b-4480-97b9-901ee82f8edd.mp4&lt;/div&gt;----------------------------------## InstallationThe plugin requires `python&gt;=3.8`, as well as `pytorch&gt;=1.7` and `torchvision&gt;=0.8`. Please follow the instructions here to install both PyTorch and TorchVision dependencies. Installing both PyTorch and TorchVision with CUDA support is strongly recommended.Install Napari via [pip]:        pip install napari[all]You can install `napari-sam` via [pip]:    pip install git+https://github.com/facebookresearch/segment-anything.git    pip install napari-samTo install latest development version :    pip install git+https://github.com/MIC-DKFZ/napari-sam.git## UsageStart Napari from the console with:    napariThen navigate to `Plugins -&gt; Segment Anything (napari-sam)` and drag &amp; drop an image into Napari. At last create, a labels layer that will be used for the SAM predictions, by clicking in the layer list on the third button.You can then auto-download one of the available SAM models (this can take 1-2 minutes),  activate one of the annotations &amp; segmentation modes, and you are ready to go!## ContributingContributions are very welcome. Tests can be run with [tox], please ensurethe coverage at least stays the same before you submit a pull request.## LicenseDistributed under the terms of the [Apache Software License 2.0] license,&quot;napari-sam&quot; is free and open source software## IssuesIf you encounter any problems, please [file an issue] along with a detailed description.[napari]: https://github.com/napari/napari[Cookiecutter]: https://github.com/audreyr/cookiecutter[@napari]: https://github.com/napari[MIT]: http://opensource.org/licenses/MIT[BSD-3]: http://opensource.org/licenses/BSD-3-Clause[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin[file an issue]: https://github.com/MIC-DKFZ/napari-sam/issues[napari]: https://github.com/napari/napari[tox]: https://tox.readthedocs.io/en/latest/[pip]: https://pypi.org/project/pip/[PyPI]: https://pypi.org/# Acknowledgements&lt;img src=&quot;https://github.com/MIC-DKFZ/napari-sam/raw/main/HI_Logo.png&quot; height=&quot;100px&quot; /&gt;&lt;img src=&quot;https://github.com/MIC-DKFZ/napari-sam/raw/main/dkfz_logo.png&quot; height=&quot;100px&quot; /&gt;napari-sam is developed and maintained by the Applied Computer Vision Lab (ACVL) of [Helmholtz Imaging](http://helmholtz-imaging.de) and the [Division of Medical Image Computing](https://www.dkfz.de/en/mic/index.php) at the [German Cancer Research Center (DKFZ)](https://www.dkfz.de/en/index.html).</longdescription>
</pkgmetadata>