<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># FastKafka&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;&lt;b&gt;Effortless Kafka integration for your web services&lt;/b&gt;------------------------------------------------------------------------![PyPI](https://img.shields.io/pypi/v/fastkafka.png) ![PyPI -Downloads](https://img.shields.io/pypi/dm/fastkafka.png) ![PyPI - PythonVersion](https://img.shields.io/pypi/pyversions/fastkafka.png)![GitHub WorkflowStatus](https://img.shields.io/github/actions/workflow/status/airtai/fastkafka/test.yaml)![CodeQL](https://github.com/airtai/fastkafka//actions/workflows/codeql.yml/badge.svg)![DependencyReview](https://github.com/airtai/fastkafka//actions/workflows/dependency-review.yml/badge.svg)![GitHub](https://img.shields.io/github/license/airtai/fastkafka.png)------------------------------------------------------------------------[FastKafka](https://fastkafka.airt.ai/) is a powerful and easy-to-usePython library for building asynchronous services that interact withKafka topics. Built on top of [Pydantic](https://docs.pydantic.dev/),[AIOKafka](https://github.com/aio-libs/aiokafka) and[AsyncAPI](https://www.asyncapi.com/), FastKafka simplifies the processof writing producers and consumers for Kafka topics, handling all theparsing, networking, task scheduling and data generation automatically.With FastKafka, you can quickly prototype and develop high-performanceKafka-based services with minimal code, making it an ideal choice fordevelopers looking to streamline their workflow and accelerate theirprojects.------------------------------------------------------------------------#### ‚≠ê‚≠ê‚≠ê Stay in touch ‚≠ê‚≠ê‚≠êPlease show your support and stay in touch by:- giving our [GitHub repository](https://github.com/airtai/fastkafka/) a  star, and- joining our [Discord server](https://discord.gg/CJWmYpyFbc).Your support helps us to stay in touch with you and encourages us tocontinue developing and improving the library. Thank you for yoursupport!------------------------------------------------------------------------#### üêùüêùüêù We were busy lately üêùüêùüêù![Activity](https://repobeats.axiom.co/api/embed/21f36049093d5eb8e5fdad18c3c5d8df5428ca30.svg &quot;Repobeats analytics image&quot;)## InstallFastKafka works on Windows, macOS, Linux, and most Unix-style operatingsystems. You can install base version of FastKafka with `pip` as usual:``` shpip install fastkafka```To install FastKafka with testing features please use:``` shpip install fastkafka[test]```To install FastKafka with asyncapi docs please use:``` shpip install fastkafka[docs]```To install FastKafka with all the features please use:``` shpip install fastkafka[test,docs]```## TutorialYou can start an interactive tutorial in Google Colab by clicking thebutton below:&lt;a href=&quot;https://colab.research.google.com/github/airtai/fastkafka/blob/main/nbs/index.ipynb&quot; target=‚Äù_blank‚Äù&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open in Colab&quot; /&gt;&lt;/a&gt;## Writing server codeTo demonstrate FastKafka simplicity of using `@produces` and `@consumes`decorators, we will focus on a simple app.The app will consume jsons containig positive floats from one topic, logthem and then produce incremented values to another topic.### MessagesFastKafka uses [Pydantic](https://docs.pydantic.dev/) to parse inputJSON-encoded data into Python objects, making it easy to work withstructured data in your Kafka-based applications. Pydantic‚Äôs[`BaseModel`](https://docs.pydantic.dev/usage/models/) class allows youto define messages using a declarative syntax, making it easy to specifythe fields and types of your messages.This example defines one `Data` mesage class. This Class will model theconsumed and produced data in our app demo, it contains one`NonNegativeFloat` field `data` that will be logged and ‚Äúprocessed‚Äùbefore being produced to another topic.These message class will be used to parse and validate incoming data inKafka consumers and producers.``` pythonfrom pydantic import BaseModel, Field, NonNegativeFloatclass Data(BaseModel):    data: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Float data example&quot;    )```### ApplicationThis example shows how to initialize a FastKafka application.It starts by defining a dictionary called `kafka_brokers`, whichcontains two entries: `&quot;localhost&quot;` and `&quot;production&quot;`, specifying localdevelopment and production Kafka brokers. Each entry specifies the URL,port, and other details of a Kafka broker. This dictionary is used forboth generating the documentation and later to run the actual serveragainst one of the given kafka broker.Next, an object of the[`FastKafka`](https://airtai.github.io/fastkafka/docs/api/fastkafka#fastkafka.FastKafka)class is initialized with the minimum set of arguments:- `kafka_brokers`: a dictionary used for generation of documentationWe will also import and create a logger so that we can log the incomingdata in our consuming function.``` pythonfrom logging import getLoggerfrom fastkafka import FastKafkalogger = getLogger(&quot;Demo Kafka app&quot;)kafka_brokers = {    &quot;localhost&quot;: {        &quot;url&quot;: &quot;localhost&quot;,        &quot;description&quot;: &quot;local development kafka broker&quot;,        &quot;port&quot;: 9092,    },    &quot;production&quot;: {        &quot;url&quot;: &quot;kafka.airt.ai&quot;,        &quot;description&quot;: &quot;production kafka broker&quot;,        &quot;port&quot;: 9092,        &quot;protocol&quot;: &quot;kafka-secure&quot;,        &quot;security&quot;: {&quot;type&quot;: &quot;plain&quot;},    },}kafka_app = FastKafka(    title=&quot;Demo Kafka app&quot;,    kafka_brokers=kafka_brokers,)```### Function decoratorsFastKafka provides convenient function decorators `@kafka_app.consumes`and `@kafka_app.produces` to allow you to delegate the actual process of- consuming and producing data to Kafka, and- decoding and encoding JSON encode messagesfrom user defined functions to the framework. The FastKafka frameworkdelegates these jobs to AIOKafka and Pydantic libraries.These decorators make it easy to specify the processing logic for yourKafka consumers and producers, allowing you to focus on the corebusiness logic of your application without worrying about the underlyingKafka integration.This following example shows how to use the `@kafka_app.consumes` and`@kafka_app.produces` decorators in a FastKafka application:- The `@kafka_app.consumes` decorator is applied to the `on_input_data`  function, which specifies that this function should be called whenever  a message is received on the ‚Äúinput_data‚Äù Kafka topic. The  `on_input_data` function takes a single argument which is expected to  be an instance of the `Data` message class. Specifying the type of the  single argument is instructing the Pydantic to use `Data.parse_raw()`  on the consumed message before passing it to the user defined function  `on_input_data`.- The `@produces` decorator is applied to the `to_output_data` function,  which specifies that this function should produce a message to the  ‚Äúoutput_data‚Äù Kafka topic whenever it is called. The `to_output_data`  function takes a single float argument `data`. It it increments the  data returns it wrapped in a `Data` object. The framework will call  the `Data.json().encode(&quot;utf-8&quot;)` function on the returned value and  produce it to the specified topic.``` python@kafka_app.consumes(topic=&quot;input_data&quot;, auto_offset_reset=&quot;latest&quot;)async def on_input_data(msg: Data):    logger.info(f&quot;Got data: {msg.data}&quot;)    await to_output_data(msg.data)@kafka_app.produces(topic=&quot;output_data&quot;)async def to_output_data(data: float) -&gt; Data:    processed_data = Data(data=data+1.0)    return processed_data```## Testing the serviceThe service can be tested using the[`Tester`](https://airtai.github.io/fastkafka/docs/api/fastkafka/testing/Tester#fastkafka.testing.Tester)instances which internally starts InMemory implementation of Kafkabroker.The Tester will redirect your consumes and produces decorated functionsto the InMemory Kafka broker so that you can quickly test your appwithout the need for a running Kafka broker and all its dependencies.``` pythonfrom fastkafka.testing import Testermsg = Data(    data=0.1,)# Start Tester app and create InMemory Kafka broker for testingasync with Tester(kafka_app) as tester:    # Send Data message to input_data topic    await tester.to_input_data(msg)    # Assert that the kafka_app responded with incremented data in output_data topic    await tester.awaited_mocks.on_output_data.assert_awaited_with(        Data(data=1.1), timeout=2    )```    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting    [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()    [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['input_data']    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['output_data']    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [INFO] Demo Kafka app: Got data: 0.1    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping### RecapWe have created a simple FastKafka application. The app will consume the`Data` from the `input_data` topic, log it and produce the incrementeddata to `output_data` topic.To test the app we have:1.  Created the app2.  Started our Tester class which mirrors the developed app topics for    testing purposes3.  Sent Data message to `input_data` topic4.  Asserted and checked that the developed service has reacted to Data    message## Running the serviceThe service can be started using builtin faskafka run CLI command.Before we can do that, we will concatenate the code snippets from aboveand save them in a file `&quot;application.py&quot;```` python# content of the &quot;application.py&quot; filefrom pydantic import BaseModel, Field, NonNegativeFloatfrom fastkafka import FastKafkafrom fastkafka._components.logger import get_loggerlogger = get_logger(__name__)class Data(BaseModel):    data: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Float data example&quot;    )kafka_brokers = {    &quot;localhost&quot;: {        &quot;url&quot;: &quot;localhost&quot;,        &quot;description&quot;: &quot;local development kafka broker&quot;,        &quot;port&quot;: 9092,    },    &quot;production&quot;: {        &quot;url&quot;: &quot;kafka.airt.ai&quot;,        &quot;description&quot;: &quot;production kafka broker&quot;,        &quot;port&quot;: 9092,        &quot;protocol&quot;: &quot;kafka-secure&quot;,        &quot;security&quot;: {&quot;type&quot;: &quot;plain&quot;},    },}kafka_app = FastKafka(    title=&quot;Demo Kafka app&quot;,    kafka_brokers=kafka_brokers,)@kafka_app.consumes(topic=&quot;input_data&quot;, auto_offset_reset=&quot;latest&quot;)async def on_input_data(msg: Data):    logger.info(f&quot;Got data: {msg.data}&quot;)    await to_output_data(msg.data)@kafka_app.produces(topic=&quot;output_data&quot;)async def to_output_data(data: float) -&gt; Data:    processed_data = Data(data=data+1.0)    return processed_data```To run the service, use the FastKafka CLI command and pass the module(in this case, the file where the app implementation is located) and theapp simbol to the command.``` shfastkafka run --num-workers=1 --kafka-broker localhost application:kafka_app```After running the command, you should see the following output in yourcommand line:    [1504]: 23-05-31 11:36:45.874 [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to 'localhost:9092'    [1504]: 23-05-31 11:36:45.875 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [1504]: 23-05-31 11:36:45.937 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [1504]: 23-05-31 11:36:45.937 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}    [1504]: 23-05-31 11:36:45.956 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [1504]: 23-05-31 11:36:45.956 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'input_data'})    [1504]: 23-05-31 11:36:45.956 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'input_data'}    [1504]: 23-05-31 11:36:45.956 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [1506]: 23-05-31 11:36:45.993 [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to 'localhost:9092'    [1506]: 23-05-31 11:36:45.994 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [1506]: 23-05-31 11:36:46.014 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [1506]: 23-05-31 11:36:46.015 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}    [1506]: 23-05-31 11:36:46.040 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [1506]: 23-05-31 11:36:46.042 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'input_data'})    [1506]: 23-05-31 11:36:46.043 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'input_data'}    [1506]: 23-05-31 11:36:46.043 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [1506]: 23-05-31 11:36:46.068 [ERROR] aiokafka.cluster: Topic input_data not found in cluster metadata    [1506]: 23-05-31 11:36:46.070 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'input_data': 0}.     [1504]: 23-05-31 11:36:46.131 [WARNING] aiokafka.cluster: Topic input_data is not available during auto-create initialization    [1504]: 23-05-31 11:36:46.132 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'input_data': 0}.     [1506]: 23-05-31 11:37:00.237 [ERROR] aiokafka: Unable connect to node with id 0: [Errno 111] Connect call failed ('172.28.0.12', 9092)    [1506]: 23-05-31 11:37:00.237 [ERROR] aiokafka: Unable to update metadata from [0]    [1504]: 23-05-31 11:37:00.238 [ERROR] aiokafka: Unable connect to node with id 0: [Errno 111] Connect call failed ('172.28.0.12', 9092)    [1504]: 23-05-31 11:37:00.238 [ERROR] aiokafka: Unable to update metadata from [0]    [1506]: 23-05-31 11:37:00.294 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [1506]: 23-05-31 11:37:00.294 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    Starting process cleanup, this may take a few seconds...    23-05-31 11:37:00.345 [INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 1504...    23-05-31 11:37:00.345 [INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 1506...    [1504]: 23-05-31 11:37:00.347 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [1504]: 23-05-31 11:37:00.347 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    23-05-31 11:37:00.607 [INFO] fastkafka._server: terminate_asyncio_process(): Process 1506 was already terminated.    23-05-31 11:37:00.822 [INFO] fastkafka._server: terminate_asyncio_process(): Process 1504 was already terminated.## DocumentationThe kafka app comes with builtin documentation generation using[AsyncApi HTML generator](https://www.asyncapi.com/tools/generator).AsyncApi requires Node.js to be installed and we provide the followingconvenience command line for it:``` shfastkafka docs install_deps```    23-05-31 11:38:24.128 [INFO] fastkafka._components.docs_dependencies: AsyncAPI generator installedTo generate the documentation programatically you just need to call thefollowing command:``` shfastkafka docs generate application:kafka_app```    23-05-31 11:38:25.113 [INFO] fastkafka._components.asyncapi: Old async specifications at '/content/asyncapi/spec/asyncapi.yml' does not exist.    23-05-31 11:38:25.118 [INFO] fastkafka._components.asyncapi: New async specifications generated at: '/content/asyncapi/spec/asyncapi.yml'    23-05-31 11:38:43.455 [INFO] fastkafka._components.asyncapi: Async docs generated at 'asyncapi/docs'    23-05-31 11:38:43.455 [INFO] fastkafka._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'    Done! ‚ú®    Check out your shiny new generated files at /content/asyncapi/docs.This will generate the *asyncapi* folder in relative path where all yourdocumentation will be saved. You can check out the content of it with:``` shls -l asyncapi```    total 8    drwxr-xr-x 4 root root 4096 May 31 11:38 docs    drwxr-xr-x 2 root root 4096 May 31 11:38 specIn docs folder you will find the servable static html file of yourdocumentation. This can also be served using our `fastkafka docs serve`CLI command (more on that in our guides).In spec folder you will find a asyncapi.yml file containing the asyncAPI specification of your application.We can locally preview the generated documentation by running thefollowing command:``` shfastkafka docs serve application:kafka_app```    23-05-31 11:38:45.250 [INFO] fastkafka._components.asyncapi: New async specifications generated at: '/content/asyncapi/spec/asyncapi.yml'    23-05-31 11:39:04.410 [INFO] fastkafka._components.asyncapi: Async docs generated at 'asyncapi/docs'    23-05-31 11:39:04.411 [INFO] fastkafka._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'    Done! ‚ú®    Check out your shiny new generated files at /content/asyncapi/docs.    Serving documentation on http://127.0.0.1:8000    127.0.0.1 - - [31/May/2023 11:39:14] &quot;GET / HTTP/1.1&quot; 200 -    127.0.0.1 - - [31/May/2023 11:39:14] &quot;GET /css/global.min.css HTTP/1.1&quot; 200 -    127.0.0.1 - - [31/May/2023 11:39:14] &quot;GET /js/asyncapi-ui.min.js HTTP/1.1&quot; 200 -    127.0.0.1 - - [31/May/2023 11:39:14] &quot;GET /css/asyncapi.min.css HTTP/1.1&quot; 200 -    Interupting serving of documentation and cleaning up...From the parameters passed to the application constructor, we get thedocumentation bellow:``` pythonfrom fastkafka import FastKafkakafka_brokers = {    &quot;localhost&quot;: {        &quot;url&quot;: &quot;localhost&quot;,        &quot;description&quot;: &quot;local development kafka broker&quot;,        &quot;port&quot;: 9092,    },    &quot;production&quot;: {        &quot;url&quot;: &quot;kafka.airt.ai&quot;,        &quot;description&quot;: &quot;production kafka broker&quot;,        &quot;port&quot;: 9092,        &quot;protocol&quot;: &quot;kafka-secure&quot;,        &quot;security&quot;: {&quot;type&quot;: &quot;plain&quot;},    },}kafka_app = FastKafka(    title=&quot;Demo Kafka app&quot;,    kafka_brokers=kafka_brokers,)```![Kafka_servers](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-servers.png)The following documentation snippet are for the consumer as specified inthe code above:![Kafka_consumer](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-consumer.png)The following documentation snippet are for the producer as specified inthe code above:![Kafka_producer](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-producer.png)Finally, all messages as defined as subclasses of *BaseModel* aredocumented as well:![Kafka\_![Kafka_servers](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-messages.png)](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-messages.png)## LicenseFastKafka is licensed under the Apache License 2.0A permissive license whose main conditions require preservation ofcopyright and license notices. Contributors provide an express grant ofpatent rights. Licensed works, modifications, and larger works may bedistributed under different terms and without source code.The full text of the license can be found[here](https://raw.githubusercontent.com/airtai/fastkafka/main/LICENSE).</longdescription>
</pkgmetadata>