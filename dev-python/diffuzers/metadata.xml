<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># diffuzersA web ui and deployable API for [ü§ó diffusers](https://github.com/huggingface/diffusers).&lt; under development, request features using issues, prs not accepted atm &gt;&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/abhishekkrthakur/diffuzers/blob/main/diffuzers.ipynb&quot;&gt;  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;&lt;/a&gt;&lt;a href='https://diffuzers.readthedocs.io/en/latest/?badge=latest'&gt;    &lt;img src='https://readthedocs.org/projects/diffuzers/badge/?version=latest' alt='Documentation Status' /&gt;&lt;/a&gt;![image](https://github.com/abhishekkrthakur/diffuzers/raw/main/static/screenshot.jpeg)If something doesnt work as expected, or if you need some features which are not available, then create request using [github issues](https://github.com/abhishekkrthakur/diffuzers/issues)## Features available in the app:- text to image- image to image- instruct pix2pix- textual inversion- inpainting- outpainting (coming soon)- image info- stable diffusion upscaler- gfpgan- clip interrogator- more coming soon!## Features available in the api:- text to image- image to image- instruct pix2pix- textual inversion- inpainting- outpainting (via inpainting)- more coming soon!## InstallationTo install bleeding edge version of diffuzers, clone the repo and install it using pip.```bashgit clone https://github.com/abhishekkrthakur/diffuzerscd diffuzerspip install -e .```Installation using pip:    ```bash pip install diffuzers```## Usage### Web AppTo run the web app, run the following command:```bashdiffuzers app```### APITo run the api, run the following command:```bashdiffuzers api```Starting the API requires the following environment variables:```export X2IMG_MODEL=stabilityai/stable-diffusion-2-1export DEVICE=cuda```If you want to use inpainting:```export INPAINTING_MODEL=stabilityai/stable-diffusion-2-inpainting```To use long prompt weighting, use:```export PIPELINE=lpw_stable_diffusion```If you have `OUTPUT_PATH` in environment variables, all generations will be saved in `OUTPUT_PATH`. You can also use other (or private) huggingface models. To use private models, you must login using `huggingface-cli login`.API docs are available at `host:port/docs`. For example, with default settings, you can access docs at: `127.0.0.1:10000/docs`.## All CLI Options for running the app:```bash‚ùØ diffuzers app --helpusage: diffuzers &lt;command&gt; [&lt;args&gt;] app [-h] [--output OUTPUT] [--share] [--port PORT] [--host HOST]                                        [--device DEVICE] [--ngrok_key NGROK_KEY]‚ú® Run diffuzers appoptional arguments:  -h, --help            show this help message and exit  --output OUTPUT       Output path is optional, but if provided, all generations will automatically be saved to this                        path.  --share               Share the app  --port PORT           Port to run the app on  --host HOST           Host to run the app on  --device DEVICE       Device to use, e.g. cpu, cuda, cuda:0, mps (for m1 mac) etc.  --ngrok_key NGROK_KEY                        Ngrok key to use for sharing the app. Only required if you want to share the app```## All CLI Options for running the api:```bash‚ùØ diffuzers api --helpusage: diffuzers &lt;command&gt; [&lt;args&gt;] api [-h] [--output OUTPUT] [--port PORT] [--host HOST] [--device DEVICE]                                        [--workers WORKERS]‚ú® Run diffuzers apioptional arguments:  -h, --help         show this help message and exit  --output OUTPUT    Output path is optional, but if provided, all generations will automatically be saved to this                     path.  --port PORT        Port to run the app on  --host HOST        Host to run the app on  --device DEVICE    Device to use, e.g. cpu, cuda, cuda:0, mps (for m1 mac) etc.  --workers WORKERS  Number of workers to use```## Using private models from huggingface hubIf you want to use private models from huggingface hub, then you need to login using `huggingface-cli login` command.Note: You can also save your generations directly to huggingface hub if your output path points to a huggingface hub dataset repo and you have access to push to that repository. Thus, you will end up saving a lot of disk space. </longdescription>
</pkgmetadata>