<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;img src=&quot;https://i.imgur.com/o6cxmaP.jpg&quot; width=400 style=&quot;margin-bottom:60px;&quot;&gt;  &lt;a href=&quot;https://www.python.org/downloads/release/python-360/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/econuy&quot;&gt;&lt;/a&gt;  &lt;a href=&quot;https://img.shields.io/pypi/l/econuy&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/l/econuy&quot;&gt;&lt;/a&gt;  &lt;a href=&quot;https://pypi.org/project/econuy/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/econuy&quot;&gt;&lt;/a&gt;  &lt;a href=&quot;https://travis-ci.com/rxavier/econuy&quot;&gt;&lt;img src=&quot;https://travis-ci.com/rxavier/econuy.svg?branch=master&quot;&gt;&lt;/a&gt;  &lt;a href=&quot;https://econuy.readthedocs.io/en/latest/?badge=latest&quot;&gt;&lt;img src=&quot;https://readthedocs.org/projects/econuy/badge/?version=latest&quot;&gt;&lt;/a&gt;  &lt;a href=&quot;https://codecov.io/gh/rxavier/econuy&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/rxavier/econuy/branch/master/graph/badge.svg&quot;&gt;&lt;/a&gt;# OverviewThis project simplifies gathering and processing of Uruguayan economic statistics. Data is retrieved from (mostly) government sources, processed into a familiar tabular format, tagged with useful metadata and can be transformed in several ways (converting to dollars, calculating rolling averages, resampling to other frequencies, etc.).If [this screenshot](https://i.imgur.com/Ku5OR0y.jpg) gives you anxiety, this package should be of interest.A webapp with a limited but interactive version of econuy is available at [econ.uy](https://econ.uy). Check out the [repo](https://github.com/rxavier/econuy-web) as well.The most basic econuy workflow goes like this:```pythonfrom econuy.core import Pipelinep = Pipeline()p.get(&quot;labor_rates&quot;)```# Installation* PyPI:```bashpip install econuy```* Git:```bashgit clone https://github.com/rxavier/econuy.gitcd econuypython setup.py install```# Usage**[Full API documentation available at RTD](https://econuy.readthedocs.io/en/latest/api.html)**## The `Pipeline()` classThis is the recommended entry point for the package. It allows setting up the common behavior for downloads, and holds the current working dataset.```pythonfrom econuy.core import Pipelinep = Pipeline(location=&quot;your_directory&quot;)```### The `Pipeline.get()` methodRetrieves datasets (generally downloads them, unless the `download` attribute is `False` and the requested dataset exists at the `location`) and loads them into the `dataset` attribute as a Pandas DataFrame.The `Pipeline.available_datasets()` method returns a `dict` with the available options.```pythonfrom econuy.core import Pipelinefrom sqlalchemy import create_engineeng = create_engine(&quot;dialect+driver://user:pwd@host:port/database&quot;)p = Pipeline(location=eng)p.get(&quot;industrial_production&quot;)```Which also shows that econuy supports SQLAlchemy `Engine` or `Connection` objects.Note that every time a dataset is retrieved, `Pipeline` will1. Check if a previous version exists at `location`. If it does, it will read it and combine it with the new data (unless `download=False`, in which case only existing data will be retrieved)2. Save the dataset to `location`, unless the `always_save` attribute is set to `False` or no new data is available.Data can be written and read to and from CSV or Excel files (controlled by the `read_fmt` and `save_fmt` attributes) or SQL (automatically determined from `location`).### Dataset metadataMetadata for each dataset is held in Pandas MultiIndexes with the following:1. Indicator name2. Topic or area3. Frequency4. Currency5. Inflation adjustment6. Unit7. Seasonal adjustment8. Type (stock or flow)9. Cumulative periodsWhen writing, metadata can be included as dataset headers (Pandas MultiIndex columns), placed on another sheet if writing to Excel, or dropped. This is controlled by `read_header` and `save_header`.### Pipeline transformation methods`Pipeline` objects with a valid dataset can access 6 transformation methods that modify the held dataset.* `resample()` - resample data to a different frequency, taking into account whether data is of stock or flow type.* `chg_diff()` - calculate percent changes or differences for same period last year, last period or at annual rate.* `decompose()` - seasonally decompose series into trend or seasonally adjusted components.* `convert()` - convert to US dollars, constant prices or percent of GDP.* `rebase()` - set a period or window as 100, scale rest accordingly* `rolling()` - calculate rolling windows, either average or sum.```pythonfrom econuy.core import Pipelinep = Pipeline()p.get(&quot;balance_nfps&quot;)p.convert(flavor=&quot;usd&quot;)p.resample(rule=&quot;A-DEC&quot;, operation=&quot;sum&quot;)```### Saving the current datasetWhile `Pipeline.get()` will generally save the retrieved dataset to `location`, transformation methods won't automatically write data.However, `Pipeline.save()` can be used, which will overwrite the file on disk (or SQL table) with the contents in `dataset`.## The `Session()` classLike a `Pipeline`, except it can hold several datasets.The `datasets` attribute is a `dict` of name-DataFrame pairs. Additionally, `Session.get()` accepts a sequence of strings representing several datasets.Transformation and saving methods support a `select` parameter that determines which held datasets are considered.```pythonfrom econuy.session import Sessions = Session(location=&quot;your/directory&quot;)s.get([&quot;cpi&quot;, &quot;nxr_monthly&quot;])s.get(&quot;commodity_index&quot;)s.rolling(window=12, operation=&quot;mean&quot;, select=[&quot;nxr_monthly&quot;, &quot;commodity_index&quot;])````Session.get_bulk()` makes it easy to get several datasets in one line.```pythonfrom econuy.session import Sessions = Session()s.get_bulk(&quot;all&quot;)``````pythonfrom econuy.session import Sessions = Session()s.get_bulk(&quot;fiscal_accounts&quot;)````Session.concat()` combines selected datasets into a single DataFrame with a common frequency, and adds it as a new key-pair in `datasets`.## External binaries and libraries### unrar librariesThe [patool](https://github.com/wummel/patool) package is used in order to access data provided in `.rar` format. This package requires that you have the `unrar` binaries in your system, which in most cases you should already have. You can can get them from [here](https://www.rarlab.com/rar_add.htm) if you don't.### Selenium webdriversSome retrieval functions need Selenium to be configured in order to scrape data. These functions include a `driver` parameter in which a Selenium Webdriver can be passed, or they will attempt to configure a Chrome webdriver, even downloading the chromedriver binary if needed. This still requires an existing Chrome installation.----# Caveats and plans## CaveatsThis project is heavily based on getting data from online sources that could change without notice, causing methods that download data to fail. While I try to stay on my toes and fix these quickly, it helps if you create an issue when you find one of these (or even submit a fix!).## Plans* Implement a CLI.* ~~Provide methods to make keeping an updated database easy~~. `Session.get_bulk()` mostly covers this.* ~~Visualization.~~ (I have decided that visualization should be up to the end-user. However, the [webapp](https://econ.uy) is available for this purpose).* Translations for dataset descriptions and metadata.</longdescription>
</pkgmetadata>