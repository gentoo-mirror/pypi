<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Welcome to fastai================&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;![CI](https://github.com/fastai/fastai/workflows/CI/badge.svg)[![PyPI](https://img.shields.io/pypi/v/fastai?color=blue&amp;label=pypi%20version.png)](https://pypi.org/project/fastai/#description)[![Conda (channelonly)](https://img.shields.io/conda/vn/fastai/fastai?color=seagreen&amp;label=conda%20version.png)](https://anaconda.org/fastai/fastai)[![Build fastaiimages](https://github.com/fastai/docker-containers/workflows/Build%20fastai%20images/badge.svg)](https://github.com/fastai/docker-containers)![docs](https://github.com/fastai/fastai/workflows/docs/badge.svg)## InstallingYou can use fastai without any installation by using [GoogleColab](https://colab.research.google.com/). In fact, every page of thisdocumentation is also available as an interactive notebook - click “Openin colab” at the top of any page to open it (be sure to change the Colabruntime to “GPU” to have it run fast!) See the fast.ai documentation on[Using Colab](https://course.fast.ai/start_colab) for more information.You can install fastai on your own machines with conda (highlyrecommended), as long as you’re running Linux or Windows (NB: Mac is notsupported). For Windows, please see the “Running on Windows” forimportant notes.If you’re using[miniconda](https://docs.conda.io/en/latest/miniconda.html)(recommended) then run (note that if you replace `conda` with[mamba](https://github.com/mamba-org/mamba) the install process will bemuch faster and more reliable):``` bashconda install -c fastchan fastai```…or if you’re using[Anaconda](https://www.anaconda.com/products/individual) then run:``` bashconda install -c fastchan fastai anaconda```To install with pip, use: `pip install fastai`. If you install with pip,you should install PyTorch first by following the PyTorch [installationinstructions](https://pytorch.org/get-started/locally/).If you plan to develop fastai yourself, or want to be on the cuttingedge, you can use an editable install (if you do this, you should alsouse an editable install of[fastcore](https://github.com/fastai/fastcore) to go with it.) Firstinstall PyTorch, and then:    git clone https://github.com/fastai/fastai    pip install -e &quot;fastai[dev]&quot;## Learning fastaiThe best way to get started with fastai (and deep learning) is to read[thebook](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527),and complete [the free course](https://course.fast.ai).To see what’s possible with fastai, take a look at the [QuickStart](https://docs.fast.ai/quick_start.html), which shows how to usearound 5 lines of code to build an image classifier, an imagesegmentation model, a text sentiment model, a recommendation system, anda tabular model. For each of the applications, the code is much thesame.Read through the [Tutorials](https://docs.fast.ai/tutorial.html) tolearn how to train your own models on your own datasets. Use thenavigation sidebar to look through the fastai documentation. Everyclass, function, and method is documented here.To learn about the design and motivation of the library, read the [peerreviewed paper](https://www.mdpi.com/2078-2489/11/2/108/htm).## About fastaifastai is a deep learning library which provides practitioners withhigh-level components that can quickly and easily providestate-of-the-art results in standard deep learning domains, and providesresearchers with low-level components that can be mixed and matched tobuild new approaches. It aims to do both things without substantialcompromises in ease of use, flexibility, or performance. This ispossible thanks to a carefully layered architecture, which expressescommon underlying patterns of many deep learning and data processingtechniques in terms of decoupled abstractions. These abstractions can beexpressed concisely and clearly by leveraging the dynamism of theunderlying Python language and the flexibility of the PyTorch library.fastai includes:- A new type dispatch system for Python along with a semantic type  hierarchy for tensors- A GPU-optimized computer vision library which can be extended in pure  Python- An optimizer which refactors out the common functionality of modern  optimizers into two basic pieces, allowing optimization algorithms to  be implemented in 4–5 lines of code- A novel 2-way callback system that can access any part of the data,  model, or optimizer and change it at any point during training- A new data block API- And much more…fastai is organized around two main design goals: to be approachable andrapidly productive, while also being deeply hackable and configurable.It is built on top of a hierarchy of lower-level APIs which providecomposable building blocks. This way, a user wanting to rewrite part ofthe high-level API or add particular behavior to suit their needs doesnot have to learn how to use the lowest level.&lt;img alt=&quot;Layered API&quot; src=&quot;https://raw.githubusercontent.com/fastai/fastai/master/images/layered.png&quot; width=&quot;345&quot;&gt;## Migrating from other librariesIt’s very easy to migrate from plain PyTorch, Ignite, or any otherPyTorch-based library, or even to use fastai in conjunction with otherlibraries. Generally, you’ll be able to use all your existing dataprocessing code, but will be able to reduce the amount of code yourequire for training, and more easily take advantage of modern bestpractices. Here are migration guides from some popular libraries to helpyou on your way:- [Plain PyTorch](https://docs.fast.ai/examples/migrating_pytorch.html)- [Ignite](https://docs.fast.ai/examples/migrating_ignite.html)- [Lightning](https://docs.fast.ai/examples/migrating_lightning.html)- [Catalyst](https://docs.fast.ai/examples/migrating_catalyst.html)## Windows SupportWhen installing with `mamba` or `conda` replace `-c fastchan` in theinstallation with `-c pytorch -c nvidia -c fastai`, since fastchan isnot currently supported on Windows.Due to python multiprocessing issues on Jupyter and Windows,`num_workers` of `Dataloader` is reset to 0 automatically to avoidJupyter hanging. This makes tasks such as computer vision in Jupyter onWindows many times slower than on Linux. This limitation doesn’t existif you use fastai from a script.See [thisexample](https://github.com/fastai/fastai/blob/master/nbs/examples/dataloader_spawn.py)to fully leverage the fastai API on Windows.## TestsTo run the tests in parallel, launch:`nbdev_test`For all the tests to pass, you’ll need to install the dependenciesspecified as part of dev_requirements in settings.ini`pip install -e .[dev]`Tests are written using `nbdev`, for example see the documentation for`test_eq`.## ContributingAfter you clone this repository, make sure you have run`nbdev_install_hooks` in your terminal. This install Jupyter and githooks to automatically clean, trust, and fix merge conflicts innotebooks.After making changes in the repo, you should run `nbdev_prepare` andmake additional and necessary changes in order to pass all the tests.## Docker ContainersFor those interested in official docker containers for this project,they can be found[here](https://github.com/fastai/docker-containers#fastai).</longdescription>
</pkgmetadata>