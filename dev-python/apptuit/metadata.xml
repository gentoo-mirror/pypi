<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Python client for Apptuit.AI[![Build Status](https://www.travis-ci.org/ApptuitAI/apptuit-py.svg?branch=master)](https://www.travis-ci.org/ApptuitAI/apptuit-py)[![codecov](https://codecov.io/gh/ApptuitAI/apptuit-py/branch/master/graph/badge.svg)](https://codecov.io/gh/ApptuitAI/apptuit-py)[![PyPI](https://img.shields.io/pypi/v/apptuit.svg)](https://pypi.org/project/apptuit/)[![Pyversions](https://img.shields.io/pypi/pyversions/apptuit.svg?style=flat)](https://pypi.org/project/apptuit/)[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)## Installation```pip install apptuit --upgrade```## Dependencies**Requirements**  - `requests`, `pyformance` - installed automatically if you use `pip` to install apptuit  - `pandas` - not installed by default, you should install it manually if you intend to use the `query` API and  create dataframes using the `to_df()` method (see [Querying for Data](#querying-for-data))## Usage### Contents - [Introduction](#introduction)   * [Working with Apptuit Client](#working-with-apptuit-client)   * [Working with Apptuit Pyformance Reporter](#working-with-apptuit-pyformance-reporter)   * [Configuration](#configuration) - [Sending Data](#sending-data)   * [Sending data using Apptuit pyformance reporter](#sending-data-using-apptuit-pyformance-reporter)     * [Error Handling in ApptuitReporter](#error-handling-in-apptuitreporter)     * [Sending Tags/Metadata](#tagsmetadata)     * [About Host tag](#about-host-tag)     * [Restrictions on Tags](#restrictions-on-tags-and-metric-names)     * [Meta Metrics](#meta-metrics)     * [Python Process Metrics](#python-process-metrics) - [Sending Data using `send()` API](#sending-data-using-send-api) - [Sending Data using `send_timeseries()` API](#sending-data-using-send_timeseries-api) - [Querying for Data](#querying-for-data)### IntroductionThis package provides functionality to send timeseries data to Apptuit and also to query it.There are two main components - The Apptuit client - provides core functionality to query and send data- Apptuit pyformance reporter - provides a high level abstraction on top of the clientto make it easy for you to report metrics from your applications to Apptuit.It is based on Coda Hale's metrics design and provides primitives like`meter`, `gauge`, `counter` to accumulate and report data.It uses [Pyformance](https://github.com/omergertel/pyformance/) underneath.#### Working with Apptuit Client:The Apptuit client object can be created as simply as the following line:```pythonfrom apptuit import Apptuitclient = Apptuit(token=my_apptuit_token,                 global_tags={&quot;service&quot;: &quot;order-service&quot;},                 sanitize_mode=&quot;prometheus&quot;)```- `token`: should be your apptuit token- `global_tags`: should be the set of default tags you want to apply on all your data. It is an optional parameter- `sanitize_mode`: Is a string value which specifies the sanitization mode to be usedfor metric names and tag keys. You can set `sanitize_mode` to three values:    - `None`: disables sanitization.    - `apptuit`: set the sanitize mode to apptuit, which will replace    all the invalid characters with `_`. Valid characters in this mode are all    ASCII letters, digits, `/`, `-`, `.`, `_` and Unicode letters.    Anyhing else is invalid character.    - `prometheus`: set the sanitize mode to prometheus, which will replace    all the invalid characters with `_`. Valid characters in this mode are ASCII letters, digits    and `_`, anything else is considered invalid.Apart from these, the Apptuit constructor takes a couple of more optional parameters explained below:- `api_endpoint`: This should be the http endpoint for calling Apptuit apis. Normally you don't need to specify this and the default value is set to `https://api.apptuit.ai`.- `ignore_environ_tags`: This is False by default. It tells the client whether to look up forthe global tags in environment variables or not. Global tags are tags which are applied to all thedatapoints sent through the client. We will have more to say on this in the configuration section.The client provides two methods, `query` and `send`, which are described in the[Querying for Data](#querying-for-data) and[Sending data using send()](#sending-data-using-send-api) sections respectively.#### Working with Apptuit Pyformance ReporterThe apptuit pyformance reporter is an abstraction based on Code Hale's metrics. It provideshigh level primitives to accumulate data in the form of metrics such as `meter`, `timer`,`gauge` etc. and send to Apptuit. These things are described in moredetail in the [reporter section](#sending-data-using-apptuit-pyformance-reporter),here we will see how to create a reporter and various parameters it supports.```pythonfrom apptuit.pyformance import ApptuitReporterfrom pyformance import MetricsRegistryreporter_tags = {&quot;service&quot;: &quot;order-service&quot;}registry = MetricsRegistry()reporter = ApptuitReporter(token=&quot;my_apptuit_token&quot;,                           registry=registry,                           reporting_interval=60,                           tags=reporter_tags,                           collect_process_metrics=True,                           sanitize_mode=&quot;prometheus&quot;)```Here:- `token`: Is your Apptuit token- `registry`: Is an instance of MetricsRegistry (explained more in[reporter section](#sending-data-using-apptuit-pyformance-reporter))- `reporting_interval`: Number of seconds to wait before reporing again- `tags`: A dictionary of tag keys and values.These tags apply to all the metrics reported through this reporter.- `collect_process_metrics`: Is a boolean value which will enable or disable collection of various metrics related to the Python process (CPU, memory, GC, and threads). By defaultit is disabled, set this parameter to `True` to enable it.- `sanitize_mode`: This is same as the `sanitize_mode` parameter for theclient (see above in client usage example).#### ConfigurationAs we saw above, we need to pass the token and global tags as parameter to the Apptuit client when instantiating it. Alternatively we can set these asenvironment variables, so that we don't need to hard-code them in our code.These environment variables are described below.* `APPTUIT_API_TOKEN`: If the Apptuit client and the ApptuitReporter are not passed a token parameter they look for the token in this variable. If this variable is also not set, the client will raise`ApptuitException` to indicate about the missing token* `APPTUIT_TAGS`: This is an alternative for the `global_tags` parameter for the Apptuit client. If the Apptuit client does not receive a value for `global_tags` parameter it checks this environment variable. Both the `global_tags` parameterand `APPTUIT_TAGS` environment variable are strictly optional. If present, the Apptuit client adds those tags to everypoint it is sending.The format of the value of this variable is as follows:```shexport APPTUIT_TAGS=&quot;tag_key1: tag_val1, tag_key2: tag_val2, tag_key3: tag_val3&quot;```The spaces after the comma and colon are optional.The `APPTUIT_TAGS` variable is also read by the `ApptuitReporter`, which combines them with its reporter tags.In case of a conflict of same tag keys in both sets of tags, the reporter tag take preference.**Note**: Support for these variable was added in the version `1.0.0` of apptuit-py and is not availablein any of the earlier released versions.### Sending dataThere are two ways of sending the data to Apptuit. First is to use the `ApptuitReporter`, andthe second options is to use the `send()` method of the Apptuit client.We will show how to use both of the options below.### Sending data using Apptuit pyformance reporter```pythonimport socketfrom pyformance import MetricsRegistryfrom apptuit.pyformance.apptuit_reporter import ApptuitReporterclass OrderService:    def __init__(self, apptuit_token):        self.registry = MetricsRegistry()        self.init_reporter(apptuit_token, self.registry)    def init_reporter(self, token, registry):        hostname = socket.gethostname()        global_tags = {&quot;host&quot;: hostname, &quot;env&quot;: &quot;dev&quot;, &quot;service&quot;: &quot;order-service&quot;}        self.reporter = ApptuitReporter(registry=registry,                                    reporting_interval=60, # data reported every 1 minute                                    token=token,                                    tags=global_tags,                                    retry=2 #this will retry in case of 500 response or connection errors occur.                                    )        # reporter.start() will start reporting the data asynchronously based on the reporting_interval set.        self.reporter.start()    def handle_order(self, order):        order_counter = self.registry.counter(&quot;order_count&quot;)        # order handling related code        order_counter.inc()    def shutdown(self):        # you can stop the reporter when you no longer wish to send data or when shutting down        self.reporter.stop()```One thing worth pointing out in the above example:- In `handle_order` we create a new counter `order_counter` with the metric name `order_count`. The firsttime this method is called a new counter object will be created and registered with the registry. Forsubsequent calls, that counter will get reused since internally the registry will already have acounter with that name.####**MetricsRegistry**MetricsRegistry is the container for all the metrics in our application. We can use it to register and createvarious kinds of metrics (meter, gauge, counter etc.). For example:```pythonfrom pyformance import MetricsRegistryregistry = MetricsRegistry()counter = registry.counter(&quot;order_count&quot;)meter = registry.meter(&quot;order_requests_rate&quot;)timer = registry.timer(&quot;order_requests_processing_time&quot;)```Now, let's take a look at the different types of metrics and how to use them.**Meter**A meter measures the the rate of events, such as requests per second. Meter maintains the mean rate, and1-, 5-, 15- minute moving averages.```pythonfrom pyformance import MetricsRegistryregistry = MetricsRegistry()metric_name = &quot;order_requests_rate&quot;requests_meter = registry.meter(metric_name)def handle_request(request):    requests_meter.mark()    # handle request```**Gauge**A gauge is an instantaneous measurement of a value. For example, number of pending jobs in a queue.```pythonfrom queue import Queuefrom pyformance import MetricsRegistryfrom pyformance.meters.gauge import CallbackGaugeclass QueueManager:    def __init__(self, registry, name):        self.q = Queue()        jobs_metric = registry.add(name, CallbackGauge(self.get_queue_size))    def get_queue_size(self):        return self.q.size()```The reporter will call the `get_queue_size` function at its scheduled frequency and reportthe size of the queue.**Counter**A counter can be used to simply count some data. It provides two methods `inc()` to incrementits value and `dec()` to decrement it.```pythonfrom pyformance import MetricsRegistryregistry = MetricsRegistry()jobs_counter = registry.counter('pending_jobs')def add_job(self, job):    jobs_counter.inc(1)    self.q.put(job)def take_job(self):    jobs_counter.dec(1)    self.q.get()```**Timer**A timer aggregates timing durations and provides duration statistics, as well as throughput statistics.```pythonfrom pyformance import MetricsRegistryregistry = MetricsRegistry()timer = registry.timer(&quot;response_time&quot;)def handle_request(request):    with timer.time():        return &quot;OK&quot;```The above example will use the timer to report the time taken to serve each request.**Histogram**A histogram measures the statistical distribution of values in a stream of data. It provides aggregate datasuch as the min, max, mean, sum, and count.```pythonfrom pyformance import MetricsRegistryregistry = MetricsRegistry()response_sizes = registry.histogram('response_size')def handle_request(request):    response = do_query(request) # process the query    response_sizes.add(response.size())```#### Error Handling in ApptuitReporterThe ApptuitReporter sends data asynchronously (unless we are explicitly using it in synchronous modeby not calling the `start()` method). In asynchronousmode it is very difficult to know if the reporter is working properly or not. To make this easier the`ApptuitReporter` takes an `error_handler` argument. `error_handler` is expected to be a function referencewhich takes 4 arguments. The signature of the function and the arguments are explained below:```python  def error_handler(status_code, successful_points_count, failed_points_count, errors):    pass```- `status_code`: The HTTP status code of the POST API call to Apptuit- `successful_points_count`: Number of points successfully processed- `failed_points_count`: Number of points which could not be processed due to errors- `errors`: List of error messages describing the reason of failure of each of the failed pointsBy default, the `ApptuitReporter` registers a `default_error_handler`, which writes the errors to `stderr`.To override that you can pass your own error handler implementation, or if you don't wish to do anything for errorsyou can pass `None` for the `error_handler` argument.**Reporter with default error handler**```pythonimport logging#reporter with default error handler (writes to stderr)reporter = ApptuitReporter(token=my_apptuit_token,                           registry=registry,                           reporting_interval=60,                           tags=reporter_tags)```**Reporter with No error handler**```pythonreporter_with_no_error_handler = ApptuitReporter(                            token=my_apptuit_token,                            registry=registry,                            reporting_interval=60,                            tags=reporter_tags,                            error_handler=None                            )```The error handler function by definition takes only four arguments.If you wish to pass extra arguments to the error handler you can useclosures or partial functions to get around the limitation.**Passing extra argument using Partial**```pythonimport loggingfrom functools import partialdef custom_error_handler(logger, status_code, successful, failed, errors):    logger.error(&quot;ApptuitReporter failed to send %d points, due to errors: %s&quot; % (failed, str(errors)))logger = logging.getLogger(&quot;logger key&quot;)apptuit_custom_error_handler = partial(custom_error_handler, logger)reporter = ApptuitReporter(            token=my_apptuit_token,            registry=registry,            reporting_interval=60,            tags=reporter_tags,            error_handler=apptuit_custom_error_handler            )```**Passing extra argument using closure**```python...import loggingfrom apptuit import ApptuitSendExceptionfrom apptuit.pyformance.apptuit_reporter import ApptuitReporter...class OrderService:    def __init__(self, apptuit_token):        ...        self.logger = logging.getLogger(&quot;OrderService&quot;)        ...    def init_reporter(self, token, registry):        ...        def apptuit_error_handler(status_code, successful, failed, errors):            logger = self.logger            logger.error(str(ApptuitSendException(                status_code, successful, failed, errors            )))        self.reporter = ApptuitReporter(...,                                    error_handler=apptuit_error_handler)        ...```#### Tags/MetadataWhen creating the ApptuitReporter, you can provide a set of tags (referred as reporter tags from now on)which will be part of all the metrics reported by that reporter. However, in order to provide tagsspecific to each metric you need to provide them when registering the metric with the registry. For example:```pythonfrom apptuit import timeseriesfrom pyformance import MetricsRegistryregistry = MetricsRegistry()metric_name = &quot;node_cpu&quot;tags = {&quot;type&quot;: &quot;idle&quot;, &quot;host&quot;: &quot;node-foo&quot;, &quot;service&quot;: &quot;order-service&quot;}metric = timeseries.encode_metric(metric_name, tags)meter = registry.meter(metric)```Here we provided the metric specific tags by calling `timeseries.encode_metric` andproviding the metric name and the tags as parameters. When registering the metric we provide thisencoded name to the registry instead of the plain metric name.To decode an encoded metric name use the `decode_metric()` function from `timeseries` module.```pythonfrom apptuit import timeseriesencoded_metric = timeseries.encode_metric(&quot;node.cpu&quot;, {&quot;type&quot;: &quot;idle&quot;})metric_name, tags = timeseries.decode_metric(encoded_metric)```A *recommended practise* is to maintain a local cache of the created metrics and reuse them, rather thancreating them every time:```pythonimport socketimport timefrom apptuit import timeseriesfrom apptuit.pyformance import ApptuitReporterfrom pyformance import MetricsRegistryclass OrderService:    def __init__(self, apptuit_token):        self.registry = MetricsRegistry()        self.init_reporter(apptuit_token, self.registry)        self.order_counters = {}    def init_reporter(self, token, registry):        hostname = socket.gethostname()        global_tags = {&quot;host&quot;: hostname, &quot;env&quot;: &quot;dev&quot;, &quot;service&quot;: &quot;order-service&quot;}        self.reporter = ApptuitReporter(registry=registry,                                    reporting_interval=60, # data reported every 1 minute                                    token=token,                                    tags=global_tags)        # reporter.start() will start reporting the data asynchronously based on the reporting_interval set.        self.reporter.start()    def get_order_counter(self, city_code):        # We have counters for every city code        if city_code not in self.order_counters:            tags = {&quot;city-code&quot;: city_code}            metric = timeseries.encode_metric(&quot;order_count&quot;, tags=tags)            self.order_counters[city_code] = self.registry.counter(metric)        return self.order_counters[city_code]    def handle_order(self, order):        order_counter = self.get_order_counter(order.city_code)        order_counter.inc()        self.process_order(order)    def shutdown(self):        # you can stop the reporter when you no longer wish to send data or when shutting down        self.reporter.stop()    def process_order(self, order):        time.sleep(5)```Here we have a method `get_order_counter` which takes the `city_code` as a parameter. Thereis a local cache of counters keyed by the encoded metric names. This avoids the unnecessary overheadof encoding the metric name and tags every time, if we already have created a counter for that city.It also ensures that we will report separate time-series for order-counts of different city codes.#### About Host TagThe reporter will add a `host` tag key with host name as its value (obtained by calling `socket.gethostname()`).This is helpful in order to group the metrics by host if the reporter is being run on multiple servers. The valueof the `host` tag key can be overridden by passing our own `host` tag in the `tags` parameter to the reporter orby setting a `host` tag in the global environment variable for tagsIf we don't wish for the `host` tag to be set by default we can disable it by setting the`disable_host_tag` parameter of the reporter to `True`. Alternatively we can set the environmentvariable `APPTUIT_DISABLE_HOST_TAG` to `True` to disable it.#### Restrictions on Tags and Metric names- **Allowed characters in tag keys and metric names** - Tag keys and metric names can have any unicode etters (as defined by unicode specification) and the following special characters:  `.`, `-`, `_`, `/`.However, if we are looking to follow Prometheus compliant naming([see specification])(https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)we should restrict them to ASCII letters, digits and  underscores only and it must match theregex `[a-zA-Z_][a-zA-Z0-9_]*`. No such restriction is applicable on tag values.- **Maximum number of tags** - Apptuit currently allows upto 25 tag key-value pairs per datapoint#### Meta MetricsThe `ApptuitReporter` also reports a set of meta metrics which can be a useful indicator if the reporter is working as expected or not, as well as to get a sense of how many points are being sent and the latency ofthe Apptuit API. These meta metrics are described below.- `apptuit_reporter_send_total` - Total number of points sent- `apptuit_reporter_send_successful` - Number of points which were succssfully processed- `apptuit_reporter_send_failed` - Number of points which failed- `apptuit_reporter_send_time` - Timing stats of of the send API#### Python Process MetricsThe `ApptutiReporter` can also be configured to report various metrics ofthe Python process it is running in. By default it is disabled but we can enable it bypassing setting the parameter `collect_process_metrics` to `True` when creating thereporter object. The reporter will collect metrics related to the system resource usageby the process (cpu, memory, IPC etc.) as well as metrics related to garbage collectionand threads. The complete list of all the metrics collected is provided below:- `python_cpu_time_used_seconds` - Total time spent by the process in user mode and system mode.- `python_memory_usage_bytes` - Total amount of memory used by the process.- `python_page_faults` - Total number of page faults received by the process.- *`python_process_swaps` - Total number of times the process was swapped-out of the main memory.- `python_block_operations` - Total number of block input and output operations.- `python_ipc_messages` - Total number of inter-process messages sent and received by the process. - *`python_system_signals` - Total number of signals received by the process.- `python_context_switches` - Total number of context switches of the process.- `python_thread` - Count of active, demon and dummy threads.- `python_gc_collection` - Count of objects collected in gc for each generation. - `python_gc_threshold` - Value of garbage collector threshold for each generation.**Note** - Metrics marked with `*` are zero on Linux because it does not support them#### Global tags, reporter tags and metric tagsWhen using the reporter we have three sets of tags, it's better to clarify a few things about them.- `ApptuitReporter` takes a set of tags as parameter. It adds these tags to all the metrics it is reporting.- If the environment variable `APPTUIT_TAGS` is set, the reporter takes those into account as well, howeverthe tags passed to it take preference in case of a conflict because of common tag keys.- Each metric being reported by the reporter might also have some tags attached, in case of a conflictbecause of common tag keys, the metric tags take preference over reporter or global tags.#### Sending data using send() APIApart from using the Pyformance reporter, you can also use the low level `send()` API from the apptuitclient to directly send the data. If you want tags while sending you can use the global_tagsparameter of Apptuit class. If global_tags are set then environmental tags will not be used.```pythonfrom apptuit import Apptuit, DataPointimport timeimport randomimport sockettoken = &quot;mytoken&quot;client = Apptuit(token=token)metrics = [&quot;proc.cpu.percent&quot;, &quot;node.memory.bytes&quot;, &quot;network.send.bytes&quot;, &quot;network.receive.bytes&quot;, &quot;node.load.avg&quot;]tags = {&quot;host&quot;: socket.gethostname()}curtime = int(time.time())dps = []while True:    curtime = int(time.time())    for metric in metrics:        dps.append(DataPoint(metric, tags, curtime, random.random()))    if len(dps) == 100:        client.send(dps,                 retry_count=3 #this will retry in case of 500 response or connection errors occur.            )        dps = []    time.sleep(60)```#### Sending data using send_timeseries() APIThe `send` API works with a list of DataPoint objects. Creating each DataPoint object involves validating the metric name andthe tags. If we are creating thousands of DataPoint objects with the metric name and tags, it can quickly get very expensive.In order to avoid that overhead, there is an alternative `send_timeseries` API as well, which accepts a list of `TimeSeries`objects. This is much more convenient as we need to create a `TimeSeries` object with a metric name and tags. Thereafterwe can add points to that timeseries object by calling its `add_point()` method. This avoids creation of DataPoint objectsand the overhead of the tag validation.Following is an example from a scraper we run internally. We call an HTTP API, get a JSON response and send it to us in theform of timeseries. In order to avoid too many API calls to Apptuit we call `send_timeseries` whenever we have accumulated50000 or more points. Once we make a `send_timeseries` call we reset the `series_list` object to contain just the latest`TimeSeries` object (all the earlier series would have been sent to Apptuit).```pythonfrom apptuit import Apptuit, TimeSeriesseries_list = []points_count = 0token = &quot;mytoken&quot;client = Apptuit(token=token)response_data = make_request()for result in response_data[&quot;results&quot;]:    metric_name = result[&quot;metric&quot;]    tags = result[&quot;tags&quot;]    series = TimeSeries(metric_name, tags)    series_list.append(series)    for timestamp, value in result[&quot;values&quot;]:        series.add_point(timestamp, value)        points_count += 1        if points_count &gt;= 50000:            client.send_timeseries(series_list)            points_count = 0            series_list = [TimeSeries(metric_name, tags)]if points_count &gt; 0:    client.send_timeseries(series_list)```### Querying for data```pythonfrom apptuit import Apptuitimport timetoken = 'my_token' # replace with your Apptuit tokenapptuit = Apptuit(token=token)start_time = int(time.time()) - 3600 # let's query for data going back 1 hour from nowquery_res = apptuit.query(&quot;fetch('proc.cpu.percent').downsample('1m', 'avg')&quot;, start=start_time                            retry_count=3 #this will retry in case of 500 response or connection errors occur.                        )# we can create a Pandas dataframe from the result object by calling to_df()df = query_res[0].to_df()# Another way of creating the DF is accessing by the metric name in the queryanother_df = query_res['proc.cpu.percent'].to_df()```It should be noted that using the `to_df()` method requires that you have `pandas` installed.We don't install `pandas` by default as part of the requirements because not every user of the librarywould want to query or create dataframes (many users just use the `send` API or the reporter functionality)</longdescription>
</pkgmetadata>