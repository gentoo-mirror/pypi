<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;    &lt;h1 align=&quot;center&quot;&gt;üß∂ Disent&lt;/h1&gt;    &lt;p align=&quot;center&quot;&gt;        &lt;i&gt;A modular disentangled representation learning framework built with PyTorch Lightning&lt;/i&gt;    &lt;/p&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://choosealicense.com/licenses/mit/&quot; target=&quot;_blank&quot;&gt;        &lt;img alt=&quot;license&quot; src=&quot;https://img.shields.io/github/license/nmichlo/disent?style=flat-square&amp;color=lightgrey&quot;/&gt;    &lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/disent&quot; target=&quot;_blank&quot;&gt;        &lt;img alt=&quot;python versions&quot; src=&quot;https://img.shields.io/pypi/pyversions/disent?style=flat-square&quot;/&gt;    &lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/disent&quot; target=&quot;_blank&quot;&gt;        &lt;img alt=&quot;pypi version&quot; src=&quot;https://img.shields.io/pypi/v/disent?style=flat-square&amp;color=blue&quot;/&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/nmichlo/disent/actions?query=workflow%3Atests&quot;&gt;        &lt;img alt=&quot;tests status&quot; src=&quot;https://github.com/nmichlo/disent/actions/workflows/python-tests.yml/badge.svg&quot;/&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/psf/black&quot; target=&quot;_blank&quot;&gt;        &lt;img alt=&quot;Code style: black&quot; src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot;/&gt;    &lt;/a&gt;    &lt;a href=&quot;https://pycqa.github.io/isort&quot; target=&quot;_blank&quot;&gt;        &lt;img alt=&quot;Imports: isort&quot; src=&quot;https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&amp;labelColor=ef8336&quot;/&gt;    &lt;/a&gt;&lt;!--     &lt;a href=&quot;https://codecov.io/gh/nmichlo/disent/&quot;&gt; --&gt;&lt;!--         &lt;img alt=&quot;code coverage&quot; src=&quot;https://img.shields.io/codecov/c/gh/nmichlo/disent?token=86IZK3J038&amp;style=flat-square&quot;/&gt; --&gt;&lt;!--     &lt;/a&gt; --&gt;&lt;!--     &lt;a href=&quot;https://github.com/nmichlo/disent&quot;&gt; --&gt;&lt;!--         &lt;img alt=&quot;last commit&quot; src=&quot;https://img.shields.io/github/last-commit/nmichlo/disent?style=flat-square&amp;color=lightgrey&quot;/&gt; --&gt;&lt;!--     &lt;/a&gt; --&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    &lt;p align=&quot;center&quot;&gt;        Visit the &lt;a href=&quot;https://disent.michlo.dev/&quot; target=&quot;_blank&quot;&gt;docs&lt;/a&gt; for more info, or browse the  &lt;a href=&quot;https://github.com/nmichlo/disent/releases&quot;&gt;releases&lt;/a&gt;.    &lt;/p&gt;    &lt;p align=&quot;center&quot;&gt;        &lt;a href=&quot;https://github.com/nmichlo/disent/issues/new/choose&quot;&gt;Contributions&lt;/a&gt; are welcome!    &lt;/p&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    &lt;br/&gt;    &lt;i&gt;&lt;b&gt; NOTE:&lt;/b&gt; My MSc. research has moved &lt;a href=&quot;https://github.com/nmichlo/msc-research&quot;&gt;here&lt;/a&gt;&lt;/i&gt;    &lt;br/&gt;    &lt;i&gt;Some of the contributions have been incorporated directly into disent&lt;/i&gt;    &lt;br/&gt;    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ&lt;/p&gt;----------------------## Table Of Contents- [Overview](#overview)- [Features](#features)    * [Datasets](#datasets)    * [Frameworks](#frameworks)    * [Metrics](#metrics)    * [Schedules &amp; Annealing](#schedules--annealing)- [Architecture](#architecture)- [Examples](#examples)    * [Python Example](#python-example)    * [Hydra Config Example](#hydra-config-example)- [Install](#install)- [Development](#development)- [Why?](#why)----------------------## OverviewDisent is a modular disentangled representation learning framework for auto-encoders,built upon PyTorch-Lightning. This framework consists of various composable componentsthat can be used to build and benchmark various disentanglement vision tasks.&gt; The name of the framework is derived from both **disent**anglement and scientific **dissent**.Get started with disent by installing it with $`pip install disent` or cloning this repository.### GoalsDisent aims to fill the following criteria:1. Provide **high quality**, **readable**, **consistent** and **easily comparable** implementations of frameworks2. **Highlight difference** between framework implementations by overriding **hooks** and minimising duplicate code 3. Use **best practice** eg. `torch.distributions`4. Be extremely **flexible** &amp; configurable5. Support low memory systems### Citing DisentPlease use the following citation if you use Disent in your own research:```bibtex@Misc{Michlo2021Disent,  author =       {Nathan Juraj Michlo},  title =        {Disent - A modular disentangled representation learning framework for pytorch},  howpublished = {Github},  year =         {2021},  url =          {https://github.com/nmichlo/disent}}```----------------------## FeaturesDisent includes implementations of modules, metrics anddatasets from various papers._Note that &quot;üßµ&quot; means that the dataset, framework or metric was introduced by disent!_### DatasetsVarious common datasets used in disentanglement research are included with disent. The dataset loaders provide various features including:- automatic downloads &amp; preperation `prepare=True`- automatic hash verification- automatic optimization of underlying hdf5 formats forlow-memory disk-based access.Data input and target dataset augmentations and transforms are supported, as well as augmentationson the GPU or CPU at different points in the pipeline.- **Ground Truth**:  + &lt;details&gt;    &lt;summary&gt;üöó &lt;a href=&quot;https://papers.nips.cc/paper/5845-deep-visual-analogy-making&quot; target=&quot;_blank&quot;&gt;Cars3D&lt;/a&gt;&lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__cars3d.jpg&quot; alt=&quot;Cars3D Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details&gt;    &lt;summary&gt;‚óªÔ∏è &lt;a href=&quot;https://github.com/deepmind/dsprites-dataset&quot; target=&quot;_blank&quot;&gt;dSprites&lt;/a&gt;&lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__dsprites.jpg&quot; alt=&quot;dSprites Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details&gt;    &lt;summary&gt;üî∫ &lt;a href=&quot;https://arxiv.org/abs/1906.03292&quot; target=&quot;_blank&quot;&gt;MPI3D&lt;/a&gt;&lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__mpi3d-real.jpg&quot; alt=&quot;MPI3D-Real Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details&gt;    &lt;summary&gt;üêò &lt;a href=&quot;https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/&quot; target=&quot;_blank&quot;&gt;SmallNORB&lt;/a&gt;&lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__smallnorb.jpg&quot; alt=&quot;Small Norb Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details&gt;    &lt;summary&gt;üåà &lt;a href=&quot;https://github.com/deepmind/3d-shapes&quot; target=&quot;_blank&quot;&gt;Shapes3D&lt;/a&gt;&lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__shapes3d.jpg&quot; alt=&quot;Shapes3D Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details&gt;    &lt;summary&gt;üèπ &lt;a href=&quot;https://github.com/YingzhenLi/Sprites&quot; target=&quot;_blank&quot;&gt;Sprites (custom)&lt;/a&gt;&lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__sprites.jpg&quot; alt=&quot;Sprites (Custom) Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details open&gt;    &lt;summary&gt;      üßµ &lt;u&gt;dSpritesImagenet&lt;/u&gt;:      &lt;i&gt;Version of DSprite with foreground or background deterministically masked out with tiny-imagenet data.&lt;/i&gt;    &lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__dsprites-imagenet-bg-100.jpg&quot; alt=&quot;dSpritesImagenet Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;- **Ground Truth Synthetic**:  + &lt;details open&gt;    &lt;summary&gt;      üßµ &lt;u&gt;XYSquares&lt;/u&gt;:      &lt;i&gt;Three non-overlapping squares that can move around a grid. This dataset is adversarial to VAEs that use pixel-wise reconstruction losses.&lt;/i&gt;    &lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__xy-squares__spacing8.jpg&quot; alt=&quot;XYSquares Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details&gt;    &lt;summary&gt;      üßµ &lt;u&gt;XYObject&lt;/u&gt;:      &lt;i&gt;A simplistic version of dSprites with a single square.&lt;/i&gt;    &lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__xy-object.jpg&quot; alt=&quot;XYObject Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;  + &lt;details open&gt;    &lt;summary&gt;      üßµ &lt;u&gt;XYObjectShaded&lt;/u&gt;:      &lt;i&gt;Exact same dataset as XYObject, but ground truth factors have a different representation.&lt;/i&gt;    &lt;/summary&gt;    &lt;p align=&quot;center&quot;&gt;&lt;img height=&quot;192&quot; src=&quot;docs/img/traversals/traversal-transpose__xy-object-shaded.jpg&quot; alt=&quot;XYObjectShaded Dataset Factor Traversals&quot;&gt;&lt;/p&gt;  &lt;/details&gt;### FrameworksDisent provides the following Auto-Encoders and Variational Auto-Encoders!- **Unsupervised**:  + &lt;u&gt;AE&lt;/u&gt;: _Auto-Encoder_  + [VAE](https://arxiv.org/abs/1312.6114): Variational Auto-Encoder  + [Beta-VAE](https://openreview.net/forum?id=Sy2fzU9gl): VAE with Scaled Loss  + [DFC-VAE](https://arxiv.org/abs/1610.00291): Deep Feature Consistent VAE  + [DIP-VAE](https://arxiv.org/abs/1711.00848): Disentangled Inferred Prior VAE  + [InfoVAE](https://arxiv.org/abs/1706.02262): Information Maximizing VAE  + [BetaTCVAE](https://arxiv.org/abs/1802.04942): Total Correlation VAE- **Weakly Supervised**:  + [Ada-GVAE](https://arxiv.org/abs/2002.02886): Adaptive GVAE, *`AdaVae.cfg(average_mode='gvae')`*, usually better than below!  + [Ada-ML-VAE](https://arxiv.org/abs/2002.02886): Adaptive ML-VAE, *`AdaVae.cfg(average_mode='ml-vae')`*- **Supervised**:  + &lt;u&gt;TAE&lt;/u&gt;: _Triplet Auto-Encoder_  + [TVAE](https://arxiv.org/abs/1802.04403): Triplet Variational Auto-EncoderIntroduced in Disent- **Unsupervised**:  + üßµ &lt;u&gt;Ada-TVAE-D&lt;/u&gt;: Adaptive Triplet VAE that uses data distances instead of ground-truth distances as the supervision signal.  + üßµ &lt;u&gt;Ada-TAE-D&lt;/u&gt;:  Adaptive Triplet AE that uses data distances instead of ground-truth distances as the supervision signal.- **Weakly Supervised**:  + üßµ &lt;u&gt;Ada-AE&lt;/u&gt;: Adaptive AE, the auto-encoder version of the Ada-GVAE- **Supervised**:  + üßµ &lt;u&gt;Ada-TVAE&lt;/u&gt;: Adaptive Triplet VAE, disentangled version of the TVAE  + üßµ &lt;u&gt;Ada-TAE&lt;/u&gt;:  Adaptive Triplet AE, disentangled version of the TAE&lt;details&gt;&lt;summary&gt;&lt;b&gt;üèó Todo&lt;/b&gt;: &lt;i&gt;Many popular disentanglement frameworks still need to be added, pleasesubmit an issue if you have a request for an additional framework.&lt;/i&gt;&lt;/summary&gt;&lt;p&gt;+ FactorVAE+ GroupVAE+ MLVAE&lt;/p&gt;&lt;/details&gt;### MetricsVarious metrics are provided by disent that can be used to evaluate thelearnt representations of models that have been trained on ground-truth data. - **Disentanglement**:  + [FactorVAE Score](https://arxiv.org/abs/1802.05983)  + [DCI](https://openreview.net/forum?id=By-7dz-AZ)  + [MIG](https://arxiv.org/abs/1802.04942)  + [SAP](https://arxiv.org/abs/1711.00848)  + [Unsupervised Scores](https://github.com/google-research/disentanglement_lib)  + üßµ &lt;u&gt;Flatness Components&lt;/u&gt;: _Measures of the three components needed to learn factored representations from distances. VAEs often learn the first two (correlation &amp; linearity), and the can happen accidentally (axis-alignment)!_    - ü™° &lt;u&gt;Ground-Truth Correlation&lt;/u&gt; - _The spearman rank correlation between latent distances and ground-truth distances._    - ü™° &lt;u&gt;Linearity Ratio&lt;/u&gt; - _How well factor traversals lie along an n-dimensional arbitrarily rotated line in the latent space_    - ü™° &lt;u&gt;Axis-Alignment Ratio&lt;/u&gt; - _How well factor traversals are represented by a single latent variable, ie. an n-dimensional line that is axis-aligned._  + üßµ &lt;u&gt;Flatness Score&lt;/u&gt; - _Measuring the max distance between factor traversal embeddings and the path length of their embeddings._&lt;details&gt;&lt;summary&gt;&lt;b&gt;üèó Todo&lt;/b&gt;: &lt;i&gt;Some popular metrics still need to be added, please submit an issue if you wish toadd your own, or you have a request.&lt;/i&gt;&lt;/summary&gt;&lt;p&gt;+ [DCIMIG](https://arxiv.org/abs/1910.05587)+ [Modularity and Explicitness](https://arxiv.org/abs/1802.05312)&lt;/p&gt;&lt;/details&gt;### Schedules &amp; AnnealingHyper-parameter annealing is supported through the use of schedules.The currently implemented schedules include:- Linear Schedule- [Cyclic](https://arxiv.org/abs/1903.10145) Schedule- Cosine Wave Schedule- *Various other wrapper schedules*----------------------## ArchitectureThe disent module structure:- `disent.dataset`: dataset wrappers, datasets &amp; sampling strategies    + `disent.dataset.data`: raw datasets    + `disent.dataset.sampling`: sampling strategies for `DisentDataset` when multiple elements are required by frameworks, eg. for triplet loss    + `disent.dataset.transform`: common data transforms and augmentations    + `disent.dataset.wrapper`: wrapped datasets are no longer ground-truth datasets, these may have some elements masked out. We can still unwrap these classes to obtain the original datasets for benchmarking.- `disent.frameworks`: frameworks, including Auto-Encoders and VAEs    + `disent.frameworks.ae`: Auto-Encoder based frameworks    + `disent.frameworks.vae`: Variational Auto-Encoder based frameworks- `disent.metrics`: metrics for evaluating disentanglement using ground truth datasets- `disent.model`: common encoder and decoder models used for VAE research- `disent.nn`: torch components for building models including layers, transforms, losses and general maths- `disent.schedule`: annealing schedules that can be registered to a framework- `disent.util`: helper classes, functions, callbacks, anything unrelated to a pytorch system/model/framework.**‚ö†Ô∏è The API Is _Mostly_ Stable ‚ö†Ô∏è**Disent is still under development. Features and APIs are subject to change!However, I will try and minimise the impact of these.A small suite of tests currently exist which will be expanded upon in time.**Hydra Experiment Directories**Easily run experiments with hydra config, these filesare not available from `pip install`.- `experiment/run.py`: entrypoint for running basic experiments with [hydra](https://github.com/facebookresearch/hydra) config- `experiment/config/config.yaml`: main configuration file, this is probably what you want to edit!- `experiment/config`: root folder for [hydra](https://github.com/facebookresearch/hydra) config files- `experiment/util`: various helper code for experiments**Extending The Default Configs**All configs in `experiment/config` can easily be extended or overriddenwithout modifying any files. We can add a new config folder to the hydra search pathby setting the environment variable `DISENT_CONFIGS_PREPEND` to point to a config folderthat should take priority over those contained in the default folder.The advantage of this is that new frameworks and datasets can be used with experiments without cloning or modifyingdisent itself. You can separate your research code from the library!- See the examples in the docs for more information!----------------------## Examples### Python ExampleThe following is a basic working example of disent that trains a BetaVAE with a cyclicbeta schedule and evaluates the trained model with various metrics.&lt;details&gt;&lt;summary&gt;&lt;b&gt;üíæ Basic Example&lt;/b&gt;&lt;/summary&gt;&lt;p&gt;```python3import lightning as Limport torchfrom torch.utils.data import DataLoaderfrom disent.dataset import DisentDatasetfrom disent.dataset.data import XYObjectDatafrom disent.dataset.sampling import SingleSamplerfrom disent.dataset.transform import ToImgTensorF32from disent.frameworks.vae import BetaVaefrom disent.metrics import metric_dcifrom disent.metrics import metric_migfrom disent.model import AutoEncoderfrom disent.model.ae import DecoderConv64from disent.model.ae import EncoderConv64from disent.schedule import CyclicSchedule# create the dataset &amp; dataloaders# - ToImgTensorF32 transforms images from numpy arrays to tensors and performs checks# - if you use `num_workers != 0` in the DataLoader, the make sure to#   wrap `trainer.fit` with `if __name__ == '__main__': ...`data = XYObjectData()dataset = DisentDataset(dataset=data, sampler=SingleSampler(), transform=ToImgTensorF32())dataloader = DataLoader(dataset=dataset, batch_size=128, shuffle=True, num_workers=0)# create the BetaVAE model# - adjusting the beta, learning rate, and representation size.module = BetaVae(    model=AutoEncoder(        # z_multiplier is needed to output mu &amp; logvar when parameterising normal distribution        encoder=EncoderConv64(x_shape=data.x_shape, z_size=10, z_multiplier=2),        decoder=DecoderConv64(x_shape=data.x_shape, z_size=10),    ),    cfg=BetaVae.cfg(        optimizer='adam',        optimizer_kwargs=dict(lr=1e-3),        loss_reduction='mean_sum',        beta=4,    ))# cyclic schedule for target 'beta' in the config/cfg. The initial value from the# config is saved and multiplied by the ratio from the schedule on each step.# - based on: https://arxiv.org/abs/1903.10145module.register_schedule(    'beta', CyclicSchedule(        period=1024,  # repeat every: trainer.global_step % period    ))# train model# - for 2048 batches/stepstrainer = L.Trainer(    max_steps=2048, gpus=1 if torch.cuda.is_available() else None, logger=False, enable_checkpointing=False)trainer.fit(module, dataloader)# compute disentanglement metrics# - we cannot guarantee which device the representation is on# - this will take a while to runget_repr = lambda x: module.encode(x.to(module.device))metrics = {    **metric_dci(dataset, get_repr, num_train=1000, num_test=500, show_progress=True),    **metric_mig(dataset, get_repr, num_train=2000),}# evaluateprint('metrics:', metrics)```&lt;/p&gt;&lt;/details&gt;Visit the [docs](https://disent.michlo.dev) for more examples!### Hydra Config ExampleThe entrypoint for basic experiments is `experiment/run.py`.Some configuration will be required, but basic experiments canbe adjusted by modifying the [Hydra Config 1.1](https://github.com/facebookresearch/hydra)files in `experiment/config`.Modifying the main `experiment/config/config.yaml` is all youneed for most basic experiments. The main config file containsa defaults list with entries corresponding to yaml configurationfiles (config options) in the subfolders (config groups) in`experiment/config/&lt;config_group&gt;/&lt;option&gt;.yaml`.&lt;details&gt;&lt;summary&gt;&lt;b&gt;üíæ Config Defaults Example&lt;/b&gt;&lt;/summary&gt;&lt;p&gt;```yamldefaults:  # data  - sampling: default__bb  - dataset: xyobject  - augment: none  # system  - framework: adavae_os  - model: vae_conv64  # training  - optimizer: adam  - schedule: beta_cyclic  - metrics: fast  - run_length: short  # logs  - run_callbacks: vis  - run_logging: wandb  # runtime  - run_location: local  - run_launcher: local  - run_action: train# &lt;rest of config.yaml left out&gt;...```&lt;/p&gt;&lt;/details&gt;Easily modify  any of these values to adjust how the basic experimentwill be run. For example, change `framework: adavae` to `framework: betavae`, orchange the dataset from `xyobject` to `shapes3d`. Add new options by adding newyaml files in the config group folders.[Weights and Biases](https://docs.wandb.ai/quickstart) is supported by changing `run_logging: none` to`run_logging: wandb`. However, you will need to login from the command line. W&amp;B logging supportsvisualisations of latent traversals.----------------------### Install```bashpip install disent```Otherwise, to install from source we recommend using a conda virtual environment.&lt;details&gt;&lt;summary&gt;&lt;b&gt;‚§µÔ∏è Install from Source&lt;/b&gt;&lt;/summary&gt;```bash# clone the repogit clone https://github.com/nmichlo/disentcd disent# create and activate the conda environment [py38,py39,py310]conda create -n disent-py310 python=3.10conda activate disent-py310# check that the correct python version is usedwhich pythonwhich pip# make sure to upgrade pippip install --upgrade pip# install minimal requirementspip install -r requirements.txt# (optional) install extra requirements# - first do the above because torch is required to compile torchsort while installingpip install -r requirements-extra.txt# (optional) install test requirementspip install -r requirements-test.txt```&lt;/details&gt;----------------------### Development[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&amp;labelColor=ef8336)](https://pycqa.github.io/isort/)Make sure to install `pre-commit` hooks to ensure code is automatically formattedcorrectly when committing or pushing changes to `disent`.```bash# install git hookspip install pre-commitpre-commit install# manually trigger all pre-commit hookspre-commit run --all-files```To run tests locally, make sure to install all the test and extra dependencies in yourenvironment.```bashpip install -r requirements.txt# torchsort first requires torch to be installedpip install -r requirements-extra.txt -r requirements-test.txt```----------------------### Why?  - Created as part of my Computer Science MSc which ended early 2022.- I needed custom high quality implementations of various VAE's.- A pytorch version of [disentanglement_lib](https://github.com/google-research/disentanglement_lib).- I didn't have time to wait for [Weakly-Supervised Disentanglement Without Compromises](https://arxiv.org/abs/2002.02886) to release  their code as part of disentanglement_lib. (As of September 2020 it has been released, but has unresolved [discrepencies](https://github.com/google-research/disentanglement_lib/issues/31)).- disentanglement_lib still uses outdated Tensorflow 1.0, and the flow of data is unintuitive because of its use of [Gin Config](https://github.com/google/gin-config).----------------------</longdescription>
</pkgmetadata>