<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># cleanlab-studio [![Build Status](https://github.com/cleanlab/cleanlab-studio/workflows/CI/badge.svg)](https://github.com/cleanlab/cleanlab-studio/actions?query=workflow%3ACI) [![PyPI](https://img.shields.io/pypi/v/cleanlab-studio.svg)][PyPI]Command line and Python library interface to [Cleanlab Studio](https://cleanlab.ai/studio/). Upload datasets and download cleansets (cleaned datasets) from Cleanlab Studio in a single line of code!- [Installation](#installation)- [Quickstart](#quickstart)- [Advanced Usage](#advanced-usage)## InstallationYou can install the Cleanlab Studio client [from PyPI][PyPI] with:```bashpip install cleanlab-studio```If you already have the client installed and wish to upgrade to the latest version, run:```bashpip install --upgrade cleanlab-studio```## Quickstart### Python APIYou can find your API key at https://app.cleanlab.ai/account.```pythonimport cleanlab_studio# create your Cleanlab Studio API client with your API key, found here: https://app.cleanlab.ai/accountstudio = Studio(&lt;your api key&gt;)# upload your dataset via a filepath, Pandas DataFrame, or PySpark DataFrame!dataset_id: str = studio.upload_dataset(&lt;your dataset&gt;, &lt;your dataset name&gt;)# navigate to Cleanlab Studio, create a project, and improve your labels# download your cleanset or apply corrections to your local Pandas or PySpark dataset!# you can find your cleanset ID by clicking on the Export Cleanset button in your projectcleanset = studio.download_cleanlab_columns(&lt;your cleanset id&gt;)corrected_dataset = studio.apply_corrections(&lt;your dataset&gt;, &lt;your cleanset id&gt;)```### CLI1. If this is your first time using the Cleanlab CLI, authenticate with `cleanlab login`. You can find your API key at https://app.cleanlab.ai/account.2. Upload your dataset (image, text, or tabular) using `cleanlab dataset upload`.3. Create a project in Cleanlab Studio.4. Improve your dataset in Cleanlab Studio (e.g., correct some labels).5. Download your cleanset with `cleanlab cleanset download`.## Dataset StructureCleanlab Studio supports the following upload types:- Text/Tabular  - CSV  - JSON  - XLS/XLSX  - Pandas DataFrame *(Python library only)*  - PySpark DataFrame *(Python library only)*  - more to come!- Image  - CSV (external media)  - JSON (external media)  - XLS/XLSX (external media)  - Pandas DataFrame (external media) *(Python library only)*  - PySpark DataFrame (external media) *(Python library only)*  - Simple ZIP upload  - Metadata ZIP upload  - more to come!Information on dataset structuring can be found by clicking the tutorial on https://app.cleanlab.ai/upload!## Advanced Usage### Schema#### Python APIAll schema information will be inferred by default when uploading a dataset through the Python API. We provide some options to override the inferred schema if necessary:- To override the dataset modality, supply a `modality` kwarg to `studio.upload_dataset()`. Supported modalities include &quot;text&quot;, &quot;tabular&quot;, and &quot;image&quot;- To override the ID column, supply an `id_column` kwarg to `studio.upload_dataset()`- To override column types in your dataset, supply a `schema_overrides` kwarg to `studio.upload_dataset()` in the following format:```{  &lt;name_of_column_to_override&gt;: {    &quot;data_type&quot;: &lt;desired_data_type&gt;,    &quot;feature_type&quot;: &lt;desired_feature_type&gt;,  },  ...}```#### CLITo specify the column types in your dataset, create a JSON file named `schema.json`. If you would like to edit an inferred schema (rather than starting from scratch) follow these steps:1. Kick off a dataset upload using: `cleanlab dataset upload`2. Once schema generation is complete, you'll be asked whether you'd like to use our inferred schema. Enter `n` to decline3. You'll then be asked whether you'd like to save the inferred schema. Enter `y` to accept. Then enter the filename you'd like to save to (`schema.json` by default)4. Edit the schema file as you wish5. Kick off a dataset upload again using: `cleanlab dataset upload --schema_path [path to schema file]`Your schema file should be formatted as follows:```json{  &quot;metadata&quot;: {    &quot;id_column&quot;: &quot;tweet_id&quot;,    &quot;modality&quot;: &quot;text&quot;,    &quot;name&quot;: &quot;Tweets.csv&quot;  },  &quot;fields&quot;: {    &quot;tweet_id&quot;: {      &quot;data_type&quot;: &quot;string&quot;,      &quot;feature_type&quot;: &quot;identifier&quot;    },    &quot;sentiment&quot;: {      &quot;data_type&quot;: &quot;string&quot;,      &quot;feature_type&quot;: &quot;categorical&quot;    },    &quot;sentiment_confidence&quot;: {      &quot;data_type&quot;: &quot;float&quot;,      &quot;feature_type&quot;: &quot;numeric&quot;    },    &quot;retweet_count&quot;: {      &quot;data_type&quot;: &quot;integer&quot;,      &quot;feature_type&quot;: &quot;numeric&quot;    },    &quot;text&quot;: {      &quot;data_type&quot;: &quot;string&quot;,      &quot;feature_type&quot;: &quot;text&quot;    },    &quot;tweet_created&quot;: {      &quot;data_type&quot;: &quot;boolean&quot;,      &quot;feature_type&quot;: &quot;boolean&quot;    },    &quot;tweet_created&quot;: {      &quot;data_type&quot;: &quot;string&quot;,      &quot;feature_type&quot;: &quot;datetime&quot;    },  },  &quot;version&quot;: &quot;0.1.12&quot;}```This is the schema of a hypothetical dataset `Tweets.csv` that contains tweets, where the column `tweet_id` contains aunique identifier for each record. Each column in the dataset is specified under `fields` with its data type and featuretype.#### Data types and Feature types**Data type** refers to the type of the field's values: string, integer, float, or boolean.Note that the integer type is partially *strict*, meaning floats that are equal to integers (e.g. `1.0`, `2.0`, etc)will be accepted, but floats like `0.8` and `1.5` will not. In contrast, the float type is *lenient*, meaning integersare accepted. Users should select the float type if the field may include float values. Note too that integers can havecategorical and identifier feature types, whereas floats cannot.For booleans, the list of accepted values are: true/false, t/f, yes/no, 1/0, 1.0/0.0.**Feature type** refers to the secondary type of the field, relating to how it is used in a machine learning model, suchas whether it is:- a categorical value- a numeric value- a datetime value- a boolean value- text- an identifier â€” a string / integer that identifies some entity- a filepath value (only valid for image datasets)Some feature types can only correspond to specific data types. The list of possible feature types for each data type isshown below| Data type  | Feature type                                         ||:-----------|:-----------------------------------------------------|| string     | text, categorical, datetime, identifier, filepath    || integer    | categorical, datetime, identifier, numeric           || float      | datetime, numeric                                    || boolean    | boolean                                              |The `datetime` type should be used for datetime strings, e.g. &quot;2015-02-24 11:35:52 -0800&quot;, and Unix timestamps (whichwill be integers or floats). Datetime values must be parseableby [polars.from_epoch](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.from_epoch.html) for integer/floats or [polars.Expr.str.strptime](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.Expr.str.strptime.html) for strings.`version` indicates the version of the Cleanlab CLI package version used to generate the schema.[PyPI]: https://pypi.org/project/cleanlab-studio/</longdescription>
</pkgmetadata>