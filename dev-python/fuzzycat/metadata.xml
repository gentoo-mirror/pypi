<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;&lt;!-- Photo is CC BY 2.0 by Chika Watanabe from flickr --&gt;&lt;a href=&quot;https://www.flickr.com/photos/chikawatanabe/192112067&quot;&gt;&lt;img src=&quot;static/192112067_046be9fd21_b.jpg&quot;&gt;&lt;/a&gt;&lt;/div&gt;`fuzzycat`: bibliographic fuzzy matching for fatcat.wiki========================================================![https://pypi.org/project/fuzzycat/](https://img.shields.io/pypi/v/fuzzycat?style=flat-square)This Python library contains routines for finding near-duplicate bibliographicentities (primarily research papers), and estimating whether two metadatarecords describe the same work (or variations of the same work). Some routinesare designed to work &quot;offline&quot; with batches of billions of sorted metadatarecords, and others are designed to work &quot;online&quot; making queries against hostedweb services and catalogs.`fuzzycat` was originally developed by Martin Czygan at the Internet Archive,and is used in the construction of a [citationgraph](https://gitlab.com/internetarchive/refcat) and to identify duplicaterecords in the [fatcat.wiki](https://fatcat.wiki) catalog and[scholar.archive.org](https://scholar.archive.org) search index.**DISCLAIMER:** this tool is still under development, as indicated by the &quot;0&quot;major version. The interface, semantics, and behavior are likely to be tweaked.## QuickstartInside a `virtualenv` (or similar), install with [pip](https://pypi.org/project/pip/):```pip install fuzzycat```The `fuzzycat.simple` module contains high-level helpers which query InternetArchive hosted services:    import elasticsearch    from fuzzycat.simple import *    es_client = elasticsearch.Elasticsearch(&quot;https://search.fatcat.wiki:443&quot;)    # parses reference using GROBID (at https://grobid.qa.fatcat.wiki),    # then queries Elasticsearch (at https://search.fatcat.wiki),    # then scores candidates against latest catalog record fetched from    #  https://api.fatcat.wiki    best_match = closest_fuzzy_unstructured_match(        &quot;&quot;&quot;Cunningham HB, Weis JJ, Taveras LR, Huerta S. Mesh migration following abdominal hernia repair: a comprehensive review. Hernia. 2019 Apr;23(2):235-243. doi: 10.1007/s10029-019-01898-9. Epub 2019 Jan 30. PMID: 30701369.&quot;&quot;&quot;,        es_client=es_client)    print(best_match)    # FuzzyReleaseMatchResult(status=&lt;Status.EXACT: 'exact'&gt;, reason=&lt;Reason.DOI: 'doi'&gt;, release={...})    # same as above, but without the GROBID parsing, and returns multiple results    matches = close_fuzzy_biblio_matches(        dict(            title=&quot;Mesh migration following abdominal hernia repair: a comprehensive review&quot;,            first_author=&quot;Cunningham&quot;,            year=2019,            journal=&quot;Hernia&quot;,        ),        es_client=es_client,    )A CLI tool is included for processing records in UNIX stdin/stdout pipelines:    # print usage    python -m fuzzycat## Features and Use-CasesThe [refcat project](https://gitlab.com/internetarchive/refcat) builds on topof this library to build a citation graph by processing billions of structuredand unstructured reference records extracted from scholarly papers (note: jforperformance critical parts, some code has been ported to Go, albeit the testsuite is shared between the Python and Go implementations).Automated imports of metadata records into the fatcat catalog use fuzzycat tofilter new metadata which look like duplicates of existing records from othersources.In conjunction with standard command-line tools (like `sort`), fatcat bulkmetadata snapshots can be clustered and reduced into groups to flag duplicaterecords for merging.Extracted reference strings from any source (webpages, books, papers, wikis,databases, etc) can be resolved against the fatcat catalog of scholarly papers.## Support and AcknowledgementsWork on this software received support from the Andrew W. Mellon Foundationthrough multiple phases of the [&quot;Ensuring the Persistent Access of Open AccessJournal Literature&quot;](https://mellon.org/grants/grants-database/advanced-search/?amount-low=&amp;amount-high=&amp;year-start=&amp;year-end=&amp;city=&amp;state=&amp;country=&amp;q=%22Ensuring+the+Persistent+Access%22&amp;per_page=25) project (see [original announcement](http://blog.archive.org/2018/03/05/andrew-w-mellon-foundation-awards-grant-to-the-internet-archive-for-long-tail-journal-preservation/)).Additional acknowledgements [at fatcat.wiki](https://fatcat.wiki/about).</longdescription>
</pkgmetadata>