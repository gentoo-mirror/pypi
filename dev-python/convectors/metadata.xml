<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Convectors: build end-to-end NLP pipelines==========Inspired by the Keras syntax, Convectors allows you to build NLP pipelines by adding different processing Layers.Fully compatible with pandas and Keras, it can either process list or pandas series on the fly, or apply processing to a whole DataFrame by using columns as inputs and outputs. Tensorflow's Keras models can be added as a layer, embedded and saved within a larger end-to-end NLP model.```pip install convectors```Simple classification example=====In this basic example, we create an NLP pipeline for a sequence classification task:```pythonfrom convectors import load_modelfrom convectors.layers import Argmax, Keras, Sequence, Tokenizefrom sklearn.datasets import fetch_20newsgroupsfrom tensorflow.keras.layers import LSTM, Dense, Embeddingfrom tensorflow.keras.models import Sequential# load datatraining_set = fetch_20newsgroups(subset=&quot;train&quot;)testing_set = fetch_20newsgroups(subset=&quot;test&quot;)# create encoder modelencoder = Tokenize(stopwords=[&quot;en&quot;])encoder += Sequence(max_features=20000, pad=True, maxlen=200)# get and transform training dataX_train = encoder(training_set.data)  # fit and transformy_train = training_set.target  # get training data# infer number of features and classesN_FEATURES = encoder[&quot;Sequence&quot;].n_features + 1N_CLASSES = y_train.max() + 1EMBEDDING_DIM = 32# create keras model and fitmodel = Sequential()model.add(Embedding(N_FEATURES, EMBEDDING_DIM, mask_zero=True))model.add(LSTM(32, activation=&quot;tanh&quot;, return_sequences=False))model.add(Dense(32, activation=&quot;tanh&quot;))model.add(Dense(N_CLASSES, activation=&quot;softmax&quot;))model.compile(&quot;nadam&quot;, &quot;sparse_categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;])model.fit(X_train, y_train, epochs=1, batch_size=800)# once learned, add Keras modelencoder += Keras(model=model, trained=True)encoder += Argmax()encoder.verbose = False  # turn verbosity off# for model persistence:encoder.save(&quot;model.p&quot;)encoder = load_model(&quot;model.p&quot;)# predict for new datay_pred = encoder(testing_set.data)y_true = testing_set.target# print accuracyprint((y_pred == y_true).mean())```</longdescription>
</pkgmetadata>