<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![rave_logo](docs/rave.png)# RAVE: Realtime Audio Variational autoEncoderOfficial implementation of _RAVE: A variational autoencoder for fast and high-quality neural audio synthesis_ ([article link](https://arxiv.org/abs/2111.05011)) by Antoine Caillon and Philippe Esling.If you use RAVE as a part of a music performance or installation, be sure to cite either this repository or the article !If you want to share / discuss / ask things about RAVE you can do so in our [discord server](https://discord.gg/dhX73sPTBb) !## Previous versionsThe original implementation of the RAVE model can be restored using```bashgit checkout v1```## InstallationInstall RAVE using```bashpip install acids-rave```You will need **ffmpeg** on your computer. You can install it locally inside your virtual environment using```bashconda install ffmpeg```&lt;!-- Detailed instructions to setup a training station for this project are available [here](docs/training_setup.md). --&gt;## ColabA colab to train RAVEv2 is now available thanks to [hexorcismos](https://github.com/moiseshorta) ![![colab_badge](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ih-gv1iHEZNuGhHPvCHrleLNXvooQMvI?usp=sharing)## UsageTraining a RAVE model usually involves 3 separate steps, namely _dataset preparation_, _training_ and _export_.### Dataset preparationYou can know prepare a dataset using two methods: regular and lazy. Lazy preprocessing allows RAVE to be trained directly on the raw files (i.e. mp3, ogg), without converting them first. **Warning**: lazy dataset loading will increase your CPU load by a large margin during training, especially on Windows. This can however be useful when training on large audio corpus which would not fit on a hard drive when uncompressed. In any case, prepare your dataset using```bashrave preprocess --input_path /audio/folder --output_path /dataset/path (--lazy)```### TrainingRAVEv2 has many different configurations. The improved version of the v1 is called `v2`, and can therefore be trained with```bashrave train --config v2 --db_path /dataset/path --name give_a_name```We also provide a discrete configuration, similar to SoundStream or EnCodec```bashrave train --config discrete ...```By default, RAVE is built with non-causal convolutions. If you want to make the model causal (hence lowering the overall latency of the model), you can use the causal mode```bashrave train --config discrete --config causal ...```Many other configuration files are available in `rave/configs` and can be combined. Here is a list of all the available configurations&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Type&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=6&gt;Architecture&lt;/td&gt;&lt;td&gt;v1&lt;/td&gt;&lt;td&gt;Original continuous model&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;v2&lt;/td&gt;&lt;td&gt;Improved continuous model (faster, higher quality)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;v3&lt;/td&gt;&lt;td&gt;v2 with Snake activation, descript discriminator and Adaptive Instance Normalization for real style transfer&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;discrete&lt;/td&gt;&lt;td&gt;Discrete model (similar to SoundStream or EnCodec)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;onnx&lt;/td&gt;&lt;td&gt;Noiseless v1 configuration for onnx usage&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;raspberry&lt;/td&gt;&lt;td&gt;Lightweight configuration compatible with realtime RaspberryPi 4 inference&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=3&gt;Regularization (v2 only)&lt;/td&gt;&lt;td&gt;default&lt;/td&gt;&lt;td&gt;Variational Auto Encoder objective (ELBO)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;wasserstein&lt;/td&gt;&lt;td&gt;Wasserstein Auto Encoder objective (MMD)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;spherical&lt;/td&gt;&lt;td&gt;Spherical Auto Encoder objective&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=1&gt;Discriminator&lt;/td&gt;&lt;td&gt;spectral_discriminator&lt;/td&gt;&lt;td&gt;Use the MultiScale discriminator from EnCodec.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=2&gt;Others&lt;/td&gt;&lt;td&gt;causal&lt;/td&gt;&lt;td&gt;Use causal convolutions&lt;/td&gt;&lt;/tr&lt;tr&gt;&lt;td&gt;noise&lt;/td&gt;&lt;td&gt;Enable noise synthesizer V2&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;### ExportOnce trained, export your model to a torchscript file using```bashrave export --run /path/to/your/run (--streaming)```Setting the `--streaming` flag will enable cached convolutions, making the model compatible with realtime processing. **If you forget to use the streaming mode and try to load the model in Max, you will hear clicking artifacts.**## Realtime usageThis section presents how RAVE can be loaded inside [`nn~`](https://acids-ircam.github.io/nn_tilde/) in order to be used live with Max/MSP or PureData.### ReconstructionA pretrained RAVE model named `darbouka.gin` available on your computer can be loaded inside `nn~` using the following syntax, where the default method is set to forward (i.e. encode then decode)&lt;img src=&quot;docs/rave_method_forward.png&quot; width=400px/&gt;This does the same thing as the following patch, but slightly faster.&lt;img src=&quot;docs/rave_encode_decode.png&quot; width=210px /&gt;### High-level manipulationHaving an explicit access to the latent representation yielded by RAVE allows us to interact with the representation using Max/MSP or PureData signal processing tools:&lt;img src=&quot;docs/rave_high_level.png&quot; width=310px /&gt;### Style transferBy default, RAVE can be used as a style transfer tool, based on the large compression ratio of the model. We recently added a technique inspired from StyleGAN to include Adaptive Instance Normalization to the reconstruction process, effectively allowing to define *source* and *target* styles directly inside Max/MSP or PureData, using the attribute system of `nn~`.&lt;img src=&quot;docs/rave_attribute.png&quot; width=550px&gt;Other attributes, such as `enable` or `gpu` can enable/disable computation, or use the gpu to speed up things (still experimental).## Pretrained modelsSeveral pretrained streaming models [are available here](https://acids-ircam.github.io/rave_models_download). We'll keep the list updated with new models.## Where is the prior ?[Here !](https://github.com/caillonantoine/msprior)## DiscussionIf you have questions, want to share your experience with RAVE or share musical pieces done with the model, you can use the [Discussion tab](https://github.com/acids-ircam/RAVE/discussions) !## Demonstration### RAVE x nn~Demonstration of what you can do with RAVE and the nn~ external for maxmsp ![![RAVE x nn~](http://img.youtube.com/vi/dMZs04TzxUI/mqdefault.jpg)](https://www.youtube.com/watch?v=dMZs04TzxUI)### embedded RAVEUsing nn~ for puredata, RAVE can be used in realtime on embedded platforms ![![RAVE x nn~](http://img.youtube.com/vi/jAIRf4nGgYI/mqdefault.jpg)](https://www.youtube.com/watch?v=jAIRf4nGgYI)# FundingThis work is led at IRCAM, and has been funded by the following projects- [ANR MakiMono](https://acids.ircam.fr/course/makimono/)- [ACTOR](https://www.actorproject.org/)- [DAFNE+](https://dafneplus.eu/) NÂ° 101061548&lt;img src=&quot;https://ec.europa.eu/regional_policy/images/information-sources/logo-download-center/eu_co_funded_en.jpg&quot; width=200px/&gt;</longdescription>
</pkgmetadata>