<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Rhino Speech-to-Intent EngineMade in Vancouver, Canada by [Picovoice](https://picovoice.ai)Rhino is Picovoice's Speech-to-Intent engine. It directly infers intent from spoken commands within a given context ofinterest, in real-time. For example, given a spoken command:&gt; Can I have a small double-shot espresso?Rhino infers that the user would like to order a drink and emits the following inference result:```json{  &quot;isUnderstood&quot;: &quot;true&quot;,  &quot;intent&quot;: &quot;orderBeverage&quot;,  &quot;slots&quot;: {    &quot;beverage&quot;: &quot;espresso&quot;,    &quot;size&quot;: &quot;small&quot;,    &quot;numberOfShots&quot;: &quot;2&quot;  }}```Rhino is:* using deep neural networks trained in real-world environments.* compact and computationally-efficient, making it perfect for IoT.* self-service. Developers and designers can train custom models using [Picovoice Console](https://console.picovoice.ai/).## Compatibility- Python 3.5+- Runs on Linux (x86_64), Mac (x86_64, arm64), Windows (x86_64), Raspberry Pi (all variants), and BeagleBone.## Installation```consolepip3 install pvrhino```## AccessKeyRhino requires a valid Picovoice `AccessKey` at initialization. `AccessKey` acts as your credentials when using Rhino SDKs.You can get your `AccessKey` for free. Make sure to keep your `AccessKey` secret.Signup or Login to [Picovoice Console](https://console.picovoice.ai/) to get your `AccessKey`.## UsageCreate an instance of the engine:```pythonimport pvrhinoaccess_key = &quot;${ACCESS_KEY}&quot; # AccessKey obtained from Picovoice Console (https://console.picovoice.ai/)handle = pvrhino.create(access_key=access_key, context_path='/absolute/path/to/context')```Where `context_path` is the absolute path to Speech-to-Intent context created either using[Picovoice Console](https://console.picovoice.ai/) or one of the default contexts available on Rhino's GitHub repository.The sensitivity of the engine can be tuned using the `sensitivity` parameter. It is a floating-point number within[0, 1]. A higher sensitivity value results in fewer misses at the cost of (potentially) increasing the erroneousinference rate.```pythonimport pvrhinoaccess_key = &quot;${ACCESS_KEY}&quot; # AccessKey obtained from Picovoice Console (https://console.picovoice.ai/)handle = pvrhino.create(access_key=access_key, context_path='/absolute/path/to/context', sensitivity=0.25)```When initialized, the valid sample rate is given by `handle.sample_rate`. Expected frame length (number of audio samplesin an input array) is `handle.frame_length`. The engine accepts 16-bit linearly-encoded PCM and operates onsingle-channel audio.```pythondef get_next_audio_frame():    passwhile True:    is_finalized = rhino.process(get_next_audio_frame())    if is_finalized:        inference = rhino.get_inference()        if not inference.is_understood:            # add code to handle unsupported commands            pass        else:            intent = inference.intent            slots = inference.slots            # add code to take action based on inferred intent and slot values```When done resources have to be released explicitly:```pythonhandle.delete()```## Non-English ContextsIn order to run inference on non-English contexts you need to use the corresponding model file. The model files for all supported languages are available [here](../../lib/common).## Demos[pvrhinodemo](https://pypi.org/project/pvrhinodemo/) provides command-line utilities for processing real-timeaudio (i.e. microphone) and files using Rhino.</longdescription>
</pkgmetadata>