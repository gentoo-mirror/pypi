<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![](https://img.shields.io/pypi/v/whatlies)![](https://img.shields.io/pypi/pyversions/whatlies)![](https://img.shields.io/github/license/koaning/whatlies)[![Downloads](https://pepy.tech/badge/whatlies)](https://pepy.tech/project/whatlies)# whatliesA library that tries to help you to understand (note the pun).&gt; &quot;What lies in word embeddings?&quot;This small library offers tools to make visualisation easier of bothword embeddings as well as operations on them.## Produced&lt;img src=&quot;docs/square-logo.svg&quot; width=75 height=75 align=&quot;right&quot;&gt;This project was initiated at [Rasa](https://rasa.com) as a by-product ofour efforts in the developer advocacy and research teams. The project is maintained by [koaning](https://github.com/koaning) in order to support more use-cases. ## FeaturesThis library has tools to help you understand what lies in word embeddings. This includes:- simple tools to create (interactive) visualisations- support for many language backends including spaCy, fasttext, tfhub, huggingface and bpemb- lightweight scikit-learn featurizer support for all these backends## InstallationYou can install the package via pip;```bashpip install whatlies```This will install the base dependencies. Depending on thetransformers and language backends that you'll be using youmay want to install more. Here's some of the possible installationsettings you could go for.```bashpip install whatlies[spacy]pip install whatlies[tfhub]pip install whatlies[transformers]```If you want it all you can also install via;```bashpip install whatlies[all]```Note that this will install dependencies but it**will not** install all the language models you mightwant to visualise. For example, you might stillneed to manually download spaCy models if you intendto use that backend.## Getting StartedMore in depth getting started guides can be found on the [documentation page](https://koaning.github.io/whatlies/).## ExamplesThe idea is that you can load embeddings from a language backendand use mathematical operations on it.```pythonfrom whatlies import EmbeddingSetfrom whatlies.language import SpacyLanguagelang = SpacyLanguage(&quot;en_core_web_md&quot;)words = [&quot;cat&quot;, &quot;dog&quot;, &quot;fish&quot;, &quot;kitten&quot;, &quot;man&quot;, &quot;woman&quot;,         &quot;king&quot;, &quot;queen&quot;, &quot;doctor&quot;, &quot;nurse&quot;]emb = EmbeddingSet(*[lang[w] for w in words])emb.plot_interactive(x_axis=emb[&quot;man&quot;], y_axis=emb[&quot;woman&quot;])```![](docs/gif-zero.gif)You can even do fancy operations. Like projecting onto and awayfrom vector embeddings! You can perform these on embeddings aswell as sets of embeddings.  In the example below we attemptto filter away gender bias using linear algebra operations.```pythonorig_chart = emb.plot_interactive('man', 'woman')new_ts = emb | (emb['king'] - emb['queen'])new_chart = new_ts.plot_interactive('man', 'woman')```![](docs/gif-one.gif)There's also things like **pca** and **umap**.```pythonfrom whatlies.transformers import Pca, Umaporig_chart = emb.plot_interactive('man', 'woman')pca_plot = emb.transform(Pca(2)).plot_interactive()umap_plot = emb.transform(Umap(2)).plot_interactive()pca_plot | umap_plot```![](docs/gif-two.gif)## Scikit-Learn SupportEvery language backend in this video is available as a scikit-learn featurizer as well.```pythonimport numpy as npfrom whatlies.language import BytePairLanguagefrom sklearn.pipeline import Pipelinefrom sklearn.linear_model import LogisticRegressionpipe = Pipeline([    (&quot;embed&quot;, BytePairLanguage(&quot;en&quot;)),    (&quot;model&quot;, LogisticRegression())])X = [    &quot;i really like this post&quot;,    &quot;thanks for that comment&quot;,    &quot;i enjoy this friendly forum&quot;,    &quot;this is a bad post&quot;,    &quot;i dislike this article&quot;,    &quot;this is not well written&quot;]y = np.array([1, 1, 1, 0, 0, 0])pipe.fit(X, y)```## DocumentationTo learn more and for a getting started guide, check out the [documentation](https://koaning.github.io/whatlies/).## Similar ProjectsThere are some similar projects out and we figured it fair to mention and compare them here.&lt;details&gt;  &lt;summary&gt;&lt;b&gt;Julia Bazi≈Ñska &amp; Piotr Migdal Web App&lt;/b&gt;&lt;/summary&gt;    &lt;p&gt;The original inspiration for this project came from &lt;a href=&quot;https://lamyiowce.github.io/word2viz/&quot;&gt;this web app&lt;/a&gt;    and &lt;a href=&quot;https://www.youtube.com/watch?v=AGgCqpouKSs&quot;&gt;this pydata talk&lt;/a&gt;. It is a web app that takes a    while to load but it is really fun to play with. The goal of this project is to make it easier to make similar    charts from jupyter using different language backends.&lt;/p&gt;&lt;/details&gt;&lt;details&gt;    &lt;summary&gt;&lt;b&gt;Tensorflow Projector&lt;/b&gt;&lt;/summary&gt;    &lt;p&gt;From google there's the &lt;a href=&quot;https://projector.tensorflow.org/&quot;&gt;tensorflow projector project&lt;/a&gt;. It offers    highly interactive 3d visualisations as well as some transformations via tensorboard.&lt;/p&gt;    &lt;ul&gt;    &lt;li&gt;The tensorflow projector will create projections in tensorboard, which you can also load    into jupyter notebook but whatlies makes visualisations directly.&lt;/li&gt;    &lt;li&gt;The tensorflow projector supports interactive 3d visuals, which whatlies currently doesn't.&lt;/li&gt;    &lt;li&gt;Whatlies offers lego bricks that you can chain together to get a visualisation started. This    also means that you're more flexible when it comes to transforming data before visualising it.&lt;/li&gt;    &lt;/ul&gt;&lt;/details&gt;&lt;details&gt;    &lt;summary&gt;&lt;b&gt;Parallax&lt;/b&gt;&lt;/summary&gt;    &lt;p&gt;From Uber AI Labs there's &lt;a href=&quot;https://github.com/uber-research/parallax&quot;&gt;parallax&lt;/a&gt; which is described    in a paper &lt;a href=&quot;https://arxiv.org/abs/1905.12099&quot;&gt;here&lt;/a&gt;. There's a common mindset in the two tools;    the goal is to use arbitrary user defined projections to understand embedding spaces better.    That said, some differences that are worth to mention.&lt;/p&gt;    &lt;ul&gt;    &lt;li&gt;It relies on bokeh as a visualisation backend and offers a lot of visualisation types    (like radar plots). Whatlies uses altair and tries to stick to simple scatter charts.    Altair can export interactive html/svg but it will not scale as well if you've drawing    many points at the same time.&lt;/li&gt;    &lt;li&gt;Parallax is meant to be run as a stand-alone app from the command line while Whatlies is    meant to be run from the jupyter notebook.&lt;/li&gt;    &lt;li&gt;Parallax gives a full user interface while Whatlies offers lego bricks that you can chain    together to get a visualisation started.&lt;/li&gt;    &lt;li&gt;Whatlies relies on language backends (like spaCy, huggingface) to fetch word embeddings.    Parallax allows you to instead fetch raw files on disk.&lt;/li&gt;    &lt;li&gt;Parallax has been around for a while, Whatlies is more new and therefore more experimental.&lt;/li&gt;    &lt;/ul&gt;&lt;/details&gt;## Local DevelopmentIf you want to develop locally you can start by running this command.```bashmake develop```### DocumentationThis is generated via```make docs```### CitationPlease use the following citation when you found `whatlies` helpful for any of your work (find the `whatlies` paper [here](https://www.aclweb.org/anthology/2020.nlposs-1.8)):```@inproceedings{warmerdam-etal-2020-going,    title = &quot;Going Beyond {T}-{SNE}: Exposing whatlies in Text Embeddings&quot;,    author = &quot;Warmerdam, Vincent  and      Kober, Thomas  and      Tatman, Rachael&quot;,    booktitle = &quot;Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS)&quot;,    month = nov,    year = &quot;2020&quot;,    address = &quot;Online&quot;,    publisher = &quot;Association for Computational Linguistics&quot;,    url = &quot;https://www.aclweb.org/anthology/2020.nlposs-1.8&quot;,    doi = &quot;10.18653/v1/2020.nlposs-1.8&quot;,    pages = &quot;52--60&quot;,    abstract = &quot;We introduce whatlies, an open source toolkit for visually inspecting word and sentence embeddings. The project offers a unified and extensible API with current support for a range of popular embedding backends including spaCy, tfhub, huggingface transformers, gensim, fastText and BytePair embeddings. The package combines a domain specific language for vector arithmetic with visualisation tools that make exploring word embeddings more intuitive and concise. It offers support for many popular dimensionality reduction techniques as well as many interactive visualisations that can either be statically exported or shared via Jupyter notebooks. The project documentation is available from https://koaning.github.io/whatlies/.&quot;,}```</longdescription>
</pkgmetadata>