<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>*****************************************************************testscenarios: extensions to python unittest to support scenarios*****************************************************************  Copyright (c) 2009, Robert Collins &lt;robertc@robertcollins.net&gt;    Licensed under either the Apache License, Version 2.0 or the BSD 3-clause  license at the users choice. A copy of both licenses are available in the  project source as Apache-2.0 and BSD. You may not use this file except in  compliance with one of these two licences.    Unless required by applicable law or agreed to in writing, software  distributed under these licenses is distributed on an &quot;AS IS&quot; BASIS, WITHOUT  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the  license you chose for the specific language governing permissions and  limitations under that license.testscenarios provides clean dependency injection for python unittest styletests. This can be used for interface testing (testing many implementations viaa single test suite) or for classic dependency injection (provide tests withdependencies externally to the test code itself, allowing easy testing indifferent situations).Dependencies============* Python 2.6+* testtools &lt;https://launchpad.net/testtools&gt;Why TestScenarios=================Standard Python unittest.py provides on obvious method for running a singletest_foo method with two (or more) scenarios: by creating a mix-in thatprovides the functions, objects or settings that make up the scenario. This ishowever limited and unsatisfying. Firstly, when two projects are cooperatingon a test suite (for instance, a plugin to a larger project may want to runthe standard tests for a given interface on its implementation), then it iseasy for them to get out of sync with each other: when the list of TestCaseclasses to mix-in with changes, the plugin will either fail to run some testsor error trying to run deleted tests. Secondly, its not as easy to work withruntime-created-subclasses (a way of dealing with the aforementioned skew)because they require more indirection to locate the source of the test, and willoften be ignored by e.g. pyflakes pylint etc.It is the intent of testscenarios to make dynamically running a single testin multiple scenarios clear, easy to debug and work with even when the listof scenarios is dynamically generated.Defining Scenarios==================A **scenario** is a tuple of a string name for the scenario, and a dict ofparameters describing the scenario.  The name is appended to the test name, andthe parameters are made available to the test instance when it's run.Scenarios are presented in **scenario lists** which are typically Python listsbut may be any iterable.Getting Scenarios applied=========================At its heart the concept is simple. For a given test object with a list ofscenarios we prepare a new test object for each scenario. This involves:* Clone the test to a new test with a new id uniquely distinguishing it.* Apply the scenario to the test by setting each key, value in the scenario  as attributes on the test object.There are some complicating factors around making this happen seamlessly. Thesefactors are in two areas:* Choosing what scenarios to use. (See Setting Scenarios For A Test).* Getting the multiplication to happen. Subclasssing++++++++++++If you can subclass TestWithScenarios, then the ``run()`` method inTestWithScenarios will take care of test multiplication. It will at testexecution act as a generator causing multiple tests to execute. For this to work reliably TestWithScenarios must be first in the MRO and you cannotoverride run() or __call__. This is the most robust method, in the sensethat any test runner or test loader that obeys the python unittest protocolwill run all your scenarios.Manual generation+++++++++++++++++If you cannot subclass TestWithScenarios (e.g. because you are usingTwistedTestCase, or TestCaseWithResources, or any one of a number of otheruseful test base classes, or need to override run() or __call__ yourself) then you can cause scenario application to happen later by calling``testscenarios.generate_scenarios()``. For instance::  &gt;&gt;&gt; import unittest  &gt;&gt;&gt; try:  ...     from StringIO import StringIO  ... except ImportError:  ...     from io import StringIO  &gt;&gt;&gt; from testscenarios.scenarios import generate_scenariosThis can work with loaders and runners from the standard library, or possibly otherimplementations::  &gt;&gt;&gt; loader = unittest.TestLoader()  &gt;&gt;&gt; test_suite = unittest.TestSuite()  &gt;&gt;&gt; runner = unittest.TextTestRunner(stream=StringIO())  &gt;&gt;&gt; mytests = loader.loadTestsFromNames(['doc.test_sample'])  &gt;&gt;&gt; test_suite.addTests(generate_scenarios(mytests))  &gt;&gt;&gt; runner.run(test_suite)  &lt;unittest...TextTestResult run=1 errors=0 failures=0&gt;Testloaders+++++++++++Some test loaders support hooks like ``load_tests`` and ``test_suite``.Ensuring your tests have had scenario application done through these hooks canbe a good idea - it means that external test runners (which support these hookslike ``nose``, ``trial``, ``tribunal``) will still run your scenarios. (Ofcourse, if you are using the subclassing approach this is already a surety).With ``load_tests``::  &gt;&gt;&gt; def load_tests(standard_tests, module, loader):  ...     result = loader.suiteClass()  ...     result.addTests(generate_scenarios(standard_tests))  ...     return resultas a convenience, this is available in ``load_tests_apply_scenarios``, so amodule using scenario tests need only say ::  &gt;&gt;&gt; from testscenarios import load_tests_apply_scenarios as load_testsPython 2.7 and greater support a different calling convention for `load_tests``&lt;https://bugs.launchpad.net/bzr/+bug/607412&gt;.  `load_tests_apply_scenarios`copes with both.With ``test_suite``::  &gt;&gt;&gt; def test_suite():  ...     loader = TestLoader()  ...     tests = loader.loadTestsFromName(__name__)  ...     result = loader.suiteClass()  ...     result.addTests(generate_scenarios(tests))  ...     return resultSetting Scenarios for a test============================A sample test using scenarios can be found in the doc/ folder.See `pydoc testscenarios` for details.On the TestCase+++++++++++++++You can set a scenarios attribute on the test case::  &gt;&gt;&gt; class MyTest(unittest.TestCase):  ...  ...     scenarios = [  ...         ('scenario1', dict(param=1)),  ...         ('scenario2', dict(param=2)),]This provides the main interface by which scenarios are found for a given test.Subclasses will inherit the scenarios (unless they override the attribute).After loading+++++++++++++Test scenarios can also be generated arbitrarily later, as long as the test hasnot yet run. Simply replace (or alter, but be aware that many tests may share asingle scenarios attribute) the scenarios attribute. For instance in thisexample some third party tests are extended to run with a custom scenario. ::  &gt;&gt;&gt; import testtools  &gt;&gt;&gt; class TestTransport:  ...     &quot;&quot;&quot;Hypothetical test case for bzrlib transport tests&quot;&quot;&quot;  ...     pass  ...  &gt;&gt;&gt; stock_library_tests = unittest.TestLoader().loadTestsFromNames(  ...     ['doc.test_sample'])  ...  &gt;&gt;&gt; for test in testtools.iterate_tests(stock_library_tests):  ...     if isinstance(test, TestTransport):  ...         test.scenarios = test.scenarios + [my_vfs_scenario]  ...  &gt;&gt;&gt; suite = unittest.TestSuite()  &gt;&gt;&gt; suite.addTests(generate_scenarios(stock_library_tests))Generated tests don't have a ``scenarios`` list, because they don't normallyrequire any more expansion.  However, you can add a ``scenarios`` list back onto them, and then run them through ``generate_scenarios`` again to generate thecross product of tests. ::  &gt;&gt;&gt; class CrossProductDemo(unittest.TestCase):  ...     scenarios = [('scenario_0_0', {}),  ...                  ('scenario_0_1', {})]  ...     def test_foo(self):  ...         return  ...  &gt;&gt;&gt; suite = unittest.TestSuite()  &gt;&gt;&gt; suite.addTests(generate_scenarios(CrossProductDemo(&quot;test_foo&quot;)))  &gt;&gt;&gt; for test in testtools.iterate_tests(suite):  ...     test.scenarios = [  ...         ('scenario_1_0', {}),   ...         ('scenario_1_1', {})]  ...  &gt;&gt;&gt; suite2 = unittest.TestSuite()  &gt;&gt;&gt; suite2.addTests(generate_scenarios(suite))  &gt;&gt;&gt; print(suite2.countTestCases())  4Dynamic Scenarios+++++++++++++++++A common use case is to have the list of scenarios be dynamic based on pluginsand available libraries. An easy way to do this is to provide a global scopescenarios somewhere relevant to the tests that will use it, and then that canbe customised, or dynamically populate your scenarios from a registry etc.For instance::  &gt;&gt;&gt; hash_scenarios = []  &gt;&gt;&gt; try:  ...     from hashlib import md5  ... except ImportError:  ...     pass  ... else:  ...     hash_scenarios.append((&quot;md5&quot;, dict(hash=md5)))  &gt;&gt;&gt; try:  ...     from hashlib import sha1  ... except ImportError:  ...     pass  ... else:  ...     hash_scenarios.append((&quot;sha1&quot;, dict(hash=sha1)))  ...  &gt;&gt;&gt; class TestHashContract(unittest.TestCase):  ...  ...     scenarios = hash_scenarios  ...  &gt;&gt;&gt; class TestHashPerformance(unittest.TestCase):  ...  ...     scenarios = hash_scenariosForcing Scenarios+++++++++++++++++The ``apply_scenarios`` function can be useful to apply scenarios to a testthat has none applied. ``apply_scenarios`` is the workhorse for``generate_scenarios``, except it takes the scenarios passed in rather thanintrospecting the test object to determine the scenarios. The``apply_scenarios`` function does not reset the test scenarios attribute,allowing it to be used to layer scenarios without affecting existing scenarioselection.Generating Scenarios====================Some functions (currently one :-) are available to ease generation of scenariolists for common situations.Testing Per Implementation Module+++++++++++++++++++++++++++++++++It is reasonably common to have multiple Python modules that provide the samecapabilities and interface, and to want apply the same tests to all of them.In some cases, not all of the statically defined implementations will be ableto be used in a particular testing environment.  For example, there may be botha C and a pure-Python implementation of a module.  You want to test the Cmodule if it can be loaded, but also to have the tests pass if the C module hasnot been compiled.The ``per_module_scenarios`` function generates a scenario for each namedmodule. The module object of the imported module is set in the suppliedattribute name of the resulting scenario.Modules which raise ``ImportError`` during import will have the``sys.exc_info()`` of the exception set instead of the module object. Testscan check for the attribute being a tuple to decide what to do (e.g. to skip).Note that for the test to be valid, all access to the module under test must gothrough the relevant attribute of the test object.  If one of theimplementations is also directly imported by the test module or any other,testscenarios will not magically stop it being used.Advice on Writing Scenarios===========================If a parameterised test is because of a bug run without being parameterized,it should fail rather than running with defaults, because this can hide bugs.Producing Scenarios===================The `multiply_scenarios` function produces the cross-product of the scenariospassed in::  &gt;&gt;&gt; from testscenarios.scenarios import multiply_scenarios  &gt;&gt;&gt;   &gt;&gt;&gt; scenarios = multiply_scenarios(  ...      [('scenario1', dict(param1=1)), ('scenario2', dict(param1=2))],  ...      [('scenario2', dict(param2=1))],  ...      )  &gt;&gt;&gt; scenarios == [('scenario1,scenario2', {'param2': 1, 'param1': 1}),  ...               ('scenario2,scenario2', {'param2': 1, 'param1': 2})]  True</longdescription>
</pkgmetadata>