<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># ⏳ tiktoken-asynctiktoken is a fast [BPE](https://en.wikipedia.org/wiki/Byte_pair_encoding) tokeniser for use withOpenAI's models.```pythonimport asyncioimport tiktoken_asyncenc = asyncio.run(tiktoken_async.get_encoding(&quot;cl100k_base&quot;))assert enc.decode(enc.encode(&quot;hello world&quot;)) == &quot;hello world&quot;# To get the tokeniser corresponding to a specific model in the OpenAI API:enc = asyncio.run(tiktoken_async.encoding_for_model(&quot;gpt-4&quot;))```The open source version of `tiktoken-async` can be installed from PyPI:```pip install tiktoken-async```The tokeniser API is documented in `tiktoken_async/core.py`.Example code using `tiktoken` can be found in the[OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb).## Performance`tiktoken` is between 3-6x faster than a comparable open source tokeniser:![image](https://raw.githubusercontent.com/openai/tiktoken/main/perf.svg)Performance measured on 1GB of text using the GPT-2 tokeniser, using `GPT2TokenizerFast` from`tokenizers==0.13.2`, `transformers==4.24.0` and `tiktoken==0.2.0`.## Getting helpPlease post questions in the [issue tracker](https://github.com/openai/tiktoken/issues).If you work at OpenAI, make sure to check the internal documentation or feel free to contact@shantanu.## Extending tiktokenYou may wish to extend `tiktoken-async` to support new encodings. There are two ways to do this.**Create your `Encoding` object exactly the way you want and simply pass it around.**```pythonimport asynciocl100k_base = asyncio.run(tiktoken.get_encoding(&quot;cl100k_base&quot;))# In production, load the arguments directly instead of accessing private attributes# See openai_public.py for examples of arguments for specific encodingsenc = tiktoken_async.Encoding(    # If you're changing the set of special tokens, make sure to use a different name    # It should be clear from the name what behaviour to expect.    name=&quot;cl100k_im&quot;,    pat_str=cl100k_base._pat_str,    mergeable_ranks=cl100k_base._mergeable_ranks,    special_tokens={        **cl100k_base._special_tokens,        &quot;&lt;|im_start|&gt;&quot;: 100264,        &quot;&lt;|im_end|&gt;&quot;: 100265,    })```**Use the `tiktoken_async_ext` plugin mechanism to register your `Encoding` objects with `tiktoken_async`.**This is only useful if you need `tiktoken_async.get_encoding` to find your encoding, otherwise preferoption 1.To do this, you'll need to create a namespace package under `tiktoken_async_ext`.Layout your project like this, making sure to omit the `tiktoken_ext/__init__.py` file:```my_tiktoken_extension├── tiktoken_async_ext│   └── my_encodings.py└── setup.py````my_encodings.py` should be a module that contains a variable named `ENCODING_CONSTRUCTORS`.This is a dictionary from an encoding name to a function that takes no arguments and returnsarguments that can be passed to `tiktoken_async.Encoding` to construct that encoding. For an example, see`tiktoken_async_ext/openai_public.py`. For precise details, see `tiktoken_async/registry.py`.Your `setup.py` should look something like this:```pythonfrom setuptools import setup, find_namespace_packagessetup(    name=&quot;my_tiktoken_extension&quot;,    packages=find_namespace_packages(include=['tiktoken_async_ext*']),    install_requires=[&quot;tiktoken_async&quot;],    ...)```Then simply `pip install ./my_tiktoken_extension` and you should be able to use yourcustom encodings! Make sure **not** to use an editable install.</longdescription>
</pkgmetadata>