<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># HuggingFace runtime for MLServerThis package provides a MLServer runtime compatible with HuggingFace Transformers.## UsageYou can install the runtime, alongside `mlserver`, as:```bashpip install mlserver mlserver-huggingface```For further information on how to use MLServer with HuggingFace, you can checkout this [worked out example](../../docs/examples/huggingface/README.md).## Content TypesThe HuggingFace runtime will always decode the input request using its ownbuilt-in codec.Therefore, [content type annotations](../../docs/user-guide/content-type) atthe request level will **be ignored**.Not that this **doesn't include [input-level contenttype](../../docs/user-guide/content-type#Codecs) annotations**, which will berespected as usual.## SettingsThe HuggingFace runtime exposes a couple extra parameters which can be used tocustomise how the runtime behaves.These settings can be added under the `parameters.extra` section of your`model-settings.json` file, e.g.```{code-block} json---emphasize-lines: 5-8---{  &quot;name&quot;: &quot;qa&quot;,  &quot;implementation&quot;: &quot;mlserver_huggingface.HuggingFaceRuntime&quot;,  &quot;parameters&quot;: {    &quot;extra&quot;: {      &quot;task&quot;: &quot;question-answering&quot;,      &quot;optimum_model&quot;: true    }  }}```````{note}These settings can also be injected through environment variables prefixed with `MLSERVER_MODEL_HUGGINGFACE_`, e.g.```bashMLSERVER_MODEL_HUGGINGFACE_TASK=&quot;question-answering&quot;MLSERVER_MODEL_HUGGINGFACE_OPTIMUM_MODEL=true```````### ReferenceYou can find the full reference of the accepted extra settings for theHuggingFace runtime below:```{eval-rst}.. autopydantic_settings:: mlserver_huggingface.settings.HuggingFaceSettings```</longdescription>
</pkgmetadata>