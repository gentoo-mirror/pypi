<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;    &lt;img src=&quot;imgs/keras4torch_logo.svg&quot; alt=&quot;Keras4Torch&quot; height=48&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    &lt;strong&gt;A compatible-with-keras wrapper for training PyTorch models✨&lt;/strong&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://pypi.python.org/pypi/keras4torch&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/keras4torch.svg&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://pepy.tech/project/keras4torch&quot;&gt;&lt;img src=&quot;https://pepy.tech/badge/keras4torch&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt;    &lt;!-- &lt;a href=&quot;https://www.buymeacoffee.com/blueloveTH&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Buy%20me%20a-coffee-cyan.svg?logo=buy-me-a-coffee&amp;logoColor=cyan&quot;&gt;&lt;/a&gt; --&gt;    &lt;a href=&quot;https://codecov.io/gh/blueloveTH/keras4torch&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/blueloveTH/keras4torch/branch/main/graph/badge.svg&quot; alt=&quot;CodeCov&quot;/&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/blueloveTH/keras4torch/blob/master/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/blueloveTH/keras4torch.svg&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://keras4torch.readthedocs.io/en/latest&quot;&gt;Documentations&lt;/a&gt;    •    &lt;a href=&quot;https://github.com/blueloveTH/keras4torch/discussions/5&quot;&gt;Dev Logs&lt;/a&gt;    •    &lt;a href=&quot;https://github.com/blueloveTH/keras4torch/tree/main/minimum&quot;&gt;Mini Version&lt;/a&gt;&lt;/p&gt;`keras4torch` provides a high-level API to train PyTorch models compatible with Keras. This project is designed for beginner with these objectives: +   Help people who are new to PyTorch but familar with Keras+   Reduce the cost for migrating Keras model implementation to PyTorch---&lt;p align=&quot;center&quot;&gt;    &lt;h4 align=&quot;center&quot;&gt;Use &lt;code&gt;keras4torch&lt;/code&gt; for Kaggle's code competition! Check this &lt;a href=&quot;https://www.kaggle.com/blueloveth/keras4torch&quot;&gt;package dataset&lt;/a&gt; and &lt;a href=&quot;https://www.kaggle.com/blueloveth/keras4torch-starter&quot;&gt;starter notebook.&lt;/a&gt;&lt;/h4&gt;&lt;/p&gt;---## Installation```pip install keras4torch```PyTorch 1.6+ and Python 3.6+ is required.## Quick startSuppose you have a `nn.Module` to train.```pythonmodel = torchvision.models.resnet18(num_classes=10)```All you need to do is wrapping it via `k4t.Model()`.```pythonimport keras4torch as k4tmodel = k4t.Model(model)```Now, there're two workflows can be used for training.The **NumPy workflow** is compatible with Keras.+   `.compile(optimizer, loss, metrics)` for settings of optimizer, loss and metrics+   `.fit(x, y, epochs, batch_size, ...)` takes raw numpy input for training+   `.evaluate(x, y)` outputs a `dict` result of your metrics+   `.predict(x)` for doing predictionsAnd **DataLoader workflow** is more flexible and of pytorch style.+   `.compile(optimizer, loss, metrics)` same as NumPy workflow+   `.fit_dl(train_loader, val_loader, epochs)` for training the model via `DataLoader`+   `.evaluate_dl(data_loader)` same as NumPy workflow but takes `DataLoader`+   `.predict_dl(data_loader)` same as NumPy workflow but takes `DataLoader`The two workflows can be mixed.## MNIST exampleHere we show a complete example of training a ConvNet on MNIST.```pythonimport torchimport torchvisionfrom torch import nnimport keras4torch as k4t```#### Step1: Preprocess data```pythonmnist = torchvision.datasets.MNIST(root='./', download=True)x, y = mnist.train_data.unsqueeze(1), mnist.train_labelsx = x.float() / 255.0    # scale the pixels to [0, 1]x_train, y_train = x[:40000], y[:40000]x_test, y_test = x[40000:], y[40000:]```#### Step2: Define the modelIf you have a `nn.Module` already, just wrap it via `k4t.Model`. For example,```pythonmodel = torchvision.models.resnet50(num_classes=10)model = k4t.Model(model)```For building models from scratch, you can use `KerasLayer` (located in `k4t.layers`) for automatic shape inference, which can free you from calculating the input channels.As is shown below, `k4t.layers.Conv2d(32, kernel_size=3)` equals `nn.Conv2d(?, 32, kernel_size=3)` where the first parameter `?` (i.e. `in_channels`) will be determined by itself.```pythonmodel = torch.nn.Sequential(    k4t.layers.Conv2d(32, kernel_size=3), nn.ReLU(),    nn.MaxPool2d(2, 2),     k4t.layers.Conv2d(64, kernel_size=3), nn.ReLU(),    nn.Flatten(),    k4t.layers.Linear(10))```A model containing `KerasLayer` needs an extra `.build(input_shape)` operation.```pythonmodel = k4t.Model(model).build([1, 28, 28])```#### Step3: Summary the model```pythonmodel.summary()``````txt=========================================================================================Layer (type:depth-idx)                   Output Shape              Param #=========================================================================================├─Conv2d*: 1-1                           [-1, 32, 26, 26]          320├─ReLU: 1-2                              [-1, 32, 26, 26]          --├─MaxPool2d: 1-3                         [-1, 32, 13, 13]          --├─Conv2d*: 1-4                           [-1, 64, 11, 11]          18,496├─ReLU: 1-5                              [-1, 64, 11, 11]          --├─Flatten: 1-6                           [-1, 7744]                --├─Linear*: 1-7                           [-1, 10]                  77,450=========================================================================================Total params: 96,266Trainable params: 96,266Non-trainable params: 0Total mult-adds (M): 2.50=========================================================================================```#### Step4: Config optimizer, loss and metrics```pythonmodel.compile(optimizer='adam', loss=nn.CrossEntropyLoss(), metrics=['acc'])```If GPU is available, it will be used automatically. You can also pass `device` parameter to `.compile()` explicitly.#### Step5: Training```pythonhistory = model.fit(x_train, y_train,                epochs=30,                batch_size=512,                validation_split=0.2,                )``````txtTrain on 32000 samples, validate on 8000 samples:Epoch 1/30 - 2.8s - loss: 0.6109 - acc: 0.8372 - val_loss: 0.2712 - val_acc: 0.9235 - lr: 1e-03Epoch 2/30 - 1.5s - loss: 0.2061 - acc: 0.9402 - val_loss: 0.1494 - val_acc: 0.9579 - lr: 1e-03Epoch 3/30 - 1.5s - loss: 0.1202 - acc: 0.9653 - val_loss: 0.0974 - val_acc: 0.9719 - lr: 1e-03Epoch 4/30 - 1.5s - loss: 0.0835 - acc: 0.9757 - val_loss: 0.0816 - val_acc: 0.9769 - lr: 1e-03... ...```#### Step6: Plot learning curve```history.plot(kind='line', y=['loss', 'val_loss'])```&lt;img src=&quot;imgs/learning_curve.svg&quot;  /&gt;#### Step7: Evaluate on test set```pythonmodel.evaluate(x_test, y_test)``````txt{'loss': 0.06655170023441315, 'acc': 0.9839999675750732}```## CommunicationWe have activated [Github Discussion](https://github.com/blueloveTH/keras4torch/discussions) for Q&amp;A and most general topics!For bugs report, please use [Github Issues](https://github.com/blueloveTH/keras4torch/issues).</longdescription>
</pkgmetadata>