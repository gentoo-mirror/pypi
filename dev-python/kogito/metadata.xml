<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># kogitoA Python NLP Commonsense Knowledge Inference ToolkitSystem Description available here: https://arxiv.org/abs/2211.08451## Installation### Installation with pip**kogito** can be installed using pip.```shpip install kogito```It requires a minimum ``python`` version of ``3.8``.## Setup### Inference**kogito** uses [spacy](https://spacy.io) under the hood for various text processing purposes, so, a [spacy](https://spacy.io) language package has to be installed before running the inference module.```shpython -m spacy download en_core_web_sm``` By default, ``CommonsenseInference`` module uses ``en_core_web_sm`` to initialize ``spacy`` pipeline, but a different language pipeline can be specified as well.### EvaluationIf you also would like evaluate knowledge models using `METEOR` score, then you need to download the following ``nltk`` libraries:```pythonimport nltknltk.download(&quot;punkt&quot;)nltk.download(&quot;wordnet&quot;)nltk.download(&quot;omw-1.4&quot;)```## Quickstart**kogito** provides an easy interface to interact with knowledge inference or commonsense reasoning models such as [COMET](https://arxiv.org/abs/2010.05953) to generate inferences from a text input.Here is a sample usage of the library where you can initialize an inference module, a custom commonsense reasoning model, and generate a knowledge graph from text on the fly.```pythonfrom kogito.models.bart.comet import COMETBARTfrom kogito.inference import CommonsenseInference# Load pre-trained model from HuggingFacemodel = COMETBART.from_pretrained(&quot;mismayil/comet-bart-ai2&quot;)# Initialize inference module with a spacy language pipelinecsi = CommonsenseInference(language=&quot;en_core_web_sm&quot;)# Run inferencetext = &quot;PersonX becomes a great basketball player&quot;kgraph = csi.infer(text, model)# Save output knowledge graph to JSON filekgraph.to_jsonl(&quot;kgraph.json&quot;)```Here is an excerpt from the result of the above code sample:```json{&quot;head&quot;: &quot;PersonX becomes a great basketball player&quot;, &quot;relation&quot;: &quot;Causes&quot;, &quot;tails&quot;: [&quot; PersonX practices every day.&quot;, &quot; PersonX plays basketball every day&quot;, &quot; PersonX practices every day&quot;]}{&quot;head&quot;: &quot;basketball&quot;, &quot;relation&quot;: &quot;ObjectUse&quot;, &quot;tails&quot;: [&quot; play with friends&quot;, &quot; play basketball with&quot;, &quot; play basketball&quot;]}{&quot;head&quot;: &quot;player&quot;, &quot;relation&quot;: &quot;CapableOf&quot;, &quot;tails&quot;: [&quot; play game&quot;, &quot; win game&quot;, &quot; play football&quot;]}{&quot;head&quot;: &quot;great basketball player&quot;, &quot;relation&quot;: &quot;HasProperty&quot;, &quot;tails&quot;: [&quot; good at basketball&quot;, &quot; good at sports&quot;, &quot; very good&quot;]}{&quot;head&quot;: &quot;become player&quot;, &quot;relation&quot;: &quot;isAfter&quot;, &quot;tails&quot;: [&quot; play game&quot;, &quot; become coach&quot;, &quot; play with&quot;]}```This is just one way to generate commonsense inferences and **kogito** offers much more. For complete documentation, check out the [kogito docs](https://kogito.readthedocs.io).## Development### Setup**kogito** uses [Poetry](https://python-poetry.org/) to manage its dependencies. Install poetry from the official repository first:```shcurl -sSL https://install.python-poetry.org | python3 -```Then run the following command to install package dependencies:```shpoetry install```## DataIf you need the ATOMIC2020 data to train your knowledge models, you can download it from AI2:For ATOMIC:```shwget https://storage.googleapis.com/ai2-mosaic/public/atomic/v1.0/atomic_data.tgz```For ATOMIC 2020:```shwget https://ai2-atomic.s3-us-west-2.amazonaws.com/data/atomic2020_data-feb2021.zip```## PaperIf you want to learn more about the library design, models and data used for this toolkit, check out our [paper](https://arxiv.org/abs/2211.08451). The paper can be cited as:```@article{Ismayilzada2022kogito,  title={kogito: A Commonsense Knowledge Inference Toolkit},  author={Mete Ismayilzada and Antoine Bosselut},  journal={ArXiv},  volume={abs/2211.08451},  year={2022}}```If you work with knowledge models, consider citing the following papers:```@article{Hwang2020COMETATOMIC, author = {Jena D. Hwang and Chandra Bhagavatula and Ronan Le Bras and Jeff Da and Keisuke Sakaguchi and Antoine Bosselut and Yejin Choi}, booktitle = {Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)}, title = {COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs}, year = {2021}}@inproceedings{Bosselut2019COMETCT, author = {Antoine Bosselut and Hannah Rashkin and Maarten Sap and Chaitanya Malaviya and Asli Ã‡elikyilmaz and Yejin Choi}, booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)}, title = {COMET: Commonsense Transformers for Automatic Knowledge Graph Construction}, year = {2019}}```## AcknowledgementsSignificant portion of the model training and evaluation code has been adapted from the original [codebase](https://github.com/allenai/comet-atomic-2020) for the paper [(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs.](https://www.semanticscholar.org/paper/COMET-ATOMIC-2020%3A-On-Symbolic-and-Neural-Knowledge-Hwang-Bhagavatula/e39503e01ebb108c6773948a24ca798cd444eb62)</longdescription>
</pkgmetadata>