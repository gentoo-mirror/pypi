<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>=====================================SageMaker TensorFlow Training Toolkit=====================================The SageMaker TensorFlow Training Toolkit is an open source library for making theTensorFlow framework run on `Amazon SageMaker &lt;https://aws.amazon.com/documentation/sagemaker/&gt;`__.This repository also contains Dockerfiles which install this library, TensorFlow, and dependenciesfor building SageMaker TensorFlow images.For information on running TensorFlow jobs on SageMaker:- `SageMaker Python SDK documentation &lt;https://sagemaker.readthedocs.io/en/stable/using_tf.html&gt;`__- `SageMaker Notebook Examples &lt;https://github.com/awslabs/amazon-sagemaker-examples&gt;`__Table of Contents-----------------#. `Getting Started &lt;#getting-started&gt;`__#. `Building your Image &lt;#building-your-image&gt;`__#. `Running the tests &lt;#running-the-tests&gt;`__Getting Started---------------Prerequisites~~~~~~~~~~~~~Make sure you have installed all of the following prerequisites on yourdevelopment machine:- `Docker &lt;https://www.docker.com/&gt;`__For Testing on GPU^^^^^^^^^^^^^^^^^^-  `Nvidia-Docker &lt;https://github.com/NVIDIA/nvidia-docker&gt;`__Recommended^^^^^^^^^^^-  A Python environment management tool. (e.g.   `PyEnv &lt;https://github.com/pyenv/pyenv&gt;`__,   `VirtualEnv &lt;https://virtualenv.pypa.io/en/stable/&gt;`__)Building your Image-------------------`Amazon SageMaker &lt;https://aws.amazon.com/documentation/sagemaker/&gt;`__utilizes Docker containers to run all training jobs &amp; inference endpoints.The Docker images are built from the Dockerfiles specified in`docker/ &lt;https://github.com/aws/sagemaker-tensorflow-containers/tree/master/docker&gt;`__.The Dockerfiles are grouped based on TensorFlow version and separatedbased on Python version and processor type.The Dockerfiles for TensorFlow 2.0+ are available in the`tf-2 &lt;https://github.com/aws/sagemaker-tensorflow-container/tree/tf-2&gt;`__ branch.To build the images, first copy the files under`docker/build_artifacts/ &lt;https://github.com/aws/sagemaker-tensorflow-container/tree/tf-2/docker/build_artifacts&gt;`__to the folder container the Dockerfile you wish to build.::    # Example for building a TF 2.1 image with Python 3    cp docker/build_artifacts/* docker/2.1.0/py3/.After that, go to the directory containing the Dockerfile you wish to build,and run ``docker build`` to build the image.::    # Example for building a TF 2.1 image for CPU with Python 3    cd docker/2.1.0/py3    docker build -t tensorflow-training:2.1.0-cpu-py3 -f Dockerfile.cpu .Don't forget the period at the end of the ``docker build`` command!Running the tests-----------------Running the tests requires installation of the SageMaker TensorFlow Training Toolkit code and its testdependencies.::    git clone https://github.com/aws/sagemaker-tensorflow-container.git    cd sagemaker-tensorflow-container    pip install -e .[test]Tests are defined in`test/ &lt;https://github.com/aws/sagemaker-tensorflow-container/tree/master/test&gt;`__and include unit, integration and functional tests.Unit Tests~~~~~~~~~~If you want to run unit tests, then use:::    # All test instructions should be run from the top level directory    pytest test/unitIntegration Tests~~~~~~~~~~~~~~~~~Running integration tests require `Docker &lt;https://www.docker.com/&gt;`__ and `AWScredentials &lt;https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html&gt;`__,as the integration tests make calls to a couple AWS services. The integration and functionaltests require configurations specified within their respective`conftest.py &lt;https://github.com/aws/sagemaker-tensorflow-containers/blob/master/test/integration/conftest.py&gt;`__.Make sure to update the account-id and region at a minimum.Integration tests on GPU require `Nvidia-Docker &lt;https://github.com/NVIDIA/nvidia-docker&gt;`__.Before running integration tests:#. Build your Docker image.#. Pass in the correct pytest arguments to run tests against your Docker image.If you want to run local integration tests, then use:::    # Required arguments for integration tests are found in test/integ/conftest.py    pytest test/integration --docker-base-name &lt;your_docker_image&gt; \                            --tag &lt;your_docker_image_tag&gt; \                            --framework-version &lt;tensorflow_version&gt; \                            --processor &lt;cpu_or_gpu&gt;::    # Example    pytest test/integration --docker-base-name preprod-tensorflow \                            --tag 1.0 \                            --framework-version 1.4.1 \                            --processor cpuFunctional Tests~~~~~~~~~~~~~~~~Functional tests are removed from the current branch, please see them in older branch `r1.0 &lt;https://github.com/aws/sagemaker-tensorflow-container/tree/r1.0#functional-tests&gt;`__.Contributing------------Please read`CONTRIBUTING.md &lt;https://github.com/aws/sagemaker-tensorflow-containers/blob/master/CONTRIBUTING.md&gt;`__for details on our code of conduct, and the process for submitting pullrequests to us.License-------SageMaker TensorFlow Containers is licensed under the Apache 2.0 License. It is copyright 2018Amazon.com, Inc. or its affiliates. All Rights Reserved. The license is available at:http://aws.amazon.com/apache2.0/</longdescription>
</pkgmetadata>