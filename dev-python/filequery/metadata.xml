<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># filequeryQuery CSV and Parquet files using SQL. This uses DuckDB behind the scenes so any valid SQL for DuckDB will work here.## installation```bashpip install filequery```## CLI usageRun `filequery --help` to see what options are available.```usage: __main__.py [-h] [--filename FILENAME] [--filesdir FILESDIR] [--query QUERY] [--query_file QUERY_FILE] [--out_file OUT_FILE [OUT_FILE ...]] [--out_file_format OUT_FILE_FORMAT] [--delimiter DELIMITER] [--config CONFIG]options:  -h, --help            show this help message and exit  --filename FILENAME   path to a CSV, Parquet or JSON file  --filesdir FILESDIR   path to a directory which can contain a combination of CSV, Parquet and JSON files  --query QUERY         SQL query to execute against file  --query_file QUERY_FILE                        path to file with query to execute  --out_file OUT_FILE [OUT_FILE ...]                        file to write results to instead of printing to standard output  --out_file_format OUT_FILE_FORMAT                        either csv or parquet, defaults to csv  --delimiter DELIMITER                        delimiter to use when printing result or writing to CSV file  --config CONFIG       path to JSON config file```For basic usage, provide a path to a CSV or Parquet file and a query to execute against it. The table name will be the file name without the extension.```bashfilequery --filename example/test.csv --query 'select * from test'```Examples```bashfilequery --filename example/json_test.json --query 'select nested.nest_id, nested.nested_val from json_test' # query json``````bashfilequery --filesdir example/data --query 'select * from test inner join test1 on test.col1 = test1.col1' # query multiple files in a directory``````bashfilequery --filesdir example/data --query_file example/queries/join.sql # point to a file containing SQL``````bashfilequery --filesdir example/data --query_file example/queries/json_csv_join.sql # SQL file joining data from JSON and CSV files``````bashfilequery --filesdir example/test.csv --query 'select * from test; select sum(col3) from test;' # output multiple query results to multiple files```You can also provide a config file instead of specifying the arguments when running the command.```bashfilequery --config &lt;path to config file&gt;```The config file should be a json file. See example config file contents below.```json{    &quot;filename&quot;: &quot;../example/test.csv&quot;,    &quot;query&quot;: &quot;select col1, col2 from test&quot;}``````json{    &quot;filesdir&quot;: &quot;../example/data&quot;,    &quot;query_file&quot;: &quot;../example/queries/join.sql&quot;,    &quot;out_file&quot;: &quot;result.parquet&quot;,    &quot;out_file_format&quot;: &quot;parquet&quot;}```See the `example` directory in the repo for more examples.## module usageYou can also use filequery in your own programs. See the example below.```pythonfrom filequery.filedb import FileDbquery = 'select * from test'# read test.csv into a table called &quot;test&quot;fdb = FileDb('example/test.csv')# return QueryResult objectres = fdb.exec_query(query)# formats result as csvprint(str(res))# saves query result to result.csvres.save_to_file('result.csv')# saves query result as parquet filefdb.export_query(query, 'result.parquet', FileType.PARQUET)```## developmentPackages required for distribution should go in `requirements.txt`.To build the wheel:```bashpip install -r requirements-dev.txtmake```## testingTo test the CLI, cd into the `src` directory and run `filequery` as a module.```bashpython -m filequery ...```To run unit tests, stay in the root of the project. The unit tests add `src` to the path so `filequery` can be imported properly.```bashpython tests/test_filequery.py```</longdescription>
</pkgmetadata>