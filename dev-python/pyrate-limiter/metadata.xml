<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;img align=&quot;left&quot; width=&quot;95&quot; height=&quot;120&quot; src=&quot;docs/_static/logo.png&quot;&gt;# PyrateLimiterThe request rate limiter using Leaky-bucket algorithm.Full project documentation can be found at [pyratelimiter.readthedocs.io](https://pyratelimiter.readthedocs.io).[![PyPI version](https://badge.fury.io/py/pyrate-limiter.svg)](https://badge.fury.io/py/pyrate-limiter)[![PyPI - Python Versions](https://img.shields.io/pypi/pyversions/pyrate-limiter)](https://pypi.org/project/pyrate-limiter)[![codecov](https://codecov.io/gh/vutran1710/PyrateLimiter/branch/master/graph/badge.svg?token=E0Q0YBSINS)](https://codecov.io/gh/vutran1710/PyrateLimiter)[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/vutran1710/PyrateLimiter/graphs/commit-activity)[![PyPI license](https://img.shields.io/pypi/l/ansicolortags.svg)](https://pypi.python.org/pypi/pyrate-limiter/)&lt;br&gt;## Contents- [PyrateLimiter](#pyratelimiter)  - [Contents](#contents)  - [Features](#features)  - [Installation](#installation)  - [Basic usage](#basic-usage)    - [Defining rate limits](#defining-rate-limits)    - [Applying rate limits](#applying-rate-limits)    - [Identities](#identities)  - [Handling exceeded limits](#handling-exceeded-limits)    - [Bucket analogy](#bucket-analogy)    - [Rate limit exceptions](#rate-limit-exceptions)    - [Rate limit delays](#rate-limit-delays)  - [Additional usage options](#additional-usage-options)    - [Decorator](#decorator)    - [Contextmanager](#contextmanager)    - [Async decorator/contextmanager](#async-decoratorcontextmanager)  - [Backends](#backends)    - [Memory](#memory)    - [SQLite](#sqlite)    - [Redis](#redis)    - [Custom backends](#custom-backends)  - [Additional features](#additional-features)    - [Time sources](#time-sources)  - [Examples](#examples)## Features* Tracks any number of rate limits and intervals you want to define* Independently tracks rate limits for multiple services or resources* Handles exceeded rate limits by either raising errors or adding delays* Several usage options including a normal function call, a decorator, or a contextmanager* Async support* Includes optional SQLite and Redis backends, which can be used to persist limit tracking across  multiple threads, processes, or application restarts## InstallationInstall using pip:```pip install pyrate-limiter```Or using conda:```conda install --channel conda-forge pyrate-limiter```## Basic usage### Defining rate limitsConsider some public API (like LinkedIn, GitHub, etc.) that has rate limits like the following:```- 500 requests per hour- 1000 requests per day- 10000 requests per month```You can define these rates using the `RequestRate` class, and add them to a `Limiter`:``` pythonfrom pyrate_limiter import Duration, RequestRate, Limiterhourly_rate = RequestRate(500, Duration.HOUR) # 500 requests per hourdaily_rate = RequestRate(1000, Duration.DAY) # 1000 requests per daymonthly_rate = RequestRate(10000, Duration.MONTH) # 10000 requests per monthlimiter = Limiter(hourly_rate, daily_rate, monthly_rate)```or``` pythonfrom pyrate_limiter import Duration, RequestRate, Limiterrate_limits = (      RequestRate(500, Duration.HOUR), # 500 requests per hour      RequestRate(1000, Duration.DAY), # 1000 requests per day      RequestRate(10000, Duration.MONTH), # 10000 requests per month)limiter = Limiter(*rate_limits)```Note that these rates need to be ordered by interval length; in other words, an hourly rate mustcome before a daily rate, etc.### Applying rate limitsThen, use `Limiter.try_acquire()` wherever you are making requests (or other rate-limited operations).This will raise an exception if the rate limit is exceeded.```pythonimport requestsdef request_function():    limiter.try_acquire('identity')    requests.get('https://example.com')while True:    request_function()```Alternatively, you can use `Limiter.ratelimit()` as a function decorator:```python@limiter.ratelimit('identity')def request_function():    requests.get('https://example.com')```See [Additional usage options](#additional-usage-options) below for more details.### IdentitiesNote that both `try_acquire()` and `ratelimit()` take one or more `identity` arguments. Typically this isthe name of the service or resource that is being rate-limited. This allows you to track rate limitsfor these resources independently. For example, if you have a service that is rate-limited by user:```pythondef request_function(user_ids):    limiter.try_acquire(*user_ids)    for user_id in user_ids:        requests.get(f'https://example.com?user_id={user_id}')```## Handling exceeded limitsWhen a rate limit is exceeded, you have two options: raise an exception, or add delays.### Bucket analogy&lt;img height=&quot;300&quot; align=&quot;right&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/c/c4/Leaky_bucket_analogy.JPG&quot;&gt;At this point it's useful to introduce the analogy of &quot;buckets&quot; used for rate-limiting. Here is aquick summary:* This library implements the [Leaky Bucket algorithm](https://en.wikipedia.org/wiki/Leaky_bucket).* It is named after the idea of representing some kind of fixed capacity -- like a network or service -- as a bucket.* The bucket &quot;leaks&quot; at a constant rate. For web services, this represents the **ideal or permitted request rate**.* The bucket is &quot;filled&quot; at an intermittent, unpredicatble rate, representing the **actual rate of requests**.* When the bucket is &quot;full&quot;, it will overflow, representing **canceled or delayed requests**.### Rate limit exceptionsBy default, a `BucketFullException` will be raised when a rate limit is exceeded.The error contains a `meta_info` attribute with the following information:* `identity`: The identity it received* `rate`: The specific rate that has been exceeded* `remaining_time`: The remaining time until the next request can be sentHere's an example that will raise an exception on the 4th request:```pythonfrom pyrate_limiter import (Duration, RequestRate,                            Limiter, BucketFullException)rate = RequestRate(3, Duration.SECOND)limiter = Limiter(rate)for _ in range(4):    try:        limiter.try_acquire('vutran')    except BucketFullException as err:        print(err)        # Output: Bucket for vutran with Rate 3/1 is already full        print(err.meta_info)        # Output: {'identity': 'vutran', 'rate': '3/1', 'remaining_time': 2.9,        #          'error': 'Bucket for vutran with Rate 3/1 is already full'}```The rate part of the output is constructed as: `limit / interval`. On the above example, the limitis 3 and the interval is 1, hence the `Rate 3/1`.### Rate limit delaysYou may want to simply slow down your requests to stay within the rate limits instead of cancelingthem. In that case you can use the `delay` argument. Note that this is only available for`Limiter.ratelimit()`:```python@limiter.ratelimit('identity', delay=True)def my_function():    do_stuff()```If you exceed a rate limit with a long interval (daily, monthly, etc.), you may not want to delaythat long. In this case, you can set a `max_delay` (in seconds) that you are willing to wait inbetween calls:```python@limiter.ratelimit('identity', delay=True, max_delay=360)def my_function():    do_stuff()```In this case, calls may be delayed by at most 360 seconds to stay within the rate limits; any longerthan that, and a `BucketFullException` will be raised instead. Without specifying `max_delay`, callswill be delayed as long as necessary.## Additional usage optionsBesides `Limiter.try_acquire()`, some additional usage options are available using `Limiter.ratelimit()`:### Decorator`Limiter.ratelimit()` can be used as a decorator:```python@limiter.ratelimit('identity')def my_function():    do_stuff()```As with `Limiter.try_acquire()`, if calls to the wrapped function exceed the rate limits youdefined, a `BucketFullException` will be raised.### Contextmanager`Limiter.ratelimit()` also works as a contextmanager:```pythondef my_function():    with limiter.ratelimit('identity', delay=True):        do_stuff()```### Async decorator/contextmanager`Limiter.ratelimit()` also support async functions, either as a decorator or contextmanager:```python@limiter.ratelimit('identity', delay=True)async def my_function():    await do_stuff()async def my_function():    async with limiter.ratelimit('identity'):        await do_stuff()```When delays are enabled for an async function, `asyncio.sleep()` will be used instead of `time.sleep()`.## BackendsA few different bucket backends are available, which can be selected using the `bucket_class`argument for `Limiter`. Any additional backend-specific arguments can be passedvia `bucket_kwargs`.### MemoryThe default bucket is stored in memory, backed by a `queue.Queue`. A list implementation is also available:```pythonfrom pyrate_limiter import Limiter, MemoryListBucketlimiter = Limiter(bucket_class=MemoryListBucket)```### SQLiteIf you need to persist the bucket state, a SQLite backend is available.By default it will store the state in the system temp directory, and you can usethe `path` argument to use a different location:```pythonfrom pyrate_limiter import Limiter, SQLiteBucketlimiter = Limiter(bucket_class=SQLiteBucket)```By default, the database will be stored in the system temp directory. You can specify a differentpath via `bucket_kwargs`:```pythonlimiter = Limiter(    bucket_class=SQLiteBucket,    bucket_kwargs={'path': '/path/to/db.sqlite'},)```#### ConcurrencyThis backend is thread-safe.If you want to use SQLite with multiprocessing, some additional protections are needed. Forthese cases, a separate `FileLockSQLiteBucket` class is available. This requires installing the[py-filelock](https://py-filelock.readthedocs.io) library.```pythonlimiter = Limiter(bucket_class=FileLockSQLiteBucket)```### RedisIf you have a larger, distributed application, Redis is an ideal backend. Thisoption requires [redis-py](https://github.com/andymccurdy/redis-py).Note that this backend requires a `bucket_name` argument, which will be used as a prefix for theRedis keys created. This can be used to disambiguate between multiple services using the same Redisinstance with pyrate-limiter.**Important**: you might want to consider adding `expire_time` for each buckets. In a scenario where some `identity` produces a request rate that is too sparsed, it is a good practice to expire the bucket which holds such identity's info to save memory.```pythonfrom pyrate_limiter import Limiter, RedisBucket, Duration, RequestRaterates = [    RequestRate(5, 10 * Duration.SECOND),    RequestRate(8, 20 * Duration.SECOND),]limiter = Limiter(    *rates    bucket_class=RedisBucket,    bucket_kwargs={        'bucket_name':        'my_service',        'expire_time': rates[-1].interval,    },)```#### Connection settingsIf you need to pass additional connection settings, you can use the `redis_pool` bucket argument:```pythonfrom redis import ConnectionPoolredis_pool = ConnectionPool(host='localhost', port=6379, db=0)rate = RequestRate(5, 10 * Duration.SECOND)limiter = Limiter(    rate,    bucket_class=RedisBucket,    bucket_kwargs={'redis_pool': redis_pool, 'bucket_name': 'my_service'},)```#### Redis clustersRedis clusters are also supported, which requires[redis-py-cluster](https://github.com/Grokzen/redis-py-cluster):```pythonfrom pyrate_limiter import Limiter, RedisClusterBucketlimiter = Limiter(bucket_class=RedisClusterBucket)```### Custom backendsIf these don't suit your needs, you can also create your own bucket backend by extending `pyrate_limiter.bucket.AbstractBucket`.## Additional features### Time sourcesBy default, monotonic time is used, to ensure requests are always logged in the correct order.You can specify a custom time source with the `time_function` argument. For example, you may want touse the current UTC time for consistency across a distributed application using a Redis backend.```pythonfrom datetime import datetimefrom pyrate_limiter import Duration, Limiter, RequestRaterate = RequestRate(5, Duration.SECOND)limiter_datetime = Limiter(rate, time_function=lambda: datetime.utcnow().timestamp())```Or simply use the basic `time.time()` function:```pythonfrom time import timerate = RequestRate(5, Duration.SECOND)limiter_time = Limiter(rate, time_function=time)```## ExamplesTo prove that pyrate-limiter is working as expected, here is a complete example to demonstraterate-limiting with delays:```pythonfrom time import perf_counter as timefrom pyrate_limiter import Duration, Limiter, RequestRatelimiter = Limiter(RequestRate(5, Duration.SECOND))n_requests = 27@limiter.ratelimit(&quot;test&quot;, delay=True)def limited_function(start_time):    print(f&quot;t + {(time() - start_time):.5f}&quot;)start_time = time()for _ in range(n_requests):    limited_function(start_time)print(f&quot;Ran {n_requests} requests in {time() - start_time:.5f} seconds&quot;)```And an equivalent example for async usage:```pythonimport asynciofrom time import perf_counter as timefrom pyrate_limiter import Duration, Limiter, RequestRatelimiter = Limiter(RequestRate(5, Duration.SECOND))n_requests = 27@limiter.ratelimit(&quot;test&quot;, delay=True)async def limited_function(start_time):    print(f&quot;t + {(time() - start_time):.5f}&quot;)async def test_ratelimit():    start_time = time()    tasks = [limited_function(start_time) for _ in range(n_requests)]    await asyncio.gather(*tasks)    print(f&quot;Ran {n_requests} requests in {time() - start_time:.5f} seconds&quot;)asyncio.run(test_ratelimit())```</longdescription>
</pkgmetadata>