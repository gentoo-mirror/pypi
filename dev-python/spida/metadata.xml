<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Spida: Stable Diffusion API Wrapper for Automatic1111 WebUI[![PyPI Version](https://img.shields.io/pypi/v/spida.svg)](https://pypi.org/project/spida/)[![License](https://img.shields.io/pypi/l/spida.svg)](https://github.com/h2see/spida/blob/master/LICENSE)Spida is a Python package that serves as a wrapper for the Stable Diffusion API provided by the Automatic1111 WebUI. It simplifies the usage of the Stable Diffusion model for generating AI-generated images from text prompts. Spida also includes support for the ControlNet extension, allowing users to condition the generation process using ControlNet modules. Spida is an anagram of SDAPI (Stable Diffusion API).## DependenciesSpida requires the [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) with the [ControlNet Extension](https://github.com/Mikubill/sd-webui-controlnet). Spida was tested with Stable Diffusion WebUI git commit hash `89f9faa63388756314e8a1d96cf86bf5e0663045` and ControlNet Extension git commit hash `d831043cb81e97724ccf9f071da391d479440a77`.**Note:** You must use the `--api` command line argument in the `webui_startfile`.## InstallationYou can install Spida using pip:```shellpip install spida```## Usage### Quick StartTo use Spida in your python project, import it as shown here:```pythonimport spida```The following code demonstrates a basic call to the `txt2img()` function. The code uses the prompt `&quot;cow&quot;` returns a numpy image array, `imgs`. Only one image is created, so `imgs[0]` is used to retrieve it. The image is then displayed using the `show()` function.```pythonimgs = spida.txt2img(&quot;cow&quot;)spida.show(imgs[0])```For ControlNet functionality jump to: [Example](#using-controlnet-in-txt2img)### Starting the Local APIBefore using Spida, it is recommended to start the local API provided by the Automatic1111 WebUI. However, it is not required. This can be done using the `start()` function:```pythonspida.start()```### Selecting the Stable Diffusion ModelTo set the Stable Diffusion model to be used, you can use the `model()` function:```pythonspida.model(&quot;model_name&quot;)```The `model_name` parameter should be the name of the desired Stable Diffusion model. `model_name` doesn't have to be an exact match. Spida will automatically search for the closest match by default.### Generating Images from Text PromptsSpida allows you to generate AI-generated images from text prompts using the Stable Diffusion model. The `txt2img()` function is used for this purpose:```pythonimages = spida.txt2img(&quot;text_prompt&quot;)```The `text_prompt` parameter should be the desired text prompt for generating the images. You can also specify additional parameters such as the number of steps, image shape, batch size, and more. Spida provides options to control various aspects of the generation process.### Using the ControlNet ExtensionSpida supports the ControlNet extension, which allows for conditioning the generation process using ControlNet modules. You can use the `annotate()` function to annotate a batch of images using a specified ControlNet module:```pythonannotated_images = spida.annotate(images, annotator=&quot;controlnet_module&quot;)```The `controlnet_module` parameter should be the name of the ControlNet module to be used for annotation.### Retrieving InfoSpida has multiple functions for retrieving information, they are listed here:```python# get functionsspida.get_models()spida.get_samplers()spida.get_annotators()spida.get_cnet_models()spida.get_styles()# search functionsspida.search_models(&quot;model_name&quot;)spida.search_samplers(&quot;sampler_name&quot;)spida.search_annotators(&quot;annotator_name&quot;)spida.search_cnet_models(&quot;cnet_model_name&quot;)spida.search_styles(&quot;style_name&quot;)```### Utility FunctionsSpida also provides the following utility functions:```pythonspida.open()spida.show()spida.save()spida.grid_img()```## Examples### Generating multiple images from a text prompt```pythonimport spida# Start the local APIspida.start()# Set the Stable Diffusion modelspida.model(&quot;model_name&quot;)# Generate multiple images from a text promptimages = spida.txt2img(&quot;text_prompt&quot;, batch_count=4)# Create an image grid from images and display itimg_grid = spida.grid_img(images)spida.show(img_grid)```### Annotating images using ControlNet```pythonimport spida# Start the local APIspida.start()# Set the Stable Diffusion modelspida.model(&quot;model_name&quot;)# Generate images from a text promptimages = spida.txt2img(&quot;text_prompt&quot;)# Annotate the images using a ControlNet moduleannotated_images = spida.annotate(images, annotator=&quot;controlnet_module&quot;)# Create an image grid from images and display itimg_grid = spida.grid_img(annotated_images)spida.show(img_grid)```### Using ControlNet in txt2img```pythonimport spidaimport numpy as np# Start the local APIspida.start()# Set the Stable Diffusion modelspida.model(&quot;model_name&quot;)# Create an image to annotateimgs = spida.txt2img(&quot;chair&quot;)# Generate the settings for a ControlNet unitcset = spida.cnet_settings(imgs[0])# Use the settings for conditioning the generation processresults = spida.txt2img(&quot;chair&quot;, cnet_settings=cset)# Create and display a grid showing each step of the processgrid = spida.grid_img(np.array([imgs[0], results[1], results[0]]), (1, None))spida.show(grid)```## LicenseThis project is licensed under the [MIT License](https://github.com/h2see/spida/blob/master/LICENSE).</longdescription>
</pkgmetadata>