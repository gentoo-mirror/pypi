<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># geofileops [![Actions Status](https://github.com/geofileops/geofileops/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/geofileops/geofileops/actions/workflows/tests.yml?query=workflow%3ATests) [![Coverage Status](https://codecov.io/gh/geofileops/geofileops/branch/main/graph/badge.svg)](https://codecov.io/gh/geofileops/geofileops)[![PyPI version](https://img.shields.io/pypi/v/geofileops.svg)](https://pypi.org/project/geofileops)[![Conda version](https://anaconda.org/conda-forge/geofileops/badges/version.svg)](https://anaconda.org/conda-forge/geofileops)This python library aims to make it easier and faster to develop spatial analysis onlarge vector GIS files.It provides an easy to use API that can accomplish a lot with few lines of code. Mosttypical GIS operations are available: e.g. [buffer](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.buffer), [dissolve](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.dissolve),[erase](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.erase)/difference, [intersection](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.intersection), [union](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.union),... Check out the [API reference](https://geofileops.readthedocs.io/en/stable/reference.html)for a full list.Geofileops is tested on geopackage and shapefile input files. However, geopackageis recommended as it will give better performance for most operations.The aim is that there is no size limit on the files that can be processed on standardhardware. To make processing faster, the operations can use all available CPU's. Insome cases (complex) geometries can be cut in smaller tiles to speed up processingfurther. For operations like buffer this won't make a big difference as it doesn't needa lot of CPU power, but calculating the intersection between two large files, dissolvinglarge files,... will be a lot faster.The following chart gives an impression of the speed improvement that can be expectedwhen processing larger files (including I/O) with 10 CPU's available. More informationabout this benchmark can be found [here](https://github.com/geofileops/geobenchmark).![Geo benchmark](https://github.com/geofileops/geobenchmark/blob/main/results_vector_ops/GeoBenchmark.png)</longdescription>
</pkgmetadata>