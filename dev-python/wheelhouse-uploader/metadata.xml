<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>wheelhouse-uploader===================Upload/download wheels to/from cloud storage using Apache Libcloud.Helps package maintainers build wheels for their packages and uploadthem to PyPI.The cloud storage containers are typically populated by ContinuousIntegration servers that generate and test binary packages on variousplatforms (Windows and OSX for several versions and architectures forPython). At release time the project maintainer can collect all thegenerated package for a specific version of the project and upload themall at once to PyPI.Installation------------.. code:: bash   pip install wheelhouse-uploaderUsage-----The canonical use case is:1. Continuous Integration (CI) workers build and test the project   packages for various platforms and versions of Python, for instance   using the commands:   .. code:: bash      pip install wheel      python setup.py bdist_wheel2. CI workers use ``wheelhouse-uploader`` to upload the generated   artifacts to one or more cloud storage containers (e.g. one container   per platform, or one for the master branch and the other for release   tags):   .. code:: bash      python -m wheelhouse_uploader upload container_name3. The project maintainer uses the ``wheelhouse-uploader`` distutils   extensions to fetch all the generated build artifacts for a specific   version number to its local ``dist`` folder and upload them all at   once to PyPI when making a release.   .. code:: bash      python setup.py sdist fetch_artifacts upload_allUploading artifact to a cloud storage container~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Use the following command:.. code:: bash   python -m wheelhouse_uploader upload \       --username=mycloudaccountid --secret=xxx \       --local-folder=dist/ my_wheelhouseor:.. code:: bash   export WHEELHOUSE_UPLOADER_USERNAME=mycloudaccountid   export WHEELHOUSE_UPLOADER_SECRET=xxx   python -m wheelhouse_uploader upload --local-folder dist/ my_wheelhouseWhen used in a CI setup such as http://travis-ci.org orhttp://appveyor.com, the environment variables are typically configuredin the CI configuration files such as ``.travis.yml`` or``appveyor.yml``. The secret API key is typically encrypted and exposedwith a ``secure:`` prefix in those files.The files in the ``dist/`` folder will be uploaded to a container named``my_wheelhouse`` on the ``CLOUDFILES`` (Rackspace) cloud storageprovider.You can pass a custom ``--provider`` param to select the cloud storagefrom the list of `supportedproviders &lt;https://libcloud.readthedocs.org/en/latest/storage/supported_providers.html&gt;`__.Assuming the container will be published as a static website using thecloud provider CDN options, the ``upload`` command also maintains an``index.html`` file with links to all the files previously uploaded tothe container.It is recommended to configure the container CDN cache TTL to a shorterthan usual duration such as 15 minutes to be able to quickly perform arelease once all artifacts have been uploaded by the CI servers.Fetching artifacts manually~~~~~~~~~~~~~~~~~~~~~~~~~~~The following command downloads items that have been previouslypublished to a web page with an index with HTML links to the projectfiles:.. code:: bash   python -m wheelhouse_uploader fetch \       --version=X.Y.Z --local-folder=dist/ \       project-name http://wheelhouse.example.org/Uploading previously archived artifacts to PyPI (deprecated)~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~**DEPRECATION NOTICE**: while the following still works, you are advisedto use the alternative tool:`twine &lt;https://pypi.python.org/pypi/twine&gt;`__ that makes it easy toscript uploads of packages to PyPI without messing around with distutilsand ``setup.py``.Ensure that the ``setup.py`` file of the project registers the``wheelhouse-uploader`` distutils extensions:.. code:: python   cmdclass = {}   try:       # Used by the release manager of the project to add support for:       # python setup.py sdist fetch_artifacts upload_all       import wheelhouse_uploader.cmd       cmdclass.update(vars(wheelhouse_uploader.cmd))   except ImportError:       pass   ...   setup(       ...       cmdclass=cmdclass,   )Put the URL of the public artifact repositories populated by the CIworkers in the ``setup.cfg`` file of the project:.. code:: ini   [wheelhouse_uploader]   artifact_indexes=       http://wheelhouse.site1.org/       http://wheelhouse.site2.org/Fetch all the artifacts matching the current version of the project asconfigured in the local ``setup.py`` file and upload them all to PyPI:.. code:: bash   python setup.py fetch_artifacts upload_allNote: this will reuse PyPI credentials stored in ``$HOME/.pypirc`` if``python setup.py register`` or ``upload`` were called previously.TODO~~~~-  test on as many cloud storage providers as possible (please send an   email to olivier.grisel@ensta.org if you can make it work on a   non-Rackspace provider),-  check that CDN activation works everywhere (it’s failing on Rackspace   currently: need to investigate) otherwise the workaround is to enable   CDN manually in the management web UI,-  make it possible to fetch private artifacts using the cloud storage   protocol instead of HTML index pages.</longdescription>
</pkgmetadata>