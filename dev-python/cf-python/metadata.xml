<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>CF Python=========The Python cf package is an Earth science data analysis library thatis built on a complete implementation of the `CF datamodel &lt;https://cfconventions.org/cf-conventions/cf-conventions.html#appendix-CF-data-model&gt;`_.Documentation=============http://ncas-cms.github.io/cf-pythonDask====From version 3.14.0, the ``cf`` package uses `Dask&lt;https://docs.dask.org&gt;`_ for all of its data manipulations.Recipes=======https://ncas-cms.github.io/cf-python/recipesTutorial========https://ncas-cms.github.io/cf-python/tutorialInstallation============http://ncas-cms.github.io/cf-python/installationCommand line utilities======================During installation the ``cfa`` command line utility is alsoinstalled, which* generates text descriptions of field constructs contained in files,  and* creates new datasets aggregated from existing files.Visualization=============Powerful, flexible, and very simple to produce visualizations of fieldconstructs are available with the[cfplot](http://ajheaps.github.io/cf-plot) package, that needs to beinstalled seprately to the ``cf`` package.See the `cfplot gallery&lt;http://ajheaps.github.io/cf-plot/gallery.html&gt;`_ for the full rangerange plotting possibilities with example code.Functionality=============The ``cf`` package implements the `CF data model&lt;https://cfconventions.org/cf-conventions/cf-conventions.html#appendix-CF-data-model&gt;`_for its internal data structures and so is able to process anyCF-compliant dataset. It is not strict about CF-compliance, however,so that partially conformant datasets may be ingested from existingdatasets and written to new datasets. This is so that datasets whichare partially conformant may nonetheless be modified in memory.The ``cf`` package can:* read field constructs from netCDF, CDL, PP and UM datasets,* create new field constructs in memory,* write and append field constructs to netCDF datasets on disk,* read, write, and create coordinates defined by geometry cells,* read netCDF and CDL datasets containing hierarchical groups,* inspect field constructs,* test whether two field constructs are the same,* modify field construct metadata and data,* create subspaces of field constructs,* write field constructs to netCDF datasets on disk,* incorporate, and create, metadata stored in external files,* read, write, and create data that have been compressed by convention  (i.e. ragged or gathered arrays, or coordinate arrays compressed by  subsampling), whilst presenting a view of the data in its  uncompressed form,* combine field constructs arithmetically,* manipulate field construct data by arithmetical and trigonometrical  operations,* perform statistical collapses on field constructs,* perform histogram, percentile and binning operations on field  constructs,* regrid field constructs with (multi-)linear, nearest neighbour,  first- and second-order conservative and higher order patch recovery  methods,* apply convolution filters to field constructs,* create running means from field constructs,* apply differential operators to field constructs,* create derived quantities (such as relative vorticity).</longdescription>
</pkgmetadata>