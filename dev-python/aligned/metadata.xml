<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># AlignedAligned help defining a single source of truth for logic while keeping the technology stack flexible. Such innovation has been possible by removing the need to depend on a processing engine, leading to less- and more transparent- code. Furthermore, the declarative API has made it possible to comment, add data validation, and define feature transformation at the same location. Therefore, it leads to a precise definition of the intended result.Main advantages:- Test new features faster- Adapt faster to new technical and business requirements.- Stop technology lock-in, like processing engines and infrastructure.- Stop vendor lock-in. Deploy to any provider that fits youAs a result, loading model featurs can be done with the following code.```pythonawait store.model(&quot;titanic&quot;).features_for(entities).as_pandas()```Read the post about [how the most elegant MLOps tool was created](https://matsmoll.github.io/2022/12/31/How-I-created-the-most-elegant-MLOps-tool.html)Also check out the the [example repo](https://github.com/otovo/aligned-example) to see how it can be usedAligned is still in actice development, so changes are likely.## Feature ViewsWrite features as the should be, as data models.Then get code completion and typesafety by referencing them in other features.This makes the features light weight, data source indipendent, and flexible.```pythonclass TitanicPassenger(FeatureView):    metadata = FeatureViewMetadata(        name=&quot;passenger&quot;,        description=&quot;Some features from the titanic dataset&quot;,        batch_source=FileSource.csv_at(&quot;titanic.csv&quot;),        stream_source=HttpStreamSource(topic_name=&quot;titanic&quot;)    )    passenger_id = Entity(dtype=Int32())    # Input values    age = (        Float()            .description(&quot;A float as some have decimals&quot;)            .is_required()            .lower_bound(0)            .upper_bound(110)    )    name = String()    sex = String().accepted_values([&quot;male&quot;, &quot;female&quot;])    survived = Bool().description(&quot;If the passenger survived&quot;)    sibsp = Int32().lower_bound(0, is_inclusive=True).description(&quot;Number of siblings on titanic&quot;)    cabin = String()    # Creates two one hot encoded values    is_male, is_female = sex.one_hot_encode(['male', 'female'])    # Standard scale the age.    # This will fit the scaler using a data slice from the batch source    # limited to maximum 100 rows. We can also uese a time constraint if wanted    scaled_age = age.standard_scaled(limit=100)```## Data sourcesAlinged makes handling data sources easy, as you do not have to think about how it is done.Only define where the data is, and we handle the dirty work.```pythonmy_db = PostgreSQLConfig(env_var=&quot;DATABASE_URL&quot;)class TitanicPassenger(FeatureView):    metadata = FeatureViewMetadata(        name=&quot;passenger&quot;,        description=&quot;Some features from the titanic dataset&quot;,        batch_source=my_db.table(            &quot;passenger&quot;,            mapping_keys={                &quot;Passenger_Id&quot;: &quot;passenger_id&quot;            }        ),        stream_source=HttpStreamSource(topic_name=&quot;titanic&quot;)    )    passenger_id = Entity(dtype=Int32())```### Fast developmentMaking iterativ and fast exploration in ML is important. This is why Aligned also makes it super easy to combine, and test multiple sources.```pythonmy_db = PostgreSQLConfig.localhost()aws_bucket = AwsS3Config(...)class SomeFeatures(FeatureView):    metadata = FeatureViewMetadata(        name=&quot;some_features&quot;,        description=&quot;...&quot;,        batch_source=my_db.table(&quot;local_features&quot;)    )    # Some features    ...class AwsFeatures(FeatureView):    metadata = FeatureViewMetadata(        name=&quot;aws&quot;,        description=&quot;...&quot;,        batch_source=aws_bucket.file_at(&quot;path/to/file.parquet&quot;)    )    # Some features    ...```## Model ServiceUsually will you need to combine multiple features for each model.This is where a `ModelService` comes in.Here can you define which features should be exposed.```python# Uses the variable name, as the model service name.# Can also define a custom name, if wanted.titanic_model = ModelService(    features=[        TitanicPassenger.select_all(),        # Select features with code completion        LocationFeatures.select(lambda view: [            view.distance_to_shore,            view.distance_to_closest_boat        ]),    ])```## Data EnrichersIn manny cases will extra data be needed in order to generate some features.We therefore need some way of enriching the data.This can easily be done with Alinged's `DataEnricher`s.```pythonmy_db = PostgreSQLConfig.localhost()redis = RedisConfig.localhost()user_location = my_db.data_enricher( # Fetch all user locations    sql=&quot;SELECT * FROM user_location&quot;).cache( # Cache them for one day    ttl=timedelta(days=1),    cache_key=&quot;user_location_cache&quot;).lock( # Make sure only one processer fetches the data at a time    lock_name=&quot;user_location_lock&quot;,    redis_config=redis)async def distance_to_users(df: DataFrame) -&gt; Series:    user_location_df = await user_location.load()    ...    return distancesclass SomeFeatures(FeatureView):    metadata = FeatureViewMetadata(...)    latitude = Float()    longitude = Float()    distance_to_users = Float().transformed(distance_to_users, using_features=[latitude, longitude])```## Access DataYou can easily create a feature store that contains all your feature definitions.This can then be used to genreate data sets, setup an instce to serve features, DAG's etc.```pythonstore = FeatureStore.from_dir(&quot;.&quot;)# Select all features from a single feature viewdf = await store.all_for(&quot;passenger&quot;, limit=100).to_df()```### Centraliced Feature Store DefinitionYou would often share the features with other coworkers, or split them into different stages, like `staging`, `shadow`, or `production`.One option is therefore to reference the storage you use, and load the `FeatureStore` from there.```pythonaws_bucket = AwsS3Config(...)store = await aws_bucket.file_at(&quot;production.json&quot;).feature_store()# This switches from the production online store to the offline store# Aka. the batch sources defined on the feature viewsexperimental_store = store.offline_store()```This json file can be generated by running `alinged apply`.### Select multiple feature views```pythondf = await store.features_for({    &quot;passenger_id&quot;: [1, 50, 110]}, features=[    &quot;passenger:scaled_age&quot;,    &quot;passenger:is_male&quot;,    &quot;passenger:sibsp&quot;    &quot;other_features:distance_to_closest_boat&quot;,]).to_df()```### Model ServiceSelecting features for a model is super simple.```pythondf = await store.model(&quot;titanic_model&quot;).features_for({    &quot;passenger_id&quot;: [1, 50, 110]}).to_df()```### Feature ViewIf you want to only select features for a specific feature view, then this is also possible.```pythonprev_30_days = await store.feature_view(&quot;match&quot;).previous(days=30).to_df()sample_of_20 = await store.feature_view(&quot;match&quot;).all(limit=20).to_df()```## Data qualityAlinged will make sure all the different features gets formatted as the correct datatype.In addition will aligned also make sure that the returend features aligne with defined constraints.```pythonclass TitanicPassenger(FeatureView):    ...    age = (        Float()            .is_required()            .lower_bound(0)            .upper_bound(110)    )    sibsp = Int32().lower_bound(0, is_inclusive=True)```Then since our feature view have a `is_required` and a `lower_bound`, will the `.validate(...)` command filter out the entites that do not follow that behavior.```pythonfrom aligned.validation.pandera import PanderaValidatordf = await store.model(&quot;titanic_model&quot;).features_for({    &quot;passenger_id&quot;: [1, 50, 110]}).validate(    PanderaValidator()  # Validates all features).to_df()```## Feature ServerThis expectes that you either run the command in your feature store repo, or have a file with a `RepoReference` instance.You can also setup an online source like Redis, for faster storage.```pythonredis = RedisConfig.localhost()aws_bucket = AwsS3Config(...)repo_files = RepoReference(    env_var_name=&quot;ENVIRONMENT&quot;,    repo_paths={        &quot;production&quot;: aws_bucket.file_at(&quot;feature-store/production.json&quot;),        &quot;shadow&quot;: aws_bucket.file_at(&quot;feature-store/shadow.json&quot;),        &quot;staging&quot;: aws_bucket.file_at(&quot;feature-store/staging.json&quot;)        # else generate the feature store from the current dir    })# Use redis as the online source, if not running localyif repo_files.selected != &quot;local&quot;:    online_source = redis.online_source()```Then run `aligned serve`, and a FastAPI server will start. Here can you push new features, which then transforms and stores the features, or just fetch them.</longdescription>
</pkgmetadata>