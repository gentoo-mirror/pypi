<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># skypoint-python-cdm-connectorPython Spark CDM Connector by SkyPoint. Apache Spark connector for the Microsoft Azure &quot;Common Data Model&quot;. Reading and writing is supported and it is a work in progress. Please file issues for any bugs that you find. For more information about the Azure Common Data Model, check out [this page](https://docs.microsoft.com/en-us/common-data-model/data-lake). &lt;br&gt;We support Azure Data Lake Service (ADLS) and AWS S3 as storage, historical data preservation using snapshots of the schema &amp; data files and usage within PySpark, Azure Functions etc.  *Upcoming Support for incremental data refresh handling, [CDM 1.1](https://docs.microsoft.com/en-us/common-data-model/cdm-manifest and Google Cloud (Cloud Storage). &lt;br&gt;## Example1. Please look into the sample usage file skypoint_python_cdm.py2. Dynamically add/remove entities, annotations and attributes3. Pass Reader and Writer object for any storage account you like to write/read data to/from.4. Check out the below code for basic read and write examples.```python# Initialize empty modelm = Model()# Sample dataframedf = {&quot;country&quot;: [&quot;Brazil&quot;, &quot;Russia&quot;, &quot;India&quot;, &quot;China&quot;, &quot;South Africa&quot;, &quot;ParaSF&quot;],       &quot;currentTime&quot;: [datetime.now(), datetime.now(), datetime.now(), datetime.now(), datetime.now(), datetime.now()],       &quot;area&quot;: [8.516, 17.10, 3.286, 9.597, 1.221, 2.222],       &quot;capital&quot;: [&quot;Brasilia&quot;, &quot;Moscow&quot;, &quot;New Dehli&quot;, &quot;Beijing&quot;, &quot;Pretoria&quot;, &quot;ParaSF&quot;],       &quot;population&quot;: [200.4, 143.5, 1252, 1357, 52.98, 12.34] }df = pd.DataFrame(df)# Generate entity from the dataframeentity = Model.generate_entity(df, &quot;customEntity&quot;)# Add generated entity to modelm.add_entity(entity)# Add model level annotation# Annotation can be added at entity level as well as attribute levelModel.add_annotation(&quot;modelJsonAnnotation&quot;, &quot;modelJsonAnnotationValue&quot;, m)# Create an ADLSWriter to write into ADLSwriter = ADLSWriter(&quot;ACCOUNT_NAME&quot;, &quot;ACCOUNT_KEY&quot;,                     &quot;CONTAINER_NAME&quot;, &quot;STORAGE_NAME&quot;, &quot;DATAFLOW_NAME&quot;)    # Write data as well as model.json in ADLS storagem.write_to_storage(&quot;customEntity&quot;, df, writer)```## ContributingThis project welcomes contributions and suggestions. ## References[Model.json version1 schema](https://github.com/microsoft/CDM/blob/master/docs/schema/modeljsonschema.json)[A clean implementation for Python Objects from/to model.json file](https://github.com/Azure-Samples/cdm-azure-data-services-integration/blob/master/CDM/python/CdmModel.py)</longdescription>
</pkgmetadata>