<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Prometheus ECS Discoverer[![PyPI version](https://badge.fury.io/py/prometheus-ecs-discoverer.svg)](https://pypi.python.org/pypi/prometheus-ecs-discoverer/)[![Maintenance](https://img.shields.io/badge/maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)[![downloads](https://img.shields.io/pypi/dm/prometheus-ecs-discoverer)](https://pypi.org/project/prometheus-ecs-discoverer/)[![docs](https://img.shields.io/badge/docs-here-blue)](https://trallnag.github.io/prometheus-ecs-discoverer/)![release](https://github.com/trallnag/prometheus-ecs-discoverer/workflows/release/badge.svg)![test branches](https://github.com/trallnag/prometheus-ecs-discoverer/workflows/test%20branches/badge.svg)[![codecov](https://codecov.io/gh/trallnag/prometheus-ecs-discoverer/branch/master/graph/badge.svg)](https://codecov.io/gh/trallnag/prometheus-ecs-discoverer)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)Based on [prometheus-ecs-sd](https://github.com/signal-ai/prometheus-ecs-sd),this project enables your Prometheus to **dynamically scrape targets** deployedin AWS ECS. The discoverer is perfect if you don't havea service discovery system like Consul in-place. It provides an easy-to-usealternative and can be used in low- to mid-sized environments with **hundredsof tasks** running in parallel.Once the discoverer is up and running, any task can be made visible toPrometheus.![diagram](https://raw.githubusercontent.com/trallnag/prometheus-ecs-discoverer/master/documents/drawio-diagram.png)What are the advantages of using this project over [prometheus-ecs-sd](https://github.com/signal-ai/prometheus-ecs-sd)?* Modified throttling in combination with the already existing caching allows    the usage in environments with hundreds of tasks.* Every target can expose custom labels via its environment variables. This way    you can provide more ways to aggregate metrics. For example by type of API.* Deploy as container (provided and can be used directly) or Python package.    No need to manually install boto3 and so on.* Instrumented with Prometheus. Allows more insights into the discoverer. You    can monitor how long discovery rounds take and stuff like used memory.    Dashboard already included and ready to use.* Extensive testing with high coverage ensures functionality.* More configuration options. For example structured logs.## SetupAs this project is based on[prometheus-ecs-sd](https://github.com/signal-ai/prometheus-ecs-sd), the setupis very similar / exactly the same. The setup consists out of three parts.The targets must be prepared by adding environment variables. Next, PromEDitself must be deployed. And finally, the Prometheus configuration must beupdated.### Prepare targetsTargets are setup via setting environment variables in the task definitions.#### Mark container as targetSet `PROMETHEUS_TARGET` to `true` to make PromED consider the container. Thisby itself is already enough to make it work with the configured defaults.Alternatively you can use the `dockerLabels` in the container definition. Forthis you have to set the PromED setting `MARKER_TYPE` to `dockerLabels`instead of the default `environment`.#### Specify metrics endpoint(s)If your metrics are not exposed on the default `/metrics` endpoint, you canspecifiy the endpoint with `PROMETHEUS_ENDPOINT`.You can also declare multiple endpoints and different intervals. The supportedintervals are `15s`, `30s`, `1m` and `5m`. Based on the interval, targets willend up in different files. The default interval is &quot;generic&quot;. Examples for this:* `5m:/mymetrics,30s:/mymetrics2`* `/mymetrics`* `/mymetrics,30s:/mymetrics2`By default, all targets will end up in a single file called `tasks.json` in theconfigured directory (defaults to `/tmp`).#### Set custom labels for containerSometimes you might want to add additonal labels to targets to group them.For example by the used API type (REST vs. GraphQL). This can be done by addingenvironment variables to the container definition in the respective taskdefinition with the  `PROMETHEUS_LABEL_` prefix. For example`PROMETHEUS_LABEL_api_type` or `PROMETHEUS_LABEL_foo`. Environment variablesset from within the container are not visible to PromED and are ignored.```json&quot;environment&quot;: [  { &quot;name&quot;: &quot;PROMETHEUS_LABEL_foo&quot;, &quot;value&quot;: &quot;bar&quot; },  { &quot;name&quot;: &quot;PROMETHEUS_LABEL_high&quot;, &quot;value&quot;: &quot;fi&quot; },]```There is an alternative for this using the `dockerLabels` attribute instead.PromED always checks both locations. Unlike with the environment variables,the additional target labels are all contained in one string. You can configurethe label PromED should look for by setting `CUSTOM_LABELS_KEY`. It works likethis:```json&quot;dockerLabels&quot;: {  &quot;promed.custom_labels&quot;: &quot;foo=bar, high=fi,what=ever&quot;}```The third option is to use the `WITH_DOCKER_LABELS` setting to give PromED anarray of labels it should always try to map from `dockerLabels` to targetlabels. The PromED config could look like this (notice the config prefix):```json&quot;environment&quot;: {  &quot;PROMED_WITH_DOCKER_LABELS&quot;: &quot;['com.company.namespace', 'com.company.alias']&quot;}```A container that uses these labels:```json&quot;dockerLabels&quot;: {  &quot;com.company.namespace&quot;: &quot;whatever&quot;,  &quot;com-company-alias&quot;: &quot;zoomzoom&quot;}```PromED translates it to `com_company_namespace` and `com_company_alias`.#### Customize networkingRegarding networking, all network modes are supported (`bridge`, `host`and `awsvpc`).If `PROMETHEUS_PORT` and `PROMETHEUS_CONTAINER_PORT` are not set, the scriptwill pick the first port from the container definition (in awsvpc and hostnetwork mode) or the container host network bindings in bridge mode. OnFargate, if `PROMETHEUS_PORT` is not set, it will default to port `80`.If `PROMETHEUS_CONTAINER_PORT` is set, it will look at the container hostnetwork bindings, and find the entry with a matching `containerPort`. It willthen use the `hostPort` found there as target port. This is useful when thecontainer port is known, but the `hostPort` is randomly picked by ECS (bysetting `hostPort` to `0` in the task definition).If your container uses multiple ports, it's recommended to specify`PROMETHEUS_PORT` (`awsvpc`, `host`) or `PROMETHEUS_CONTAINER_PORT` (`bridge`).*Quoted from[prometheus-ecs-sd](https://github.com/signal-ai/prometheus-ecs-sd)commit `ece6ca2`.*### Deploy PromEDYou can either use the Python package directly or go for the Docker image.Please note that just running the package / image is not enough. The enviornmentmust be ready for boto3. This includes credentials and approbiate rights.#### Using package from PyPIAvailable under the name `prometheus_ecs_discoverer`. To start PromED:```shpython -m prometheus_ecs_discoverer.run```To configure PromED you can either provide a settings file or use plainenvironment variables.  Please see [Configuration](#configuration) for moreinfo. Please see [Configuration](#configuration) for more info.#### Using Docker imageThe image `trallnag/prometheus_ecs_discoverer` can be found[here](https://hub.docker.com/r/trallnag/prometheus_ecs_discoverer).The recommended way for configuring the image is to use environment variables.You will probably want to run the discoverer in ECS. Here, you don't have toprovide credentials assuming everything is set up correctly. Boto3 willautomatically detect relative credentials URI and retrieve them from AWS.Nevertheless, the region must be set by you.#### AWS IAMThe actions that PromED is performing on the AWS API can be found in[aws-iam-policy.json](https://github.com/trallnag/prometheus-ecs-discoverer/blob/master/documents/aws-iam-policy.json).The allowed actions must be attached to an approbiate role. If you deployPromED in ECS, this should look like in [aws-iam-ecs-role.json](https://github.com/trallnag/prometheus-ecs-discoverer/blob/master/documents/aws-iam-ecs-role.json).### Configure PrometheusIf you want all your targets to be scraped in the same interval, the followingjob is enough.```txt- job_name: 'ecs'  file_sd_configs:    - files:        - /tmp/tasks.json  relabel_configs:    - source_labels: [metrics_path]      action: replace      target_label: __metrics_path__      regex: (.+)```By default, PromED exposes an `/metrics` endpoint.```txt- job_name: discovery  static_configs:    - targets: [&quot;discovery:8080&quot;]```## ConfigurationAs this project is based on[prometheus-ecs-sd](https://github.com/signal-ai/prometheus-ecs-sd),the configuration is mostly compatible.PromED uses [Dynconf](https://www.dynaconf.com/) for config management. Thereare two main ways you can configure the application. Either by providing acustom settings file with the env var `SETTINGS_FILES_FOR_DYNACONF` (see[here](https://www.dynaconf.com/configuration/#on-environment-options))or directly setting the respective values via env vars with the `PROMED_`prefix. All supported settings together with their default values can be found[`settings.toml` (click me)](https://github.com/trallnag/prometheus-ecs-discoverer/blob/master/prometheus_ecs_discoverer/settings.toml).## Grafana DashboardYou can find the Grafana dashboards for PromED in the documents folder.![dashboard-screenshot](https://raw.githubusercontent.com/trallnag/prometheus-ecs-discoverer/master/documents/screenshot-dashboard-PromED.png)A second dashboard contains panels with Grafana Alerts enabled.![dashboard-screenshot](https://raw.githubusercontent.com/trallnag/prometheus-ecs-discoverer/master/documents/screenshot-dashboard-PromED-Alerting.png)## PrerequesitesSee [pyproject.toml](https://github.com/trallnag/prometheus-ecs-discoverer/blob/master/pyproject.toml).## DevelopmentDeveloping and building this package on a local machine requires[Python Poetry](https://python-poetry.org/). I recommend to run Poetry intandem with [Pyenv](https://github.com/pyenv/pyenv). Once the repository iscloned, run `poetry install` and `poetry shell`. From here you may start theIDE of your choice.</longdescription>
</pkgmetadata>