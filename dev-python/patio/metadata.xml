<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![PyPI - License](https://img.shields.io/pypi/l/patio)](https://pypi.org/project/patio) [![Wheel](https://img.shields.io/pypi/wheel/patio)](https://pypi.org/project/patio) [![Mypy](http://www.mypy-lang.org/static/mypy_badge.svg)]() [![PyPI](https://img.shields.io/pypi/v/patio)](https://pypi.org/project/patio) [![PyPI](https://img.shields.io/pypi/pyversions/patio)](https://pypi.org/project/patio) [![Coverage Status](https://coveralls.io/repos/github/patio-python/patio/badge.svg?branch=master)](https://coveralls.io/github/patio-python/patio?branch=master) ![tox](https://github.com/patio-python/patio/workflows/tests/badge.svg?branch=master)PATIO=====PATIO is an acronym for **P**ython **A**synchronous **T**asks for Async**IO**.Motivation----------I wanted to create an easily extensible library, for distributed task execution,like [`celery`](https://docs.celeryq.dev/), only targeting asyncio as the maindesign approach.By design, the library should be suitable for small projects and the reallylarge distributed projects. The general idea is that the user simply splitsthe projects code base into functions of two roles â€“ background tasks and triggers of these background tasks.Also, this should help your project to scale horizontally. It allows to makeworkers or callers available across the network using embedded TCP, or usingplugins to communicate through the existing messaging infrastructure.Quickstart----------The minimal example, which executes tasks in a thread pool:```pythonimport asynciofrom functools import reducefrom patio import Registryfrom patio.broker import MemoryBrokerfrom patio.executor import ThreadPoolExecutorrpc = Registry()@rpc(&quot;mul&quot;)def multiply(*args: int) -&gt; int:    return reduce(lambda x, y: x * y, args)async def main():    async with ThreadPoolExecutor(rpc, max_workers=4) as executor:        async with MemoryBroker(executor) as broker:            print(                await asyncio.gather(                    *[broker.call(&quot;mul&quot;, 1, 2, 3) for _ in range(100)]                )            )if __name__ == '__main__':    asyncio.run(main())```The `ThreadPoolExecutor` in this example is the entity that will execute thetasks. If the tasks in your project are asynchronous, you can select`AsyncExecutor`, and then the code will look like this:```pythonimport asynciofrom functools import reducefrom patio import Registryfrom patio.broker import MemoryBrokerfrom patio.executor import AsyncExecutorrpc = Registry()@rpc(&quot;mul&quot;)async def multiply(*args: int) -&gt; int:    # do something asynchronously    await asyncio.sleep(0)    return reduce(lambda x, y: x * y, args)async def main():    async with AsyncExecutor(rpc, max_workers=4) as executor:        async with MemoryBroker(executor) as broker:            print(                await asyncio.gather(                    *[broker.call(&quot;mul&quot;, 1, 2, 3) for _ in range(100)]                )            )if __name__ == '__main__':    asyncio.run(main())```These examples may seem complicated, but don't worry, the next section detailsthe general concepts and hopefully a lot will become clear to you.The main concepts-----------------The main idea in developing this library was to create a maximallymodular and extensible system that can be expanded with third-partyintegrations or directly in the user's code.The basic elements from which everything is built are:* `Registry` - Key-Value like store for the functions* `Executor` - The thing which execute functions from the registry* `Broker` - The actor who distributes tasks in your distributed  (or local) system.Registry--------This is a container of functions for their subsequent execution.You can register a function by specific name or without it,in which case the function is assigned a unique name that depends onthe source code of the function.This registry does not necessarily have to match on the calling and calledsides, but for functions that you register without a name it is must be,and then you should not need to pass the function name but the functionitself when you will call it.An instance of the registry must be transferred to the broker,the first broker in the process of setting up will block the registryto write, that is, registering new functions will be impossible.An optional ``project`` parameter, this is essentially like a namespacethat will help avoid clash functions in different projects with the samename. It is recommended to specify it and the broker should also use thisparameter, so it should be the same value within the same project.You can either manually register elements or use aregistry instance as a decorator:```pythonfrom patio import Registryrpc = Registry(project=&quot;example&quot;)# Will be registered with auto generated name@rpcdef mul(a, b):    return a * b@rpc('div')def div(a, b):    return a / bdef pow(a, b):    return a ** bdef sub(a, b):    return a - b# Register with auto generated namerpc.register(pow)rpc.register(sub, &quot;sub&quot;)```Alternatively using ``register`` method:```pythonfrom patio import Registryrpc = Registry(project=&quot;example&quot;)def pow(a, b):    return a ** bdef sub(a, b):    return a - b# Register with auto generated namerpc.register(pow)rpc.register(sub, &quot;sub&quot;)```Finally, you can register functions explicitly, as if it werejust a dictionary:```pythonfrom patio import Registryrpc = Registry(project=&quot;example&quot;)def mul(a, b):    return a * brpc['mul'] = mul```Executor--------An Executor is an entity that executes local functions from registry.The following executors are implemented in the package:* `AsyncExecutor` - Implements pool of asynchronous tasks* `ThreadPoolExecutor` - Implements pool of threads* `ProcessPoolExecutor` - Implements pool of processes* `NullExecutor` - Implements nothing and exists just for forbid execute  anything explicitly.Its role is to reliably execute jobs without taking too much so as not tocause a denial of service, or excessive memory consumption.The executor instance is passing to the broker, it's usually appliesit to the whole registry. Therefore, you should understand what functionsthe registry must contain to choose kind of an executor.Broker------The basic approach for distributing tasks is to shift the responsibilityfor the distribution to the user implementation. In this way, taskdistribution can be implemented through third-party brokers, databases,or something else.This package is implemented by the following brokers:* `MemoryBroker` - To distribute tasks within a single process.   A very simple implementation, in case you don't know yet how   your application will develop and just want to leave the decision   of which broker to use for later, while laying the foundation for   switching to another broker.* `TCPBroker` - Simple implementation of the broker just using TCP,   both Server and Client mode is supported for both the task executor   and the task provider.### `MemoryBroker`It's a good start if you don't need to assign tasks in a distributedfashion right now.In fact, it's a simple way to run tasks in the executor from the otherplaces in your project.### `TCPBroker`It allows you to make your tasks distributed without resorting to externalmessage brokers.The basic idea of TCP broker implementation is that in terms ofperforming tasks, there is no difference between them, it isjust a way to establish a connection, both the server and theclient can be the one who performs tasks and the one who setsthem, and it is also possible in a mixed mode.In other words, deciding who will be the server and who will be theclient in your system is just a way to connect and find each otherin your distributed system.Here are the ways of organizing communication between theserver and the clients.#### Server centric scheme example![server centric](https://raw.githubusercontent.com/patio-python/patio/feature/tcp-broker/images/server-centric.svg &quot;Server Centric&quot;)This diagram describes a simple example, if there is one serverand one client exchanging messages via TCP.#### One client multiple servers example![multiple servers](https://raw.githubusercontent.com/patio-python/patio/feature/tcp-broker/images/multiple-servers.svg &quot;One client multiple servers&quot;)This is an example of how a client establishes connections to a set server.#### Full mesh example![full mesh](https://raw.githubusercontent.com/patio-python/patio/feature/tcp-broker/images/full-mesh.svg &quot;Full mesh&quot;)Full mesh scheme, all clients are connected to all servers.#### AuthorizationAuthorization takes place at the start of the connection,for this the parameter `key=` (`b''` is by default) must contain the same keysfor client and server.**It is important to understand that this is not 100% protection againstattacks like MITM etc.**This approach should only be used if the client and server are on a trustednetwork. In order to secure traffic as it traverses the Internet, the`ssl_context=` parameter should be prepended to both the server and the client(see example bellow).#### ExamplesThe examples below will hopefully help you figure this out.##### Server executing tasks```pythonfrom functools import reduceimport asynciofrom patio import Registryfrom patio.broker.tcp import TCPServerBrokerfrom patio.executor import ThreadPoolExecutorrpc = Registry(project=&quot;test&quot;, auto_naming=False)def mul(*args):    return reduce(lambda x, y: x * y, args)async def main():    rpc.register(mul, &quot;mul&quot;)    async with ThreadPoolExecutor(rpc) as executor:        async with TCPServerBroker(executor) as broker:            # Start IPv4 server            await broker.listen(address='127.0.0.1')            # Start IPv6 server            await broker.listen(address='::1', port=12345)            await broker.join()if __name__ == &quot;__main__&quot;:    asyncio.run(main())```##### Client calling tasks remotely```pythonimport asynciofrom patio import Registryfrom patio.broker.tcp import TCPClientBrokerfrom patio.executor import NullExecutorrpc = Registry(project=&quot;test&quot;, auto_naming=False)async def main():    async with NullExecutor(rpc) as executor:        async with TCPClientBroker(executor) as broker:            # Connect to the IPv4 address            await broker.connect(address='127.0.0.1')            # Connect to the IPv6 address (optional)            await broker.connect(address='::1', port=12345)            print(                await asyncio.gather(*[                    broker.call('mul', i, i) for i in range(10)                ]),            )if __name__ == &quot;__main__&quot;:    asyncio.run(main())```##### Examples with SSLThe task comes down to passing the ssl context to the server and to the client.Below you will see an example of how to make a couple of self-signedcertificates, and an authorization CA. Original post[here](https://gist.github.com/fntlnz/cf14feb5a46b2eda428e000157447309).This is just an example, and if you want to use your own certificates, justcreate an ssl context as required by your security policy.###### Certificate authority creation**Attention:** this is the key used to sign the certificate requests, anyoneholding this can sign certificates on your behalf. So keep it in a safe place!```shellopenssl req -x509 \  -sha256 -days 3650 \  -nodes \  -newkey rsa:2048 \  -subj &quot;/CN=Patio Example CA/C=CC/L=West Island&quot; \  -keyout CA.key -out CA.pem```###### Server certificate creationFirst create server private key:```shellopenssl genrsa -out server.key 2048```Then create the certificate request signing this key:```shellopenssl req \  -new -sha256 \  -key server.key \  -subj &quot;/CN=server.example.net/C=CC/L=West Island&quot; \  -out server.csr```Sign this request by CA:```shellopenssl x509 -req \  -days 365 -sha256 \  -in server.csr \  -CA CA.pem \  -CAkey CA.key \  -CAcreateserial \  -out server.pem```This should be enough to encrypt the traffic.##### Server with SSL executing tasks```pythonfrom functools import reduceimport asyncioimport sslfrom patio import Registryfrom patio.broker.tcp import TCPServerBrokerfrom patio.executor import ThreadPoolExecutorrpc = Registry(project=&quot;test&quot;, auto_naming=False)def mul(*args):    return reduce(lambda x, y: x * y, args)async def main():    rpc.register(mul, &quot;mul&quot;)    ssl_context = ssl.SSLContext()    ssl_context.load_verify_locations(&quot;path/to/CA.pem&quot;)    ssl_context.load_cert_chain(&quot;path/to/server.pem&quot;, &quot;path/to/server.key&quot;)    async with ThreadPoolExecutor(rpc) as executor:        async with TCPServerBroker(executor, ssl_context=ssl_context) as broker:            # Start IPv4 server            await broker.listen(address='127.0.0.1')            # Start IPv6 server            await broker.listen(address='::1', port=12345)            await broker.join()if __name__ == &quot;__main__&quot;:    asyncio.run(main())```##### Client calling tasks remotely```pythonimport asyncioimport sslfrom patio import Registryfrom patio.broker.tcp import TCPClientBrokerfrom patio.executor import NullExecutorrpc = Registry(project=&quot;test&quot;, auto_naming=False)async def main():    ssl_context = ssl.create_default_context(cafile=&quot;path/to/CA.pem&quot;)    async with NullExecutor(rpc) as executor:        async with TCPClientBroker(executor, ssl_context=ssl_context) as broker:            # Connect to the IPv4 address            await broker.connect(address='127.0.0.1')            # Connect to the IPv6 address (optional)            await broker.connect(address='::1', port=12345)            print(                await asyncio.gather(*[                    broker.call('mul', i, i) for i in range(10)                ]),            )if __name__ == &quot;__main__&quot;:    asyncio.run(main())```</longdescription>
</pkgmetadata>