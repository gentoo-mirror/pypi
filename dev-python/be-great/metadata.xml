<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![PyPI version](https://badge.fury.io/py/be-great.svg)](https://badge.fury.io/py/be-great) [![Downloads](https://static.pepy.tech/badge/be-great)](https://pepy.tech/project/be-great)[//]: # (![Screenshot]&amp;#40;https://github.com/kathrinse/be_great/blob/main/imgs/GReaT_logo.png&amp;#41;)&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/kathrinse/be_great/raw/main/imgs/GReaT_logo.png&quot; width=&quot;326&quot;/&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Generation of Realistic Tabular data&lt;/strong&gt;&lt;br&gt; with pretrained Transformer-based language models&lt;/p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;Our GReaT framework utilizes the capabilities of pretrained large language Transformer models to synthesize realistic tabular data. New samples are generated with just a few lines of code, following an easy-to-use API. Please see our [publication](https://openreview.net/forum?id=cEygmQNOeI) for more details. ## GReaT InstallationThe GReaT framework can be easily installed using with [pip](https://pypi.org/project/pip/) - requires a Python version &gt;= 3.9: ```bashpip install be-great```## GReaT QuickstartIn the example below, we show how the GReaT approach is used to generate synthetic tabular data for the California Housing dataset.```pythonfrom be_great import GReaTfrom sklearn.datasets import fetch_california_housingdata = fetch_california_housing(as_frame=True).framemodel = GReaT(llm='distilgpt2', batch_size=32, epochs=25)model.fit(data)synthetic_data = model.sample(n_samples=100)```[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kathrinse/be_great/blob/main/examples/GReaT_colab_example.ipynb)### Imputing a sampleGReaT also features an interface to impute, i.e., fill in, missing values in arbitrary combinations. This requires a trained ``model``, for instance one obtained using the code snippet above, and a ```pd.DataFrame``` where missing values are set to NaN.A minimal example is provided below:```python# test_data: pd.DataFrame with samples from the distribution# model: GReaT trained on the data distribution that should be imputed# Drop values randomly from test_dataimport numpy as npfor clm in test_data.columns:    test_data[clm]=test_data[clm].apply(lambda x: (x if np.random.rand() &gt; 0.5 else np.nan))imputed_data = model.impute(test_data, max_length=200)```## GReaT Citation If you use GReaT, please link or cite our work:``` bibtex@inproceedings{borisov2023language,  title={Language Models are Realistic Tabular Data Generators},  author={Vadim Borisov and Kathrin Sessler and Tobias Leemann and Martin Pawelczyk and Gjergji Kasneci},  booktitle={The Eleventh International Conference on Learning Representations },  year={2023},  url={https://openreview.net/forum?id=cEygmQNOeI}}```## GReaT AcknowledgementsWe sincerely thank the [HuggingFace](https://huggingface.co/) :hugs: framework. </longdescription>
</pkgmetadata>