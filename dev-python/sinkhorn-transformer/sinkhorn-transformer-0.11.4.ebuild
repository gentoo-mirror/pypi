# automatically generated by g-sorcery
# please do not edit this file

EAPI=8

REALNAME="sinkhorn-transformer"
REALVERSION="0.11.4"
DIGEST_SOURCES="yes"
PYTHON_COMPAT=( python{3_9,3_10,3_11} )
DISTUTILS_USE_PEP517=standalone

inherit python-r1 gs-pypi

DESCRIPTION="Sinkhorn Transformer - Sparse Sinkhorn Attention"

HOMEPAGE="https://github.com/lucidrains/sinkhorn-transformer"
LICENSE="MIT"
SRC_URI="https://files.pythonhosted.org/packages/34/7c/55333b4a92d6276cb2a2056f070771fb60885a10b7e29169c0fba2e4434d/sinkhorn_transformer-${REALVERSION}.tar.gz"
SOURCEFILE="sinkhorn_transformer-${REALVERSION}.tar.gz"
RESTRICT="test"

SLOT="0"
KEYWORDS="~amd64 ~x86"

IUSE=""
DEPENDENCIES="dev-python/axial-positional-embedding[${PYTHON_USEDEP}]
	dev-python/local-attention[${PYTHON_USEDEP}]
	dev-python/product-key-memory[${PYTHON_USEDEP}]
	dev-python/torch[${PYTHON_USEDEP}]"
BDEPEND="${DEPENDENCIES}"
RDEPEND="${DEPENDENCIES}"
