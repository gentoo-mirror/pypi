<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Zennit![Zennit-Logo](https://raw.githubusercontent.com/chr5tphr/zennit/0.5.1/share/img/zennit.png)[![Documentation Status](https://readthedocs.org/projects/zennit/badge/?version=latest)](https://zennit.readthedocs.io/en/latest/?badge=latest)[![tests](https://github.com/chr5tphr/zennit/actions/workflows/tests.yml/badge.svg)](https://github.com/chr5tphr/zennit/actions/workflows/tests.yml)[![PyPI Version](https://img.shields.io/pypi/v/zennit)](https://pypi.org/project/zennit/)[![License](https://img.shields.io/pypi/l/zennit)](https://github.com/chr5tphr/zennit/blob/master/COPYING.LESSER)Zennit (**Z**ennit **e**xplains **n**eural **n**etworks **i**n **t**orch) is ahigh-level framework in Python using Pytorch for explaining/exploring neuralnetworks. Its design philosophy is intended to provide high customizability andintegration as a standardized solution for applying rule-based attributionmethods in research, with a strong focus on Layerwise Relevance Propagation(LRP). Zennit strictly requires models to use Pytorch's `torch.nn.Module`structure (including activation functions).Zennit is currently under active development, but should be mostly stable.If you find Zennit useful for your research, please consider citing our related[paper](https://arxiv.org/abs/2106.13200):```@article{anders2021software,      author  = {Anders, Christopher J. and                 Neumann, David and                 Samek, Wojciech and                 MÃ¼ller, Klaus-Robert and                 Lapuschkin, Sebastian},      title   = {Software for Dataset-wide XAI: From Local Explanations to Global Insights with {Zennit}, {CoRelAy}, and {ViRelAy}},      journal = {CoRR},      volume  = {abs/2106.13200},      year    = {2021},}```## DocumentationThe latest documentation is hosted at[zennit.readthedocs.io](https://zennit.readthedocs.io/en/latest/).## InstallTo install directly from PyPI using pip, use:```shell$ pip install zennit```Alternatively, install from a manually cloned repository to try out the examples:```shell$ git clone https://github.com/chr5tphr/zennit.git$ pip install ./zennit```## UsageAt its heart, Zennit registers hooks at Pytorch's Module level, to modify thebackward pass to produce rule-based attributions like LRP (instead of the usualgradient). All rules are implemented as hooks([`zennit/rules.py`](https://github.com/chr5tphr/zennit/blob/0.5.1/src/zennit/rules.py)) and most use the LRP basis`BasicHook` ([`zennit/core.py`](https://github.com/chr5tphr/zennit/blob/0.5.1/src/zennit/core.py)).**Composites** ([`zennit/composites.py`](https://github.com/chr5tphr/zennit/blob/0.5.1/src/zennit/composites.py)) are a wayof choosing the right hook for the right layer. In addition to the abstract**NameMapComposite**, which assigns hooks to layers by name, and**LayerMapComposite**, which assigns hooks to layers based on their Type, thereexist explicit **Composites**, some of which are `EpsilonGammaBox` (`ZBox` ininput, `Epsilon` in dense, `Gamma` in convolutions) or `EpsilonPlus` (`Epsilon`in dense, `ZPlus` in convolutions). All composites may be used by directlyimporting from `zennit.composites`, or by using their snake-case name as keyfor `zennit.composites.COMPOSITES`.**Canonizers** ([`zennit/canonizers.py`](https://github.com/chr5tphr/zennit/blob/0.5.1/src/zennit/canonizers.py)) temporarilytransform models into a canonical form, if required, like`SequentialMergeBatchNorm`, which automatically detects and merges BatchNormlayers followed by linear layers in sequential networks, or`AttributeCanonizer`, which temporarily overwrites attributes of applicablemodules, e.g. to handle the residual connection in ResNet-Bottleneck modules.**Attributors** ([`zennit/attribution.py`](https://github.com/chr5tphr/zennit/blob/0.5.1/src/zennit/attribution.py)) directlyexecute the necessary steps to apply certain attribution methods, like thesimple `Gradient`, `SmoothGrad` or `Occlusion`. An optional **Composite** maybe passed, which will be applied during the **Attributor**'s execution tocompute the modified gradient, or hybrid methods.Using all of these components, an LRP-type attribution for VGG16 withbatch-norm layers with respect to label 0 may be computed using:```pythonimport torchfrom torchvision.models import vgg16_bnfrom zennit.composites import EpsilonGammaBoxfrom zennit.canonizers import SequentialMergeBatchNormfrom zennit.attribution import Gradientdata = torch.randn(1, 3, 224, 224)model = vgg16_bn()canonizers = [SequentialMergeBatchNorm()]composite = EpsilonGammaBox(low=-3., high=3., canonizers=canonizers)with Gradient(model=model, composite=composite) as attributor:    out, relevance = attributor(data, torch.eye(1000)[[0]])```A similar setup using [the example script](https://github.com/chr5tphr/zennit/blob/0.5.1/share/example/feed_forward.py)produces the following attribution heatmaps:![beacon heatmaps](https://raw.githubusercontent.com/chr5tphr/zennit/0.5.1/share/img/beacon_vgg16_epsilon_gamma_box.png)For more details and examples, have a look at our[**documentation**](https://zennit.readthedocs.io/en/latest/).### More Example HeatmapsMore heatmaps of various attribution methods for VGG16 and ResNet50, allgenerated using[`share/example/feed_forward.py`](https://github.com/chr5tphr/zennit/blob/0.5.1/share/example/feed_forward.py), can be foundbelow.&lt;details&gt;  &lt;summary&gt;Heatmaps for VGG16&lt;/summary&gt;  ![vgg16 heatmaps](https://raw.githubusercontent.com/chr5tphr/zennit/0.5.1/share/img/beacon_vgg16_various.webp)&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Heatmaps for ResNet50&lt;/summary&gt;  ![resnet50 heatmaps](https://raw.githubusercontent.com/chr5tphr/zennit/0.5.1/share/img/beacon_resnet50_various.webp)&lt;/details&gt;## ContributingSee [CONTRIBUTING.md](https://github.com/chr5tphr/zennit/blob/0.5.1/CONTRIBUTING.md) for detailed instructions on how to contribute.## LicenseZennit is licensed under the GNU LESSER GENERAL PUBLIC LICENSE VERSION 3 ORLATER -- see the [LICENSE](https://github.com/chr5tphr/zennit/blob/0.5.1/LICENSE), [COPYING](https://github.com/chr5tphr/zennit/blob/0.5.1/COPYING) and[COPYING.LESSER](https://github.com/chr5tphr/zennit/blob/0.5.1/COPYING.LESSER) files for details.</longdescription>
</pkgmetadata>