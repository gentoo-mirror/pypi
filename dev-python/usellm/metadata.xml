<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># useLLM - Use Large Language Models in Python AppThe `usellm` Python library enables interaction with a chat-based Large Language Model (LLM) service. This interaction can be used to perform various language-related tasks, like generating chat conversation using the OpenAI API. It's designed as a Python port of the [`usellm`](https://usellm.org) JavaScript library.## InstallationThe library can be installed with `pip`:```pip install usellm```## Example UsageHere is a basic usage example:```pythonfrom usellm import Message, Options, UseLLM# Initialize the serviceservice = UseLLM(service_url=&quot;https://usellm.org/api/llm&quot;)# Prepare the conversationmessages = [  Message(role=&quot;system&quot;, content=&quot;You are a helpful assistant.&quot;),  Message(role=&quot;user&quot;, content=&quot;What can you do for me?&quot;),]options = Options(messages=messages)# Interact with the serviceresponse = service.chat(options)# Print the assistant's responseprint(response.content)```The above code will generate a response using the OpenAI ChatGPT API. The service URL &quot;https://usellm.org/api/llm&quot; should be used only for testing.## Classes and Methods### 1. `UseLLM` classThe `UseLLM` class provides the interface for interacting with the LLM service.Methods:- `__init__(self, service_url: str)`: Initializes a new instance of the `UseLLM` class.- `chat(self, options: Options) -&gt; Message`: Interacts with the LLM using the provided `Options`, and returns a `Message` instance that represents the LLM's response.### 2. `Options` classThe `Options` class represents a set of configuration options for a chat interaction with the LLM.- `messages`: A list of `Message` instances representing the conversation up to the current point.- `stream`: A boolean indicating if the interaction is a streaming interaction. Note: streaming is currently not supported.- `template`: A string representing a message template to guide the conversation.- `inputs`: A dictionary of additional inputs for the conversation.Methods:- `__init__(self, messages: Optional[List[Message]] = [], stream: Optional[bool] = None, template: Optional[str] = None, inputs: Optional[dict] = None)`: Initializes a new instance of the `Options` class.### 3. `Message` classThe `Message` class represents a message in a conversation. It consists of two main attributes:- `role`: The role of the message sender. Common values could be `system`, `user`, `assistant`.- `content`: The content of the message.Methods:- `__init__(self, role: str, content: str)`: Initializes a new instance of the `Message` class.- `__repr__(self) -&gt; str`: Returns a string representation of the `Message` instance.- `__str__(self) -&gt; str`: Returns a string representation of the `Message` instance.- `to_dict(self) -&gt; dict`: Returns a dictionary representation of the `Message` instance.- `to_json(self) -&gt; str`: Returns a JSON string representation of the `Message` instance.## ExceptionsThe library raises an `Exception` in the following situations:- If the `stream` option is set to `True`, because streaming is not currently supported.- If the HTTP response status code from the LLM service is not 200.- If the HTTP response from the LLM service contains an &quot;error&quot; field.- If the HTTP response from the LLM service does not contain a &quot;choices&quot; field.Please create an issue to report bugs or suggest improvements. Learn more about the original JavaScript library here: https://usellm.org</longdescription>
</pkgmetadata>