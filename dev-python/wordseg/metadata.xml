<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># wordseg[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4077433.svg)](https://doi.org/10.5281/zenodo.4077433)[![PyPI version](https://badge.fury.io/py/wordseg.svg)](https://pypi.org/project/wordseg)[![Supported Python versions](https://img.shields.io/pypi/pyversions/wordseg.svg)](https://pypi.org/project/wordseg)[![CircleCI](https://circleci.com/gh/jacksonllee/wordseg/tree/main.svg?style=shield)](https://circleci.com/gh/jacksonllee/wordseg/tree/main)`wordseg` is a Python package of word segmentation models.Table of contents:* [Installation](https://github.com/jacksonllee/wordseg#installation)* [Usage](https://github.com/jacksonllee/wordseg#usage)* [License](https://github.com/jacksonllee/wordseg#license)* [Changelog](https://github.com/jacksonllee/wordseg#changelog)* [Contributing](https://github.com/jacksonllee/wordseg/blob/main/CONTRIBUTING.md)* [Citation](https://github.com/jacksonllee/wordseg#citation)## Installation`wordseg` is available through pip:```bashpip install wordseg```To install `wordseg` from the GitHub source:```bashgit clone https://github.com/jacksonllee/wordseg.gitcd wordsegpip install -e &quot;.[dev]&quot;```## Usage`wordseg` implements a word segmentation model as a Python class.An instantiated model class object has the following methods(emulating the scikit-learn-styled API for machine learning):* `fit`: Train the model with segmented sentences.* `predict`: Predict the segmented sentences from unsegmented sentences.The implemented model classes are as follows:* `RandomSegmenter`:  Segmentation is predicted at random at each potential word  boundary independently for some given probability. No training is required.* `LongestStringMatching`:   This model constructs predicted words by moving  from left to right along an unsegmented sentence and  finding the longest matching words, constrained by a maximum word length parameter.Sample code snippet:```pythonfrom src.wordseg import LongestStringMatching# Initialize a model.model = LongestStringMatching(max_word_length=4)# Train the model.# `fit` takes an iterable of segmented sentences (a tuple or list of strings).model.fit(  [    (&quot;this&quot;, &quot;is&quot;, &quot;a&quot;, &quot;sentence&quot;),    (&quot;that&quot;, &quot;is&quot;, &quot;not&quot;, &quot;a&quot;, &quot;sentence&quot;),  ])# Make some predictions; `predict` gives a generator, which is materialized by list() here.list(model.predict([&quot;thatisadog&quot;, &quot;thisisnotacat&quot;]))# [['that', 'is', 'a', 'd', 'o', 'g'], ['this', 'is', 'not', 'a', 'c', 'a', 't']]# We can't get 'dog' and 'cat' because they aren't in the training data.```## LicenseMIT License. Please see [`LICENSE.txt`](https://github.com/jacksonllee/wordseg/blob/main/LICENSE.txt).## ChangelogPlease see [`CHANGELOG.md`](https://github.com/jacksonllee/wordseg/blob/main/CHANGELOG.md).## ContributingPlease see [`CONTRIBUTING.md`](https://github.com/jacksonllee/wordseg/blob/main/CONTRIBUTING.md).## CitationLee, Jackson L. 2023. wordseg: Word segmentation models in Python. https://doi.org/10.5281/zenodo.4077433```bibtex@software{leengrams,  author       = {Jackson L. Lee},  title        = {wordseg: Word segmentation models in Python},  year         = 2023,  doi          = {10.5281/zenodo.4077433},  url          = {https://doi.org/10.5281/zenodo.4077433}}```</longdescription>
</pkgmetadata>