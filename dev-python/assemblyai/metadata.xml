<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;img src=&quot;https://github.com/AssemblyAI/assemblyai-python-sdk/blob/master/assemblyai.png?raw=true&quot; width=&quot;500&quot;/&gt;---[![CI Passing](https://github.com/AssemblyAI/assemblyai-python-sdk/actions/workflows/test.yml/badge.svg)](https://github.com/AssemblyAI/assemblyai-python-sdk/actions/workflows/test.yml)[![GitHub License](https://img.shields.io/github/license/AssemblyAI/assemblyai-python-sdk)](https://github.com/AssemblyAI/assemblyai-python-sdk/blob/master/LICENSE)[![PyPI version](https://badge.fury.io/py/assemblyai.svg)](https://badge.fury.io/py/assemblyai)[![PyPI Python Versions](https://img.shields.io/pypi/pyversions/assemblyai)](https://pypi.python.org/pypi/assemblyai/)![PyPI - Wheel](https://img.shields.io/pypi/wheel/assemblyai)[![AssemblyAI Twitter](https://img.shields.io/twitter/follow/AssemblyAI?label=%40AssemblyAI&amp;style=social)](https://twitter.com/AssemblyAI)[![AssemblyAI YouTube](https://img.shields.io/youtube/channel/subscribers/UCtatfZMf-8EkIwASXM4ts0A)](https://www.youtube.com/@AssemblyAI)[![Discord](https://img.shields.io/discord/875120158014853141?logo=discord&amp;label=Discord&amp;link=https%3A%2F%2Fdiscord.com%2Fchannels%2F875120158014853141&amp;style=social)](https://assemblyai.com/discord)# AssemblyAI's Python SDK&gt; _Build with AI models that can transcribe and understand audio_With a single API call, get access to AI models built on the latest AI breakthroughs to transcribe and understand audio and speech data securely at large scale.# Overview- [AssemblyAI's Python SDK](#assemblyais-python-sdk)- [Overview](#overview)- [Documentation](#documentation)- [Quick Start](#quick-start)  - [Installation](#installation)  - [Examples](#examples)    - [**Core Examples**](#core-examples)    - [**LeMUR Examples**](#lemur-examples)    - [**Audio Intelligence Examples**](#audio-intelligence-examples)    - [**Real-Time Examples**](#real-time-examples)  - [Playgrounds](#playgrounds)- [Advanced](#advanced)  - [How the SDK handles Default Configurations](#how-the-sdk-handles-default-configurations)    - [Defining Defaults](#defining-defaults)    - [Overriding Defaults](#overriding-defaults)  - [Synchronous vs Asynchronous](#synchronous-vs-asynchronous)  - [Polling Intervals](#polling-intervals)  - [Retrieving Existing Transcripts](#retrieving-existing-transcripts)    - [Retrieving a Single Transcript](#retrieving-a-single-transcript)    - [Retrieving Multiple Transcripts as a Group](#retrieving-multiple-transcripts-as-a-group)    - [Retrieving Transcripts Asynchronously](#retrieving-transcripts-asynchronously)# DocumentationVisit our [AssemblyAI API Documentation](https://www.assemblyai.com/docs) to get an overview of our models!# Quick Start## Installation```bashpip install -U assemblyai```## ExamplesBefore starting, you need to set the API key. If you don't have one yet, [**sign up for one**](https://www.assemblyai.com/dashboard/signup)!```pythonimport assemblyai as aai# set the API keyaai.settings.api_key = f&quot;{ASSEMBLYAI_API_KEY}&quot;```---### **Core Examples**&lt;details&gt;  &lt;summary&gt;Transcribe a Local Audio File&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;./my-local-audio-file.wav&quot;)print(transcript.text)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Transcribe an URL&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)print(transcript.text)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Export Subtitles of an Audio File&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)# in SRT formatprint(transcript.export_subtitles_srt())# in VTT formatprint(transcript.export_subtitles_vtt())```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;List all Sentences and Paragraphs&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)sentences = transcript.get_sentences()for sentence in sentences:  print(sentence.text)paragraphs = transcript.get_paragraphs()for paragraph in paragraphs:  print(paragraph.text)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Search for Words in a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)matches = transcript.word_search([&quot;price&quot;, &quot;product&quot;])for match in matches:  print(f&quot;Found '{match.text}' {match.count} times in the transcript&quot;)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Add Custom Spellings on a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaiconfig = aai.TranscriptionConfig()config.set_custom_spelling(  {    &quot;Kubernetes&quot;: [&quot;k8s&quot;],    &quot;SQL&quot;: [&quot;Sequel&quot;],  })transcriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;, config)print(transcript.text)```&lt;/details&gt;---### **LeMUR Examples**&lt;details&gt;  &lt;summary&gt;Use LeMUR to Summarize Multiple Transcripts&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript_group = transcriber.transcribe_group(    [        &quot;https://example.org/customer1.mp3&quot;,        &quot;https://example.org/customer2.mp3&quot;,    ],)result = transcript_group.lemur.summarize(  context=&quot;Customers asking for cars&quot;,  answer_format=&quot;TLDR&quot;)print(result.response)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Use LeMUR to Ask Questions on a Single Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/customer.mp3&quot;)# ask some questionsquestions = [    aai.LemurQuestion(question=&quot;What car was the customer interested in?&quot;),    aai.LemurQuestion(question=&quot;What price range is the customer looking for?&quot;),]result = transcript.lemur.question(questions)for q in result.response:    print(f&quot;Question: {q.question}&quot;)    print(f&quot;Answer: {q.answer}&quot;)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Use LeMUR to Ask for Action Items from a Single Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/customer.mp3&quot;)result = transcript.lemur.action_items(    context=&quot;Customers asking for help with resolving their problem&quot;,    answer_format=&quot;Three bullet points&quot;,)print(result.response)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Use LeMUR to Ask Anything with a Custom Prompt&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/customer.mp3&quot;)result = transcript.lemur.task(  &quot;You are a helpful coach. Provide an analysis of the transcript &quot;  &quot;and offer areas to improve with exact quotes. Include no preamble. &quot;  &quot;Start with an overall summary then get into the examples with feedback.&quot;,)print(result.response)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Use LeMUR to with Input Text&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()config = aai.TranscriptionConfig(  speaker_labels=True,)transcript = transcriber.transcribe(&quot;https://example.org/customer.mp3&quot;, config=config)# Example converting speaker label utterances into LeMUR input texttext = &quot;&quot;for utt in transcript.utterances:    text += f&quot;Speaker {utt.speaker}:\n{utt.text}\n&quot;result = aai.Lemur().task(  &quot;You are a helpful coach. Provide an analysis of the transcript &quot;  &quot;and offer areas to improve with exact quotes. Include no preamble. &quot;  &quot;Start with an overall summary then get into the examples with feedback.&quot;,  input_text=text)print(result.response)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Delete data previously sent to LeMUR&lt;/summary&gt;```pythonimport assemblyai as aai# Create a transcript and a corresponding LeMUR request that may contain senstive information.transcriber = aai.Transcriber()transcript_group = transcriber.transcribe_group(  [    &quot;https://example.org/customer1.mp3&quot;,  ],)result = transcript_group.lemur.summarize(  context=&quot;Customers providing sensitive, personally identifiable information&quot;,  answer_format=&quot;TLDR&quot;)# Get the request ID from the LeMUR responserequest_id = result.request_id# Now we can delete the data about this requestdeletion_result = aai.Lemur.purge_request_data(request_id)print(deletion_result)```&lt;/details&gt;---### **Audio Intelligence Examples**&lt;details&gt;  &lt;summary&gt;PII Redact a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaiconfig = aai.TranscriptionConfig()config.set_redact_pii(  # What should be redacted  policies=[      aai.PIIRedactionPolicy.credit_card_number,      aai.PIIRedactionPolicy.email_address,      aai.PIIRedactionPolicy.location,      aai.PIIRedactionPolicy.person_name,      aai.PIIRedactionPolicy.phone_number,  ],  # How it should be redacted  substitution=aai.PIISubstitutionPolicy.hash,)transcriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;, config)```To request a copy of the original audio file with the redacted information &quot;beeped&quot; out, set `redact_pii_audio=True` in the config.Once the `Transcript` object is returned, you can access the URL of the redacted audio file with `get_redacted_audio_url`, or save the redacted audio directly to disk with `save_redacted_audio`.```pythonimport assemblyai as aaitranscript = aai.Transcriber().transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(    redact_pii=True,    redact_pii_policies=[aai.PIIRedactionPolicy.person_name],    redact_pii_audio=True  ))redacted_audio_url = transcript.get_redacted_audio_url()transcript.save_redacted_audio(&quot;redacted_audio.mp3&quot;)```[Read more about PII redaction here.](https://www.assemblyai.com/docs/Models/pii_redaction)&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Summarize the content of a transcript over time&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(auto_chapters=True))for chapter in transcript.chapters:  print(f&quot;Summary: {chapter.summary}&quot;)  # A one paragraph summary of the content spoken during this timeframe  print(f&quot;Start: {chapter.start}, End: {chapter.end}&quot;)  # Timestamps (in milliseconds) of the chapter  print(f&quot;Healine: {chapter.headline}&quot;)  # A single sentence summary of the content spoken during this timeframe  print(f&quot;Gist: {chapter.gist}&quot;)  # An ultra-short summary, just a few words, of the content spoken during this timeframe```[Read more about auto chapters here.](https://www.assemblyai.com/docs/Models/auto_chapters)&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Summarize the content of a transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(summarization=True))print(transcript.summary)```By default, the summarization model will be `informative` and the summarization type will be `bullets`. [Read more about summarization models and types here](https://www.assemblyai.com/docs/Models/summarization#types-and-models).To change the model and/or type, pass additional parameters to the `TranscriptionConfig`:```pythonconfig=aai.TranscriptionConfig(  summarization=True,  summary_model=aai.SummarizationModel.catchy,  summary_type=aai.SummarizationType.headline)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Detect Sensitive Content in a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(content_safety=True))# Get the parts of the transcript which were flagged as sensitivefor result in transcript.content_safety.results:  print(result.text)  # sensitive text snippet  print(result.timestamp.start)  print(result.timestamp.end)  for label in result.labels:    print(label.label)  # content safety category    print(label.confidence) # model's confidence that the text is in this category    print(label.severity) # severity of the text in relation to the category# Get the confidence of the most common labels in relation to the entire audio filefor label, confidence in transcript.content_safety.summary.items():  print(f&quot;{confidence * 100}% confident that the audio contains {label}&quot;)# Get the overall severity of the most common labels in relation to the entire audio filefor label, severity_confidence in transcript.content_safety.severity_score_summary.items():  print(f&quot;{severity_confidence.low * 100}% confident that the audio contains low-severity {label}&quot;)  print(f&quot;{severity_confidence.medium * 100}% confident that the audio contains mid-severity {label}&quot;)  print(f&quot;{severity_confidence.high * 100}% confident that the audio contains high-severity {label}&quot;)```[Read more about the content safety categories.](https://www.assemblyai.com/docs/Models/content_moderation#all-labels-supported-by-the-model)By default, the content safety model will only include labels with a confidence greater than 0.5 (50%). To change this, pass `content_safety_confidence` (as an integer percentage between 25 and 100, inclusive) to the `TranscriptionConfig`:```pythonconfig=aai.TranscriptionConfig(  content_safety=True,  content_safety_confidence=80,  # only include labels with a confidence greater than 80%)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Analyze the Sentiment of Sentences in a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(sentiment_analysis=True))for sentiment_result in transcript.sentiment_analysis:  print(sentiment_result.text)  print(sentiment_result.sentiment)  # POSITIVE, NEUTRAL, or NEGATIVE  print(sentiment_result.confidence)  print(f&quot;Timestamp: {sentiment_result.start} - {sentiment_result.end}&quot;)```If `speaker_labels` is also enabled, then each sentiment analysis result will also include a `speaker` field.```python# ...config = aai.TranscriptionConfig(sentiment_analysis=True, speaker_labels=True)# ...for sentiment_result in transcript.sentiment_analysis:  print(sentiment_result.speaker)```[Read more about sentiment analysis here.](https://www.assemblyai.com/docs/Models/sentiment_analysis)&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Identify Entities in a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(entity_detection=True))for entity in transcript.entities:  print(entity.text) # i.e. &quot;Dan Gilbert&quot;  print(entity.entity_type) # i.e. EntityType.person  print(f&quot;Timestamp: {entity.start} - {entity.end}&quot;)```[Read more about entity detection here.](https://www.assemblyai.com/docs/Models/entity_detection)&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Detect Topics in a Transcript (IAB Classification)&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(iab_categories=True))# Get the parts of the transcript that were tagged with topicsfor result in transcript.iab_categories.results:  print(result.text)  print(f&quot;Timestamp: {result.timestamp.start} - {result.timestamp.end}&quot;)  for label in result.labels:    print(label.label)  # topic    print(label.relevance)  # how relevant the label is for the portion of text# Get a summary of all topics in the transcriptfor label, relevance in transcript.iab_categories.summary.items():  print(f&quot;Audio is {relevance * 100}% relevant to {label}&quot;)```[Read more about IAB classification here.](https://www.assemblyai.com/docs/Models/iab_classification)&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Identify Important Words and Phrases in a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(  &quot;https://example.org/audio.mp3&quot;,  config=aai.TranscriptionConfig(auto_highlights=True))for result in transcript.auto_highlights.results:  print(result.text) # the important phrase  print(result.rank) # relevancy of the phrase  print(result.count) # number of instances of the phrase  for timestamp in result.timestamps:    print(f&quot;Timestamp: {timestamp.start} - {timestamp.end}&quot;)```[Read more about auto highlights here.](https://www.assemblyai.com/docs/Models/key_phrases)&lt;/details&gt;---### **Real-Time Examples**[Read more about our Real-Time service.](https://www.assemblyai.com/docs/Guides/real-time_streaming_transcription)&lt;details&gt;  &lt;summary&gt;Stream your Microphone in Real-Time&lt;/summary&gt;```pythonimport assemblyai as aaidef on_open(session_opened: aai.RealtimeSessionOpened):  &quot;This function is called when the connection has been established.&quot;  print(&quot;Session ID:&quot;, session_opened.session_id)def on_data(transcript: aai.RealtimeTranscript):  &quot;This function is called when a new transcript has been received.&quot;  if not transcript.text:    return  if isinstance(transcript, aai.RealtimeFinalTranscript):    print(transcript.text, end=&quot;\r\n&quot;)  else:    print(transcript.text, end=&quot;\r&quot;)def on_error(error: aai.RealtimeError):  &quot;This function is called when the connection has been closed.&quot;  print(&quot;An error occured:&quot;, error)def on_close():  &quot;This function is called when the connection has been closed.&quot;  print(&quot;Closing Session&quot;)# Create the Real-Time transcribertranscriber = aai.RealtimeTranscriber(  on_data=on_data,  on_error=on_error,  sample_rate=44_100,  on_open=on_open, # optional  on_close=on_close, # optional)# Start the connectiontranscriber.connect()# Open a microphone streammicrophone_stream = aai.extras.MicrophoneStream()# Press CTRL+C to aborttranscriber.stream(microphone_stream)transcriber.close()```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Transcribe a Local Audio File in Real-Time&lt;/summary&gt;```pythonimport assemblyai as aaidef on_data(transcript: aai.RealtimeTranscript):  &quot;This function is called when a new transcript has been received.&quot;  if not transcript.text:    return  if isinstance(transcript, aai.RealtimeFinalTranscript):    print(transcript.text, end=&quot;\r\n&quot;)  else:    print(transcript.text, end=&quot;\r&quot;)def on_error(error: aai.RealtimeError):  &quot;This function is called when the connection has been closed.&quot;  print(&quot;An error occured:&quot;, error)# Create the Real-Time transcribertranscriber = aai.RealtimeTranscriber(  on_data=on_data,  on_error=on_error,  sample_rate=44_100,)# Start the connectiontranscriber.connect()# Only WAV/PCM16 single channel supported for nowfile_stream = aai.extras.stream_file(  filepath=&quot;audio.wav&quot;,  sample_rate=44_100,)transcriber.stream(file_stream)transcriber.close()```&lt;/details&gt;---## PlaygroundsVisit one of our Playgrounds:- [LeMUR Playground](https://www.assemblyai.com/playground/v2/source)- [Transcription Playground](https://www.assemblyai.com/playground)# Advanced## How the SDK handles Default Configurations### Defining DefaultsWhen no `TranscriptionConfig` is being passed to the `Transcriber` or its methods, it will use a default instance of a `TranscriptionConfig`.If you would like to re-use the same `TranscriptionConfig` for all your transcriptions,you can set it on the `Transcriber` directly:```pythonconfig = aai.TranscriptionConfig(punctuate=False, format_text=False)transcriber = aai.Transcriber(config=config)# will use the same config for all `.transcribe*(...)` operationstranscriber.transcribe(&quot;https://example.org/audio.wav&quot;)```### Overriding DefaultsYou can override the default configuration later via the `.config` property of the `Transcriber`:```pythontranscriber = aai.Transcriber()# override the `Transcriber`'s config with a new configtranscriber.config = aai.TranscriptionConfig(punctuate=False, format_text=False)```In case you want to override the `Transcriber`'s configuration for a specific operation with a different one, you can do so via the `config` parameter of a `.transcribe*(...)` method:```pythonconfig = aai.TranscriptionConfig(punctuate=False, format_text=False)# set a default configurationtranscriber = aai.Transcriber(config=config)transcriber.transcribe(    &quot;https://example.com/audio.mp3&quot;,    # overrides the above configuration on the `Transcriber` with the following    config=aai.TranscriptionConfig(dual_channel=True, disfluencies=True))```## Synchronous vs AsynchronousCurrently, the SDK provides two ways to transcribe audio files.The synchronous approach halts the application's flow until the transcription has been completed.The asynchronous approach allows the application to continue running while the transcription is being processed. The caller receives a [`concurrent.futures.Future`](https://docs.python.org/3/library/concurrent.futures.html) object which can be used to check the status of the transcription at a later time.You can identify those two approaches by the `_async` suffix in the `Transcriber`'s method name (e.g. `transcribe` vs `transcribe_async`).## Polling IntervalsBy default we poll the `Transcript`'s status each `3s`. In case you would like to adjust that interval:```pythonimport assemblyai as aaiaai.settings.polling_interval = 1.0```## Retrieving Existing Transcripts### Retrieving a Single TranscriptIf you previously created a transcript, you can use its ID to retrieve it later.```pythonimport assemblyai as aaitranscript = aai.Transcript.get_by_id(&quot;&lt;TRANSCRIPT_ID&gt;&quot;)print(transcript.id)print(transcript.text)```### Retrieving Multiple Transcripts as a GroupYou can also retrieve multiple existing transcripts and combine them into a single `TranscriptGroup` object. This allows you to perform operations on the transcript group as a single unit, such as querying the combined transcripts with LeMUR.```pythonimport assemblyai as aaitranscript_group = aai.TranscriptGroup.get_by_ids([&quot;&lt;TRANSCRIPT_ID_1&gt;&quot;, &quot;&lt;TRANSCRIPT_ID_2&gt;&quot;])summary = transcript_group.lemur.summarize(context=&quot;Customers asking for cars&quot;, answer_format=&quot;TLDR&quot;)print(summary)```### Retrieving Transcripts AsynchronouslyBoth `Transcript.get_by_id` and `TranscriptGroup.get_by_ids` have asynchronous counterparts, `Transcript.get_by_id_async` and `TranscriptGroup.get_by_ids_async`, respectively. These functions immediately return a `Future` object, rather than blocking until the transcript(s) are retrieved.See the above section on [Synchronous vs Asynchronous](#synchronous-vs-asynchronous) for more information.</longdescription>
</pkgmetadata>