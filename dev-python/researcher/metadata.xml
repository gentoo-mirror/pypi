<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Researcher&quot;I walk slowly, but I never walk backward.&quot;    - Abraham LinconResearcher makes it easier for data science practitioners to record and reproduce the results of their data science experiments. Conceptually `researcher` breaks the data science process into distinct **experiments**. Each experiment has **parameters** (number of training epochs, dataset used, model architecture, etc.) which differentiate it from other experiments, and **results** (final validation loss, lowest training accuracy, etc.) which are the observations made when an experiment was run. The idea behind researcher is that for every experiment you run, you should record both the parameters involved and the results they achieved. This will make it easier to analyse complex interactions between different parameters and re-create experimental conditions at a later date.## UsageTo see an example of how `researcher` in action, check out `mnist_demo.ipynb` on the [github repo](https://github.com/Lewington-pitsos/researcher), but essentially usage has 3 stages:### 1. Define Experiment ParametersIn geneal for any data science project you will spend a great deal of your time choosing parameters for experiments. These parameters might include which activation functions to use, how many epochs to train for or which data augmentation procedures to use. Ideally every time you conduct an experiment, you should record the parameters which are involved in that experiment and those parameters should be sufficient for someone else to replicate that exact experiment at a later date. The approach favoured by `researcher` is to have a helper function which takes a dictionary of parameters, runs an experiment under those parameters, and returns the experiment results. Something like the following incomplete code snippet:```pythonimport researcher as rsimport tensorflow as tfdef run_experiment(params):    model = tf.keras.models.Sequential([      tf.keras.layers.Flatten(input_shape=(28, 28, 1)),      tf.keras.layers.Dense(params[&quot;depth&quot;],activation=params[&quot;activation_function&quot;]),      tf.keras.layers.Dense(10, activation=params[&quot;final_activation&quot;])    ])    model.compile(        loss='sparse_categorical_crossentropy',        optimizer=tf.keras.optimizers.Adam(params[&quot;lr&quot;]),        metrics=['accuracy'],    )    model.fit(        SOME_DATASET,        epochs=params[&quot;epochs&quot;],        validation_data=SOME_OTHER_DATASET,     )    return model.historyparams = {    &quot;activation_function&quot;: &quot;relu&quot;,    &quot;final_activation&quot;: &quot;softmax&quot;,    &quot;depth&quot;: 256,    &quot;epochs&quot;: 8,    &quot;lr&quot;: 0.001}results = run_experiment(params)```By varying `params` you can perform multiple experiments under different conditions. Good practice is to give each `params` dictionary a `&quot;title&quot;` key which summarizes the experiment and makes it easier to quickly identify experiments in future.```pythonparams = {    &quot;title&quot;: &quot;deep-adam-relu&quot;,    &quot;activation_function&quot;: &quot;relu&quot;,    &quot;final_activation&quot;: &quot;softmax&quot;,    &quot;depth&quot;: 256,    &quot;epochs&quot;: 8,    &quot;lr&quot;: 0.001}results = run_experiment(params)```### 2. Save Experiment ResultsData science experiments become much more useful when you record their results in a consistent format. Then if you discover anything important, you can easily share your discovery with others and keep track of it in a quantifiable form for your own future benefit. This is what `researcher` helps with. First create an empty directory to save all your experiment data:`mkdir records`Then, each time you run an experiment, simply pack the results into a dictionary and use `researcher` to save it in that directory, along with the experimental parameters.```pythonfinal_results = {}for key, values in results.history.items():    final_results[key] = valuesrs.record_experiment(params, &quot;records/&quot;, observations=final_results)```The parameters and results will be saved into a `.json` file in the `records/` directory and given a unique experiment hash that can later be used to identify it (though a `&quot;title&quot;` key is also helpful).**Note**: because `researcher` serializes experiments using JSON, you cannot include any non json-serializable objects in `params` when using `researcher`.### 3. Load and View Experiment Results`researcher` also helps you load and visualize saved experiments:```pythonexperiments = rs.all_experiments(&quot;records/&quot;)```Experiments are loaded into a `researcher.experiment.Experiment` instance, which is a light wrapper around the raw parameters and results that were saved initially:```pythonexperiments[0].data# {# 'title': 'deep-adam-relu',# 'activation_function': 'relu',# 'final_activation': 'softmax',# 'depth': 256,# 'epochs': 8,# 'lr': 0.001,# 'hash': 'eebb49b9d1487396dd6c0e5271cc3083',# 'timestamp': '2020-12-10_00:01:04',# 'observations': {'loss': [0.35920432209968567,#     0.16782893240451813,#     0.12179006636142731,#     0.09385494887828827,#     0.07634902000427246],# 'accuracy': [0.9017833471298218,#     0.9524166584014893,#     0.9652500152587891,#     0.972683310508728,#     0.9780666828155518],# 'val_loss': [0.1982543170452118,#     0.1372576504945755,#     0.11536946892738342,#     0.1035531759262085,#     0.08903338760137558],# 'val_accuracy': [0.9441999793052673,#     0.9607999920845032,#     0.9675999879837036,#     0.9672999978065491,#     0.9717000126838684]},# }```You can also use some pre-built plotting functions to visualize these experimental results (see `researcher/dashboard.py`), but depending on what kinds of experiments you're running, you'll probably want to define your own.```pythonimport matplotlib.pyplot as pltdef plot_metric(e, metric):    plt.plot(e.data[&quot;observations&quot;][metric])plot_metric(experiments[0], &quot;loss&quot;)plot_metric(experiments[0], &quot;val_loss&quot;)```</longdescription>
</pkgmetadata>