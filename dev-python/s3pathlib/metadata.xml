<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>.. image:: https://readthedocs.org/projects/s3pathlib/badge/?version=latest    :target: https://s3pathlib.readthedocs.io/en/latest/    :alt: Documentation Status.. image:: https://github.com/aws-samples/s3pathlib-project/workflows/CI/badge.svg    :target: https://github.com/aws-samples/s3pathlib-project/actions?query=workflow:CI.. image:: https://img.shields.io/pypi/v/s3pathlib.svg    :target: https://pypi.python.org/pypi/s3pathlib.. image:: https://img.shields.io/pypi/l/s3pathlib.svg    :target: https://pypi.python.org/pypi/s3pathlib.. image:: https://img.shields.io/pypi/pyversions/s3pathlib.svg    :target: https://pypi.python.org/pypi/s3pathlib    .. image:: https://img.shields.io/pypi/dm/s3pathlib.svg    :target: https://pypi.python.org/pypi/s3pathlib------.. image:: https://img.shields.io/badge/Link-Document-orange.svg    :target: https://s3pathlib.readthedocs.io/en/latest/.. image:: https://img.shields.io/badge/Link-API-blue.svg    :target: https://s3pathlib.readthedocs.io/en/latest/py-modindex.html.. image:: https://img.shields.io/badge/Link-Source_Code-blue.svg    :target: https://s3pathlib.readthedocs.io/en/latest/py-modindex.html.. image:: https://img.shields.io/badge/Link-Submit_Issue-blue.svg    :target: https://github.com/aws-samples/s3pathlib-project/issues.. image:: https://img.shields.io/badge/Link-Request_Feature-blue.svg    :target: https://github.com/aws-samples/s3pathlib-project/issues.. image:: https://img.shields.io/badge/Link-Download-blue.svg    :target: https://pypi.org/pypi/s3pathlib#filesWelcome to ``s3pathlib`` Documentation==============================================================================``s3pathlib`` is the python package provides the Pythonic objective oriented programming (OOP) interface to manipulate AWS S3 object / directory. The api is similar to the ``pathlib`` `standard library &lt;https://docs.python.org/3/library/pathlib.html&gt;`_ and very intuitive for human... note::    You may not viewing the full document, `FULL DOCUMENT IS HERE &lt;https://s3pathlib.readthedocs.io/en/latest/&gt;`_Quick Start------------------------------------------------------------------------------.. note::    `COMPREHENSIVE DOCUMENT guide / features / best practice can be found at HERE &lt;https://s3pathlib.readthedocs.io/en/latest/#full-table-of-content&gt;`_**Import the library, declare a S3 object**.. code-block:: python    # import    &gt;&gt;&gt; from s3pathlib import S3Path    # construct from string, auto join parts    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;folder&quot;, &quot;file.txt&quot;)    &gt;&gt;&gt; p.bucket    'bucket'    &gt;&gt;&gt; p.key    'folder/file.txt'    &gt;&gt;&gt; p.uri    's3://bucket/folder/file.txt'    &gt;&gt;&gt; p.console_url # click to preview it in AWS console    'https://s3.console.aws.amazon.com/s3/object/bucket?prefix=folder/file.txt'    &gt;&gt;&gt; p.arn    'arn:aws:s3:::bucket/folder/file.txt'**Talk to AWS S3 and get some information**.. code-block:: python    # s3pathlib maintains a &quot;context&quot; object that holds the AWS authentication information    # you just need to build your own boto session object and attach to it    &gt;&gt;&gt; import boto3    &gt;&gt;&gt; from s3pathlib import context    &gt;&gt;&gt; context.attach_boto_session(    ...     boto3.session.Session(    ...         region_name=&quot;us-east-1&quot;,    ...         profile_name=&quot;my_aws_profile&quot;,    ...     )    ... )    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;folder&quot;, &quot;file.txt&quot;)    &gt;&gt;&gt; p.etag    '3e20b77868d1a39a587e280b99cec4a8'    &gt;&gt;&gt; p.size    56789000    &gt;&gt;&gt; p.size_for_human    '51.16 MB'    # folder works too, you just need to use a tailing &quot;/&quot; to identify that    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;datalake/&quot;)    &gt;&gt;&gt; p.count_objects()    7164 # number of files under this prefix    &gt;&gt;&gt; p.calculate_total_size()    (7164, 236483701963) # 7164 objects, 220.24 GB    &gt;&gt;&gt; p.calculate_total_size(for_human=True)    (7164, '220.24 GB') # 7164 objects, 220.24 GB**Manipulate Folder in S3**Native S3 Write API (those operation that change the state of S3) only operate on object level. And the `list_objects &lt;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.list_objects_v2&gt;`_ API returns 1000 objects at a time. You need additional effort to manipulate objects recursively. ``s3pathlib`` **CAN SAVE YOUR LIFE**.. code-block:: python    # create a S3 folder    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;github&quot;, &quot;repos&quot;, &quot;my-repo/&quot;)    # upload all python file from /my-github-repo to s3://bucket/github/repos/my-repo/    &gt;&gt;&gt; p.upload_dir(&quot;/my-repo&quot;, pattern=&quot;**/*.py&quot;, overwrite=False)    # copy entire s3 folder to another s3 folder    &gt;&gt;&gt; p2 = S3Path(&quot;bucket&quot;, &quot;github&quot;, &quot;repos&quot;, &quot;another-repo/&quot;)    &gt;&gt;&gt; p1.copy_to(p2, overwrite=True)    # delete all objects in the folder, recursively, to clean up your test bucket    &gt;&gt;&gt; p.delete_if_exists()    &gt;&gt;&gt; p2.delete_if_exists()**S3 Path Filter**Ever think of filter S3 object by it's attributes like: dirname, basename, file extension, etag, size, modified time? It is supposed to be simple in Python:.. code-block:: python    &gt;&gt;&gt; root = S3Path(&quot;bucket&quot;) # assume you have a lots of files in this bucket    &gt;&gt;&gt; iterproxy = root.iter_objects().filter(    ...     S3Path.size &gt;= 10_000_000, S3Path.ext == &quot;.csv&quot; # add filter    ... )    &gt;&gt;&gt; iterproxy.one() # fetch one    S3Path('s3://bucket/larger-than-10MB-1.csv')    &gt;&gt;&gt; iterproxy.many(3) # fetch three    [        S3Path('s3://bucket/larger-than-10MB-1.csv'),        S3Path('s3://bucket/larger-than-10MB-2.csv'),        S3Path('s3://bucket/larger-than-10MB-3.csv'),    ]    &gt;&gt;&gt; for p in iterproxy: # iter the rest    ...     print(p)**File Like Object for Simple IO**``S3Path`` is file-like object. It support ``open`` and context manager syntax out of the box. Here are only some highlight examples:.. code-block:: python    # Stream big file by line    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;log.txt&quot;)    &gt;&gt;&gt; with p.open(&quot;r&quot;) as f:    ...     for line in f:    ...         do what every you want    # JSON io    &gt;&gt;&gt; import json    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;config.json&quot;)    &gt;&gt;&gt; with p.open(&quot;w&quot;) as f:    ...     json.dump({&quot;password&quot;: &quot;mypass&quot;}, f)    # pandas IO    &gt;&gt;&gt; import pandas as pd    &gt;&gt;&gt; p = S3Path(&quot;bucket&quot;, &quot;dataset.csv&quot;)    &gt;&gt;&gt; df = pd.DataFrame(...)    &gt;&gt;&gt; with p.open(&quot;w&quot;) as f:    ...     df.to_csv(f)Getting Help------------------------------------------------------------------------------Please use the ``python-s3pathlib`` tag on Stack Overflow to get help.Submit a ``I want help`` issue tickets on `GitHub Issues &lt;https://github.com/aws-samples/s3pathlib-project/issues/new/choose&gt;`_Contributing------------------------------------------------------------------------------Please see the `Contribution Guidelines &lt;https://github.com/aws-samples/s3pathlib-project/blob/main/CONTRIBUTING.rst&gt;`_.Copyright------------------------------------------------------------------------------s3pathlib is an open source project. See the `LICENSE &lt;https://github.com/aws-samples/s3pathlib-project/blob/main/LICENSE&gt;`_ file for more information.</longdescription>
</pkgmetadata>