<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![The autoembedder](https://raw.githubusercontent.com/chrislemke/autoembedder/master/docs/assets/images/image.png)# The Autoembedder[![deploy package](https://github.com/chrislemke/autoembedder/actions/workflows/deploy-package.yml/badge.svg)](https://github.com/chrislemke/autoembedder/actions/workflows/deploy-package.yml)[![Codacy Badge](https://app.codacy.com/project/badge/Grade/0d7834c236b242b6b45728acc44af37c)](https://www.codacy.com/gh/chrislemke/autoembedder/dashboard?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=chrislemke/autoembedder&amp;amp;utm_campaign=Badge_Grade)[![pypi](https://img.shields.io/pypi/v/autoembedder)](https://pypi.org/project/autoembedder/)[![python version](https://img.shields.io/pypi/pyversions/autoembedder?logo=python&amp;logoColor=yellow)](https://python.org)[![docs](https://img.shields.io/badge/docs-mkdoks%20material-blue)](https://chrislemke.github.io/autoembedder/)[![license](https://img.shields.io/github/license/chrislemke/autoembedder)](https://github.com/chrislemke/autoembedder/blob/main/LICENSE)[![downloads](https://img.shields.io/pypi/dm/autoembedder)](https://pypistats.org/packages/autoembedder)[![mypy](http://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)[![black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)[![isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&amp;labelColor=ef8336)](https://pycqa.github.io/isort/)[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;logoColor=white)](https://github.com/pre-commit/pre-commit)## IntroductionThe Autoembedder is an autoencoder with additional embedding layers for the categorical columns. Its usage is flexible, and hyperparameters like the number of layers can be easily adjusted and tuned. The data provided for training can be either a path to a [Dask](https://docs.dask.org/en/stable/dataframe.html) or [Pandas](https://pandas.pydata.org/) DataFrame stored in the Parquet format or the DataFrame object directly.## InstallationIf you are using [Poetry](https://python-poetry.org/), you can install the package with the following command:```bashpoetry add autoembedder```If you are using [pip](https://pypi.org/project/pip/), you can install the package with the following command:```bashpip install autoembedder```## Installing dependenciesWith [Poetry](https://python-poetry.org/):```bashpoetry install```With [pip](https://pypi.org/project/pip/):```bashpip install -r requirements.txt```## Usage### 0. Some imports```pythonfrom autoembedder import Autoembedder, dataloader, fit```### 1. Create dataloadersFirst, we create two [`dataloaders`](https://chrislemke.github.io/autoembedder/autoembedder.data/#autoembedder.data.Dataset.__init__). One for training, and the other for validation data. As `source` they either accept a path to a Parquet file, to a folder of Parquet files or a [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)/[Dask](https://docs.dask.org/en/stable/dataframe.html) DataFrame.```pythontrain_dl = dataloader(train_df)valid_dl = dataloader(vaild_df)```### 2. Set parametersNow, we need to set the parameters. They are going to be used for handling the data and training the model. In this example, only parameters for the training are set. [Here](https://github.com/chrislemke/autoembedder#parameters) you find a list of all possible parameters. This should do it:```pythonparameters = {    &quot;hidden_layers&quot;: [[25, 20], [20, 10]],    &quot;epochs&quot;: 10,    &quot;lr&quot;: 0.0001,    &quot;verbose&quot;: 1,}```### 3. Initialize the autoembedderThen, we need to initialize the [autoembedder](https://chrislemke.github.io/autoembedder/autoembedder.model/#autoembedder.model.Autoembedder). In this example, we are not using any categorical features. So we can skip the `embedding_sizes` argument.```pythonmodel = Autoembedder(parameters, num_cont_features=train_df.shape[1])```### 4. Train the modelEverything is set up. Now we can [fit](https://chrislemke.github.io/autoembedder/autoembedder.learner/#autoembedder.learner.fit) the model.```pythonfit(parameters, model, train_dl, valid_dl)```## ExampleCheck out [this Jupyter notebook](https://github.com/chrislemke/autoembedder/blob/main/example.ipynb) for an applied example using the [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) from Kaggle.## ParametersThis is a list of all parameters that can be passed to the Autoembedder for training. When using the training script the `_` needs to be replaced with `-` and the parameters need to be passed as arguments. For boolean values please have a look at the `Comment` column for understanding how to pass them.## Run the training scriptYou can also simply use the training script::```bashpython3 training.py \--epochs 20 \--train-input-path &quot;path/to/your/train_data&quot; \--test-input-path &quot;path/to/your/test_data&quot; \--hidden-layers &quot;[[12, 6], [6, 3]]&quot;```for help just run:```bashpython3 training.py --help```| Argument             | Type  | Required | Default value                 | Comment                                                                                                                                                                                  || -------------------- | ----- | -------- | ----------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- || batch_size           | int   | False    | 32                            |                                                                                                                                                                                          || drop_last            | bool   | False    | True                             |  --drop-last / --no-drop-last                                                                                                                                                                               || pin_memory           | bool   | False    | True                             | --pin-memory / --no-pin-memory                                                                                                                                                                               || num_workers          | int   | False    | 0                             | 0 means that the data will be loaded in the main process                                                                                                                                 || use_mps              | bool   | False    | False                             | --use-mps / --no-use-mps                                        || model_title          | str   | False    | autoembedder_{`datetime`}.bin |                                                                                                                                                                                          || model_save_path      | str   | False    |                               |                                                                                                                                                                                          || n_save_checkpoints   | int   | False    |                               |                                                                                                                                                                                          || lr                   | float | False    | 0.001                         |                                                                                                                                                                                          || amsgrad              | bool   | False    | False                             | --amsgrad / --no-amsgrad                                                                                                                                                                               || epochs               | int   | True     |                               || dropout_rate         | float | False    | 0                             | Dropout rate for the dropout layers in the encoder and decoder.                                                                                                                          || layer_bias           | bool   | False    | True                             | --layer-bias / --no-layer-bias                                                                                                                                                                               |  || weight_decay         | float | False    | False                             |                                                                                                                                                                                          || l1_lambda            | float | False    | 0                             |                                                                                                                                                                                          || xavier_init          | bool   | False    | False                             | --xavier-init / --no-xavier-init                                                                                                                                                                               || activation           | str   | False    | tanh                          | Activation function; either `tanh`, `relu`, `leaky_relu` or `elu`                                                                                                                        || tensorboard_log_path | str   | False    |                               |                                                                                                                                                                                          || trim_eval_errors     | bool   | False    | False                             |--trim-eval-errors / --no-trim-eval-errors; Removes the max and min loss when calculating the `mean loss diff` and `median loss diff`. This can be useful if some rows create very high losses.                                      || verbose              | int   | False    | 0                             | Set this to `1` if you want to see the model summary and the validation and evaluation results. set this to `2` if you want to see the training progress bar. `0` means no output.       || target               | str   | False    |                               | The target column. If not set no evaluation will be performed.                                                                                                                           || train_input_path     | str   | True     |                               |                                                                                                                                                                                          || test_input_path      | str   | True     |                               || eval_input_path      | str   | False    |                               | Path to the evaluation data. If no path is provided no evaluation will be performed.                                                                                                     |  || hidden_layers        | str   | True     |                               | Contains a string representation of a list of list of integers which represents the hidden layer structure. E.g.: `&quot;[[64, 32], [32, 16], [16, 8]]&quot;` activation                           || cat_columns          | str   | False    | &quot;[]&quot;                          | Contains a string representation of a list of list of categorical columns (strings). The columns which use the same encoder should be together in a list. E.g.: `&quot;[['a', 'b'], ['c']]&quot;`. || drop-cat-columns           | bool   | False    |                             |--drop-cat-columns / --no-drop-cat-columns## Why additional embedding layers?The additional embedding layers automatically embed all columns with the Pandas `category` data type. If categorical columns have another data type, they will not be embedded and will be handled like continuous columns. Simply encoding the categorical values (e.g., with the usage of a label encoder) decreases the quality of the outcome.</longdescription>
</pkgmetadata>