<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># TPU CareAutomatically take good care of your preemptible TPUs## Table of Contents* [TPU Care](#tpu-care)    * [Table of Contents](#table-of-contents)    * [Features](#features)    * [Getting Started](#getting-started)        * [Installation](#installation)    * [Examples](#examples)        * [Long-running preemptible training](#long-running-preemptible-training)        * [Sweeps](#sweeps)    * [Citation](#citation)## Features* **Reliable code execution**: TPU Care starts a TPU, ensures it's set up as specified and continues the experiment  whenever the node dies. Think of it like [TerraForm](https://www.terraform.io/) + [Ansible](https://www.ansible.com/)  for machine learning.* **Maintenance of large swarms**: When running multiple nodes, TPU Care will automatically delete dead instances while  keeping as many alive as possible.* **Code generation**: To simplify setup, TPU Care efficiently clones your git repository and ensures trustable  execution of your `run_command` that continues even during outages.* **Optimized management**: When a node dies, TPU Care deletes it within five minutes and creates a new one the second  there is capacity.## Getting Started### Installation```BASHpython3 -m pip install tpucare```## ExamplesWe've been using TPU Care for a while at [HomebrewNLP](https://github.com/HomebrewNLP/). In fact, this library is justthe branched out core of the original production-ready HomebrewNLP code. At HomebrewNLP, there were two major use-casesfor this library. We started both massive hyperparameter sweeps which consumed 900,000 TPU-core hours within threemonths and stable training on large TPU pods. Below, you can see a list of TPUs which are largely managed by TPUCare: ![PU Output](https://i.imgur.com/LcOm0Bc.png)&lt;p align=&quot;center&quot;&gt;Screenshot from &lt;a href=&quot;https://github.com/shawwn/tpunicorn&quot;&gt;TPUnicorn&lt;/a&gt;, a CLI-based TPU managed software&lt;/p&gt;In the following sections, you'll learn how we use at massive scale with minimal code effort.### Long-running preemptible trainingFor example, the following code can be used to create a production-ready v3-256 usingthe [HomebrewNLP-Jax](https://github.com/HomebrewNLP/HomebrewNLP-Jax) codebase (see [examples/pod.py](https://github.com/clashluke/tpucare/blob/main/examples/pod.py) for an executable version):```PYTHONimport dataclassesimport typingfrom netrc import netrcimport yamlfrom tpucare import exec_command, exec_on_tpu, send_to_tpu, start_single@dataclasses.dataclassclass Context:    retry: intZONE = &quot;europe-west4-a&quot;HOST = &quot;big-pod&quot;RUN_NAME = &quot;256-core-tpu&quot;def load_config(ctx: Context):    with open(&quot;config.yaml&quot;, 'r') as f:        config = f.read()    config = yaml.safe_load(config)    wandb_api = wandb.Api()    config[&quot;training&quot;][&quot;do_checkpoint&quot;] = True    base_checkpoint_path = config[&quot;training&quot;][&quot;checkpoint_path&quot;]    start_step = 0    for run in wandb_api.runs(f&quot;{config['wandb']['entity']}/{config['wandb']['project']}&quot;):        if run.name == config['wandb']['name']:            start_step = run.summary[&quot;_step&quot;]            break    start_step -= start_step % config[&quot;training&quot;][&quot;checkpoint_interval&quot;]    config[&quot;training&quot;][&quot;start_step&quot;] = start_step    config[&quot;wandb&quot;][&quot;name&quot;] = f&quot;{RUN_NAME}-{ctx.retry}&quot;    if ctx.retry &gt; 0:        config[&quot;training&quot;][&quot;checkpoint_load_path&quot;] = config[&quot;training&quot;][&quot;checkpoint_path&quot;]    config[&quot;training&quot;][&quot;checkpoint_path&quot;] = f&quot;{base_checkpoint_path}-{ctx.retry}&quot;    return yaml.dump(config)def start_fn(ctx: Context, worker: int):    &quot;&quot;&quot;    This function gets executed in threads to start a run on a new TPU. It receives the context object returned by     `creation_callback` as well as the worker id which corresponds to the slice id this code was executed on in a     multi-host setup. For single-host setups, such as v3-8s, the &quot;worker&quot; will always be set to 0.    Ideally, it'd copy necessary files to the TPU and then run those. Here, `exec_command` can be used to create an     execution command that automatically spawns a `screen` session which persists even when the SSH connection gets cut.    &quot;&quot;&quot;    send_to_tpu(HOST, ZONE, &quot;config.yaml&quot;, load_config(ctx), worker)    cmd = exec_command(repository=&quot;https://github.com/HomebrewNLP/HomebrewNLP-Jax&quot;, wandb_key=wandb_key)    send_to_tpu(HOST, ZONE, &quot;setup.sh&quot;, cmd, worker)    exec_on_tpu(HOST, ZONE, &quot;bash setup.sh&quot;, worker)def creation_callback(host: str, ctx: typing.Optional[Context]) -&gt; Context:    &quot;&quot;&quot;    The `creation_callback` is called once whenever a new TPU gets created and can be used to persist state    (such as retry counters) across multiple invocations.    &quot;&quot;&quot;    if ctx is None:  # first invocation        return Context(0)    ctx.retry += 1    return ctxdef main(service_account: str, tpu_version: int = 3, slices: int = 32, preemptible: bool = True):    start_single(host=HOST, tpu_version=tpu_version, zone=ZONE, preemptible=preemptible,                 service_account=service_account, slices=slices, start_fn=start_fn,                 creation_callback=creation_callback)```### SweepsSimilarly, large swarms of instances can be launched trivially using tpucare. Here, we largely do the same setup asabove, but call `launch_multiple` instead of `launch_single` which takes the additional argument `tpus` specifying thenumber of TPUs that should be launched and babysit. Depending on capacity and quota, the actual number of TPUs you getmight be lower than the number of TPUs specified.```PYTHONdef main(service_account: str, tpus: int, tpu_version: int = 3, slices: int = 32, preemptible: bool = True):    start_multiple(prefix=HOST, tpu_version=tpu_version, zone=ZONE, preemptible=preemptible,                   service_account=service_account, slices=slices, start_fn=start_fn,                   creation_callback=creation_callback, tpus=tpus)```However, this would simply launch the same run many times. If you instead plan to register them with a[WandB Sweep](https://docs.wandb.ai/guides/sweeps/configuration), we need to modify the `start_fn` to join the wandbsweep.\By patching in the code below, tpucare will start and maintain a large swarm of TPUs all working towards the samehyperparameter optimization problem.```PYTHONimport wandbwith open(&quot;sweep.yaml&quot;, 'r') as f:  # sweep config passed straight to wandb    config = yaml.safe_load(f.read())sweep_id = wandb.sweep(config, entity=&quot;homebrewnlp&quot;, project=&quot;gpt&quot;)def start_fn(ctx: Context, worker: int):    cmd = exec_command(repository=&quot;https://github.com/HomebrewNLP/HomebrewNLP-Jax&quot;, wandb_key=wandb_key,                       run_command=f&quot;/home/ubuntu/.local/bin/wandb agent {sweep_id}&quot;)    send_to_tpu(HOST, ZONE, &quot;setup.sh&quot;, cmd, worker)    exec_on_tpu(HOST, ZONE, &quot;bash setup.sh&quot;, worker)```The full executable code can be foundin [examples/sweep.py](https://github.com/clashluke/tpucare/blob/main/examples/sweep.py).Similarly, the `start_fn` could be adapted to start an inference serverfor [HomebrewNLP](https://github.com/HomebrewNLP/HomebrewNLP-Jax/)or [Craiyon](https://huggingface.co/spaces/dalle-mini/dalle-mini) or even execute machine learning unit-tests inparallel.## Citation```BIBTEX@software{nestler_lucas_2022_6837312,  author       = {Nestler, Lucas},  title        = {TPU Care},  month        = jul,  year         = 2022,  publisher    = {Zenodo},  version      = {0.0.2},  doi          = {10.5281/zenodo.6837312},  url          = {https://doi.org/10.5281/zenodo.6837312}}```</longdescription>
</pkgmetadata>