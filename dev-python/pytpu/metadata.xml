<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># IVA TPU Python API## Main entities### TPUDeviceTPUDevice is a device handle### TPUProgramTPUProgram contains TPU instructions and weigths data### TPUProgramInfoObject can be used to configure inference.```config = TPUProgramInfo()config.max_tasks_count = 4 # configures depth of tasks queue in driverconfig.disable_static_checker = true # disables static checker for programprogram = TPUProgram(&quot;program.tpu&quot;, config)```### TPUInferenceTPUInference contains input/output data## Example```pythonimport asyncioimport numpy as npfrom iva_tpu import TPUDevice, TPUProgram, TPUInferencefrom iva_applications.resnet50 import image_to_tensorfrom iva_applications.imagenet import tpu_tensor_to_classesfrom PIL import Imageimage = Image.open('ILSVRC2012_val_00000045.JPEG')tensor = image_to_tensor(image)device = TPUDevice()program = TPUProgram(&quot;resnet50.tpu&quot;) #default TPUProgramInfo is totally finedevice.load_program(program)inference = TPUInference(program)inference.load([tensor])status_future = device.load_inference(inference)  # device returns future for inference statusevent_loop = asyncio.get_event_loop()status = event_loop.run_until_complete(status_future)assert status.is_success # check that there is no errors during inferenceoutput = inference.get() # get resultstpu_tensor_to_classes(output[0], top=1)```## TPU Dictionary interface```...program = TPUProgram(&quot;resnet50.tpu&quot;)inference = TPUInference(program)inference.load({&quot;Placeholder:0&quot;: tensor})...assert status.is_successoutput = inference.get(as_dist=True)tpu_tensor_to_classes(output[&quot;logits:0&quot;], top=1)```## TPU Blocking interface```status = device.load_inference_sync(inference) #would block until completion```## TPU Raw buffer examples```import asynciofrom iva_tpu import TPUDevice, TPUProgram, TPUInference, ProcessingModeprogram = TPUProgram(&quot;omega_program_dnn_quant_3.0.0.tpu&quot;)device = TPUDevice()device.load_program(program)inference = TPUInference(program)with open(&quot;f.bin&quot;, &quot;rb&quot;) as f:    buf=f.read()inference.load([buf], mode=ProcessingMode.RAW)asyncio.get_event_loop().run_until_complete(device.load_inference(inference))outputs = inference.get(mode=ProcessingMode.RAW)for i in range(3):  o = outputs[i]  with open(f&quot;o{i}.bin&quot;, &quot;wb&quot;) as f:    f.write(o)```## TPU Single inference statistics examples```result = device.load_inference_sync(inference)result.timings # contains statistics about inferenceresult.timings[&quot;queue_timings&quot;] # contains array of timings for 3 queues (QUEUE_TRANSFER_TO, QUEUE_EXECUTOR, QUEUE_TRANSFER_FROM)result.timings[&quot;queue_timings&quot;][%d] # contains tuple of 2 elements: idle time and actual work timeresult.timings[&quot;queue_timings&quot;][%d][%d] # contains tuple of 3 values: last, average, maximum through all inferences for the device objectresult.timings[&quot;execution_timing&quot;][%d] # same as before but with execution on tpu timings```## TPU Global statistics examples```device = TPUDevice()device.stats # returns object with global statistics about the current devicedevice.stats[&quot;mem&quot;] # current usage of memory in the device```</longdescription>
</pkgmetadata>