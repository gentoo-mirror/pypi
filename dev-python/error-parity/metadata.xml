<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># error-parity![Tests status](https://github.com/socialfoundations/error-parity/actions/workflows/python-package.yml/badge.svg)![PyPI status](https://github.com/socialfoundations/error-parity/actions/workflows/python-publish.yml/badge.svg)![PyPI version](https://badgen.net/pypi/v/error-parity)![OSI license](https://badgen.net/pypi/license/error-parity)![Python compatibility](https://badgen.net/pypi/python/error-parity)&lt;!-- ![PyPI version](https://img.shields.io/pypi/v/error-parity) --&gt;&lt;!-- ![OSI license](https://img.shields.io/pypi/l/error-parity) --&gt;&lt;!-- ![Compatible python versions](https://img.shields.io/pypi/pyversions/error-parity) --&gt;Fast postprocessing of any score-based predictor to meet fairness criteria.The `error-parity` package can achieve strict or relaxed fairness constraint fulfillment, which can be useful to compare ML models at equal fairness levels.## InstallingInstall package from [PyPI](https://pypi.org/project/error-parity/):```pip install error-parity```Or, for development, you can clone the repo and install from local sources:```git clone https://github.com/socialfoundations/error-parity.gitpip install ./error-parity```## Getting started&gt; See detailed example notebooks under the [**examples folder**](./examples/).```pyfrom error_parity import RelaxedThresholdOptimizer# Given any trained model that outputs real-valued scoresfair_clf = RelaxedThresholdOptimizer(    predictor=lambda X: model.predict_proba(X)[:, -1],   # for sklearn API    # predictor=model,  # use this for a callable model    constraint=&quot;equalized_odds&quot;,    tolerance=0.05,     # fairness constraint tolerance)# Fit the fairness adjustment on some data# This will find the optimal _fair classifier_fair_clf.fit(X=X, y=y, group=group)# Now you can use `fair_clf` as any other classifier# You have to provide group information to compute fair predictionsy_pred_test = fair_clf(X=X_test, group=group_test)```## How it worksGiven a callable score-based predictor (i.e., `y_pred = predictor(X)`), and some `(X, Y, S)` data to fit, `RelaxedThresholdOptimizer` will:1. Compute group-specific ROC curves and their convex hulls;2. Compute the `r`-relaxed optimal solution for the chosen fairness criterion (using [cvxpy](https://www.cvxpy.org));3. Find the set of group-specific binary classifiers that match the optimal solution found.    - each group-specific classifier is made up of (possibly randomized) group-specific thresholds over the given predictor;    - if a group's ROC point is in the interior of its ROC curve, partial randomization of its predictions may be necessary.## Features and implementation road-mapWe welcome community contributions for [cvxpy](https://www.cvxpy.org) implementations of other fairness constraints.Currently implemented fairness constraints:- [x] equality of odds (Hardt et al., 2016);  - i.e., equal group-specific TPR and FPR;  - use `constraint=&quot;equalized_odds&quot;`;- [x] equal opportunity;  - i.e., equal group-specific TPR;  - use `constraint=&quot;true_positive_rate_parity&quot;`;- [x] predictive equality;  - i.e., equal group-specific FPR;  - use `constraint=&quot;false_positive_rate_parity&quot;`;Road-map:- [ ] demographic parity;  - i.e., equal group-specific predicted prevalence;## CitingThis repository contains code and supplementary materials for the following preprint:&gt; Andr√© F. Cruz and Moritz Hardt. &quot;Unprocessing Seven Years of Algorithmic Fairness.&quot; [arXiv preprint, 2023](https://arxiv.org/pdf/2306.07261.pdf).</longdescription>
</pkgmetadata>