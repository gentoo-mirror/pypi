<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Express Pascal Voc ToolsA tool for creating, reading and visualizing Pascal VOC annotations.**Report Bugs** [here](https://github.com/Redcof/pascal_voc_tools/issues)# Getting Started## Install`pip install express-pascal-voc-tools`## Single file Parsing```pythonfrom voc_tools import reader as voc_reader# `from_xml()` parse XMLfor anno in voc_reader.from_xml(r&quot;sixray_data\train\Annotations\P00002.xml&quot;):    print(anno.xmin, anno.xmax)# `from_image()` Parse XML by providing image path(it will automatically choose the correct XML)for anno in voc_reader.from_image(r&quot;sixray_data\train\JPEGImages\P00002.jpeg&quot;):    print(anno.xmin, anno.xmax)# `from_file()` Get the parsed metadata as a tuplefor anno in voc_reader.from_file(r&quot;sixray_data\train\JPEGImages\P00002.xml&quot;):    print(anno.raw())for anno in voc_reader.from_file(r&quot;sixray_data\train\JPEGImages\P00002.jpeg&quot;):    print(anno.raw())# `from_dir()` Get the parsed metadata as a tuple for entire directoryfor anno in voc_reader.from_dir(&quot;sixray_data\train&quot;)):    print(anno.raw())```### Dataset level parsingUsing `VOCDataset` class we can address a Pascal VOC dataset. In general Pascal VOCDatasets are organised as below:```commandlinemy_dataset    |    +- train    |   |    |   +- Annotations    |   |  |    |   |  +- ITEM001.xml    |   |  +- ITEM002.xml    |   +- JPEGImages    |       |    |       +- ITEM001.jpeg    |       +- ITEM002.jpeg    +- test        |        +- Annotations        |  |        |  +- ITEM0010.xml        |  +- ITEM0020.xml        +- JPEGImages            |            +- ITEM0010.jpeg            +- ITEM0020.jpeg``````pythonfrom voc_tools.utils import VOCDatasetdataset_path = &quot;/my_dataset&quot;# initialize a datasetmy_dataset = VOCDataset(dataset_path)# fetch annotation bulkfor annotations, jpeg in my_dataset.train.fetch():    print(annotations[0].filename, jpeg.image.shape)# fetch annotationfor anno, jpeg in my_dataset.train.fetch(bulk=False):    print(anno, jpeg.image.shape)# parse the annotations into memory for train datasetmy_dataset.train.load()my_dataset.test.load()# returns a list of class names in train datasetmy_dataset.train.class_names()my_dataset.test.class_names()# save parsed information into csvmy_dataset.train.load().to_csv(&quot;./train_metadata.csv&quot;)my_dataset.test.load().to_csv(&quot;./train_metadata.csv&quot;)# purge the parsed metadata to free memorymy_dataset.train.unload()my_dataset.test.unload()```## Caption SupportThis is an optional feature introduced to facilitate the new trends in prompt engineering and text based Generative AI.In this case the dataset must contain a `text` directory as below:```commandlinemy_dataset    |    +- train    |   |    |   +- Annotations    |   |  |    |   |  +- ITEM001.xml    |   |  +- ITEM002.xml    |   +- JPEGImages    |       |    |       +- ITEM001.jpeg    |       +- ITEM002.jpeg    |   +- text    |       |    |       +- ITEM001.text    |       +- ITEM002.text    +- test        |        +- Annotations        |  |        |  +- ITEM0010.xml        |  +- ITEM0020.xml        +- JPEGImages            |            +- ITEM0010.jpeg            +- ITEM0020.jpeg        +- text            |            +- ITEM0010.text            +- ITEM0020.text``````pythonfrom voc_tools.utils import VOCDatasetdataset_path = &quot;/my_dataset&quot;voc_caption_data = VOCDataset(dataset_path, caption_support=True)  # init dataset with caption# read caption bulkfor captions in voc_caption_data.train.caption.fetch():    print(captions[0].raw())# read caption one by onefor caption in voc_caption_data.train.caption.fetch(bulk=False):    print(caption.raw())# save captions to a CSVvoc_caption_data.train.caption.to_csv(&quot;train_captions.csv&quot;)```### Visualize```pythonfrom voc_tools.visulizer import from_jpeg, see_jpegjpeg = from_jpeg(r&quot;sixray_data\train\JPEGImages\P00002.jpg&quot;)jpeg.see()# ORsee_jpeg(r&quot;sixray_data\train\JPEGImages\P00002.jpg&quot;)```### Load not PascalVOC dataset```pythonimport pathlibfrom voc_tools.constants import VOC_IMAGESfrom voc_tools.reader import list_dirfrom voc_tools.utils import Dataset, VOCDatasetdataset = pathlib.Path(r&quot;path/to/dataset&quot;)# set global flagsDataset.IMAGE_DIR = &quot;images&quot;  # Say, instead of 'JPEGImages', the images are stored in 'images' directory# reading filepathsfile_paths = list(list_dir(str(dataset / &quot;train&quot;), dir_flag=VOC_IMAGES, fullpath=True))file_paths.extend(list(list_dir(str(dataset / &quot;test&quot;), dir_flag=VOC_IMAGES, fullpath=True)))# if you have captions stored in 'captions' directoryvoc_data = VOCDataset(dataset, caption_support=True)```# CollaborateGitHub: [https://github.com/Redcof/pascal_voc_tools.git](https://github.com/Redcof/pascal_voc_tools.git)**Build and Publish**1. `python setup.py sdist bdist_wheel`1. `python -m twine upload dist/*`</longdescription>
</pkgmetadata>