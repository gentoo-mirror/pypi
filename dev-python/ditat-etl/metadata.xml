<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Ditat ETLMultiple tools and utilities for ETL pipelines and others.## DatabasesUseful wrappers for databases and methods to execute queries.### _Postgres_It is compatible with pandas.DataFrame interaction, either reading as dataframes and pushing to the db.```pythonfrom ditat_etl.databases import Postgresconfig = {    &quot;database&quot;: &quot;xxxx&quot;,    &quot;user&quot;: &quot;xxxx&quot;,    &quot;password&quot;: &quot;xxxx&quot;,    &quot;host&quot;: &quot;xxxxx&quot;,    &quot;port&quot;: &quot;xxxx&quot;}p = Postgres(config)```The main base function is query.```pythonp.query(  query_statement: list or str,  df: bool=False,  as_dict: bool=False,  commit: bool=True,  returning: bool=True,  mogrify: bool=False,  mogrify_tuple: tuple or list=None,  verbose=False)```This function is a workaround of pandas.to_sql() which drops the table before inserting.It really works like an upsert and it gives you the option to do nothing or update on the column(s) constraint.```pythonp.insert_df_to_sql(  df: pd.DataFrame,  tablename: str,  commit=True,  conflict_on: str or list=None,  do_update_columns: bool or list=False,  verbose=False):```This one is similar, it lets you &quot;upsert&quot; without necessarily having a primary key or constraint.Ideally use the previous method.```pythonp.update_df_to_sql(  df: pd.DataFrame,  tablename: str,  on_columns: str or list,  insert_new=True,  commit=True,  verbose=False,  overwrite=False):```This class also has some smaller utitlies for describing tables, getting information,creating tables and indexes among others.## Salesforce### _SalesforceObj_Salesforce wrapper adding functionalities to Simple Salesforce.You can connect with login crendentials or through the Oauth2 protocol with a refresh token and client crendentials.```pythonfrom ditat_etl.salesforce import SalesforceObjsf_config = {  &quot;organizationId&quot;: &quot;xxx&quot;,  &quot;password&quot;: &quot;xxx&quot;,  &quot;security_token&quot;: &quot;xxx&quot;,  &quot;username&quot;: &quot;xxx&quot;,  # Session Id for refresh token  &quot;session_id&quot;: &quot;xxx&quot;}# With login credentialssf = Salesforce(sf_config)# With Oauth2 refresh token and client credentialssf = SalesforceObj(  sf_config,  client_id='xxx',  client_secret='xxx',)```The core of this class is the query method.```pythonsf.query(  tablename='xxx',  columns=None,  limit=None,  df=False,  date_from=None,  date_to=None,  date_window=None,  date_window_variable='LastModifiedDate',  verbose=False,  timeout=None,  max_columns=100,)```Most times you can directly use the parallel execution.```pythonsf.query_parallel(  tablename='xxx',  columns=None,  limit=None,  df=False,  date_window=None,  date_window_variable='LastModifiedDate',  verbose=False,  n_chunks=4)```Update records```pythonsf.update(  tablename=&quot;xxx&quot;,  record_list=[{'Id': '11111', 'field1': '1111'}],  batch_size=1000)```Insert records (update as an option)```pythonsf.insert_df(  tablename='xxx',  dataframe=pd.DataFrame,  batch_size=10000,  update=True,  conflict_on='Name',  return_response=False,)```## Entity Resolution and DeduplicationThe Matcher allows you to match two datasets on certain criteriaand also find duplicates.### _Matcher_```pythonfrom ditat_etl.utils.entity_resolution import Matchermatcher = Matcher(exact_domain=False)```### *Entity Resolution*Set both datasets as dataframes. Specify the names of the columns to useas criteria for matching```python# Set df 1matcher.set_df(  data=pd.DataFrame,  name='df_1',  index='id',  domain=None,  address=None,  phone=None,  country=None,  entity_name=None)# Set df 2 matcher.set_df(  data=pd.DataFrame,  name='df_2',  index='id',  domain=None,  address=None,  phone=None,  country=None,  entity_name=None)# Runmatches = matches.run(  save=False,  verbose=True,  deduping=False,  match_type_included=None,  match_type_excluded=None,  match_count_th=3)```### *Deduplication*```pythonresults = matcher.dedupe(  data=pd.DataFrame,  index='id',  domain=None,  address=None,  phone=None,  country=None,  entity_name=None,  save=True,  match_type_included=None,  match_type_excluded=None,  match_count_th=3,  include_self=True)```## TimeItThe TimeIt class helps you time functions, methods, blocks of code.```pythonfrom ditat_etl.time import TimeItA)@TimeItdef f():passf()&gt;&gt; f takes: 0.0006 sec.B) @TimeIt(decimals=8)def f():passf()&gt;&gt; f takes: 0.00000003 sec.C) with TimeIt():time.sleep(0.3)&gt;&gt; indented block takes: 0.3005 sec.D) class Foo:@TimeIt() # It has to be a callable for classesdef m(self):passFoo().m()&gt;&gt; m takes: 0.0 sec.```## Enrichment### _PeopleDataLabs_```pythonfrom ditat_etl.utils.enrichment import PeopleDataLabspdl = PeopleDataLabs(    api_key='xxx',    check_existing_method='s3',    bucket_name='xxx',)```You can:- Enrich company- Search company- Enrich person- Search person```pythonr = pdl.enrich_company(min_likelihood=5,required='website',save=True,check_existing=True,s3_recalculate=False,company_name='companyx')'''PLEASE CHECK https://docs.peopledatalabs.com/docs FOR MORE DETAILS'''```## Url### _functions_```pythonfrom ditat_etl.url.functions import eval_url, extract_domaindata = [    'laskdj',    'www.google.com',    'accounts.google.com',    'https://www.emol.com/economia/']for d in data:    r = extract_domain(d)    print(r)print('####')r = eval_url(data)print(r)``````bashNonegoogle.comaccounts.google.comemol.com####Initializing 4 workers.eval_url takes: 1.3309 sec.{'laskdj': None, 'www.google.com': 'google.com', 'accounts.google.com': 'accounts.google.com', 'https://www.emol.com/economia/': 'emol.com'}```### _Url_Extension of module requests/urllib3 for Proxy usage and Bulk usage.*High-level usage*```pythonfrom ditat_etl import urlresponse = url.get('https://google.com')# You can pass the same parameters as the library requests and other special parameters.# Check low level usage for more details.```*Low-level usage*```pythonfrom ditat_etl.url import Urlu = Url()```We use the logging module and it is set by default with 'DEBUG'.You can change this parameter to any allowed level```python3u = Url(debug_level='WARNING') # Just an example```Manage your proxies```pythonu.add_proxies(n=3) # Added 3 new proxies (not necessarily valid) to self.proxiesu.clean_proxies() # Multithreaded to validate and keep only valid proxies.``````pythonprint(u.proxies)# You can also u.proxies = [], set them manually but this is not recommended.```#### Main functionality```pythondef request(    queue: str or list,    expected_status_code: int=200,    n_times: int=1,    max_retries: int=None,    use_proxy=False,    _raise=True,    ***kwargs    ):```Examples```pythonresult = u.request('https://google.com')result = u.request(queue=['https://google.com', 'htttps://facebook.com'], use_proxy=True)# You can also pass optional parameter valid por a requests &quot;Request&quot;import jsonresult = u.request(queue='https://example.com', method='post', data=json.dumps({'hello': 'world'}))```</longdescription>
</pkgmetadata>