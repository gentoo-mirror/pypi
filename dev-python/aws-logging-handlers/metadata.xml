<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>AWS Logging Handlers====================A python multithreaded logging handler package that streams records toAWS services objects with support for the following AWS services: \* S3\* KinesisSupports gzip compression(in S3)Getting Started---------------Prerequisites~~~~~~~~~~~~~Asynchronous multipart uploading relies on the ability to use multiplethreads #### Packages:::   boto3Installing~~~~~~~~~~Installation using pip::   pip install aws-logging-handlersExamples~~~~~~~~Stream log records to S3 and Kinesis::    import logging    from aws_logging_handlers.S3 import S3Handler    from aws_logging_handlers.Kinesis import KinesisHandler    bucket=&quot;test_bucket&quot; # The bucket should already exist    # The log will be rotated to a new object either when an object reaches 5 MB or when 120 seconds pass from the last rotation/initial logging    s3_handler = S3Handler(&quot;test_log&quot;, bucket, workers=3)    kinesis_handler = KinesisHandler('log_test', 'us-east-1', workers=1)    formatter = logging.Formatter('[%(asctime)s] %(filename)s:%(lineno)d} %(levelname)s - %(message)s')    s3_handler.setFormatter(formatter)    kinesis_handler.setFormatter(formatter)    logger = logging.getLogger('root')    logger.setLevel(logging.INFO)    logger.addHandler(s3_handler)    logger.addHandler(kinesis_handler)    for i in range(0, 100000):        logger.info(&quot;test info message&quot;)        logger.warning(&quot;test warning message&quot;)        logger.error(&quot;test error message&quot;)    logging.shutdown()To be developed----------------  Support for asyncio-  Logging and upload metricsLicense-------This project is licensed under the MIT License - see the `LICENSE.md`_file for details.. _LICENSE.md: LICENSE</longdescription>
</pkgmetadata>