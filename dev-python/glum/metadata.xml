<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># glum[![CI](https://github.com/Quantco/glm_benchmarks/workflows/CI/badge.svg)](https://github.com/Quantco/glum/actions)[![Docs](https://readthedocs.org/projects/pip/badge/?version=latest&amp;style=flat)](https://glum.readthedocs.io/)[![Conda-forge](https://img.shields.io/conda/vn/conda-forge/glum?logoColor=white&amp;logo=conda-forge)](https://anaconda.org/conda-forge/glum)[![PypiVersion](https://img.shields.io/pypi/v/glum.svg?logo=pypi&amp;logoColor=white)](https://pypi.org/project/glum)[![PythonVersion](https://img.shields.io/pypi/pyversions/glum?logoColor=white&amp;logo=python)](https://pypi.org/project/glum)[Documentation](https://glum.readthedocs.io/en/latest/)Generalized linear models (GLM) are a core statistical tool that include many common methods like least-squares regression, Poisson regression and logistic regression as special cases. At QuantCo, we have used GLMs in e-commerce pricing, insurance claims prediction and more. We have developed `glum`, a fast Python-first GLM library. The development was based on [a fork of scikit-learn](https://github.com/scikit-learn/scikit-learn/pull/9405), so it has a scikit-learn-like API. We are thankful for the starting point provided by Christian Lorentzen in that PR!The goal of `glum` is to be at least as feature-complete as existing GLM libraries like `glmnet` or `h2o`. It supports* Built-in cross validation for optimal regularization, efficiently exploiting a “regularization path”* L1 regularization, which produces sparse and easily interpretable solutions* L2 regularization, including variable matrix-valued (Tikhonov) penalties, which are useful in modeling correlated effects* Elastic net regularization* Normal, Poisson, logistic, gamma, and Tweedie distributions, plus varied and customizable link functions* Box constraints, linear inequality constraints, sample weights, offsetsThis repo also includes tools for benchmarking GLM implementations in the `glum_benchmarks` module. For details on the benchmarking, [see here](src/glum_benchmarks/README.md). Although the performance of `glum` relative to `glmnet` and `h2o` depends on the specific problem, we find that when N &gt;&gt; K (there are more observations than predictors), it is consistently much faster for a wide range of problems.![Performance benchmarks](docs/_static/headline_benchmark.png#gh-light-mode-only)![Performance benchmarks](docs/_static/headline_benchmark_dark.png#gh-dark-mode-only)For more information on `glum`, including tutorials and API reference, please see [the documentation](https://glum.readthedocs.io/en/latest/).Why did we choose the name `glum`? We wanted a name that had the letters GLM and wasn't easily confused with any existing implementation. And we thought glum sounded like a funny name (and not glum at all!). If you need a more professional sounding name, feel free to pronounce it as G-L-um. Or maybe it stands for &quot;Generalized linear... ummm... modeling?&quot;# A classic example predicting housing prices```python&gt;&gt;&gt; from sklearn.datasets import fetch_openml&gt;&gt;&gt; from glum import GeneralizedLinearRegressor&gt;&gt;&gt;&gt;&gt;&gt; # This dataset contains house sale prices for King County, which includes&gt;&gt;&gt; # Seattle. It includes homes sold between May 2014 and May 2015.&gt;&gt;&gt; house_data = fetch_openml(name=&quot;house_sales&quot;, version=3, as_frame=True)&gt;&gt;&gt;&gt;&gt;&gt; # Use only select features&gt;&gt;&gt; X = house_data.data[...     [...         &quot;bedrooms&quot;,...         &quot;bathrooms&quot;,...         &quot;sqft_living&quot;,...         &quot;floors&quot;,...         &quot;waterfront&quot;,...         &quot;view&quot;,...         &quot;condition&quot;,...         &quot;grade&quot;,...         &quot;yr_built&quot;,...         &quot;yr_renovated&quot;,...     ]... ].copy()&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; # Model whether a house had an above or below median price via a Binomial&gt;&gt;&gt; # distribution. We'll be doing L1-regularized logistic regression.&gt;&gt;&gt; price = house_data.target&gt;&gt;&gt; y = (price &lt; price.median()).values.astype(int)&gt;&gt;&gt; model = GeneralizedLinearRegressor(...     family='binomial',...     l1_ratio=1.0,...     alpha=0.001... )&gt;&gt;&gt;&gt;&gt;&gt; _ = model.fit(X=X, y=y)&gt;&gt;&gt;&gt;&gt;&gt; # .report_diagnostics shows details about the steps taken by the iterative solver&gt;&gt;&gt; diags = model.get_formatted_diagnostics(full_report=True)&gt;&gt;&gt; diags[['objective_fct']]        objective_fctn_iter               0            0.6930911            0.4895002            0.4495853            0.4436814            0.4434985            0.443497```# InstallationPlease install the package through conda-forge:```bashconda install glum -c conda-forge```</longdescription>
</pkgmetadata>