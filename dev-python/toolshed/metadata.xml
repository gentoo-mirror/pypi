<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Toolshed: Less Boiler-Plate |build|_===========================.. |build| image:: https://travis-ci.org/brentp/toolshed.svg.. _build: https://travis-ci.org/brentp/toolshedThis is a collection of well-tested, simple modules and functionsthat I use frequently.Files-----If you have a &quot;proper&quot; CSV file with quoting and such, use python's `csv`_module.If all you have is a file with a header and you want to get a dictionaryfor each row::    &gt;&gt;&gt; from toolshed import reader, header, nopen    &gt;&gt;&gt; for d in reader('toolshed/tests/data/file_data.txt'):    ...    print d['a'], d['b'], d['c']    1 2 3    11 12 13    21 22 23Or as a namedtuple::    &gt;&gt;&gt; from collections import namedtuple    &gt;&gt;&gt; for d in reader('toolshed/tests/data/file_data.txt', header=namedtuple):    ...    print d.a, d.b, d.c    1 2 3    11 12 13    21 22 23works the same for gzipped, bzipped, and .xls files and for stdin (via &quot;-&quot;)and for files over http/ftp::    &gt;&gt;&gt; for drow in (d for d in reader('toolshed/tests/data/file_data.txt.gz') if int(d['a']) &gt; 10):    ...    print drow['a'], drow['b'], drow['c']    11 12 13    21 22 23if one can specify the header to a file without one using the `header=` kwarg.If `header` is &quot;ordered&quot; then an OrderedDictionary will be used so thatdrow.keys() and d.values() will return the values in the order they appeared in the file.If `header` is a callable (a function or class) then, for each row, thatcallable will be called for each row with a single argument which is thelist of columns in the future, it may be called as:  callable(\*row) insteadof callable(row). **comments welcome**.the `toolshed.nopen` can open a file over http, https, ftp, a gzipped file, abzip file, or a subprocess with the same syntax.    &gt;&gt;&gt; nopen('toolshed/tests/data/file_data.txt.gz') # doctest: +ELLIPSIS    &lt;gzip open file ...&gt;    &gt;&gt;&gt; nopen('|ls') # doctest: +ELLIPSIS    &lt;generator object process_iter at ...&gt;you may need to send stdin to a proc:    # NOTE mode is None    &gt;&gt;&gt; proc = nopen(&quot;|awk '(NR % 2 == 1)'&quot;, mode=None)    # write some stuff to STDIN    &gt;&gt;&gt; proc.stdin.write(&quot;number\n&quot;)    &gt;&gt;&gt; for i in range(5):    ...    proc.stdin.write(&quot;%i\n&quot; % i)    # IMPORTANT! close stdin    &gt;&gt;&gt; proc.stdin.close()    # the read stdout    &gt;&gt;&gt; for d in reader(proc.stdout, header=True):    ...    print d    {'number': '1'}    {'number': '3'}In addition, you can skip the first lines of a file with a function like::    skipper = lambda toks: toks[0].startswith('#')    for d in reader('file-with-extra-header.txt', skip_while=skipper):        do_stuff(d)Pools-----ctrl+c on a long-running multi-processing pool is often non-responsive.if we use toolshed.pool(), that is fixed (using signal).this module also provides pmap, which wraps multiprocessing.Pool.map()to expand args, so we can do::    &gt;&gt;&gt; def fn(a, b):  return a + b    &gt;&gt;&gt; from toolshed import pmap    &gt;&gt;&gt; list(pmap(fn, [(1, 1), (2, 3)]))    [2, 5]and the fn will be mapped in parallel and we didn't need a wrapper functionfor fn like:    def wrapper(args):        return fn(*args)as we would normally.Note that this is like:    &gt;&gt;&gt; from itertools import starmap    &gt;&gt;&gt; list(starmap(fn, [(1, 1), (2, 3)]))    [2, 5]But Pool.starmap is not available until python 3.3This can cause problems in cases where your 'fn' expectsargs, instead of the exploded arguments. In the future, it may introspect fn,but that is not implemented for now.Links-----.. _`csv`: http://docs.python.org/library/csv.html</longdescription>
</pkgmetadata>