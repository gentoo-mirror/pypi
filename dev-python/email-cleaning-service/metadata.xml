<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># email_cleaning_serviceThis is an email segmenting service which takes a list of emails as input and returns the the header, body and signature of each message in the email## Getting StartedThe project is published on Pypi and can be installed using the following command```pypip install email-cleaning-service```## UsageThe package can be used as follows```pyfrom email_cleaning_service.control import EmailCleaneremail_cleaner = EmailCleaner(tracking_uri, storage_uri)```Usage revolves around the emailCleaner classwhich is the preferred interface for the package. The class takes two arguments, the tracking_uri and the storage_uri. The tracking_uri is the uri of the MLflow tracking server and the storage_uri is the uri of the storage server (can be a path to a local folder).BaseModel classes exist to simplify interactions with the class. The most important of these is the PipelineSpecs class which is used to define the pipeline to be used for cleaning the emails.```pyfrom email_cleaning_service.utils.request_classes import PipelineSpecspipeline_specs = PipelineSpecs(    classifier_origin=&quot;mlflow&quot;, # or &quot;h5&quot; or &quot;config    classifier_id=&quot;a1f66311816e417cb94db7c2457b25d1&quot;,    encoder_origin=&quot;hugg&quot;, # or &quot;mlflow&quot;    encoder_id=&quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot;,    encoder_dim=384,    features=[            &quot;phone_number&quot;,            &quot;url&quot;,            &quot;punctuation&quot;,            &quot;horizontal_separator&quot;,            &quot;hashtag&quot;,            &quot;pipe&quot;,            &quot;email&quot;,            &quot;capitalized&quot;,            &quot;full_caps&quot;        ]      # Can be any combination of the above features)```**The above pipeline is the recommended one for multilingual email segmenting for now.**The pipeline contains 3 main elements:* The embedding model: This is the model used to embed the emails into a vector space. The model can be either a huggingface model or an MLflow model. If the model is from hugging face, specify encoder_origin as &quot;hugg&quot; and the encoder_id as the model name on the platform. If the model is from MLflow, specify encoder_origin as &quot;mlflow&quot; and the encoder_id as the id of the run you want to use the model from on the MLFlow server.* The extracted features: a list of regex features that are concatenated to the embedding of each sentence* The classifier: This is the model used to realise the final classification and the separation of a thread in multiple messages. The model can come from mlflow in which case the run_id must be specified or from a h5 file in which case the path to the file must be specified.The pipeline can then be used as follows:```pyemail_list = [    &quot;This is a test email. I am testing the email cleaner.\nYours truly, Paul&quot;,    &quot;Hello team!\nThis is another test email with two lines.\n I am testing the email cleaner&quot;,    &quot;Bonjour!\nCeci est un autre email\n\nAu revoir!\nPaul&quot;,]email_cleaner.segment(email_list, pipeline_specs)```The output should look like this:```py{'threads': [{'source': 'This is a test email. I am testing the email cleaner.\nYours truly, Paul\n0781759532',   'messages': [{'full': 'This is a test email. I am testing the email cleaner.\nYours truly, Paul\n0781759532',     'header': '',     'disclaimer': '',     'greetings': '',     'body': 'This is a test email. I am testing the email cleaner.\nYours truly, Paul\n0781759532',     'signature': '',     'caution': ''}]},  {'source': 'Hello team!\nThis is another test email with two lines.\n I am testing the email cleaner.',   'messages': [{'full': 'Hello team!\nThis is another test email with two lines.\n I am testing the email cleaner.',     'header': '',     'disclaimer': '',     'greetings': '',     'body': 'Hello team!',     'signature': 'This is another test email with two lines.\n I am testing the email cleaner.',     'caution': ''}]},  {'source': 'Bonjour!\nCeci est un autre email\n\nAu revoir!\nPaul',   'messages': [{'full': 'Bonjour!\nCeci est un autre email\nAu revoir!\nPaul',     'header': '',     'disclaimer': '',     'greetings': '',     'body': 'Bonjour!\nCeci est un autre email\nAu revoir!',     'signature': 'Paul',     'caution': ''}]}]}```## Model TrainingThis package also includes support for training pipelines. You can either train (fine-tune) an encoder model or a classifier model. A note-worthy difference between the 2 is that encoders are trained with a single line of the email as input while classifiers are trained with a sequence of 64 lines as input.The csv files used for training must use be contain lines from emails and have the following columns:* Email: a unique Id for each email used to group email lines together* Text: the text of the email line* Section: the section of the email line (disclaimer, header, greetings, body, signature and caution represented as 1 thru 6 respectively)* FragmentChange: a boolean (0 or 1) indicating whether the line is a fragment change or not### Training an EncoderTo train an encoder, use the EncoderSpecs class and the RunSpecs class as follows:```pyfrom email_cleaning_service.utils.request_classes import EncoderSpecs, RunSpecsdataset = RunSpecs(    run_name=&quot;demo_encoder_test_run_2&quot;,    csv_train=&quot;./train_multi_71.csv&quot;,    csv_test=&quot;./test_multi_48.csv&quot;,    batch_size=4,    metrics=[],    lr=0.0001,    epochs=1,)encoder_specs = EncoderSpecs(    origin=&quot;mlflow&quot;,    encoder=&quot;14a633237e734575ad7f8eac9bd0319e&quot;)email_cleaner.train_encoder(dataset, encoder_specs)```The EncoderSpecs class takes two arguments, origin and encoder which are the same as in PipelineSpecs. The RunSpecs define how you want to train the model. The arguments are:* run_name: The name of the run on the MLflow server* csv_train: The path to the csv file containing the training data* csv_test: The path to the csv file containing the test data* batch_size: The batch size to use for training* metrics: A list of metrics to track during training. The metrics must be defined in the metrics.py file in utils* lr: The learning rate to use for training* epochs: The number of epochs to train for### Training a ClassifierTo train a classifier, an entire pipeline must be defined. This is done using the PipelineSpecs class as follows:```pydataset = RunSpecs(    run_name=&quot;with_fine_tuned_encoder&quot;,    batch_size=4,    csv_train=&quot;./train_multi.csv&quot;,    csv_test=&quot;./test_multi.csv&quot;,    metrics=[&quot;seq_f1&quot;, &quot;frag_f1&quot;],    lr=0.007,    epochs=3,)pipeline_specs = PipelineSpecs(    classifier_origin=&quot;h5&quot;,    classifier_id=&quot;./temp/base_multi_miniLM_classifier_optimized/multi_miniLM_classifier.h5&quot;,    encoder_origin=&quot;mlflow&quot;,    encoder_id=&quot;316fb5040b0a4353ade2e967290944ff&quot;,    encoder_dim=384,    features=[            &quot;phone_number&quot;,            &quot;url&quot;,            &quot;punctuation&quot;,            &quot;horizontal_separator&quot;,            &quot;hashtag&quot;,            &quot;pipe&quot;,            &quot;email&quot;,            &quot;capitalized&quot;,            &quot;full_caps&quot;        ])email_cleaner.train_classifier(dataset, pipeline_specs)```## Package Structure![package_architecture](./assets/package_architecture.png)## Maintaining the Package## Known Issues</longdescription>
</pkgmetadata>