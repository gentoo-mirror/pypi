<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># nbmake[![codecov](https://codecov.io/gh/treebeardtech/nbmake/branch/main/graph/badge.svg?token=9GuDM35FuO)](https://codecov.io/gh/treebeardtech/nbmake)[![PyPI versions](https://img.shields.io/pypi/pyversions/nbmake?logo=python&amp;logoColor=white)](https://pypi.org/project/nbmake)[![PyPI versions](https://img.shields.io/pypi/v/nbmake?logo=python&amp;logoColor=white)](https://pypi.org/project/nbmake)[![PyPI Downloads](https://img.shields.io/pypi/dm/nbmake)](https://pypi.org/project/nbmake)**What?** Pytest plugin for testing and releasing notebook documentation**Why?** To raise the quality of scientific material through better automation**Who is this for?** Research/Machine Learning Software Engineers who maintain packages/teaching materials with documentation written in notebooks.## Functionality1. Executes notebooks using pytest and nbclient, allowing parallel notebook testing2. Optionally writes back to the repo, allowing faster building of [nbsphinx](https://github.com/spatialaudio/nbsphinx) or [jupyter book](https://github.com/executablebooks/jupyter-book) docs## Quick StartIf you have a notebook that runs interactively using an ipython kernel,you can try testing it automatically as follows:```shpip install pytest nbmakepytest --nbmake **/*ipynb```## Configure Cell TimeoutsYou can configure the cell timeout with the following pytest flag:```shpytest --nbmake --nbmake-timeout=3000 # allows each cell 3000 seconds to finish```## Allow Errors For a Whole NotebookThis configuration must be placed in the notebook's **top-level metadata** (not cell-level metadata).Your notebook should look like this:```json{  &quot;cells&quot;: [ ... ],  &quot;metadata&quot;: {    &quot;kernelspec&quot;: { ... },    &quot;execution&quot;: {      &quot;allow_errors&quot;: true,      &quot;timeout&quot;: 300    }  }}```## Allow a Cell to Throw an ExceptionA cell with the following metadata can throw an exception without failing the test:```json  &quot;metadata&quot;: {    &quot;tags&quot;: [      &quot;raises-exception&quot;    ]  }```## Ignore a Code CellA cell with the following metadata will not be executed by nbmake```json{  &quot;language&quot;: &quot;python&quot;,  &quot;custom&quot;: {    &quot;metadata&quot;: {      &quot;tags&quot;: [        &quot;skip-execution&quot;      ]    }  }}```## Override Notebook Kernels when TestingRegardless of the kernel configured in the notebook JSON, you can force nbmake to use a specific kernel when testing:```pytest --nbmake --nbmake-kernel=mycustomkernel```## Add Missing Jupyter Kernel to Your CI EnvironmentIf you are not using the flag above and are using a kernel name other than the default ‘python3’, you will see an error message when executing your notebooks in a fresh CI environment: `Error - No such kernel: 'mycustomkernel'`Use ipykernel to install the custom kernel:```shpython -m ipykernel install --user --name mycustomkernel```If you are using another language such as c++ in your notebooks, you may have a different process for installing your kernel.## ParallelisationFor repos containing a large number of notebooks that run slowly, you can run each notebookin parallel using `pytest-xdist`.```shpip install pytest-xdistpytest --nbmake -n=auto```It is also possible to parallelise at a CI-level using strategies, see [example](https://github.com/LabForComputationalVision/plenoptic/blob/master/.github/workflows/treebeard.yml)### Build Jupyter Books FasterUsing xdist and the `--overwrite` flag let you build a large jupyter book repo faster:```shpytest --nbmake --overwrite -n=auto examplesjb build examples```## Find missing imports in a directory of failing notebooks (new ✨)It's not always feasible to get notebooks running from top to bottom from the start.You can however, use nbmake to check that there are no `ModuleNotFoundError`s:```shpytest \  --nbmake \  --nbmake-find-import-errors \ # Ignore all errors except ModuleNotFoundError  --nbmake-timeout=20 # Skip past cells longer than 20s```## Mock out variables to simplify testingIf your notebook runs a training process that takes a long time to run, you can use nbmake'smocking feature to overwrite variables after a cell runs:```json{  &quot;cells&quot;: [    ...,    {      &quot;cell_type&quot;: &quot;code&quot;,      &quot;execution_count&quot;: null,      &quot;metadata&quot;: {        &quot;nbmake&quot;: {          &quot;mock&quot;: {            // these keys will override global variables after this cell runs            &quot;epochs&quot;: 2,            &quot;config&quot;: &quot;/test/config.json&quot;,            &quot;args&quot;: {              &quot;env&quot;: &quot;test&quot;            }          }        }      },      &quot;outputs&quot;: [],      &quot;source&quot;: [        &quot;epochs = 10\n&quot;,        &quot;...&quot;      ]    },    ...  ],  ...}```## Run test logic after a cell executesYou can fetch CI secrets and run assertions after any cell by putting scripts in the cell metadata under `nbmake.post_cell_execute`:```json{ &quot;cells&quot;: [  {   &quot;cell_type&quot;: &quot;code&quot;,   &quot;execution_count&quot;: null,   &quot;metadata&quot;: {    &quot;nbmake&quot;: {     &quot;post_cell_execute&quot;: [       &quot;y = 3&quot;,       &quot;z = x+y&quot;     ]    }   },   &quot;outputs&quot;: [],   &quot;source&quot;: [    &quot;x = 1\n&quot;,    &quot;y = 2\n&quot;,    &quot;z = 0\n&quot;,    &quot;# this cell has a post_cell_execute that assigns y and z&quot;   ]  },```## Advice on Usagenbmake is best used in a scenario where you use the ipynb files only for development. Consumption of notebooks is primarily done via a docs site, built through jupyter book, nbsphinx, or some other means. If using one of these tools, you are able to write assertion code in cells which will be [hidden from readers](https://jupyterbook.org/interactive/hiding.html).### Pre-commitTreating notebooks like source files lets you keep your repo minimal. Some tools, such as plotly may drop several megabytes of javascript in your output cells, as a result, stripping out notebooks on pre-commit is advisable:```# .pre-commit-config.yamlrepos:  - repo: https://github.com/kynan/nbstripout    rev: master    hooks:      - id: nbstripout```See https://pre-commit.com/ for more...## Disable anonymous metricsWe collect anonymous usage metrics to improve nbmake.You can disable them by setting the environment variable NBMAKE_METRICS=0## Disable NbmakeImplicitly:```pytest```Explicitly:```pytest -p no:nbmake```## See Also:* A more in-depth [intro to nbmake](https://semaphoreci.com/blog/test-jupyter-notebooks-with-pytest-and-nbmake) running on Semaphore CI* [nbmake action](https://github.com/treebeardtech/treebeard)* [pytest](https://pytest.org/)* [jupyter book](https://github.com/executablebooks/jupyter-book)* [jupyter cache](https://github.com/executablebooks/jupyter-cache)* [MyST-NB](https://github.com/executablebooks/MyST-NB)---## ℹ️ Get help with machine learning infrastructureBeyond testing notebooks, the maintainers of nbmake help software and finance companies scale their machine learning products.[Find out more](https://www.treebeard.io/).---</longdescription>
</pkgmetadata>