<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Google Ads API Report Fetcher (gaarf)Python version of Google Ads API Report Fetcher tool a.k.a. `gaarf`.Please see the full documentation in the root [README](https://github.com/google/ads-api-report-fetcher/blob/main/README.md).## Getting started### Prerequisites* Python 3.9+* pip installed* Google Ads API enabled* `google-ads.yaml` file. Learn how to create one [here](../docs/how-to-authenticate-ads-api.md).### Installation and running1. create virtual environment and install the tool```python3 -m venv gaarfsource gaarf/bin/activatepip install google-ads-api-report-fetcher```&gt; install the latest development version with `pip install -e git+https://github.com/google/ads-api-report-fetcher.git#egg=google-ads-api-report-fetcher\&amp;subdirectory=py`#### Versions of the library*  `google-ads-api-report-fetcher[sqlalchemy]` - version with SQLalchemy support* `google-ads-api-report-fetcher[simulator]` - version with support for [simulating    query results](../docs/simulating-data-with-gaarf.md) instead of calling Google Ads API.* `google-ads-api-report-fetcher[full]` - full version2.  Run the tool with `gaarf` command:```shellgaarf &lt;queries&gt; [options]```Documentation on available options see in the root [README.md](../README.md).## Using as a libraryOnce `google-ads-api-report-fetcher` is installed you can use it as a library.### Initialize `GoogleAdsApiClient` to connect to Google Ads API`GoogleAdsApiClient` is responsible for connecting to Google Ads API and provides several method for authentication.```pythonfrom gaarf.api_clients import GoogleAdsApiClient# initialize from local fileclient = GoogleAdsApiClient(path_to_config=&quot;google-ads.yaml&quot;, version=&quot;v12&quot;)# initialize from remote fileclient = GoogleAdsApiClient(path_to_config=&quot;gs://&lt;PROJECT-ID&gt;/google-ads.yaml&quot;, version=&quot;v12&quot;)# initialize from dictionarygoogle_ads_config_dict = {    &quot;developer_token&quot;: &quot;&quot;,    &quot;client_id&quot;: &quot;&quot;,    &quot;client_secret&quot;: &quot;&quot;,    &quot;refresh_token&quot;: &quot;&quot;,    &quot;client_customer_id&quot;: &quot;&quot;,    &quot;use_proto_plus&quot;: True}client = GoogleAdsApiClient(config_dict=google_ads_config_dict, version=&quot;v12&quot;)```### initialize `AdsReportFetcher` to get reports```pythonfrom gaarf.query_executor import AdsReportFetcher, AdsQueryExecutorreport_fetcher = AdsReportFetcher(client)# create query textquery_text = &quot;SELECT campaign.id AS campaign_id FROM campaign&quot;# Execute query and store `campaigns` variable# specify customer_ids explicitlycustomer_ids = ['1', '2']# or perform mcc expansion for mcc 1234567890customer_ids = report_fetcher.expand_mcc('1234567890')campaigns = report_fetcher.fetch(query_text, customer_ids)# perform mcc expansion when calling `fetch` methodcampaigns = report_fetcher.fetch(query_text, '1234567890', auto_expand=True)```#### Use macros in your queries```pythonparametrized_query_text = &quot;&quot;&quot;    SELECT        campaign.id AS campaign_id    FROM campaign    WHERE campaign.status = '{status}'    &quot;&quot;&quot;active_campaigns = report_fetcher.fetch(parametrized_query_text, customer_ids,                                        {&quot;status&quot;: &quot;ENABLED&quot;})```#### Define queriesThere are three ways how you can define a query:* in a variable* in a file* in a class (useful when you have complex parametrization and validation)```pythonfrom gaarf.base_query import BaseQueryfrom gaarf.io import reader# 1. define query as a string an save in a variablequery_string = &quot;SELECT campaign.id FROM campaign&quot;# 2. define path to a query file and read from it# path can be localquery_path = &quot;path/to/query.sql&quot;# or remotequery_path = &quot;gs://PROJECT_ID/path/to/query.sql&quot;# Instantiate readerreader_client = reader.FileReader()# And read from the pathquery = reader_client.read(query_path)# 3. define query as a classclass Campaigns(BaseQuery):    def __init__(self, status: str = &quot;ENABLED&quot;):        self.query_text = f&quot;&quot;&quot;        SELECT            campaign.id        FROM campaign        WHERE campaign.status = {status}        &quot;&quot;&quot;active_campaigns = report_fetcher.fetch(Campaigns())inactive_campaigns = report_fetcher.fetch(Campaigns(&quot;INACTIVE&quot;))```#### Iteration and slicing`AdsReportFetcher.fetch` method returns an instance of `GaarfReport` object which you can use to perform simple iteration.```pythonquery_text = &quot;&quot;&quot;    SELECT        campaign.id AS campaign_id,        campaign.name AS campaign_name,        metrics.clicks AS clicks    FROM campaign    WHERE segments.date DURING LAST_7_DAYS    &quot;&quot;&quot;campaigns = report_fetcher.fetch(query_text, '1234567890', auto_expand=True)# iterate over each row of `campaigns` reportfor row in campaigns:    # Get element as an attribute    print(row.campaign_id)    # Get element as a slice    print(row[&quot;campaign_name&quot;])    # Get element as an index (will print number of clicks)    print(row[2])    # Create new column    row[&quot;new_campaign_id&quot;] = row[&quot;campaign_id&quot;] + 1```You can easily slice the report```python# Create new reports by selecting one or more columnscampaign_only_report = campaigns[&quot;campaign_name&quot;]campaign_name_clicks_report = campaigns[[&quot;campaign_name&quot;, &quot;clicks&quot;]]# Get subset of the report# Get first row onlyfirst_campaign_row = campaigns[0]# Get first ten rows from the reportfirst_10_rows_from_campaigns = campaigns[0:10]```#### Convert report`GaarfReport` can be easily converted to common data structures:```python# convert `campaigns` to listcampaigns_list = campaigns.to_list()# convert `campaigns` to pandas DataFramecampaigns_df = campaigns.to_pandas()```#### Save report`GaarfReport` can be easily saved to local or remote storage:```pythonfrom gaarf.io import writer# initialize CSV writercsv_writer = writer.CsvWriter(destination_folder=&quot;/tmp&quot;)# initialize BigQuery writerbq_writer = writer.BigQueryWriter(project=&quot;&quot;, dataset=&quot;&quot;, location=&quot;&quot;)# initialize SQLAlchemy writersqlalchemy_writer = writer.SqlAlchemyWriter(connection_string=&quot;&quot;)# initialize Console writerconsole_writer = writer.Console(page_size=10)# save report using one of the writerscsv_writer.write(campaigns, destination=&quot;my_file_name&quot;)bq_writer.write(campaigns, destination=&quot;my_table_name&quot;)sqlalchemy_writer.write(campaigns, destination=&quot;my_table_name&quot;)```### Combine fetching and saving with `AdsQueryExecutor`If your job is to execute query and write it to local/remote storage you can use `AdsQueryExecutor` to do it easily.&gt; When reading query from file `AdsQueryExecutor` will use query file name as a name for output file/table.```pythonfrom gaarf.io import reader, writerfrom gaarf.query_executor import AdsQueryExecutor# initialize query_executor to fetch report and store them in local/remote storagequery_executor = AdsQueryExecutor(client)# initialize writercsv_writer = writer.CsvWriter(destination_folder=&quot;/tmp&quot;)reader_client = reader.FileReader()query_text = &quot;&quot;&quot;    SELECT        campaign.id AS campaign_id,        campaign.name AS campaign_name,        metrics.clicks AS clicks    FROM campaign    WHERE segments.date DURING LAST_7_DAYS    &quot;&quot;&quot;# execute query and save results to `/tmp/campaign.csv`query_executor.execute(    query_text=query_text,    query_name=&quot;campaign&quot;,    customer_ids=customer_ids,    write_client=csv_writer)# execute query from file and save to results to `/tmp/query.csv`query_path=&quot;path/to/query.sql&quot;query_executor.execute(    query_text=reader_client.read(query_path),    query_name=query_path,    customer_ids=customer_ids,    write_client=csv_writer)```## Python specific command line flags* `--optimize-performance` - accepts one of the following values:    * `NONE` - no optimizations are done    * `PROTOBUF` - convert Google Ads API response to protobuf before parsing        (speeds up query execution 5x times but forces conversion of ENUMs to integers instead of strings)    * `BATCH` -  converts all response of Ads API to a list and then parses its content in parallel    * `BATCH_PROTOBUF` - combines `BATCH` and `PROTOBUF` approaches.## DisclaimerThis is not an officially supported Google product.</longdescription>
</pkgmetadata>