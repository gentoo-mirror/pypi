<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Replicate Python clientThis is a Python client for [Replicate](https://replicate.com). It lets you run models from your Python code or Jupyter notebook, and do various other things on Replicate.## Install```shpip install replicate```## AuthenticateBefore running any Python scripts that use the API, you need to set your Replicate API token in your environment.Grab your token from [replicate.com/account](https://replicate.com/account) and set it as an environment variable:```export REPLICATE_API_TOKEN=&lt;your token&gt;```We recommend not adding the token directly to your source code, because you don't want to put your credentials in source control. If anyone used your API key, their usage would be charged to your account.## Run a modelCreate a new Python file and add the following code:```python&gt;&gt;&gt; import replicate&gt;&gt;&gt; replicate.run(        &quot;stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478&quot;,        input={&quot;prompt&quot;: &quot;a 19th century portrait of a wombat gentleman&quot;}    )['https://replicate.com/api/models/stability-ai/stable-diffusion/files/50fcac81-865d-499e-81ac-49de0cb79264/out-0.png']```Some models, like [methexis-inc/img2prompt](https://replicate.com/methexis-inc/img2prompt), receive images as inputs. To pass a file as an input, use a file handle or URL:```python&gt;&gt;&gt; output = replicate.run(        &quot;salesforce/blip:2e1dddc8621f72155f24cf2e0adbde548458d3cab9f00c0139eea840d0ac4746&quot;,        input={&quot;image&quot;: open(&quot;path/to/mystery.jpg&quot;, &quot;rb&quot;)},    )&quot;an astronaut riding a horse&quot;```## Run a model in the backgroundYou can start a model and run it in the background:```python&gt;&gt;&gt; model = replicate.models.get(&quot;kvfrans/clipdraw&quot;)&gt;&gt;&gt; version = model.versions.get(&quot;5797a99edc939ea0e9242d5e8c9cb3bc7d125b1eac21bda852e5cb79ede2cd9b&quot;)&gt;&gt;&gt; prediction = replicate.predictions.create(    version=version,    input={&quot;prompt&quot;:&quot;Watercolor painting of an underwater submarine&quot;})&gt;&gt;&gt; predictionPrediction(...)&gt;&gt;&gt; prediction.status'starting'&gt;&gt;&gt; dict(prediction){&quot;id&quot;: &quot;...&quot;, &quot;status&quot;: &quot;starting&quot;, ...}&gt;&gt;&gt; prediction.reload()&gt;&gt;&gt; prediction.status'processing'&gt;&gt;&gt; print(prediction.logs)iteration: 0, render:loss: -0.6171875iteration: 10, render:loss: -0.92236328125iteration: 20, render:loss: -1.197265625iteration: 30, render:loss: -1.3994140625&gt;&gt;&gt; prediction.wait()&gt;&gt;&gt; prediction.status'succeeded'&gt;&gt;&gt; prediction.output'https://.../output.png'```## Run a model in the background and get a webhookYou can run a model and get a webhook when it completes, instead of waiting for it to finish:```pythonmodel = replicate.models.get(&quot;kvfrans/clipdraw&quot;)version = model.versions.get(&quot;5797a99edc939ea0e9242d5e8c9cb3bc7d125b1eac21bda852e5cb79ede2cd9b&quot;)prediction = replicate.predictions.create(    version=version,    input={&quot;prompt&quot;:&quot;Watercolor painting of an underwater submarine&quot;},    webhook=&quot;https://example.com/your-webhook&quot;,    webhook_events_filter=[&quot;completed&quot;])```## Compose models into a pipelineYou can run a model and feed the output into another model:```pythonlaionide = replicate.models.get(&quot;afiaka87/laionide-v4&quot;).versions.get(&quot;b21cbe271e65c1718f2999b038c18b45e21e4fba961181fbfae9342fc53b9e05&quot;)swinir = replicate.models.get(&quot;jingyunliang/swinir&quot;).versions.get(&quot;660d922d33153019e8c263a3bba265de882e7f4f70396546b6c9c8f9d47a021a&quot;)image = laionide.predict(prompt=&quot;avocado armchair&quot;)upscaled_image = swinir.predict(image=image)```## Get output from a running modelRun a model and get its output while it's running:```pythoniterator = replicate.run(    &quot;pixray/text2image:5c347a4bfa1d4523a58ae614c2194e15f2ae682b57e3797a5bb468920aa70ebf&quot;,    input={&quot;prompts&quot;: &quot;san francisco sunset&quot;})for image in iterator:    display(image)```## Cancel a predictionYou can cancel a running prediction:```python&gt;&gt;&gt; model = replicate.models.get(&quot;kvfrans/clipdraw&quot;)&gt;&gt;&gt; version = model.versions.get(&quot;5797a99edc939ea0e9242d5e8c9cb3bc7d125b1eac21bda852e5cb79ede2cd9b&quot;)&gt;&gt;&gt; prediction = replicate.predictions.create(        version=version,        input={&quot;prompt&quot;:&quot;Watercolor painting of an underwater submarine&quot;}    )&gt;&gt;&gt; prediction.status'starting'&gt;&gt;&gt; prediction.cancel()&gt;&gt;&gt; prediction.reload()&gt;&gt;&gt; prediction.status'canceled'```## List predictionsYou can list all the predictions you've run:```pythonreplicate.predictions.list()# [&lt;Prediction: 8b0ba5ab4d85&gt;, &lt;Prediction: 494900564e8c&gt;]```## Load output filesOutput files are returned as HTTPS URLs. You can load an output file as a buffer:```pythonimport replicatefrom urllib.request import urlretrievemodel = replicate.models.get(&quot;stability-ai/stable-diffusion&quot;)version = model.versions.get(&quot;27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478&quot;)out = version.predict(prompt=&quot;wavy colorful abstract patterns, cgsociety&quot;urlretrieve(out[0], &quot;/tmp/out.png&quot;)background = Image.open(&quot;/tmp/out.png&quot;)```## DevelopmentSee [CONTRIBUTING.md](CONTRIBUTING.md)</longdescription>
</pkgmetadata>