<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![PyPI version](https://badge.fury.io/py/pytorch-widedeep.svg)](https://pypi.org/project/pytorch-widedeep/)[![Python 3.7 3.8 3.9 3.10](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-blue.svg)](https://pypi.org/project/pytorch-widedeep/)[![Build Status](https://github.com/jrzaurin/pytorch-widedeep/actions/workflows/build.yml/badge.svg)](https://github.com/jrzaurin/pytorch-widedeep/actions)[![Documentation Status](https://readthedocs.org/projects/pytorch-widedeep/badge/?version=latest)](https://pytorch-widedeep.readthedocs.io/en/latest/?badge=latest)[![codecov](https://codecov.io/gh/jrzaurin/pytorch-widedeep/branch/master/graph/badge.svg)](https://codecov.io/gh/jrzaurin/pytorch-widedeep)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/jrzaurin/pytorch-widedeep/graphs/commit-activity)[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/jrzaurin/pytorch-widedeep/issues)[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/pytorch-widedeep/shared_invite/zt-soss7stf-iXpVuLeKZz8lGTnxxtHtTw)# pytorch-widedeepA flexible package for multimodal-deep-learning to combine tabular data withtext and images using Wide and Deep models in Pytorch**Documentation:** [https://pytorch-widedeep.readthedocs.io](https://pytorch-widedeep.readthedocs.io/en/latest/index.html)**Companion posts and tutorials:** [infinitoml](https://jrzaurin.github.io/infinitoml/)**Experiments and comparisson with `LightGBM`**: [TabularDL vs LightGBM](https://github.com/jrzaurin/tabulardl-benchmark)**Slack**: if you want to contribute or just want to chat with us, join [slack](https://join.slack.com/t/pytorch-widedeep/shared_invite/zt-soss7stf-iXpVuLeKZz8lGTnxxtHtTw)### Introduction``pytorch-widedeep`` is based on Google's [Wide and Deep Algorithm](https://arxiv.org/abs/1606.07792),adjusted for multi-modal datasetsIn general terms, `pytorch-widedeep` is a package to use deep learning withtabular data. In particular, is intended to facilitate the combination of textand images with corresponding tabular data using wide and deep models. Withthat in mind there are a number of architectures that can be implemented withjust a few lines of code. For details on the main components of thosearchitectures please visit the[repo](https://github.com/jrzaurin/pytorch-widedeep).###  InstallationInstall using pip:```bashpip install pytorch-widedeep```Or install directly from github```bashpip install git+https://github.com/jrzaurin/pytorch-widedeep.git```#### Developer Install```bash# Clone the repositorygit clone https://github.com/jrzaurin/pytorch-widedeepcd pytorch-widedeep# Install in dev modepip install -e .```### Quick startBinary classification with the [adultdataset]([adult](https://www.kaggle.com/wenruliu/adult-income-dataset))using `Wide` and `DeepDense` and defaults settings.Building a wide (linear) and deep model with ``pytorch-widedeep``:```pythonimport pandas as pdimport numpy as npimport torchfrom sklearn.model_selection import train_test_splitfrom pytorch_widedeep import Trainerfrom pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessorfrom pytorch_widedeep.models import Wide, TabMlp, WideDeepfrom pytorch_widedeep.metrics import Accuracyfrom pytorch_widedeep.datasets import load_adultdf = load_adult(as_frame=True)df[&quot;income_label&quot;] = (df[&quot;income&quot;].apply(lambda x: &quot;&gt;50K&quot; in x)).astype(int)df.drop(&quot;income&quot;, axis=1, inplace=True)df_train, df_test = train_test_split(df, test_size=0.2, stratify=df.income_label)# Define the 'column set up'wide_cols = [    &quot;education&quot;,    &quot;relationship&quot;,    &quot;workclass&quot;,    &quot;occupation&quot;,    &quot;native-country&quot;,    &quot;gender&quot;,]crossed_cols = [(&quot;education&quot;, &quot;occupation&quot;), (&quot;native-country&quot;, &quot;occupation&quot;)]cat_embed_cols = [    &quot;workclass&quot;,    &quot;education&quot;,    &quot;marital-status&quot;,    &quot;occupation&quot;,    &quot;relationship&quot;,    &quot;race&quot;,    &quot;gender&quot;,    &quot;capital-gain&quot;,    &quot;capital-loss&quot;,    &quot;native-country&quot;,]continuous_cols = [&quot;age&quot;, &quot;hours-per-week&quot;]target = &quot;income_label&quot;target = df_train[target].values# prepare the datawide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)X_wide = wide_preprocessor.fit_transform(df_train)tab_preprocessor = TabPreprocessor(    cat_embed_cols=cat_embed_cols, continuous_cols=continuous_cols  # type: ignore[arg-type])X_tab = tab_preprocessor.fit_transform(df_train)# build the modelwide = Wide(input_dim=np.unique(X_wide).shape[0], pred_dim=1)tab_mlp = TabMlp(    column_idx=tab_preprocessor.column_idx,    cat_embed_input=tab_preprocessor.cat_embed_input,    continuous_cols=continuous_cols,)model = WideDeep(wide=wide, deeptabular=tab_mlp)# train and validatetrainer = Trainer(model, objective=&quot;binary&quot;, metrics=[Accuracy])trainer.fit(    X_wide=X_wide,    X_tab=X_tab,    target=target,    n_epochs=5,    batch_size=256,)# predict on testX_wide_te = wide_preprocessor.transform(df_test)X_tab_te = tab_preprocessor.transform(df_test)preds = trainer.predict(X_wide=X_wide_te, X_tab=X_tab_te)# Save and load# Option 1: this will also save training history and lr history if the# LRHistory callback is usedtrainer.save(path=&quot;model_weights&quot;, save_state_dict=True)# Option 2: save as any other torch modeltorch.save(model.state_dict(), &quot;model_weights/wd_model.pt&quot;)# From here in advance, Option 1 or 2 are the same. I assume the user has# prepared the data and defined the new model components:# 1. Build the modelmodel_new = WideDeep(wide=wide, deeptabular=tab_mlp)model_new.load_state_dict(torch.load(&quot;model_weights/wd_model.pt&quot;))# 2. Instantiate the trainertrainer_new = Trainer(model_new, objective=&quot;binary&quot;)# 3. Either start the fit or directly predictpreds = trainer_new.predict(X_wide=X_wide, X_tab=X_tab)```Of course, one can do **much more**. See the Examples folder, thedocumentation or the companion posts for a better understanding of the contentof the package and its functionalities.### Testing```pytest tests```### AcknowledgmentsThis library takes from a series of other libraries, so I think it is justfair to mention them here in the README (specific mentions are also includedin the code).The `Callbacks` and `Initializers` structure and code is inspired by the[`torchsample`](https://github.com/ncullen93/torchsample) library, which initself partially inspired by [`Keras`](https://keras.io/).The `TextProcessor` class in this library uses the[`fastai`](https://docs.fast.ai/text.transform.html#BaseTokenizer.tokenizer)'s`Tokenizer` and `Vocab`. The code at `utils.fastai_transforms` is a minoradaptation of their code so it functions within this library. To my experiencetheir `Tokenizer` is the best in class.The `ImageProcessor` class in this library uses code from the fantastic [DeepLearning for ComputerVision](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/)(DL4CV) book by Adrian Rosebrock.</longdescription>
</pkgmetadata>