<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Implementation of https://arxiv.org/abs/1904.00962 for large batch, large learning rate training.The paper doesn't specify clamp values for Ï•, so I use 10.Bonus: TensorboardX logging (example below).## Try the sample```git clone git@github.com:cybertronai/pytorch-lamb.gitcd pytorch-lambpip install -e .python test_lamb.pytensorboard --logdir=runs```## Sample resultsAt `--lr=.02`, the Adam optimizer is unable to train.Red: `python test_lamb.py --batch-size=512 --lr=.02 --wd=.01 --log-interval=30 --optimizer=adam`Blue: `python test_lamb.py --batch-size=512 --lr=.02 --wd=.01 --log-interval=30 --optimizer=lamb`![](images/loss.png)![](images/histogram.png)</longdescription>
</pkgmetadata>