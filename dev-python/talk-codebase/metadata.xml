<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>## talk-codebase [![Node.js Package](https://github.com/rsaryev/talk-codebase/actions/workflows/python-publish.yml/badge.svg)](https://github.com/rsaryev/talk-codebase/actions/workflows/python-publish.yml)* Simple configuration in just a couple of clicks* Talk-codebase is a tool that allows you to converse with your codebase using LLMs (Large Language Models) to answer your queries.* It supports offline code processing using LlamaCpp and [GPT4All](https://github.com/nomic-ai/gpt4all) without sharing your code with third parties, or you can use OpenAI if privacy is not a concern for you.* Talk-codebase is still under development, but it is a tool that can help you to improve your code. It is only recommended for educational purposes and not for production use.&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://github.com/rsaryev/talk-codebase/assets/70219513/b5d338f9-14a5-417b-9690-83f5cd66facf&quot; width=&quot;800&quot; alt=&quot;chat&quot;&gt;&lt;/p&gt;## InstallationTo install talk-codebase, you need to have:* Python 3.9* An OpenAI API [api-keys](https://platform.openai.com/account/api-keys)```bash# Install talk-codebasepip install talk-codebase# If you want some files to be ignored, add them to .gitignore.# Once `talk-codebase` is installed, you can use it to chat with your codebase in the current directory by running the following command:talk-codebase chat .```## Reset configuration```bash# If you want to reset the configuration, you can run the following command:talk-codebase configure```## Advanced configurationYou can also edit the configuration manually by editing the `~/.config.yaml` file.If for some reason you cannot find the configuration file, just run the tool and at the very beginning it will outputthe path to the configuration file.```yaml# The OpenAI API key. You can get it from https://beta.openai.com/account/api-keysapi_key: sk-xxx# Configuration for chunkingchunk_overlap: 50chunk_size: 500# Configuration for samplingk: 4max_tokens: 1048# Configuration for the LLM modelopenai_model_name: gpt-3.5-turbo# Type of model to use. You can choose between `openai` and `local`.model_type: openailocal_model_name: orca-mini-7b.ggmlv3.q4_0.bin# Path to local model. If you want to use a local model, you need to specify the path to it.model_path: 'absolute path to local model'```## Supports the following extensions:- [x] `.csv`- [x] `.doc`- [x] `.docx`- [x] `.epub`- [x] `.md`- [x] `.pdf`- [x] `.txt`- [x] `popular programming languages`## Contributing* If you find a bug in talk-codebase, please report it on the project's issue tracker. When reporting a bug, please include as much information as possible, such as the steps to reproduce the bug, the expected behavior, and the actual behavior.* If you have an idea for a new feature for Talk-codebase, please open an issue on the project's issue tracker. When suggesting a feature, please include a brief description of the feature, as well as any rationale for why the feature would be useful.* You can contribute to talk-codebase by writing code. The project is always looking for help with improving the codebase, adding new features, and fixing bugs.</longdescription>
</pkgmetadata>