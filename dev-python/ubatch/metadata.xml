<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># uBatch**uBatch** is a simple, yet elegant library for processing streams data in micro batches.**uBatch** allow to process multiple inputs data from different threadsas a single block of data, this is useful when process data in a batcheshas a lower cost than processing it independently, for example process datain GPU or take advantage from optimization of libraries written in C. Ideally,the code that processes the batches should release the Python GIL for allowingothers threads/coroutines to run, this is true in many C libraries wrapped inPython.[![Documentation Status](https://readthedocs.org/projects/ubatch/badge/?version=latest)](https://ubatch.readthedocs.io/en/latest/?badge=latest)Example```python&gt;&gt;&gt; import threading&gt;&gt;&gt;&gt;&gt;&gt; from typing import List&gt;&gt;&gt; from ubatch import ubatch_decorator&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; @ubatch_decorator(max_size=5, timeout=0.01)... def squared(a: List[int]) -&gt; List[int]:...     print(a)...     return [x ** 2 for x in a]...&gt;&gt;&gt;&gt;&gt;&gt; inputs = list(range(10))&gt;&gt;&gt;&gt;&gt;&gt; # Run squared as usual... _ = squared(inputs)[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; def thread_function(number: int) -&gt; None:...     _ = squared.ubatch(number)...&gt;&gt;&gt;&gt;&gt;&gt; # Multiple threads squared individual inputs... threads = []&gt;&gt;&gt; for i in inputs:...     t = threading.Thread(target=thread_function, args=(i,))...     threads.append(t)...     t.start()...[0, 1, 2, 3, 4][5, 6, 7, 8, 9]&gt;&gt;&gt; for t in threads:...     t.join()```The example above shows 10 threads calculating the square of a number, using**uBatch** the threads delegate the calculation task to a singleprocess that calculates them in batch.And with multiple parameters in user method```python&gt;&gt;&gt; import threading&gt;&gt;&gt; &gt;&gt;&gt; from typing import List&gt;&gt;&gt; from ubatch import ubatch_decorator&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; @ubatch_decorator(max_size=5, timeout=0.01)... def squared_cube(a: List[int], mode: List[str]) -&gt; List[int]:...     print(a)...     print(mode)...     return [x ** 2 if y == 'square' else x ** 3 for x, y in zip(a, mode)]... &gt;&gt;&gt; &gt;&gt;&gt; inputs = list(range(10))&gt;&gt;&gt; modes = ['square' if i % 2 == 0 else 'cube' for i in inputs]&gt;&gt;&gt; &gt;&gt;&gt; # Run function as usual&gt;&gt;&gt; _ = squared_cube(inputs, modes)[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]['square', 'cube', 'square', 'cube', 'square', 'cube', 'square', 'cube', 'square', 'cube']&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; def thread_function(number: int, mode: str) -&gt; None:...     _ = squared_cube.ubatch(number, mode)... &gt;&gt;&gt; &gt;&gt;&gt; # Multiple threads squared individual inputs... threads = []&gt;&gt;&gt; for i,j in zip(inputs, modes):...     t = threading.Thread(target=thread_function, args=(i,j))...     threads.append(t)...     t.start()...     [0, 1, 2, 3, 4]['square', 'cube', 'square', 'cube', 'square'][5, 6, 7, 8, 9]['cube', 'square', 'cube', 'square', 'cube']&gt;&gt;&gt; for t in threads:...     t.join()```This example is pretty similar to the previous one, the only difference isthat the decorated function receives an additional parameter and **uBatch** is able to support a variable number of parameters. If you have a function with a parameter that doesn't need to be accumulated, with every call you can use the python &quot;partial&quot; tool before the use of ubatch_decorator.```python&gt;&gt;&gt; import threading&gt;&gt;&gt; &gt;&gt;&gt; from functools import partial&gt;&gt;&gt; from typing import List, Any&gt;&gt;&gt; from ubatch import ubatch_decorator&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; def squared_cube(model: Any, a: List[int], mode: List[str]) -&gt; List[int]:...     print(a)...     print(mode)...     return [x ** 2 if y == 'square' else x ** 3 for x, y in zip(a, mode)]... &gt;&gt;&gt; squared_cube = partial(squared_cube, 'This is a model')&gt;&gt;&gt; squared_cube = ubatch_decorator(max_size=5, timeout=0.01)(squared_cube)... ...```The code after that can remains like in the previous example.## Installing uBatch and Supported Versions```bashpip install ubatch```uBatch officially supports Python 3.6+.## Why using uBatchWhen data is processed offline it is easy to collect data to be processed atsame time, the same does not happen when requests are attended online asexample using Flask, this is where the uBatch potential comes in.**TensorFlow** or **Scikit-learn** are just some of the librariesthat can take advantage of this functionality.## uBatch and application serverPython application servers work like this:When the server is initialized multiple processes are created and each processcreate a bunch of threads for handling requests. Taking advantage of thosethreads that run in parallel **uBatch** can be used to group severalinputs and process them in a single block.Let's see a Flask example:```pythonimport numpy as npfrom typing import List, Dictfrom flask import Flask, request as flask_requestfrom flask_restx import Resource, Apifrom ubatch import UBatchfrom model import load_modelapp = Flask(__name__)api = Api(app)model = load_model()predict_batch: UBatch[np.array, np.array] = UBatch(max_size=50, timeout=0.01)predict_batch.set_handler(handler=model.batch_predict)predict_batch.start()@api.route(&quot;/predict&quot;)class Predict(Resource):    def post(self) -&gt; Dict[str, List[float]]:        received_input = np.array(flask_request.json[&quot;input&quot;])        result = predict_batch.ubatch(received_input)        return {&quot;prediction&quot;: result.tolist()}```Start application server:```bashgunicorn -k gevent app:app```Another example using **uBatch** to join multiple requests into one:```pythonimport requestsfrom typing import List, Dictfrom flask import Flask, request as flask_requestfrom flask_restx import Resource, Apifrom ubatch import ubatch_decoratorapp = Flask(__name__)api = Api(app)FAKE_TITLE_MPI_URL = &quot;http://my_mpi_url/predict&quot;@ubatch_decorator(max_size=100, timeout=0.03)def batch_fake_title_post(titles: List[str]) -&gt; List[bool]:    &quot;&quot;&quot;Post a list of titles to MPI and return responses in a list&quot;&quot;&quot;    # json_post example: {&quot;predict&quot;: [&quot;title1&quot;, &quot;title2&quot;, &quot;title3&quot;]}    json_post = {&quot;predict&quot;: titles}    # response example: {&quot;predictions&quot;: [False, True. False]}    response = requests.post(FAKE_TITLE_MPI_URL, json=json_post).json()    # return: [False, True, False]    return [x for x in response[&quot;predictions&quot;]]@api.route(&quot;/predict&quot;)class Predict(Resource):    def post(self) -&gt; Dict[str, bool]:        # title example: &quot;Title1&quot;        title = flask_request.json[&quot;title&quot;]        # prediction example: False        prediction = fake_title_batch.ubatch(title)        return {&quot;prediction&quot;: prediction}```Start application server:```bashgunicorn -k gevent app:app```## Start developing uBatchInstall poetry```bashcurl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -```Clone repository```bashgit clone git@github.com:mercadolibre/ubatch.git```Start shell and install dependencies```bashcd ubatchpoetry shellpoetry install```Run tests```bashpytest```Building docs```bashcd ubatch/docspoetry shellmake html```## Licensing**uBatch** is licensed under the Apache License, Version 2.0.See [LICENSE](https://github.com/mercadolibre/ubatch/blob/master/docs/LICENSE) for the full license text.</longdescription>
</pkgmetadata>