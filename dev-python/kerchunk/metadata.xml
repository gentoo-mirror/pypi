<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># kerchunkCloud-friendly access to archival data[![Docs](https://github.com/fsspec/kerchunk/actions/workflows/default.yml/badge.svg)](https://fsspec.github.io/kerchunk/)[![Tests](https://github.com/fsspec/kerchunk/actions/workflows/tests.yml/badge.svg)](https://github.com/fsspec/kerchunk/actions/workflows/tests.yml)[![Pypi](https://img.shields.io/pypi/v/kerchunk.svg)](https://pypi.python.org/pypi/kerchunk/)[![Conda-forge](https://img.shields.io/conda/vn/conda-forge/kerchunk.svg)](https://anaconda.org/conda-forge/kerchunk)Kerchunk is a library that provides a unified way to represent a variety of chunked, compresseddata formats (e.g. NetCDF, HDF5, GRIB),allowing efficient access to the data from traditional file systems or cloud object storage.It also provides a flexible way to createvirtual datasets from multiple files.  It does this by extracting the byte ranges,compression information and other information about thedata and storing this metadata in a new, separate object.  This means that you cancreate a virtual aggregate dataset over potentially many sourcefiles, for efficient, parallel and cloud-friendly *in-situ* access without having to copy ortranslate the originals. It is a gateway to in-the-cloud massive data processing whilethe data providers still insist on using legacy formats for archival storage.*Why Kerchunk*:We provide the following things:- completely serverless architecture- metadata consolidation, so you can understand a many-file dataset (metadata plus physical storage) in a single read- read from all of the storage backends supported by fsspec, including object storage (s3, gcs, abfs, alibaba), http,  cloud user storage (dropbox, gdrive) and network protocols (ftp, ssh, hdfs, smb...)- loading of various file types (currently netcdf4/HDF, grib2, tiff, fits, zarr), potentially heterogeneous within a  single dataset, without a need to go via the specific driver (e.g., no need for h5py)- asynchronous concurrent fetch of many data chunks in one go, amortizing the cost of latency- parallel access with a library like zarr without any locks- logical datasets viewing many (&gt;~millions) data files, and direct access/subselection to them via coordinate  indexing across an arbitrary number of dimensions&lt;img alt=&quot;logo&quot; src=&quot;./kerchunk.png&quot; width=&quot;200&quot;/&gt;For further information, please see [the documentation](https://fsspec.github.io/kerchunk/).</longdescription>
</pkgmetadata>