<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![ldimbenchmark version](https://badgen.net/pypi/v/ldimbenchmark/)](https://pypi.org/project/ldimbenchmark)[![Documentation badge](https://img.shields.io/badge/Documentation-here!-GREEN.svg)](https://tumt2022.github.io/LDIMBench/)# LDIMBenchmarkLeakage Detection and Isolation Methods Benchmark&gt; Instead of collecting all the different dataset to benchmark different methods on. We wanted to create a Benchmarking Tool which makes it easy to reproduce the results of the different methods locally on your own dataset.It provides a close to real-world conditions environment and forces researchers to provide a reproducible method implementation, which is supposed to run automated on any input dataset, thus hindering custom solutions which work well in one specific case.## Usage### Installation```bashpip install ldimbenchmark```### Python```pythonfrom ldimbenchmark.datasets import DatasetLibrary, DATASETSfrom ldimbenchmark import (    LDIMBenchmark,    BenchmarkData,    BenchmarkLeakageResult,)from ldimbenchmark.classes import LDIMMethodBasefrom typing import Listclass YourCustomLDIMMethod(LDIMMethodBase):    def __init__(self):        super().__init__(            name=&quot;YourCustomLDIMMethod&quot;,            version=&quot;0.1.0&quot;        )    def train(self, data: BenchmarkData):        pass    def detect(self, data: BenchmarkData) -&gt; List[BenchmarkLeakageResult]:        return [            {                &quot;leak_start&quot;: &quot;2020-01-01&quot;,                &quot;leak_end&quot;: &quot;2020-01-02&quot;,                &quot;leak_area&quot;: 0.2,                &quot;pipe_id&quot;: &quot;test&quot;,            }        ]    def detect_datapoint(self, evaluation_data) -&gt; BenchmarkLeakageResult:        return {}datasets = DatasetLibrary(&quot;datasets&quot;).download(DATASETS.BATTLEDIM)local_methods = [YourCustomLDIMMethod()]hyperparameters = {}benchmark = LDIMBenchmark(    hyperparameters, datasets, results_dir=&quot;./benchmark-results&quot;)benchmark.add_local_methods(local_methods)benchmark.run_benchmark()benchmark.evaluate()```### CLI```bashldimbenchmark --help```## Roadmap- v1: Just Leakage Detection- v2: Provides Benchmark of Isolation Methodshttps://mathspp.com/blog/how-to-create-a-python-package-in-2022## Developmenthttps://python-poetry.org/docs/basic-usage/```bash# python 3.10# Use Environmentpoetry config virtualenvs.in-project truepoetry shellpoetry install --without ci # --with ci# Testpoetry buildcp -r dist tests/distcd testsdocker build . -t testmethodpytest -s -o log_cli=truepytest tests/test_derivation.py -k 'test_mything'pytest --testmonpytest --snapshot-update# Pytest watchptwptw -- --testmon# Watch a file during developmentnpm install -g nodemonnodemon -L experiments/auto_hyperparameter.py# Test-Publishpoetry config repositories.testpypi https://test.pypi.org/legacy/poetry config http-basic.testpypi __token__ pypi-your-api-token-herepoetry buildpoetry publish -r testpypi# Real Publishpoetry config pypi-token.pypi pypi-your-token-here```### Documentationhttps://squidfunk.github.io/mkdocs-material/https://click.palletsprojects.com/en/8.1.x/```mkdocs serve```# TODOLDIMBenchmark:Data Cleansing before working with them- per sensor type, e.g. waterflow (cut of at 0)- removing datapoints which are clearly a malfunction</longdescription>
</pkgmetadata>