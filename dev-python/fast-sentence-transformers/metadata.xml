<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Fast Sentence TransformersThis repository contains code to run faster `sentence-transformers` using tools like quantization and `ONNX`. Just run your model much faster, while a lot of memory. There is not much to it![![Python package](https://github.com/Pandora-Intelligence/fast-sentence-transformers/actions/workflows/python-package.yml/badge.svg?branch=main)](https://github.com/Pandora-Intelligence/fast-sentence-transformers/actions/workflows/python-package.yml)[![Current Release Version](https://img.shields.io/github/release/pandora-intelligence/fast-sentence-transformers.svg?style=flat-square&amp;logo=github)](https://github.com/pandora-intelligence/fast-sentence-transformers/releases)[![pypi Version](https://img.shields.io/pypi/v/fast-sentence-transformers.svg?style=flat-square&amp;logo=pypi&amp;logoColor=white)](https://pypi.org/project/fast-sentence-transformers/)[![PyPi downloads](https://static.pepy.tech/personalized-badge/fast-sentence-transformers?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=orange&amp;left_text=pip%20downloads)](https://pypi.org/project/fast-sentence-transformers/)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)# Install```bashpip install fast-sentence-transformers```Or for GPU support.```bashpip install fast-sentence-transformers[gpu]```# Quickstart```pythonfrom fast_sentence_transformers import FastSentenceTransformer as SentenceTransformer# use any sentence-transformerencoder = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;, device=&quot;cpu&quot;, quantize=True)encoder.encode(&quot;Hello hello, hey, hello hello&quot;)encoder.encode([&quot;Life is too short to eat bad food!&quot;] * 2)```# BenchmarkIndicative benchmark for CPU usage with smallest and largest model on `sentence-transformers`. Note, ONNX doesn't have GPU support for quantization yet.| model                                 | Type   | default | ONNX | ONNX+quantized | ONNX+GPU || ------------------------------------- | ------ | ------- | ---- | -------------- | -------- || paraphrase-albert-small-v2            | memory | 1x      | 1x   | 1x             | 1x       ||                                       | speed  | 1x      | 2x   | 5x             | 20x      || paraphrase-multilingual-mpnet-base-v2 | memory | 1x      | 1x   | 4x             | 4x       ||                                       | speed  | 1x      | 2x   | 5x             | 20x      |# Shout-OutThis package heavily leans on `sentence-transformers` and `txtai`.</longdescription>
</pkgmetadata>