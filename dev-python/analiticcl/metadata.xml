<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Analiticcl## IntroductionAnaliticcl is an approximate string matching or fuzzy-matching system that can be used for spellingcorrection or text normalisation (such as post-OCR correction or post-HTR correction). Texts can be checked against avalidated or corpus-derived lexicon (with or without frequency information) and spelling variants will be returned.Please see the [main README.md](../../README.md) for a further introduction, it also links to a Python tutorial.Analiticcl is written in Rust, this is the Python binding, allowing you to use analiticcl from Python as a module.## Installation### with pip```pip install analiticcl```### from sourceTo use this method, you need to have Rust installed and in your ``$PATH``. Install it through your package manager or through rustup:```curl https://sh.rustup.rs -sSf | sh -s -- -yexport PATH=&quot;$HOME/.cargo/bin:$PATH&quot;```Once Rust is installed, you can compile the analiticcl binding:```# Create a virtual env (you can use yours as well)python -m venv .envsource .env/bin/activate# Install `analiticcl` in the current virtual envpip install setuptools_rustpython setup.py install```## Usage```pythonfrom analiticcl import VariantModel, Weights, SearchParametersimport jsonmodel = VariantModel(&quot;examples/simple.alphabet.tsv&quot;, Weights(), debug=False)model.read_lexicon(&quot;examples/eng.aspell.lexicon&quot;)model.build()result = model.find_variants(&quot;udnerstand&quot;, SearchParameters(max_edit_distance=3))print(json.dumps(result, ensure_ascii=False, indent=4))print()results = model.find_all_matches(&quot;I do not udnerstand the probleem&quot;, SearchParameters(max_edit_distance=3,max_ngram=1))print(json.dumps(results, ensure_ascii=False, indent=4))```**Note:** all offsets reported by analiticcl are utf-8 byte-offsets, not character offsets! If you want proper unicode characteroffsets, pass the keyword argument `unicodeoffset=True` to `SearchParameters`. You will want to set this if you intend to doany kind of slicing in Python (which uses unicode points by default).Output:```json[    {        &quot;text&quot;: &quot;understand&quot;,        &quot;score&quot;: 0.8978494623655915,        &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;    },    {        &quot;text&quot;: &quot;understands&quot;,        &quot;score&quot;: 0.6725317693059629,        &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;    },    {        &quot;text&quot;: &quot;understood&quot;,        &quot;score&quot;: 0.6036866359447004,        &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;    },    {        &quot;text&quot;: &quot;understate&quot;,        &quot;score&quot;: 0.5967741935483871,        &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;    }]``````json[    {        &quot;input&quot;: &quot;I&quot;,        &quot;offset&quot;: {            &quot;begin&quot;: 0,            &quot;end&quot;: 1        },        &quot;variants&quot;: [            {                &quot;text&quot;: &quot;I&quot;,                &quot;score&quot;: 0.8387096774193549,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;i&quot;,                &quot;score&quot;: 0.8064516129032258,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            }        ]    },    {        &quot;input&quot;: &quot;do&quot;,        &quot;offset&quot;: {            &quot;begin&quot;: 2,            &quot;end&quot;: 4        },        &quot;variants&quot;: [            {                &quot;text&quot;: &quot;do&quot;,                &quot;score&quot;: 1.0,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;dog&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;doc&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;doz&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;dob&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;doe&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;dot&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;dos&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;ado&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;don&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;d&quot;,                &quot;score&quot;: 0.5967741935483871,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;o&quot;,                &quot;score&quot;: 0.5967741935483871,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;DOD&quot;,                &quot;score&quot;: 0.5913978494623655,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            }        ]    },    {        &quot;input&quot;: &quot;not&quot;,        &quot;offset&quot;: {            &quot;begin&quot;: 5,            &quot;end&quot;: 8        },        &quot;variants&quot;: [            {                &quot;text&quot;: &quot;not&quot;,                &quot;score&quot;: 1.0,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;knot&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;note&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;snot&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;no&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;nowt&quot;,                &quot;score&quot;: 0.5967741935483871,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;No&quot;,                &quot;score&quot;: 0.5913978494623655,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;OT&quot;,                &quot;score&quot;: 0.5913978494623655,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;pot&quot;,                &quot;score&quot;: 0.5698924731182795,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            }        ]    },    {        &quot;input&quot;: &quot;udnerstand&quot;,        &quot;offset&quot;: {            &quot;begin&quot;: 9,            &quot;end&quot;: 19        },        &quot;variants&quot;: [            {                &quot;text&quot;: &quot;understand&quot;,                &quot;score&quot;: 0.8978494623655915,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;understands&quot;,                &quot;score&quot;: 0.6725317693059629,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;understood&quot;,                &quot;score&quot;: 0.6036866359447004,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;understate&quot;,                &quot;score&quot;: 0.5967741935483871,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            }        ]    },    {        &quot;input&quot;: &quot;the&quot;,        &quot;offset&quot;: {            &quot;begin&quot;: 20,            &quot;end&quot;: 23        },        &quot;variants&quot;: [            {                &quot;text&quot;: &quot;the&quot;,                &quot;score&quot;: 1.0,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;thee&quot;,                &quot;score&quot;: 0.6908602150537635,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;thew&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;then&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;them&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;they&quot;,                &quot;score&quot;: 0.6370967741935484,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;he&quot;,                &quot;score&quot;: 0.6236559139784946,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;Thea&quot;,                &quot;score&quot;: 0.6048387096774194,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;Th&quot;,                &quot;score&quot;: 0.5913978494623655,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;He&quot;,                &quot;score&quot;: 0.5913978494623655,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;thy&quot;,                &quot;score&quot;: 0.5698924731182795,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;she&quot;,                &quot;score&quot;: 0.5698924731182795,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;tho&quot;,                &quot;score&quot;: 0.5698924731182795,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;Thu&quot;,                &quot;score&quot;: 0.5376344086021505,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;Che&quot;,                &quot;score&quot;: 0.5376344086021505,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;THC&quot;,                &quot;score&quot;: 0.5376344086021505,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;tee&quot;,                &quot;score&quot;: 0.5161290322580645,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;toe&quot;,                &quot;score&quot;: 0.5161290322580645,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;tie&quot;,                &quot;score&quot;: 0.5161290322580645,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;Te&quot;,                &quot;score&quot;: 0.510752688172043,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            }        ]    },    {        &quot;input&quot;: &quot;probleem&quot;,        &quot;offset&quot;: {            &quot;begin&quot;: 24,            &quot;end&quot;: 32        },        &quot;variants&quot;: [            {                &quot;text&quot;: &quot;problem&quot;,                &quot;score&quot;: 0.9231950844854071,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;problems&quot;,                &quot;score&quot;: 0.6908602150537635,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;probe&quot;,                &quot;score&quot;: 0.5913978494623656,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;proclaim&quot;,                &quot;score&quot;: 0.5766129032258065,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;probated&quot;,                &quot;score&quot;: 0.543010752688172,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;probates&quot;,                &quot;score&quot;: 0.543010752688172,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;prole&quot;,                &quot;score&quot;: 0.5322580645161291,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;prowlers&quot;,                &quot;score&quot;: 0.4959677419354839,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            },            {                &quot;text&quot;: &quot;parolees&quot;,                &quot;score&quot;: 0.44220430107526887,                &quot;lexicon&quot;: &quot;../../../examples/eng.aspell.lexicon&quot;            }        ]    }]```## DocumentationThe python binding exposes only a minimal interface, you can use Python's ``help()`` function to get information on theclasses provided. For more detailed information, please consult the [Analiticcl's rust API documentation](https://docs.rs/analiticcl/). The interfaces that are available in the binding are analogous to the rust versions.</longdescription>
</pkgmetadata>