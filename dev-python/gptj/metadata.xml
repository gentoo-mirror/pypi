<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># GPT-JA GPT-J API to use with python## Installing gpt-j```pip install gptj```## Parametersprompt: the prompt you wish to give to the modeltokens: the number of tokens to generate (values 204 or less are recommended)temperature: controls the randomness of the model. higher values will be more random (suggestest to keep under 1.0 or less, something like 0.3 works)top_p: top probability will use the most likely tokenstop_k: Top k probabilityrep: The likely hood of the model repeating the same tokens lower values are more repetative## Advanced Parameters user: the speaker the person who is giving gpt-j a prompt bot: an imaginary character of your choicecontext: the part of the prompt that explains what is happening in the dialogexamples: a dictionary of user intentions and how the bot should respond# Basic Usage## In the prompt enter something you want to generate```pythonfrom gpt_j.Basic_api import simple_completionprompt = &quot;def perfect_square(num):&quot;```## The maximum length of the output response```pythonmax_length = 100```## Temperature controls the creativity of the modelA low temperature means the model will take less changes when completing a promptA high temperature will make the model more creativeBoth temperature and top probability must be a float```pythontemperature = 0.09```## top probability is an alternative way to control the randomness of the modelIf you are using top probability set temperature oneIf you are using temperature set top probability to one```pythontop_probability = 1.0```## top k is an integer value that controls part of the model```pythontop_k = 40```## Repetition penalty will result in less repetative results```pythonrepetition = 0.216```## Initializing the SimpleCompletion classHere you set query equal to the desired valuesNote values higher than 512 tend to take more time to generate```pythonquery = simple_completion(prompt, length=max_length, temp=temperature, top_p=top_probability, top_k=top_k, rep=repetition)```## Finally run the function below```pythonprint(query)```# Advanced Usage ## Context is a string that is a description of the conversation```pythonfrom gpt_j.gptj_api import Completioncontext = &quot;This is a calculator bot that will answer basic math questions&quot;```## Examples should be a dictionary of {user query: the way the model should respond to the given query} list of examplesQueries are to the left while target responses should be to the rightHere we can see the user is asking the model math related questionsThe way the model should respond if given on the rightDO NOT USE PERIODS AT THE END OF USER EXAMPLE! ```pythonexamples = {    &quot;5 + 5&quot;: &quot;10&quot;,    &quot;6 - 2&quot;: &quot;4&quot;,    &quot;4 * 15&quot;: &quot;60&quot;,    &quot;10 / 5&quot;: &quot;2&quot;,    &quot;144 / 24&quot;: &quot;6&quot;,    &quot;7 + 1&quot;: &quot;8&quot;}```## Here you pass in the context and the examples```pythoncontext_setting = Completion(context, examples)```## Enter a prompt relevant to previous defined user queries```pythonprompt = &quot;48 / 6&quot;```## Pick a name relevant to what you are doingBelow you can change student to &quot;Task&quot; for example and get similar results```pythonUser = &quot;Student&quot;```## Name your imaginary friend anything you want```pythonBot = &quot;Calculator&quot;```## Max tokens is the maximum length of the output response```pythonmax_tokens = 50```## Temperature controls the randomness of the modelA low temperature means the model will take less changes when completing a promptA high temperature will make the model more creative and produce more random outputsA Note both temperature and top probability must be a float```pythontemperature = 0.09```## Top probability is an alternative way to control the randomness of the modelIf you are using it set temperature oneIf you are using temperature set top probability to one```pythontop_probability = 1.0```## top k is an integer value that controls part of the model```pythontop_k = 40```## Repetition penalty will result in less repetative results```pythonrepetition = 0.216```## Simply set all the give all the parametersUnfilled parameters will be default valuesI recommend all parameters are filled for better resultsOnce everything is done execute the code below```pythonresponse = context_setting.completion(prompt,              user=User,              bot=Bot,              max_tokens=max_tokens,              temperature=temperature,              top_p=top_probability,              top_k=top_k,              rep=reptition)```## Last but not least print the responsePlease be patient depending on the given parameters it will take longer sometimesFor quick responses just use the Basic API which is a simplified version```pythonprint(response)```Note: This a very small model of 6B parameters and won't always produce accurate results## DisclaimerI have removed the security from the API, please don't use for unethical use!I am not responsible for anything you do with the API# License and copyright ## Credit This is all possible thanks to https://github.com/vicgalle/gpt-j-apiFeel free to check out the original API## LicenseÂ© Michael D Aranalicensed under the [MIT License](LICENSE).</longdescription>
</pkgmetadata>