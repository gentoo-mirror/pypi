<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;    &lt;h1 align=&quot;center&quot;&gt;fastDeploy&lt;/h1&gt;    &lt;p align=&quot;center&quot;&gt;Deploy DL/ ML inference pipelines with minimal extra code.&lt;/p&gt;&lt;/p&gt;**Installation:** ```bashpip install --upgrade fastdeploy```**Usage:**```bash# Invoke fastdeploy fastdeploy --help# orpython -m fastdeploy --help# Start prediction &quot;loop&quot; for recipe &quot;echo_json&quot;fastdeploy --recipe ./echo_json --mode loop# Start rest apis for recipe &quot;echo_json&quot;fastdeploy --recipe ./echo_json --mode rest# Auto genereate dockerfile and build docker image. --base is docker basefastdeploy --recipe ./recipes/echo_json/ \ --mode build_rest --base python:3.6-slim# fastdeploy_echo_json built!# Run docker imagedocker run -it -p8080:8080 fastdeploy_echo_json```- [serving your model with fastDeploy](https://github.com/notAI-tech/fastDeploy/blob/master/recipe.md)- [cURL and Python inference examples](https://github.com/notAI-tech/fastDeploy/blob/master/inference.md)**fastDeploy monitor**- available on localhost:8080 (or --port)![](https://raw.githubusercontent.com/notAI-tech/fastDeploy/master/fastDeploy_monitor.png)</longdescription>
</pkgmetadata>