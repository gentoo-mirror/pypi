<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>fastxtend================&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;&lt;div&gt;### Train fastai models faster (and other useful tools)&lt;/div&gt;&lt;div&gt;![fastxtend accelerates fastai](nbs/images/imagenette_benchmark.png)&lt;/div&gt;Train fastai models faster with fastxtend’s [fusedoptimizers](optimizer.fused.html), [ProgressiveResizing](callback.progresize.html) callback, and integrated [FFCVDataLoader](ffcv.tutorial.html).## Feature overview**Train Models Faster**- Drop in [fused optimizers](optimizer.fused.html), which are 21 to 293  percent faster then fastai native optimizers.- Up to 75% optimizer memory savings with integrated  [bitsandbytes](https://github.com/TimDettmers/bitsandbytes) [8-bit  optimizers](optimizer.eightbit.html).- Increase GPU throughput and decrease training time with the  [Progressive Resizing](callback.progresize.html) callback.- Use the highly optimized [FFCV DataLoader](ffcv.tutorial.html), fully  integrated with fastai.- Integrated support for `torch.compile` via the  [Compile](callback.compiler.html) callbacks.**General Features**- Fused implementations of modern optimizers, such as  [Adan](optimizer.adan.html) and [Lion](optimizer.lion.html).- Flexible [metrics](metrics.html) which can log on train, valid, or  both. Backwards compatible with fastai metrics.- Easily use [multiple losses](multiloss.html) and log each individual  loss on train and valid.- [Multiple profilers](callback.profiler.html) for profiling training  and identifying bottlenecks.- A fast [Exponential Moving Average](callback.ema.html) callback for  smoother training.**Vision**- Apply  [`MixUp`](https://fastxtend.benjaminwarner.dev/callback.cutmixup.html#mixup),  [`CutMix`](https://fastxtend.benjaminwarner.dev/callback.cutmixup.html#cutmix),  or Augmentations at once with  [`CutMixUp`](https://fastxtend.benjaminwarner.dev/callback.cutmixup.html#cutmixup)  or  [`CutMixUpAugment`](https://fastxtend.benjaminwarner.dev/callback.cutmixup.html#cutmixupaugment).- Additional [image augmentations](vision.augment.batch.html).- Support for running fastai [batch transforms on  CPU](vision.data.html).- More [attention](vision.models.attention_modules.html) and  [pooling](vision.models.pooling.html) modules- A flexible implementation of fastai’s  [`XResNet`](https://fastxtend.benjaminwarner.dev/vision.models.xresnet.html#xresnet).**Audio**- [`TensorAudio`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensoraudio),  [`TensorSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensorspec),  [`TensorMelSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensormelspec)  objects which maintain metadata and support plotting themselves using  librosa.- A selection of performant [audio augmentations](audio.augment.html)  inspired by fastaudio and torch-audiomentations.- Uses TorchAudio to quickly convert  [`TensorAudio`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensoraudio)  waveforms into  [`TensorSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensorspec)  spectrograms or  [`TensorMelSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensormelspec)  mel spectrograms using the GPU.- Out of the box support for converting one  [`TensorAudio`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensoraudio)  to one or multiple  [`TensorSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensorspec)  or  [`TensorMelSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensormelspec)  objects from the Datablock api.- Audio [MixUp and CutMix](audio.mixup.html) Callbacks.- [`audio_learner`](https://fastxtend.benjaminwarner.dev/audio.04_learner.html#audio_learner)  which merges multiple  [`TensorSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensorspec)  or  [`TensorMelSpec`](https://fastxtend.benjaminwarner.dev/audio.01_core.html#tensormelspec)  objects before passing to the model.Check out the documentation for additional splitters, callbacks,schedulers, utilities, and more.&lt;div&gt;## Documentation&lt;https://fastxtend.benjaminwarner.dev&gt;&lt;/div&gt;## Installfastxtend is avalible on pypi:``` bashpip install fastxtend```To install with dependencies for vision, FFCV, audio, or all tasks runone of:``` bashpip install fastxtend[vision]pip install fastxtend[ffcv]pip install fastxtend[audio]pip install fastxtend[all]```Or to create an editable development install:``` bashgit clone https://github.com/warner-benjamin/fastxtend.gitcd fastxtendpip install -e &quot;.[dev]&quot;```To easily install prerequisites for all fastxtend features, use[Conda](https://docs.conda.io/en/latest) or[Miniconda](https://docs.conda.io/en/latest/miniconda.html):``` bashconda create -n fastxtend python=3.10 &quot;pytorch&gt;=2.0.0&quot; \torchvision torchaudio pytorch-cuda=11.8 cuda fastai nbdev \pkg-config libjpeg-turbo opencv tqdm terminaltables psutil \numpy numba librosa=0.9.2 timm kornia rich typer wandb \-c pytorch -c nvidia/label/cuda-11.8.0 -c fastai \-c huggingface -c conda-forgeconda activate fastxtend```replacing `pytorch-cuda=11.8` and `nvidia/label/cuda-11.8.0` with yourpreferred [supported version ofCuda](https://pytorch.org/get-started/locally). Then install fastxtendusing `pip`:``` bashpip install fastxtend[all]```## UsageLike fastai, fastxtend provides safe wildcard imports using python’s`__all__`.``` pythonfrom fastai.vision.all import *from fastxtend.vision.all import *from fastxtend.ffcv.all import *```In general, import fastxtend after all fastai imports, as fastxtendmodifies fastai. Any method modified by fastxtend is backwardscompatible with the original fastai code.## ExamplesUse a fused ForEach optimizer:``` pythonLearner(..., opt_func=adam(foreach=True))```Log an accuracy metric on the training set as a smoothed metric andvalidation set like normal:``` pythonLearner(..., metrics=[Accuracy(log_metric=LogMetric.Train, metric_type=MetricType.Smooth),                      Accuracy()])```Log multiple losses as individual metrics on train and valid:``` pythonmloss = MultiLoss(loss_funcs=[nn.MSELoss, nn.L1Loss],                  weights=[1, 3.5], loss_names=['mse_loss', 'l1_loss'])Learner(..., loss_func=mloss, metrics=RMSE(), cbs=MultiLossCallback)```Apply MixUp, CutMix, or Augmentation while training:``` pythonLearner(..., cbs=CutMixUpAugment)```Profile a fastai training loop:``` pythonfrom fastxtend.callback import simpleprofilerlearn = Learner(...).profile()learn.fit_one_cycle(2, 3e-3)```## BenchmarkTo run the benchmark on your own machine, see the [examplescripts](https://github.com/warner-benjamin/fastxtend/tree/main/examples)for details on how to replicate.</longdescription>
</pkgmetadata>