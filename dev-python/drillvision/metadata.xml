<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Drill Bit Classifier[![Python 3.9](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-360/)![GitHub CI](https://github.com/Atashnezhad/DrillBitVision/actions/workflows/main.yml/badge.svg)[![Downloads](https://static.pepy.tech/badge/drillvision)](https://pepy.tech/project/drillvision)The Drill Bit Classifier is an app that uses a Convolutional Neural Network (CNN) to classify images of drill bits. The app can be used by machinists and engineers to quickly and accurately identify the type of drill bit required for a particular job.## Description:### Preprocessing ModuleThe code is for image preprocessing for a neural network. It contains functions to download images from Bing, read data from a directory, and augment the images. The code also includes a class called Preprocessing. The class has methods to download images, find categories, get image data, and augment the images.The Preprocessing class has an initializer that takes an argument dataset_address and assigns it to an instance variable dataset_address. The download_images method downloads images from the internet using the bing_image_downloader library. The categories_name method reads the dataset directory and returns a list of categories. It also removes any files that are in the ignore list specified in the SETTING module. The image_dict method returns a dictionary with the number of images and a list of image file paths for each category. The augment_data method augments the images in each category using the ImageDataGenerator class from keras.preprocessing.image module. The augmented images are saved to the dataset_augmented directory.### Bit Vision ModuleBitVision is a versatile library initially designed for training, evaluating, and visualizing neural network models specifically tailored to subject with focus on drilling engineering classification tasks. However, it has since evolved to support general classification problems beyond drilling bits. With BitVision, you can effortlessly assemble and train models, make predictions, and generate visualizations for various classification applications, including but not limited to drilling bits.- **Model Assembly**: BitVision provides methods to assemble deep neural network models for bit vision tasks. You can add convolutional layers, batch normalization, max pooling, dropout, and dense layers based on predefined settings.- **Data Preparation**: The library handles data preprocessing tasks such as rescaling images using the ImageDataGenerator class from Keras. It also allows you to obtain details about the training, testing, and validation data, including the number of files in each category.- **Training and Evaluation**: BitVision simplifies the model training process with the fit_generator function. You can specify the number of epochs, validation data, class weights, and utilize ModelCheckpoint to save the best model based on a chosen metric. Additionally, the library provides methods to plot training and validation loss and accuracy over epochs.- **Prediction Visualization**: With BitVision, you can easily perform predictions on test images using the trained model. The library facilitates plotting images with their predicted labels and saving the figures for analysis and presentation.- **Grad-CAM Visualization**: BitVision offers functionality to visualize class activation heatmaps using Grad-CAM. You can overlay the heatmaps on the original images and save the resulting visualizations.### Transfer Learning ModuleThe code imports necessary libraries and modules, including TensorFlow, NumPy, pandas, seaborn, and matplotlib.The code defines a class called TransferModel that inherits from two other classes: Preprocessing and BitVision. These classes seem to provide additional functionality for data preprocessing and working with images.The TransferModel class has several methods for preparing the data, plotting class distributions, analyzing image names, plotting images, performing train-test split, creating data generators, and creating the model.The TransferModel class uses the MobileNetV2 architecture for transfer learning. It includes methods for creating data generators using ImageDataGenerator from TensorFlow and training the model.[//]: # (### Process Module)[//]: # (```mermaid)[//]: # (flowchart LR)[//]: # ()[//]: # (A[Download Data\n Bing module] --&gt; B[1-find category names\n 2-make an image dictionary])[//]: # (B --&gt; C[Augment data] --&gt; D)[//]: # (D[Train Test  Val Split] --&gt; E[Populate images into the\ntrain test val folders] --&gt; F[Train the model])[//]: # (```)[//]: # (### Bit Vision Module)[//]: # (```mermaid)[//]: # (flowchart LR)[//]: # (A[Categories\nproperty] --&gt; B[Data Details\nproperty])[//]: # (B --&gt; C[Assemble Model] --&gt; D[Compile Model] --&gt; E[Rescale Images\nTrain and Val] )[//]: # (--&gt; F[Fit Model] --&gt; G[Save Model])[//]: # (```)## Grad Cam Heatmap - Rollercone Bit![alt text](assets/grad_cam_rc_1.png &quot;Logo Title Text 1&quot;)## Grad Cam Heatmap - PDC Bit![alt text](assets/grad_cam_pdc_1.png &quot;Logo Title Text 1&quot;)# How to use the Drill Bit Classifier Example## Installation```bashpip install drillvision```## Usage```pythonfrom pathlib import Pathfrom neural_network_model.process_data import Preprocessingfrom neural_network_model.bit_vision import BitVisionif __name__ == &quot;__main__&quot;:    # download the images    obj = Preprocessing(dataset_address=Path(__file__).parent / &quot;dataset&quot;)    obj.download_images(limit=10)    print(obj.image_dict)    obj.augment_data(        number_of_images_tobe_gen=10,        augment_data_address=Path(__file__).parent / &quot;augmented_dataset&quot;    )    obj._train_test_split(        augmented_data_address=Path(__file__).parent / &quot;augmented_dataset&quot;,        train_test_val_split_dir_address=Path(__file__).parent / &quot;dataset_train_test_val&quot;    )    obj = BitVision(train_test_val_dir=Path(__file__).parent / &quot;dataset_train_test_val&quot;)    print(obj.categories)    print(obj.data_details)    obj.plot_image_category()    obj.compile_model()    #    model_name = &quot;model_epoch_{epoch:02d}_loss_{loss:.2f}_acc_{accuracy:.2f}_val_acc_{val_accuracy:.2f}_.h5&quot;    obj.train_model(        epochs=8,        model_save_address=Path(__file__).parent / &quot;deep_model&quot;,        model_name=model_name    )    obj.plot_history(fig_folder_address=Path(__file__).parent / &quot;figures&quot;)    best_model = obj.return_best_model_name(directory=&quot;deep_model&quot;)    obj.predict(        fig_save_address=Path(__file__).parent / &quot;figures&quot;,        model_path=Path(__file__).parent / &quot;deep_model&quot; / best_model,        test_folder_address=Path(__file__).parent / &quot;dataset_train_test_val&quot; / &quot;test&quot;    )    # find list of images in the Path(__file__).parent / &quot;dataset_train_test_val&quot; / &quot;test&quot; / &quot;pdc_bit&quot;    directory_path = Path(__file__).parent / &quot;dataset_train_test_val&quot; / &quot;test&quot; / &quot;pdc_bit&quot;    list_of_images = [str(x) for x in directory_path.glob(&quot;*.jpeg&quot;)]    obj.grad_cam_viz(        model_path=Path(__file__).parent / &quot;deep_model&quot; / best_model,        fig_to_save_address=Path(__file__).parent / &quot;figures&quot;,        img_to_be_applied_path=Path(__file__).parent / &quot;dataset_train_test_val&quot; / &quot;test&quot; / &quot;pdc_bit&quot; / list_of_images[            0],        output_gradcam_fig_name=&quot;gradcam.png&quot;    )```## Using TransferLearning Module```pythonfrom neural_network_model.transfer_learning import TransferModelfrom pathlib import Pathtransfer_model = TransferModel(    dataset_address=Path(__file__).parent / &quot;dataset&quot;)transfer_model.plot_classes_number()transfer_model.analyze_image_names()transfer_model.plot_data_images(num_rows=3, num_cols=3)transfer_model.train_model(epochs=3,                           model_save_path=(Path(__file__).parent / &quot;..&quot; / &quot;deep_model&quot;).resolve(),                           model_name=&quot;tf_model_2.h5&quot;)transfer_model.plot_metrics_results()transfer_model.results()# one can pass the model address to the predict_test methodtransfer_model.predict_test()transfer_model.grad_cam_viz(num_rows=3, num_cols=2)```Note that the dataset structure should be as follows:```├── dataset│   ├── class 1│   └── class 2│   └── class 3│   └── class .│   └── class .│   └── class .│   └── class N      ```## Visual Insight moduleThis module empowers users to enhance their images using diverse filters such as Hessian, Frangi, LBP (Local Binary Pattern), multi-Otsu thresholding, and Sobel. Additionally, the module facilitates the extraction of histogram features from the filtered outcomes. It computes histograms for each color channel (R, G, B) of the filtered image, yielding histogram counts that serve as features.Moreover, users have the capability to engage in image segmentation through the utilization of the K-means clustering algorithm. This method applies image segmentation to a batch of images within a designated directory, employing a specified clustering technique (with K-Means being the default). ## Applying Ridge operators```pythondataset_path = Path(__file__).parent / &quot;..&quot; / &quot;dataset&quot;obj = ImageNumeric(dataset_address=dataset_path)image_path = str(    (            Path(__file__).parent            / &quot;..&quot;            / &quot;dataset&quot;            / &quot;pdc_bit&quot;            / &quot;Image_26.jpg&quot;    ))obj.scikit_image_example(    image_path,    section_zoom=[0, 2000, 0, 1000],    save_path=Path(__file__).parent / &quot;..&quot; / &quot;assets&quot;,    save_name=&quot;scikit_image_example.jpg&quot;,)    ```![alt text](assets/scikit_image_example.jpg &quot;Logo Title Text 1&quot;)* Extracting histogram features```pythonobj = ImageNumeric()print(obj.image_df.head())# Load the imageimage_path = str(    (        Path(__file__).parent        / &quot;..&quot;        / &quot;dataset_ad&quot;        / &quot;MildDemented&quot;        / &quot;mildDem0.jpg&quot;    ))# Apply hessian filterhessian_features = obj.hessian_filter_feature_extraction(    image_path, plt_show=True, plt_log=True, cmap=&quot;seismic&quot;)print(hessian_features)# Apply frangi filterfrangifeatures = obj.frangi_feature_extraction(    image_path,    plt_show=True,    plt_log=True,)print(frangifeatures)# # Apply LBP filterlbp_result = obj.lbp_feature_extraction(image_path, plt_show=True, plt_log=True)print(lbp_result)# Apply Multi-Otsu thresholdingmulti_otsu_features = obj.multiotsu_threshold_feature_extraction(    image_path, plt_show=True, plt_log=True)print(multi_otsu_features)# # Apply Sobel edge detectorsobel_features = obj.sobel_edge_detection_sk(    image_path, plt_show=True, plt_log=True, cmap=&quot;gray&quot;)print(sobel_features)```* Filtering images```pythondataset_path = Path(__file__).parent / &quot;..&quot; / &quot;dataset_ad&quot;obj = ImageNumeric(dataset_address=dataset_path)# followings are code apply to whole directory# hessian by defaultobj.filter_images(    dataset_path=dataset_path,    filtered_dataset_path=Path(__file__).parent    / &quot;..&quot;    / &quot;filtered_dataset_ad_hessian&quot;,    replace_existing=False,    cmap=&quot;seismic&quot;,    filter_name=&quot;hessian&quot;,)# obj.filter_images(#     dataset_path=dataset_path,#     filtered_dataset_path=Path(__file__).parent / &quot;..&quot; / &quot;filtered_dataset_ad_frangi&quot;,#     replace_existing=False,#     cmap=&quot;seismic&quot;,#     filter_name=&quot;frangi&quot;# )# obj.filter_images(#     dataset_path=dataset_path,#     filtered_dataset_path=Path(__file__).parent / &quot;..&quot; / &quot;filtered_dataset_ad_lbp&quot;,#     replace_existing=False,#     cmap=&quot;gray&quot;,#     filter_name=&quot;lbp&quot;# )```* Image segmentation```pythondataset_path = Path(__file__).parent / &quot;..&quot; / &quot;dataset_ad&quot;obj = ImageNumeric(dataset_address=dataset_path)image_path = str(    (        Path(__file__).parent        / &quot;..&quot;        / &quot;dataset_ad&quot;        / &quot;MildDemented&quot;        / &quot;mildDem1.jpg&quot;    ))# only on one imageobj.image_segmentation_knn(    image_path, num_clusters=3, plt_show=True, cmap=&quot;viridis&quot;)# whole directoryobj.image_segmentation(    clustering_method=&quot;kmean&quot;,    dataset_path=dataset_path,    segmentation_dataset_path=Path(__file__).parent / &quot;..&quot; / &quot;segmentation_dataset_ad_kmean_3&quot;,    num_clusters=3,    cmap=&quot;viridis&quot;,)```* Displaying images from data directory```pythonobj = ImageNumeric(dataset_address=Path(__file__).parent / &quot;..&quot; / &quot;dataset_ad&quot;)# Display the images# Example title mapping (custom titles for labels)custom_titles = {    &quot;NonDemented&quot;: &quot;Healthy&quot;,    &quot;ModerateDemented&quot;: &quot;Moderate&quot;,    &quot;MildDemented&quot;: &quot;Mild&quot;,    &quot;VeryMildDemented&quot;: &quot;Very Mild&quot;,}obj.display_img_class(    selected_imgs=[        &quot;nonDem441.jpg&quot;,        &quot;verymildDem1622.jpg&quot;,        &quot;mildDem262.jpg&quot;,        &quot;moderateDem38.jpg&quot;,    ],    _random=False,    title_mapping=custom_titles,    arrangement=&quot;1x4&quot;,    figsize=(10, 5),    title_show=True,    # axes_ticks=False,)```* Color map image```pythondataset_path = Path(__file__).parent / &quot;..&quot; / &quot;dataset_ad&quot;obj = ImageNumeric(dataset_address=dataset_path)obj.apply_colormap_to_directory(    cmap=&quot;seismic&quot;,    dataset_path=dataset_path,    edited_dataset_path=Path(__file__).parent / &quot;..&quot; / &quot;edited_dataset_ad&quot;,    replace_existing=False,)```</longdescription>
</pkgmetadata>