<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot; size=&quot;15px&quot;&gt;# BigXMLParse big xml files and streams with ease[![GitHub build status](https://img.shields.io/github/workflow/status/rogdham/bigxml/build/master)](https://github.com/rogdham/bigxml/actions?query=branch:master)[![Release on PyPI](https://img.shields.io/pypi/v/bigxml)](https://pypi.org/project/bigxml/)[![Code coverage](https://img.shields.io/badge/coverage-100%25-brightgreen)](https://github.com/rogdham/bigxml/search?q=fail+under&amp;type=Code)[![Mypy type checker](https://img.shields.io/badge/type_checker-mypy-informational)](https://mypy.readthedocs.io/)[![MIT License](https://img.shields.io/pypi/l/bigxml)](https://github.com/Rogdham/bigxml/blob/master/LICENSE.txt)---[:book: Documentation](https://bigxml.rogdham.net/)&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;[:page_with_curl: Changelog](./CHANGELOG.md)&lt;/div&gt;---Parsing big XML files in Python is hard. On one hand, regular XML libraries load thewhole file into memory, which will crash the process if the file is too big. Othersolutions such as `iterparse` do read the file as they parse it, but they are complex touse if you don't want to run out of memory.This is where the _BigXML_ library shines:- Works with XML files of any size- No need to do memory management yourself- Pythonic API- Any stream can easily be parsed, not just files- Secure from usual attacks against XML parsers</longdescription>
</pkgmetadata>