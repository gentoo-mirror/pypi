<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>pytest-spark############.. image:: https://travis-ci.org/malexer/pytest-spark.svg?branch=master    :target: https://travis-ci.org/malexer/pytest-sparkpytest_ plugin to run the tests with support of pyspark (`Apache Spark`_).This plugin will allow to specify SPARK_HOME directory in ``pytest.ini``and thus to make &quot;pyspark&quot; importable in your tests which are executedby pytest.You can also define &quot;spark_options&quot; in ``pytest.ini`` to customize pyspark,including &quot;spark.jars.packages&quot; option which allows to load externallibraries (e.g. &quot;com.databricks:spark-xml&quot;).pytest-spark provides session scope fixtures ``spark_context`` and``spark_session`` which can be used in your tests.**Note:** no need to define SPARK_HOME if you've installed pyspark usingpip (e.g. ``pip install pyspark``) - it should be already importable. Inthis case just don't define SPARK_HOME neither in pytest(pytest.ini / --spark_home) nor as environment variable.Install=======.. code-block:: shell    $ pip install pytest-sparkUsage=====Set Spark location------------------To run tests with required spark_home location you need to define it byusing one of the following methods:1. Specify command line option &quot;--spark_home&quot;::    $ pytest --spark_home=/opt/spark2. Add &quot;spark_home&quot; value to ``pytest.ini`` in your project directory::    [pytest]    spark_home = /opt/spark3. Set the &quot;SPARK_HOME&quot; environment variable.pytest-spark will try to import ``pyspark`` from provided location... note::    &quot;spark_home&quot; will be read in the specified order. i.e. you can    override ``pytest.ini`` value by command line option.Customize spark_options-----------------------Just define &quot;spark_options&quot; in your ``pytest.ini``, e.g.::    [pytest]    spark_home = /opt/spark    spark_options =        spark.app.name: my-pytest-spark-tests        spark.executor.instances: 1        spark.jars.packages: com.databricks:spark-xml_2.12:0.5.0Using the ``spark_context`` fixture-----------------------------------Use fixture ``spark_context`` in your tests as a regular pyspark fixture.SparkContext instance will be created once and reused for the whole testsession.Example::    def test_my_case(spark_context):        test_rdd = spark_context.parallelize([1, 2, 3, 4])        # ...Using the ``spark_session`` fixture (Spark 2.0 and above)---------------------------------------------------------Use fixture ``spark_session`` in your tests as a regular pyspark fixture.A SparkSession instance with Hive support enabled will be created once and reused for the whole testsession.Example::    def test_spark_session_dataframe(spark_session):        test_df = spark_session.createDataFrame([[1,3],[2,4]], &quot;a: int, b: int&quot;)        # ...Overriding default parameters of the ``spark_session`` fixture--------------------------------------------------------------By default ``spark_session`` will be loaded with the following configurations : Example::    {        'spark.app.name': 'pytest-spark',        'spark.default.parallelism': 1,        'spark.dynamicAllocation.enabled': 'false',        'spark.executor.cores': 1,        'spark.executor.instances': 1,        'spark.io.compression.codec': 'lz4',        'spark.rdd.compress': 'false',        'spark.sql.shuffle.partitions': 1,        'spark.shuffle.compress': 'false',        'spark.sql.catalogImplementation': 'hive',    }You can override some of these parameters in your ``pytest.ini``. For example, removing Hive Support for the spark session : Example::    [pytest]    spark_home = /opt/spark    spark_options =        spark.sql.catalogImplementation: in-memoryDevelopment===========Tests-----Run tests locally::    $ docker-compose up --build.. _pytest: http://pytest.org/.. _Apache Spark: https://spark.apache.org/</longdescription>
</pkgmetadata>