<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># What is SQLiteKG2Vec?SQLitKG2Vec is an experimental extension of the popular pyRDF2Veclibrary for training RDF2Vec embeddings. It might in the future bemerged into the main project. This experimental extension stores thestatements of the KG as well as the generated walks into a simple SQLitedatabase. Hence, it is possible to train embeddings for huge knowledgegraphs without running into memory issues.RDF2Vec is an unsupervised technique that builds further on[Word2Vec](https://en.wikipedia.org/wiki/Word2vec), where an embeddingis learned per word, in two ways:1.  **the word based on its context**: Continuous Bag-of-Words (CBOW);2.  **the context based on a word**: Skip-Gram (SG).To create this embedding, RDF2Vec first creates &quot;sentences&quot; which can befed to Word2Vec by extracting walks of a certain depth from a KnowledgeGraph.This repository contains an implementation of the algorithm in &quot;RDF2Vec:RDF Graph Embeddings and Their Applications&quot; by Petar Ristoski, JessicaRosati, Tommaso Di Noia, Renato De Leone, Heiko Paulheim([\[paper\]](http://semantic-web-journal.net/content/rdf2vec-rdf-graph-embeddings-and-their-applications-0)[\[originalcode\]](http://data.dws.informatik.uni-mannheim.de/rdf2vec/)).# Getting StartedFor most uses-cases, here is how `pySQLiteKG2Vec` should be used togenerate embeddings and get literals from a given Knowledge Graph (KG)and entities:``` pythonfrom pyrdf2vec import RDF2VecTransformerfrom pyrdf2vec.embedders import Word2Vecfrom pyrdf2vec.graphs.io import open_from_pykeen_datasetfrom pyrdf2vec.walkers import RandomWalkerfrom pyrdf2vec.walkers.vault.sqlitevault import SQLiteCorpusVaultFactorywith open_from_pykeen_dataset('dbpedia50') as kg:    transformer = RDF2VecTransformer(        Word2Vec(epochs=10),        walkers=[RandomWalker(max_walks=200,                              max_depth=4,                              random_state=133,                              with_reverse=False,                              n_jobs=1)],        vault_factory=SQLiteCorpusVaultFactory('corpus.db'),        verbose=1    )    # train RDF2Vec    ent = kg.entities()    embeddings, _ = transformer.fit_transform(kg, ent)    with open('embeddings.tsv', 'w') as f:        writer = csv.writer(f, delimiter='\t')        for name, vector in kg.pack(ent, embeddings):            writer.writerow([name] + [x for x in vector])```## Create from PyKeen dataset[PyKeen](https://github.com/pykeen/pykeen) is a popular library forknowledge graph embeddings, and it specifies a number of datasets thatare commonly referenced in scientific literature. An SQLite KG can beconstructed from a PyKeen dataset by specifying the name of the datasetor passing the dataset instance.In the following code snippet, the &lt;span class=&quot;title-ref&quot;&gt;db100k&lt;/span&gt;dataset, which is a subsampling of DBpedia, is used to construct anSQLite KG.``` pythonfrom pyrdf2vec.graphs.io import open_from_pykeen_datasetwith open_from_pykeen_dataset('db100k', combined=True) as kg:    # ...    pass```**Parameters:**-   *combined* - &lt;span class=&quot;title-ref&quot;&gt;False&lt;/span&gt; if only the    training set of a dataset shall be used for the training of RDF2Vec.    &lt;span class=&quot;title-ref&quot;&gt;True&lt;/span&gt; if all the sets (training,    testing and validation) shall be used. It is &lt;span    class=&quot;title-ref&quot;&gt;False&lt;/span&gt; by default.## Create from TSV fileIn order to save memory for big knowledge graphs, it might be a goodidea to load the statements of such a knowledge graph from a TSV fileinto a SQLite KG. All the rows in the TSV file must have three columns,where the first column is the subject, the second is the predicate, andthe last column is the object.The following code snippet creates a new SQLite KG instance from thestatements of the specified TSV file, which has been compressed usingGZIP.``` pythonfrom pyrdf2vec.graphs.io import open_from_tsv_filewith open_from_tsv_file('statements.tsv.gz', compression='gzip') as kg:    # ...    pass```**Parameters:**-   *skip_header* - &lt;span class=&quot;title-ref&quot;&gt;True&lt;/span&gt; if the first row    shall be skipped, because it is a header row for example. &lt;span    class=&quot;title-ref&quot;&gt;False&lt;/span&gt; if it shouldn't be skipped. It is    &lt;span class=&quot;title-ref&quot;&gt;False&lt;/span&gt; by default.-   *compression* - specifies the compression type of source TSV file.    The default value is &lt;span class=&quot;title-ref&quot;&gt;None&lt;/span&gt;, which    means that the source isn't compressed. At the moment, only &lt;span    class=&quot;title-ref&quot;&gt;'gzip'&lt;/span&gt; is supported as compression type.## Create from Pandas dataframeA knowledge graph can be represented in a Pandas dataframe, and thismethod allows to create an SQLite KG from a dataframe. While thedataframe can have more than three columns, the three columnsrepresenting the subject, predicate and object must be specified in thisparticular order.The following code snippet creates a new SQLite KG instance from adataframe.``` pythonfrom pyrdf2vec.graphs.io import open_from_dataframewith open_from_dataframe(df, column_names=('subj', 'pred', 'obj')) as kg:    # ...    pass```**Parameters:**-   *column_names* - a tuple of three indices for the dataframe, which    can be an integer or string. The first entry of the tuple shall    point to the subject, the second to the predicate, and the third one    to the object. &lt;span class=&quot;title-ref&quot;&gt;(0, 1, 2)&lt;/span&gt; are the    default indices.## LimitationsThis extension has three limitations in contrast to the originalimplementation.1)  **Literals** are ignored by this implementation for now.2)  **Samplers** (besides the default one) might not work properly.## Installation`pySQLiteKG2Vec` can be installed in three ways:1.  from [PyPI](https://pypi.org/project/pySQLiteKG2Vec) using `pip`:``` bashpip install pySQLiteKG2Vec```2.  from any compatible Python dependency manager (e.g., `poetry`):``` bashpoetry add pyRDF2vec```3.  from source:``` bashgit clone https://github.com/IBCNServices/pyRDF2Vec.gitpip install .```# DocumentationFor more information on how to use `pyRDF2Vec`, [visit our onlinedocumentation](https://pyrdf2vec.readthedocs.io/en/latest/) which isautomatically updated with the latest version of the `main` branch.From then on, you will be able to learn more about the use of themodules as well as their functions available to you.# ContributionsYour help in the development of `pyRDF2Vec` is more than welcome.&lt;p align=&quot;center&quot;&gt;  &lt;img width=&quot;85%&quot; src=&quot;./assets/architecture.png&quot; alt=&quot;architecture&quot;&gt;&lt;/p&gt;The architecture of `pyRDF2Vec` makes it easy to create new extractionand sampling strategies, new embedding techniques. In order to betterunderstand how you can help either through pull requests and/or issues,please take a look at the[CONTRIBUTING](https://github.com/IBCNServices/pyRDF2Vec/blob/main/CONTRIBUTING.rst)file.# FAQ## How to Ensure the Generation of Similar Embeddings?`pySQLiteKG2Vec`'s walking strategies, sampling strategies and Word2Vecwork with randomness. To get reproducible embeddings, you firstly needto **use a seed** to ensure determinism:``` bashPYTHONHASHSEED=42 python foo.py```Added to this, you must **also specify a random state** to the walkingstrategy which will implicitly use it for the sampling strategy:``` pythonfrom pyrdf2vec.walkers import RandomWalkerRandomWalker(2, None, random_state=42)```**NOTE:** the `PYTHONHASHSEED` (e.g., 42) is to ensure determinism.Finally, to ensure random determinism for Word2Vec, you must **specify asingle worker**:``` pythonfrom pyrdf2vec.embedders import Word2VecWord2Vec(workers=1)```**NOTE:** using the `n_jobs` and `mul_req` parameters does not affectthe random determinism.## Why the Extraction Time of Walks is Faster if `max_walks=None`?Currently, **the BFS function** (using the Breadth-first searchalgorithm) is used when `max_walks=None` which is significantly**faster** than the DFS function (using the Depth-first searchalgorithm) **and extract more walks**.We hope that this algorithmic complexity issue will be solved for thenext release of `pyRDf2Vec`## How to Silence the tcmalloc Warning When Using FastText With Mediums/Large KGs?Sets the `TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD` environment variable toa high value.# ReferencingIf you use `pyRDF2Vec` in a scholarly article, we would appreciate acitation:``` bibtex@article{pyrdf2vec,  title        = {pyRDF2Vec: A Python Implementation and Extension of RDF2Vec},  author       = {Vandewiele, Gilles and Steenwinckel, Bram and Agozzino, Terencio and Ongenae, Femke},  year         = 2022,  publisher    = {arXiv},  doi          = {10.48550/ARXIV.2205.02283},  url          = {https://arxiv.org/abs/2205.02283},  copyright    = {Creative Commons Attribution 4.0 International},  organization = {IDLab},  keywords     = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}}```</longdescription>
</pkgmetadata>