<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;i&gt;moko&lt;/i&gt;는 국한문혼용 텍스트에서 한자어를 추출하는 모듈입니다. &lt;br&gt;근대한국학연구소 HK+사업단의 한국학 DB구축 연구의 일환으로 제작되었습니다.&lt;br&gt;## Installation```$ pip install moko```&lt;br&gt;## Usage&lt;b&gt; Noun chunking&lt;/b&gt;- noun_chunk_dict: dictionary based word extraction- noun_chunk_model: noun chunking module with spacing modelTraining data: 황성신문 논설기사를 관련 연구자가 띄어쓰기 한 학습데이터 활용```from moko import noun_chunker as nctext = &quot;泱泱大風이 固由於萬籟齊應이나 其初也엔 起於一蓬之末고 彼文明國之所謂 文明이 固謂其國民全軆之文明이나 其文明開發之原動力은&quot;dct_lst = nc.noun_chunk_dict(text)print(dct_lst)mdl_lst = nc.noun_chunk_model(text)print(mdl_lst)```Parameter- char_num: control word length, default is &quot;4&quot;- stopword_lst: stopword list, default list contains 654 words ('今日', '今年', '一日'...)- usrword_lst: a list of words want to include ('noun_chunk_dict' only)&lt;br&gt;&lt;b&gt; Word count &lt;/b&gt;- word_count: simple word count- co_occurence_count: return co-occurrence pair```from moko import term_analyzer as taprint(ta.word_count(noun_list))print(ta.co_occurence_count(noun_list))```&lt;br&gt;&lt;b&gt; N-word window extraction around a keyword from &lt;i&gt;noun_list&lt;/i&gt;&lt;/b&gt;mering window (Case2)- Case1: A, B, &lt;b&gt;KEY&lt;/b&gt;, C, D- Case2: A, B, &lt;b&gt;KEY&lt;/b&gt;, C, &lt;b&gt;KEY&lt;/b&gt;, &lt;b&gt;KEY&lt;/b&gt;, D, E```from moko import term_analyzer as taprint(ta.extract_window(dct_lst,&quot;文明&quot;,2))```&lt;br&gt;## To be added- Named Entity Recognition: 인명, 서명, 저자명, 기관명 - Word Embedding: w2v(skip-gram), FastText+ 띄어쓰기 모델 사용시 지시대명사, 접두어 처리문제## History&lt;b&gt;0.1.0.14 (2023-03-21)&lt;/b&gt; - First version of &lt;i&gt;moko&lt;/i&gt;</longdescription>
</pkgmetadata>