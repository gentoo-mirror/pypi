<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>.. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/pygeohydro_logo.png    :target: https://github.com/hyriver/HyRiver|.. image:: https://joss.theoj.org/papers/b0df2f6192f0a18b9e622a3edff52e77/status.svg    :target: https://joss.theoj.org/papers/b0df2f6192f0a18b9e622a3edff52e77    :alt: JOSS|.. |pygeohydro| image:: https://github.com/hyriver/pygeohydro/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pygeohydro/actions/workflows/test.yml    :alt: Github Actions.. |pygeoogc| image:: https://github.com/hyriver/pygeoogc/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pygeoogc/actions/workflows/test.yml    :alt: Github Actions.. |pygeoutils| image:: https://github.com/hyriver/pygeoutils/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pygeoutils/actions/workflows/test.yml    :alt: Github Actions.. |pynhd| image:: https://github.com/hyriver/pynhd/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pynhd/actions/workflows/test.yml    :alt: Github Actions.. |py3dep| image:: https://github.com/hyriver/py3dep/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/py3dep/actions/workflows/test.yml    :alt: Github Actions.. |pydaymet| image:: https://github.com/hyriver/pydaymet/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pydaymet/actions/workflows/test.yml    :alt: Github Actions.. |pynldas2| image:: https://github.com/hyriver/pynldas2/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/pynldas2/actions/workflows/test.yml    :alt: Github Actions.. |async| image:: https://github.com/hyriver/async-retriever/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/async-retriever/actions/workflows/test.yml    :alt: Github Actions.. |signatures| image:: https://github.com/hyriver/hydrosignatures/actions/workflows/test.yml/badge.svg    :target: https://github.com/hyriver/hydrosignatures/actions/workflows/test.yml    :alt: Github Actions================ ==================================================================== ============Package          Description                                                          Status================ ==================================================================== ============PyNHD_           Navigate and subset NHDPlus (MR and HR) using web services           |pynhd|Py3DEP_          Access topographic data through National Map's 3DEP web service      |py3dep|PyGeoHydro_      Access NWIS, NID, WQP, eHydro, NLCD, CAMELS, and SSEBop databases    |pygeohydro|PyDaymet_        Access daily, monthly, and annual climate data via Daymet            |pydaymet|PyNLDAS2_        Access hourly NLDAS-2 data via web services                          |pynldas2|HydroSignatures_ A collection of tools for computing hydrological signatures          |signatures|AsyncRetriever_  High-level API for asynchronous requests with persistent caching     |async|PyGeoOGC_        Send queries to any ArcGIS RESTful-, WMS-, and WFS-based services    |pygeoogc|PyGeoUtils_      Utilities for manipulating geospatial, (Geo)JSON, and (Geo)TIFF data |pygeoutils|================ ==================================================================== ============.. _PyGeoHydro: https://github.com/hyriver/pygeohydro.. _AsyncRetriever: https://github.com/hyriver/async-retriever.. _PyGeoOGC: https://github.com/hyriver/pygeoogc.. _PyGeoUtils: https://github.com/hyriver/pygeoutils.. _PyNHD: https://github.com/hyriver/pynhd.. _Py3DEP: https://github.com/hyriver/py3dep.. _PyDaymet: https://github.com/hyriver/pydaymet.. _PyNLDAS2: https://github.com/hyriver/pynldas2.. _HydroSignatures: https://github.com/hyriver/hydrosignaturesPyGeoHydro: Retrieve Geospatial Hydrology Data----------------------------------------------.. image:: https://img.shields.io/pypi/v/pygeohydro.svg    :target: https://pypi.python.org/pypi/pygeohydro    :alt: PyPi.. image:: https://img.shields.io/conda/vn/conda-forge/pygeohydro.svg    :target: https://anaconda.org/conda-forge/pygeohydro    :alt: Conda Version.. image:: https://codecov.io/gh/hyriver/pygeohydro/graph/badge.svg    :target: https://codecov.io/gh/hyriver/pygeohydro    :alt: CodeCov.. image:: https://img.shields.io/pypi/pyversions/pygeohydro.svg    :target: https://pypi.python.org/pypi/pygeohydro    :alt: Python Versions.. image:: https://pepy.tech/badge/pygeohydro    :target: https://pepy.tech/project/pygeohydro    :alt: Downloads|.. image:: https://www.codefactor.io/repository/github/hyriver/pygeohydro/badge/main    :target: https://www.codefactor.io/repository/github/hyriver/pygeohydro/overview/main    :alt: CodeFactor.. image:: https://img.shields.io/badge/code%20style-black-000000.svg    :target: https://github.com/psf/black    :alt: black.. image:: https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;logoColor=white    :target: https://github.com/pre-commit/pre-commit    :alt: pre-commit.. image:: https://mybinder.org/badge_logo.svg    :target: https://mybinder.org/v2/gh/hyriver/HyRiver-examples/main?urlpath=lab/tree/notebooks    :alt: Binder|Features--------PyGeoHydro (formerly named `hydrodata &lt;https://pypi.org/project/hydrodata&gt;`__) is a part of`HyRiver &lt;https://github.com/hyriver/HyRiver&gt;`__ software stack thatis designed to aid in hydroclimate analysis through web services. This package providesaccess to some public web services that offer geospatial hydrology data. It has threemain modules: ``pygeohydro``, ``plot``, and ``helpers``.PyGeoHydro supports the following datasets:* `gNATSGO &lt;https://planetarycomputer.microsoft.com/dataset/gnatsgo-rasters&gt;`__ for  US soil properties.* `Derived Soil Properties &lt;https://www.sciencebase.gov/catalog/item/5fd7c19cd34e30b9123cb51f&gt;`__  for soil porosity, available water capacity, and field capacity across the US.* `NWIS &lt;https://nwis.waterdata.usgs.gov/nwis&gt;`__ for daily mean streamflow observations  (returned as a ``pandas.DataFrame`` or ``xarray.Dataset`` with station attributes),* `SensorThings API &lt;https://labs.waterdata.usgs.gov/api-docs/about-sensorthings-api/index.html&gt;`__  for accessing real-time data of USGS sensors.* `CAMELS &lt;https://ral.ucar.edu/solutions/products/camels&gt;`__ for accessing streamflow  observations (1980-2014) and basin-level attributes of 671 stations within CONUS.* `Water Quality Portal &lt;https://www.waterqualitydata.us/&gt;`__ for accessing current and  historical water quality data from more than 1.5 million sites across the US,* `NID &lt;https://nid.sec.usace.army.mil&gt;`__ for accessing the National Inventory of Dams  web service,* `HCDN 2009 &lt;https://www2.usgs.gov/science/cite-view.php?cite=2932&gt;`__ for identifying sites  where human activity affects the natural flow of the watercourse,* `NLCD 2021 &lt;https://www.mrlc.gov/&gt;`__ for land cover/land use, imperviousness  descriptor, and canopy data. You can get data using both geometries and coordinates.* `WBD &lt;https://hydro.nationalmap.gov/arcgis/rest/services/wbd/MapServer/&gt;`__ for accessing  Hydrologic Unit (HU) polygon boundaries within the US (all HUC levels).* `SSEBop &lt;https://earlywarning.usgs.gov/ssebop/modis/daily&gt;`__ for daily actual  evapotranspiration, for both single pixel and gridded data.* `Irrigation Withdrawals &lt;https://doi.org/10.5066/P9FDLY8P&gt;`__ for estimated  monthly water use for irrigation by 12-digit hydrologic unit in the CONUS for 2015* `STN &lt;https://stn.wim.usgs.gov/STNWeb/#/&gt;`__ for access USGS Short-Term Network (STN)* `eHydro &lt;https://navigation.usace.army.mil/Survey/Hydro&gt;`__ for accessing USACE  Hydrographic Surveys that includes topobathymetry dataAlso, it includes several other functions:* ``interactive_map``: Interactive map for exploring NWIS stations within a bounding box.* ``cover_statistics``: Categorical statistics of land use/land cover data.* ``overland_roughness``: Estimate overland roughness from land use/land cover data.* ``streamflow_fillna``: Fill missing daily streamflow values with day-of-year averages.  Streamflow observations must be at least for 10-year long.The ``plot`` module includes two main functions:* ``signatures``: Hydrologic signature graphs.* ``cover_legends``: Official NLCD land cover legends for plotting a land cover dataset.* ``descriptor_legends``: Color map and legends for plotting an imperviousness descriptor dataset.The ``helpers`` module includes:* ``nlcd_helper``: A roughness coefficients lookup table for each land cover and imperviousness  descriptor type which is useful for overland flow routing among other applications.* ``nwis_error``: A dataframe for finding information about NWIS requests' errors.You can find some example notebooks `here &lt;https://github.com/hyriver/HyRiver-examples&gt;`__.Moreover, under the hood, PyGeoHydro uses`AsyncRetriever &lt;https://github.com/hyriver/async-retriever&gt;`__for making requests asynchronously with persistent caching. This improves thereliability and speed of data retrieval significantly. AsyncRetriever caches all request/responsepairs and upon making an already cached request, it will retrieve the responses from the cacheif the server's response is unchanged.You can control the request/response caching behavior and verbosity of the packageby setting the following environment variables:* ``HYRIVER_CACHE_NAME``: Path to the caching SQLite database. It defaults to  ``./cache/aiohttp_cache.sqlite``* ``HYRIVER_CACHE_EXPIRE``: Expiration time for cached requests in seconds. It defaults to  -1 (never expire).* ``HYRIVER_CACHE_DISABLE``: Disable reading/writing from/to the cache. The default is false.For example, in your code before making any requests you can do:.. code-block:: python    import os    os.environ[&quot;HYRIVER_CACHE_NAME&quot;] = &quot;path/to/file.sqlite&quot;    os.environ[&quot;HYRIVER_CACHE_EXPIRE&quot;] = &quot;3600&quot;    os.environ[&quot;HYRIVER_CACHE_DISABLE&quot;] = &quot;true&quot;You can also try using PyGeoHydro without installingit on your system by clicking on the binder badge. A Jupyter Labinstance with the HyRiver stack pre-installed will be launched in your web browser, and youcan start coding!Moreover, requests for additional functionalities can be submitted via`issue tracker &lt;https://github.com/hyriver/pygeohydro/issues&gt;`__.Citation--------If you use any of HyRiver packages in your research, we appreciate citations:.. code-block:: bibtex    @article{Chegini_2021,        author = {Chegini, Taher and Li, Hong-Yi and Leung, L. Ruby},        doi = {10.21105/joss.03175},        journal = {Journal of Open Source Software},        month = {10},        number = {66},        pages = {1--3},        title = {{HyRiver: Hydroclimate Data Retriever}},        volume = {6},        year = {2021}    }Installation------------You can install PyGeoHydro using ``pip`` after installing ``libgdal`` on your system(for example, in Ubuntu run ``sudo apt install libgdal-dev``). Moreover, PyGeoHydro has an optionaldependency for using persistent caching, ``requests-cache``. We highly recommend installingthis package as it can significantly speed up send/receive queries. You don't have to changeanything in your code, since PyGeoHydro under-the-hood looks for ``requests-cache`` andif available, it will automatically use persistent caching:.. code-block:: console    $ pip install pygeohydroAlternatively, PyGeoHydro can be installed from the ``conda-forge`` repositoryusing `Conda &lt;https://docs.conda.io/en/latest/&gt;`__:.. code-block:: console    $ conda install -c conda-forge pygeohydroQuick start-----------We can obtain river topobathymetry data using the ``EHydro`` class. We can subsetthe dataset either using a geometry or a bounding box, based on their ID, or SQL query:.. code-block:: python    from pygeohydro import EHydro    ehydro = EHydro()    topobathy = ehydro.bygeom((-122.53, 45.57, -122.52, 45.59))We can explore the available NWIS stations within a bounding box using ``interactive_map``function. It returns an interactive map and by clicking on a station some of the mostimportant properties of stations are shown... code-block:: python    import pygeohydro as gh    bbox = (-69.5, 45, -69, 45.5)    gh.interactive_map(bbox).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/interactive_map.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/nwis.ipynb    :alt: Interactive MapWe can select all the stations within this boundary box that have daily mean streamflow data from``2000-01-01`` to ``2010-12-31``:.. code-block:: python    from pygeohydro import NWIS    nwis = NWIS()    query = {        &quot;bBox&quot;: &quot;,&quot;.join(f&quot;{b:.06f}&quot; for b in bbox),        &quot;hasDataTypeCd&quot;: &quot;dv&quot;,        &quot;outputDataTypeCd&quot;: &quot;dv&quot;,    }    info_box = nwis.get_info(query)    dates = (&quot;2000-01-01&quot;, &quot;2010-12-31&quot;)    stations = info_box[        (info_box.begin_date &lt;= dates[0]) &amp; (info_box.end_date &gt;= dates[1])    ].site_no.tolist()Then, we can get the daily streamflow data in mm/day (by default the values are in cms)and plot them:.. code-block:: python    from pygeohydro import plot    qobs = nwis.get_streamflow(stations, dates, mmd=True)    plot.signatures(qobs)By default, ``get_streamflow`` returns a ``pandas.DataFrame`` that has a ``attrs`` methodcontaining metadata for all the stations. You can access it like so ``qobs.attrs``.Moreover, we can get the same data as ``xarray.Dataset`` as follows:.. code-block:: python    qobs_ds = nwis.get_streamflow(stations, dates, to_xarray=True)This ``xarray.Dataset`` has two dimensions: ``time`` and ``station_id``. It has10 variables including ``discharge`` with two dimensions while other variablesthat are station attitudes are one dimensional.We can also get instantaneous streamflow data using ``get_streamflow``. This method assumesthat the input dates are in UTC time zone and returns the data in UTC time zone as well... code-block:: python    date = (&quot;2005-01-01 12:00&quot;, &quot;2005-01-12 15:00&quot;)    qobs = nwis.get_streamflow(&quot;01646500&quot;, date, freq=&quot;iv&quot;)We can query USGS stations of type &quot;stream&quot; in Arizona using SensorThings APIas follows:.. code-block:: python    odata = {        &quot;filter&quot;: &quot;properties/monitoringLocationType eq 'Stream' and properties/stateFIPS eq 'US:04'&quot;,    }    df = sensor.query_byodata(odata)Irrigation withdrawals data can be obtained as follows:.. code-block:: python    irr = gh.irrigation_withdrawals()We can get the CAMELS dataset as a ``geopandas.GeoDataFrame`` that includes geometry andbasin-level attributes of 671 natural watersheds within CONUS and their streamflowobservations between 1980-2014 as a ``xarray.Dataset``, like so:.. code-block:: python    attrs, qobs = gh.get_camels().. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/camels.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/camels.ipynb    :alt: CAMELSThe ``WaterQuality`` has a number of convenience methods to retrieve data from theweb service. Since there are many parameter combinations that can beused to retrieve data, a general method is also provided to retrieve data fromany of the valid endpoints. You can use ``get_json`` to retrieve stations infoas a ``geopandas.GeoDataFrame`` or ``get_csv`` to retrieve stations data as a``pandas.DataFrame``. You can construct a dictionary of the parameters and passit to one of these functions. For more information on the parameters, pleaseconsult the `Water Quality Data documentation &lt;https://www.waterqualitydata.us/webservices_documentation&gt;`__.For example, let's find all the stations within a bounding box that have Caffeine data:.. code-block:: python    from pynhd import WaterQuality    bbox = (-92.8, 44.2, -88.9, 46.0)    kwds = {&quot;characteristicName&quot;: &quot;Caffeine&quot;}    wq = WaterQuality()    stations = wq.station_bybbox(bbox, kwds)Or the same criterion but within a 30-mile radius of a point:.. code-block:: python    stations = wq.station_bydistance(-92.8, 44.2, 30, kwds)Then we can get the data for all these stations the data like this:.. code-block:: python    sids = stations.MonitoringLocationIdentifier.tolist()    caff = wq.data_bystation(sids, kwds).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/water_quality.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/water_quality.ipynb    :alt: Water QualityMoreover, we can get land use/land cove data using ``nlcd_bygeom`` or ``nlcd_bycoods`` functions,percentages of land cover types using ``cover_statistics``, and overland roughness using``overland_roughness``. The ``nlcd_bycoords`` function returns a ``geopandas.GeoDataFrame``with the NLCD layers as columns and input coordinates as the ``geometry`` column. Moreover,the ``nlcd_bygeom`` function accepts both a single geometry or a ``geopandas.GeoDataFrame``as the input... code-block:: python    from pynhd import NLDI    basins = NLDI().get_basins([&quot;01031450&quot;, &quot;01318500&quot;, &quot;01031510&quot;])    lulc = gh.nlcd_bygeom(basins, 100, years={&quot;cover&quot;: [2016, 2019]})    stats = gh.cover_statistics(lulc[&quot;01318500&quot;].cover_2016)    roughness = gh.overland_roughness(lulc[&quot;01318500&quot;].cover_2019).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/lulc.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/nlcd.ipynb    :alt: Land Use/Land CoverNext, let's use ``ssebopeta_bygeom`` to get actual ET data for a basin. Note that there's a``ssebopeta_bycoords`` function that returns an ETA time series for a single coordinate... code-block:: python    geometry = NLDI().get_basins(&quot;01315500&quot;).geometry[0]    eta = gh.ssebopeta_bygeom(geometry, dates=(&quot;2005-10-01&quot;, &quot;2005-10-05&quot;)).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/eta.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/ssebop.ipynb    :alt: Actual ETAdditionally, we can pull all the US dams data using ``NID``. Let's get dams that are within thisbounding box and have a maximum storage larger than 200 acre-feet... code-block:: python    nid = NID()    dams = nid.get_bygeom((-65.77, 43.07, -69.31, 45.45), &quot;epsg:4326&quot;)    dams = nid.inventory_byid(dams.id.to_list())    dams = dams[dams.maxStorage &gt; 200]We can get also all dams within CONUS with maximum storage larger than 2500 acre-feet:.. code-block:: python    conus_geom = gh.get_us_states(&quot;contiguous&quot;)    dam_list = nid.get_byfilter([{&quot;maxStorage&quot;: [&quot;[2500 +inf]&quot;]}])    dams = nid.inventory_byid(dam_list[0].id.to_list(), stage_nid=True)    conus_dams = dams[dams.stateKey.isin(conus_geom.STUSPS)].reset_index(drop=True).. image:: https://raw.githubusercontent.com/hyriver/HyRiver-examples/main/notebooks/_static/dams.png    :target: https://github.com/hyriver/HyRiver-examples/blob/main/notebooks/nid.ipynb    :alt: DamsThe ``WBD`` class allows us to get Hydrologic Unit (HU) polygon boundaries. Let'sget the two Hudson HUC4s:.. code-block:: python    from pygeohydro import WBD    wbd = WBD(&quot;huc4&quot;)    hudson = wbd.byids(&quot;huc4&quot;, [&quot;0202&quot;, &quot;0203&quot;])Contributing------------Contributions are very welcomed. Please read`CONTRIBUTING.rst &lt;https://github.com/hyriver/pygeoogc/blob/main/CONTRIBUTING.rst&gt;`__file for instructions.Credits-------This package was created based on the `audreyr/cookiecutter-pypackage`__ project template.__ https://github.com/audreyr/cookiecutter-pypackage</longdescription>
</pkgmetadata>