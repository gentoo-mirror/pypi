<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Simple Large Language Inference Model`sllim` serves as a quality of life wrapper around the `openai-python` library.I found myself writing and rewriting the same helper functions with each new project I began, so now I am working to put these functions together into a easy to use library.Nothing here is ground-breaking; everything here is opinionated.## UsageUse the `chat` function to connect with the `ChatCompletion.create` models. By default, it uses the `gpt-3.5-turbo` model, but you can pass a `model` param to use `gpt-4````from sllim import chatchat(    [        {            &quot;role&quot;: &quot;system&quot;,            &quot;content&quot;: &quot;Example system message&quot;,        },        {            &quot;role&quot;: &quot;user&quot;,            &quot;content&quot;: &quot;Example user message&quot;,        }    ])````complete` works just like `Completion.create`, and `embed` is `Embedding.create`.## Benefits* Local file caching. Each of the functions is locally cached in request-response key-pairs to prevent excessive network activity.* Auto-retry. Timeouts for rate limits, retry for internal errors (&gt;=500 status code).* Parameter names are in the functions so that you don't have to go looking at the docs constantly.* Map reduce prompts onto data* TODO: Cost estimates before running long tasks* TODO: Describe task -&gt; run task* TODO: Allow easy estimate* TODO: Allow easy logging</longdescription>
</pkgmetadata>