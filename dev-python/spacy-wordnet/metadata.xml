<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># spaCy WordNetspaCy Wordnet is a simple custom component for using [WordNet](https://wordnet.princeton.edu/), [MultiWordnet](http://multiwordnet.fbk.eu/english/home.php) and [WordNet domains](http://wndomains.fbk.eu/) with [spaCy](http://spacy.io).The component combines the [NLTK wordnet interface](http://www.nltk.org/howto/wordnet.html) with WordNet domains to allow users to:* Get all synsets for a processed token. For example, getting all the synsets (word senses) of the word ``bank``.* Get and filter synsets by domain. For example, getting synonyms of the verb ``withdraw`` in the financial domain. ## Getting startedThe spaCy WordNet component can be easily integrated into spaCy pipelines. You just need the following:### Prerequisites* Python 3.X* spaCyYou also need to install the following NLTK wordnet data:````bashpython -m nltk.downloader wordnetpython -m nltk.downloader omw````### Install````bashpip install spacy-wordnet````### Supported languagesAlmost all Open Multi Wordnet languages are supported.## UsageOnce you choose the desired language (from the list of supported ones above), you will need to manually download a spaCy model for it. Check the list of available models for each language at [SpaCy 2.x](https://v2.spacy.io/models) or [SpaCy 3.x](https://spacy.io/usage/models).### English exampleDownload example model:```bashpython -m spacy download en_core_web_sm```Run:````pythonimport spacyfrom spacy_wordnet.wordnet_annotator import WordnetAnnotator # Load an spacy modelnlp = spacy.load('en_core_web_sm')# Spacy 3.xnlp.add_pipe(&quot;spacy_wordnet&quot;, after='tagger')# Spacy 2.x# nlp.add_pipe(WordnetAnnotator(nlp, name=&quot;spacy_wordnet&quot;), after='tagger')token = nlp('prices')[0]# wordnet object link spacy token with nltk wordnet interface by giving acces to# synsets and lemmas token._.wordnet.synsets()token._.wordnet.lemmas()# And automatically tags with wordnet domainstoken._.wordnet.wordnet_domains()````spaCy WordNet lets you find synonyms by domain of interest for example economy````pythoneconomy_domains = ['finance', 'banking']enriched_sentence = []sentence = nlp('I want to withdraw 5,000 euros')# For each token in the sentencefor token in sentence:    # We get those synsets within the desired domains    synsets = token._.wordnet.wordnet_synsets_for_domain(economy_domains)    if not synsets:        enriched_sentence.append(token.text)    else:        lemmas_for_synset = [lemma for s in synsets for lemma in s.lemma_names()]        # If we found a synset in the economy domains        # we get the variants and add them to the enriched sentence        enriched_sentence.append('({})'.format('|'.join(set(lemmas_for_synset))))# Let's see our enriched sentenceprint(' '.join(enriched_sentence))# &gt;&gt; I (need|want|require) to (draw|withdraw|draw_off|take_out) 5,000 euros    ````### Portuguese exampleDownload example model:```bashpython -m spacy download pt_core_news_sm```Run:```pythonimport spacyfrom spacy_wordnet.wordnet_annotator import WordnetAnnotator # Load an spacy modelnlp = spacy.load('pt_core_news_sm')# Spacy 3.xnlp.add_pipe(&quot;spacy_wordnet&quot;, after='tagger', config={'lang': nlp.lang})# Spacy 2.x# nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')text = &quot;Eu quero retirar 5.000 euros&quot;economy_domains = ['finance', 'banking']enriched_sentence = []sentence = nlp(text)# For each token in the sentencefor token in sentence:    # We get those synsets within the desired domains    synsets = token._.wordnet.wordnet_synsets_for_domain(economy_domains)    if not synsets:        enriched_sentence.append(token.text)    else:        lemmas_for_synset = [lemma for s in synsets for lemma in s.lemma_names('por')]        # If we found a synset in the economy domains        # we get the variants and add them to the enriched sentence        enriched_sentence.append('({})'.format('|'.join(set(lemmas_for_synset))))# Let's see our enriched sentenceprint(' '.join(enriched_sentence))# &gt;&gt; Eu (querer|desejar|esperar) retirar 5.000 euros```</longdescription>
</pkgmetadata>