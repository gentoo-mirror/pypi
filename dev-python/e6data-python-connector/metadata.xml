<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># e6data Python Connector![version](https://img.shields.io/badge/version-1.1.8-blue.svg)## IntroductionThe e6data Connector for Python provides an interface for writing Python applications that can connect to e6data and perform operations.To install the Python package, use the command below:```shellpip install e6data-python-connector```### Prerequisites* Open Inbound Port 80 in the Engine Cluster.* Limit access to Port 80 according to your organizational security policy. Public access is not encouraged.* Access Token generated in the e6data console.### Create a ConnectionUse your e6data Email ID as the username and your access token as the password.```pythonfrom e6data_python_connector import Connectionusername = '&lt;username&gt;'  # Your e6data Email ID.password = '&lt;password&gt;'  # Access Token generated in the e6data console.host = '&lt;host&gt;'  # IP address or hostname of the cluster to be used.database = '&lt;database&gt;'  # # Database to perform the query on.port = 80  # Port of the e6data engine.catalog_name = '&lt;catalog_name&gt;'conn = Connection(    host=host,    port=port,    username=username,    database=database,    password=password)```### Perform a Queries &amp; Get Results```pythonquery = 'SELECT * FROM &lt;TABLE_NAME&gt;'  # Replace with the query.cursor = conn.cursor(catalog_name=catalog_name)query_id = cursor.execute(query)  # The execute function returns a unique query ID, which can be use to abort the query.all_records = cursor.fetchall()for row in all_records:   print(row)```To fetch all the records:```pythonrecords = cursor.fetchall()```To fetch one record:```pythonrecord = cursor.fetchone()```To fetch limited records:```pythonlimit = 500records = cursor.fetchmany(limit)```To fetch all the records in buffer to reduce memory consumption:```pythonrecords_iterator = cursor.fetchall_buffer()  # Returns generatorfor item in records_iterator:    print(item)```To get the execution plan after query execution:```pythonimport jsonexplain_response = cursor.explain_analyse()query_planner = json.loads(explain_response.get('planner'))```To abort a running query:```pythonquery_id = '&lt;query_id&gt;'  # query id from execute function response.cursor.cancel(query_id)```Switch database in an existing connection:```pythondatabase = '&lt;new_database_name&gt;'  # Replace with the new database.cursor = conn.cursor(database, catalog_name)```### Get Query Time Metrics```pythonimport jsonquery = 'SELECT * FROM &lt;TABLE_NAME&gt;'cursor = conn.cursor(catalog_name)query_id = cursor.execute(query)  # execute function returns query id, can be use for aborting the query.all_records = cursor.fetchall()explain_response = cursor.explain_analyse()query_planner = json.loads(explain_response.get('planner'))execution_time = query_planner.get(&quot;total_query_time&quot;)  # In millisecondsqueue_time = query_planner.get(&quot;executionQueueingTime&quot;)  # In millisecondsparsing_time = query_planner.get(&quot;parsingTime&quot;)  # In millisecondsrow_count = query_planner.get('row_count_out')```### Get Schema - a list of Databases, Tables or ColumnsThe following code returns a dictionary of all databases, all tables and all columns connected to the cluster currently in use.This function can be used without passing database name to get list of all databases.```pythondatabases = conn.get_schema_names()  # To get list of databases.print(databases)database = '&lt;database_name&gt;'  # Replace with actual database name.tables = conn.get_tables(database=database)  # To get list of tables from a database.print(tables)table_name = '&lt;table_name&gt;'  # Replace with actual table name.columns = conn.get_tables(database=database, table=table_name)  # To get the list of columns from a table.columns_with_type = list()&quot;&quot;&quot;Getting the column name and type.&quot;&quot;&quot;for column in columns:   columns_with_type.append(dict(column_name=column.fieldName, column_type=column.fieldType))print(columns_with_type)```### Code HygieneIt is recommended to clear the cursor, close the cursor and close the connection after running a function as a best practice. This enhances performance by clearing old data from memory.```pythoncursor.clear() # Not needed when aborting a querycursor.close()conn.close()```### Code ExampleThe following code is an example which combines a few functions described above.```pythonfrom e6data_python_connector import Connectionimport jsonusername = '&lt;username&gt;'  # Your e6data Email ID.password = '&lt;password&gt;'  # Access Token generated in the e6data console.host = '&lt;host&gt;'  # IP address or hostname of the cluster to be used.database = '&lt;database&gt;'  # # Database to perform the query on.port = 80  # Port of the e6data engine.sql_query = 'SELECT * FROM &lt;TABLE_NAME&gt;'  # Replace with the actual query.catalog_name = '&lt;catalog_name&gt;'  # Replace with the actual catalog name.conn = Connection(    host=host,    port=port,    username=username,    database=database,    password=password)cursor = conn.cursor(db_name=database, catalog_name=catalog_name)query_id = cursor.execute(sql_query)all_records = cursor.fetchall()explain_response = cursor.explain_analyse()planner_result = json.loads(explain_response.get('planner'))execution_time = planner_result.get(&quot;total_query_time&quot;) / 1000  # Converting into seconds.row_count = planner_result.get('row_count_out')columns = [col[0] for col in cursor.description]  # Get the column names and merge them with the results.results = []for row in all_records:   row = dict(zip(columns, row))   results.append(row)   print(row)print('Total row count {}, Execution Time (seconds): {}'.format(row_count, execution_time))cursor.clear()cursor.close()conn.close()```</longdescription>
</pkgmetadata>