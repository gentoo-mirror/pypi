<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;!-- [![Build Status](https://app.travis-ci.com/AnotherSamWilson/fastshap.svg?branch=main)](https://app.travis-ci.com/github/AnotherSamWilson/fastshap) --&gt;[![CodeCov](https://codecov.io/gh/AnotherSamWilson/fastshap/branch/master/graphs/badge.svg?branch=master&amp;service=github)](https://codecov.io/gh/AnotherSamWilson/fastshap)## fastshap: A fast, approximate shap kernel&lt;!-- &lt;a href='https://github.com/AnotherSamWilson/miceforest'&gt;&lt;img src='https://i.imgur.com/nbrAQso.png' align=&quot;right&quot; height=&quot;300&quot; /&gt;&lt;/a&gt; --&gt;Calculating shap values can take an extremely long time. `fastshap` wasdesigned to be as fast as possible by utilizing inner and outer batchassignments to keep the calculations inside vectorized operations asoften as it can. This includes the model evaluation. If the model inquestion is more efficient for 100 samples than 10, then this sort ofvectorization can have enormous benefits.**This package specifically offers a kernel explainer**. Kernelexplainers can calculate approximate shap values of f(X) towards y forany function f.Â Much faster shap solutions are available specificallyfor gradient boosted trees and deep neural networks.A kernel explainer is ideal in situations where:1)  The model you are using does not have model-specific methods    available (for example, support vector machine)2)  You need to explain a modeling pipeline which includes variable    transformations.3)  The model has a link function or some other target transformation.    For example, you wish to explain the raw probabilities in a    classification model, instead of the log-odds.### FeaturesAdvantages of `fastshap`:  - Fast. See benchmarks for comparisons.    - Native handling of both numpy arrays and pandas dataframes including    principled treatment of categories.    - Easy built in stratification of background set.    - Capable of plotting categorical variables in dependence plots.    - Capable of determining categorical variable interactions in shap    values.    - Capable of plotting missing values in interaction variable.Disadvantages of `fastshap`:  - Only dependency plotting is supported as of now.    - Does not support feature groups yet.    - Does not support weights yet.### InstallationThis package can be installed using pip:``` bash# Using pip$ pip install fastshap --no-cache-dir```You can also download the latest development version from thisrepository. If you want to install from github with conda, you mustfirst run `conda install pip git`.``` bash$ pip install git+https://github.com/AnotherSamWilson/fastshap.git```### BenchmarksThese benchmarks compare the `shap` package `KernelExplainer` to the onein `fastshap`. All code is in `./benchmarks`. We left out model-specificshap explainers, because they are usually orders of magnitued faster andmore efficient than kernel explainers.##### Iris DatasetThe iris dataset is a table of 150 rows and 5 columns (4 features, onetarget). This benchmark measured the time to calculate the shap valuesfor different row counts. The iris dataset was concatenated to itself toget the desired dataset size:  &lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/benchmarks/iris_benchmark_time.png&quot; width=&quot;600px&quot; /&gt;&lt;table class=&quot; lightable-minimal&quot; style='font-family: &quot;Trebuchet MS&quot;, verdana, sans-serif; margin-left: auto; margin-right: auto;'&gt;&lt;thead&gt;&lt;tr&gt;&lt;th style=&quot;empty-cells: hide;&quot; colspan=&quot;1&quot;&gt;&lt;/th&gt;&lt;th style=&quot;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &quot; colspan=&quot;2&quot;&gt;&lt;div style=&quot;border-bottom: 2px solid #00000050; &quot;&gt;Avg Times&lt;/div&gt;&lt;/th&gt;&lt;th style=&quot;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &quot; colspan=&quot;2&quot;&gt;&lt;div style=&quot;border-bottom: 2px solid #00000050; &quot;&gt;StDev Times&lt;/div&gt;&lt;/th&gt;&lt;th style=&quot;empty-cells: hide;&quot; colspan=&quot;1&quot;&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&quot;text-align:right;&quot;&gt;rows&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;fastshap&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;shap&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;fastshap&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;shap&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;Relative Difference&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;150&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.27&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;5.57&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.02&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.02&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;20.41&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;300&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.54&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;11.30&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.06&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.27&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;21.11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;450&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.81&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;17.57&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.07&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.59&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;21.57&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;600&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;1.05&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;23.30&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.03&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.45&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;22.18&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;750&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;1.49&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;30.06&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.13&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0.67&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;20.17&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;##### California Housing DatasetThe California Housing dataset is a table of 20640 rows and 9 columns (8features, one target). This benchmark measured the time it took tocalculate shap values on the first 2000 rows for different sizes of thebackground dataset.  &lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/benchmarks/cali_benchmark_time.png&quot; width=&quot;600px&quot; /&gt;&lt;table class=&quot; lightable-minimal&quot; style='font-family: &quot;Trebuchet MS&quot;, verdana, sans-serif; margin-left: auto; margin-right: auto;'&gt;&lt;thead&gt;&lt;tr&gt;&lt;th style=&quot;text-align:right;&quot;&gt;rows&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;fastshap&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;shap&lt;/th&gt;&lt;th style=&quot;text-align:right;&quot;&gt;Relative Difference&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;42&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;14.61&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;128.48&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;8.79&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;52&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;19.33&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;156.86&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;8.12&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;69&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;24.79&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;203.43&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;8.21&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;104&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;38.32&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;290.76&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;7.59&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;207&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;72.80&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;515.27&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;7.08&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;413&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;146.65&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;979.44&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;6.68&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;826&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;313.18&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;1903.28&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;6.08&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;##### Effect of Outer Batch SizesIncreasing the outer batch size can have a significant effect on the runtime of the process:  &lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/benchmarks/batch_size_times.png&quot; width=&quot;600px&quot; /&gt;### Basic UsageWe will use the iris dataset for this example. Here, we load the dataand train a simple lightgbm model on the dataset:``` pythonfrom sklearn.datasets import load_irisimport pandas as pdimport lightgbm as lgbimport numpy as np# Define our dataset and target variabledata = pd.concat(load_iris(as_frame=True,return_X_y=True),axis=1)data.rename({&quot;target&quot;: &quot;species&quot;}, inplace=True, axis=1)data[&quot;species&quot;] = data[&quot;species&quot;].astype(&quot;category&quot;)target = data.pop(&quot;sepal length (cm)&quot;)# Train our modeldtrain = lgb.Dataset(data=data, label=target)lgbmodel = lgb.train(    params={&quot;seed&quot;: 1, &quot;verbose&quot;: -1},    train_set=dtrain,    num_boost_round=10)# Define the function we wish to build shap values for.model = lgbmodel.predictpreds = model(data)```We now have a `model` which takes a Pandas dataframe, and returnspredictions. We can create an explainer that will use `data` as abackground dataset to calculate the shap values of any dataset we wish:``` pythonfrom fastshap import KernelExplainerke = KernelExplainer(model, data)sv = ke.calculate_shap_values(data, verbose=False)print(all(preds == sv.sum(1)))```    ## True### PlottingDependence plots can be created by passing the shap values and variable/ interaction information to `plot_variable_effect_on_output`:``` pythonfrom fastshap.plotting import plot_variable_effect_on_outputplot_variable_effect_on_output(    sv, data,    variable=&quot;sepal width (cm)&quot;,    interaction_variable=&quot;auto&quot;)```&lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/graphics/depgraph.png&quot; width=&quot;800px&quot; /&gt;The type of plot that is generated depends on the model output, thevariable type, and the interaction variable type. For example, plottingthe effect of a categorical variable shows the following:``` pythonfrom fastshap.plotting import plot_variable_effect_on_outputplot_variable_effect_on_output(    sv, data,    variable=&quot;species&quot;,    interaction_variable=&quot;auto&quot;)```&lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/graphics/depgraph_cat.png&quot; width=&quot;800px&quot; /&gt;### Stratifying the Background SetWe can select a subset of our data to act as a background set. Bystratifying the background set on the results of the model output, wewill usually get very similar results, while decreasing the caculationtime drastically.``` pythonke.stratify_background_set(5)sv2 = ke.calculate_shap_values(  data,   background_fold_to_use=0,  verbose=False)print(np.abs(sv2 - sv).mean(0))```    ## [1.74764532e-03 1.61829094e-02 1.99534408e-03 4.02640884e-16    ##  1.71084747e-02]What we did is break up our background set into 10 different sets,stratified by the model output. We then used the first of these sets asour background set. We then compared the average difference betweenthese shap values, and the shap values we obtained from using the entiredataset.### Choosing Batch SizesIf the entire process was vectorized, it would require an array of size(`# Samples * # Coalitions * # Background samples`, `# Columns`). Where`# Coalitions` is the sum of the total number of coalitions that aregoing to be run. Even for small datasets, this becomes enormous.`fastshap` breaks this array up into chunks by splitting the processinto a series of batches.This is a list of the large arrays and their maximum size:  - Global      - Mask Matrix (`# Coalitions`, `# Columns`)  - Outer Batch      - Linear Targets (`Total Coalition Combinations`, `Outer Batch        Size`, `Output Dimension`)\`  - Inner Batch      - Model Evaluation Features (`Inner Batch Size`, `# Background        Samples`)\`The final, returned shap values will also be returned as the datatypereturned by the model.These theoretical sizes can be calculated directly so that the user candetermine appropriate batch sizes for their machine:``` python# Combines our background data back into 1 DataFrameke.stratify_background_set(1)(    mask_matrix_size,     linear_target_size,     inner_model_eval_set_size) = ke.get_theoretical_array_expansion_sizes(    data=data,    outer_batch_size=150,    inner_batch_size=150,    n_coalition_sizes=3,    background_fold_to_use=None)print(  np.product(linear_target_size) + np.product(inner_model_eval_set_size))```    ## 452100For the iris dataset, even if we sent the entire set (150 rows) throughas one batch, we only need 92100 elements stored in arrays. This ismanageable on most machines. However, this number ***grows extremelyquickly*** with the samples and number of columns. It is highly advisedto determine a good batch scheme before running this process.Another way to determine optimal batch sizes is to use the function`.get_theoretical_minimum_memory_requirements()`. This returns a list ofGigabytes needed to build the arrays above:``` python# Combines our background data back into 1 DataFrame(    mask_matrix_GB,     linear_target_GB,     inner_model_eval_set_GB) = ke.get_theoretical_minimum_memory_requirements(    data=data,    outer_batch_size=150,    inner_batch_size=150,    n_coalition_sizes=3,    background_fold_to_use=None)total_GB_needed = mask_matrix_GB + linear_target_GB + inner_model_eval_set_GBprint(f&quot;We need {total_GB_needed} GB to calculate shap values with these batch sizes.&quot;)```    ## We need 0.003368459641933441 GB to calculate shap values with these batch sizes.### Specifying a Custom Linear ModelAny linear model available from sklearn.linear\_model can be used tocalculate the shap values. If you wish for some sparsity in the shapvalues, you can use Lasso regression:``` pythonfrom sklearn.linear_model import Lasso# Use our entire background setke.stratify_background_set(1)sv_lasso = ke.calculate_shap_values(  data,   background_fold_to_use=0,  linear_model=Lasso(alpha=0.1),  verbose=False)print(sv_lasso[0,:])```    ## [-0.         -0.33797832 -0.         -0.14634971  5.84333333]The default model used is `sklearn.linear_model.LinearRegression`.### Multiclass OutputsIf the model returns multiple outputs, the resulting shap values arereturned as an array of size (`rows`, `columns + 1`, `outputs`).Therefore, to get the shap values for the effects on the second class,you need to slice the resulting shap values using `shap_values[:,:,1]`.Here is an example:``` pythonmulti_features = pd.concat(load_iris(as_frame=True,return_X_y=True),axis=1)multi_features.rename({&quot;target&quot;: &quot;species&quot;}, inplace=True, axis=1)target = multi_features.pop(&quot;species&quot;)dtrain = lgb.Dataset(data=multi_features, label=target)lgbmodel = lgb.train(    params={&quot;seed&quot;: 1, &quot;objective&quot;: &quot;multiclass&quot;, &quot;num_class&quot;: 3, &quot;verbose&quot;: -1},    train_set=dtrain,    num_boost_round=10)model = lgbmodel.predictexplainer_multi = KernelExplainer(model, multi_features)shap_values_multi = explainer_multi.calculate_shap_values(multi_features, verbose=False)# To get the shap values for the second class:print(shap_values_multi.shape)```    ## (150, 5, 3)Our shap values are a numpy array of shape `(150, 5, 3)` for each of our150 rows, 4 columns (plus expected value), and our 3 output dimensions.When plotting multiclass outputs, the classes are essentially treated asa categorical variable. However, it is possible to plot variableinteractions with *one* of the output classes, see below.  We can plot a variables shap values for each of the output classes:``` pythonplot_variable_effect_on_output(    shap_values_multi,    data,    variable=2)```&lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/graphics/multiclass_depgraph.png&quot; width=&quot;800px&quot; /&gt;We can also look at interactions if we are interested in a specificclass. For instance, if we wanted to know the effect that `sepal width(cm)` had on our first class, we could do:``` pythonplot_variable_effect_on_output(sv, data, variable=&quot;sepal width (cm)&quot;, output_index=0)```&lt;img src=&quot;https://raw.githubusercontent.com/AnotherSamWilson/fastshap/master/graphics/mc_so_depgraph.png&quot; width=&quot;800px&quot; /&gt;</longdescription>
</pkgmetadata>