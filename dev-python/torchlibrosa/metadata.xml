<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># TorchLibrosa: PyTorch implementation of LibrosaThis codebase provides PyTorch implementation of some librosa functions. If users previously used for training cpu-extracted features from librosa, but want to add GPU acceleration during training and evaluation, TorchLibrosa will provide almost identical features to standard torchlibrosa functions (numerical difference less than 1e-5).## Install```bash$ pip install torchlibrosa```## Examples 1Extract Log mel spectrogram with TorchLibrosa.```pythonimport torchimport torchlibrosa as tlbatch_size = 16sample_rate = 22050win_length = 2048hop_length = 512n_mels = 128batch_audio = torch.empty(batch_size, sample_rate).uniform_(-1, 1)  # (batch_size, sample_rate)# TorchLibrosa feature extractor the same as librosa.feature.melspectrogram()feature_extractor = torch.nn.Sequential(    tl.Spectrogram(        hop_length=hop_length,        win_length=win_length,    ), tl.LogmelFilterBank(        sr=sample_rate,        n_mels=n_mels,        is_log=False, # Default is true    ))batch_feature = feature_extractor(batch_audio) # (batch_size, 1, time_steps, mel_bins)```## Examples 2Extracting spectrogram, then log mel spectrogram, STFT and ISTFT with TorchLibrosa.```pythonimport torchimport torchlibrosa as tlbatch_size = 16sample_rate = 22050win_length = 2048hop_length = 512n_mels = 128batch_audio = torch.empty(batch_size, sample_rate).uniform_(-1, 1)  # (batch_size, sample_rate)# Spectrogramspectrogram_extractor = tl.Spectrogram(n_fft=win_length, hop_length=hop_length)sp = spectrogram_extractor.forward(batch_audio)   # (batch_size, 1, time_steps, freq_bins)# Log mel spectrogramlogmel_extractor = tl.LogmelFilterBank(sr=sample_rate, n_fft=win_length, n_mels=n_mels)logmel = logmel_extractor.forward(sp)   # (batch_size, 1, time_steps, mel_bins)# STFTstft_extractor = tl.STFT(n_fft=win_length, hop_length=hop_length)(real, imag) = stft_extractor.forward(batch_audio)# real: (batch_size, 1, time_steps, freq_bins), imag: (batch_size, 1, time_steps, freq_bins) ## ISTFTistft_extractor = tl.ISTFT(n_fft=win_length, hop_length=hop_length)y = istft_extractor.forward(real, imag, length=batch_audio.shape[-1])    # (batch_size, samples_num)```## Example 3Check the compability of TorchLibrosa to Librosa. The numerical difference should be less than 1e-5.```pythonpython3 torchlibrosa/stft.py --device='cuda'    # --device='cpu' | 'cuda'```## ContactQiuqiang Kong, qiuqiangkong@gmail.com## Cite[1] Qiuqiang Kong, Yin Cao, Turab Iqbal, Yuxuan Wang, Wenwu Wang, and Mark D. Plumbley. &quot;PANNs: Large-scale pretrained audio neural networks for audio pattern recognition.&quot; IEEE/ACM Transactions on Audio, Speech, and Language Processing 28 (2020): 2880-2894.## External linksOther related repos include:torchaudio: https://github.com/pytorch/audioAsteroid-filterbanks: https://github.com/asteroid-team/asteroid-filterbanksKapre: https://github.com/keunwoochoi/kapre</longdescription>
</pkgmetadata>