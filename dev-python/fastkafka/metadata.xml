<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>FastKafka================&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;&lt;b&gt;Effortless Kafka integration for your web services&lt;/b&gt;------------------------------------------------------------------------![PyPI](https://img.shields.io/pypi/v/fastkafka.png) ![PyPI -Downloads](https://img.shields.io/pypi/dm/fastkafka.png) ![PyPI - PythonVersion](https://img.shields.io/pypi/pyversions/fastkafka.png)![GitHub WorkflowStatus](https://img.shields.io/github/actions/workflow/status/airtai/fastkafka/test.yaml)![CodeQL](https://github.com/airtai/fastkafka//actions/workflows/codeql.yml/badge.svg)![DependencyReview](https://github.com/airtai/fastkafka//actions/workflows/dependency-review.yml/badge.svg)![GitHub](https://img.shields.io/github/license/airtai/fastkafka.png)------------------------------------------------------------------------[FastKafka](https://fastkafka.airt.ai/) is a powerful and easy-to-usePython library for building asynchronous services that interact withKafka topics. Built on top of [Pydantic](https://docs.pydantic.dev/),[AIOKafka](https://github.com/aio-libs/aiokafka) and[AsyncAPI](https://www.asyncapi.com/), FastKafka simplifies the processof writing producers and consumers for Kafka topics, handling all theparsing, networking, task scheduling and data generation automatically.With FastKafka, you can quickly prototype and develop high-performanceKafka-based services with minimal code, making it an ideal choice fordevelopers looking to streamline their workflow and accelerate theirprojects.------------------------------------------------------------------------#### ‚≠ê‚≠ê‚≠ê Stay in touch ‚≠ê‚≠ê‚≠êPlease show your support and stay in touch by:- giving our [GitHub repository](https://github.com/airtai/fastkafka/) a  star, and- joining our [Discord server](https://discord.gg/CJWmYpyFbc).Your support helps us to stay in touch with you and encourages us tocontinue developing and improving the library. Thank you for yoursupport!------------------------------------------------------------------------#### üêùüêùüêù We were busy lately üêùüêùüêù![Activity](https://repobeats.axiom.co/api/embed/21f36049093d5eb8e5fdad18c3c5d8df5428ca30.svg &quot;Repobeats analytics image&quot;)## InstallFastKafka works on macOS, Linux, and most Unix-style operating systems.You can install base version of `fastkafka` with `pip` as usual:``` shpip install fastkafka```To install fastkafka with testing features please use:``` shpip install fastkafka[test]```To install fastkafka with asyncapi docs please use:``` shpip install fastkafka[docs]```To install fastkafka with all the features please use:``` shpip install fastkafka[test,docs]```## TutorialYou can start an interactive tutorial in Google Colab by clicking thebutton below:&lt;a href=&quot;https://colab.research.google.com/github/airtai/fastkafka/blob/main/nbs/guides/Guide_00_FastKafka_Demo.ipynb&quot; target=‚Äù_blank‚Äù&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot; /&gt;&lt;/a&gt;## Writing server codeHere is an example python script using FastKafka that takes data from aKafka topic, makes a prediction using a predictive model, and outputsthe prediction to another Kafka topic.### Preparing the demo modelFirst we will prepare our model using the Iris dataset so that we candemonstrate the predictions using FastKafka. The following calldownloads the dataset and trains the model.We will wrap the model creation into a lifespan of our app so that themodel is created just before the app is started.``` pythonfrom contextlib import asynccontextmanagerfrom sklearn.datasets import load_irisfrom sklearn.linear_model import LogisticRegressionfrom fastkafka import FastKafkaml_models = {}@asynccontextmanagerasync def lifespan(app: FastKafka):    # Load the ML model    X, y = load_iris(return_X_y=True)    ml_models[&quot;iris_predictor&quot;] = LogisticRegression(random_state=0, max_iter=500).fit(        X, y    )    yield    # Clean up the ML models and release the resources    ml_models.clear()```### MessagesFastKafka uses [Pydantic](https://docs.pydantic.dev/) to parse inputJSON-encoded data into Python objects, making it easy to work withstructured data in your Kafka-based applications. Pydantic‚Äôs[`BaseModel`](https://docs.pydantic.dev/usage/models/) class allows youto define messages using a declarative syntax, making it easy to specifythe fields and types of your messages.This example defines two message classes for use in a FastKafkaapplication:- The `IrisInputData` class is used to represent input data for a  predictive model. It has four fields of type  [`NonNegativeFloat`](https://docs.pydantic.dev/usage/types/#constrained-types),  which is a subclass of float that only allows non-negative floating  point values.- The `IrisPrediction` class is used to represent the output of the  predictive model. It has a single field `species` of type string  representing the predicted species.These message classes will be used to parse and validate incoming datain Kafka consumers and producers.``` pythonfrom pydantic import BaseModel, Field, NonNegativeFloatclass IrisInputData(BaseModel):    sepal_length: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Sepal length in cm&quot;    )    sepal_width: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Sepal width in cm&quot;    )    petal_length: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Petal length in cm&quot;    )    petal_width: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Petal width in cm&quot;    )class IrisPrediction(BaseModel):    species: str = Field(..., example=&quot;setosa&quot;, description=&quot;Predicted species&quot;)```### ApplicationThis example shows how to initialize a FastKafka application.It starts by defining a dictionary called `kafka_brokers`, whichcontains two entries: `&quot;localhost&quot;` and `&quot;production&quot;`, specifying localdevelopment and production Kafka brokers. Each entry specifies the URL,port, and other details of a Kafka broker. This dictionary is used forboth generating the documentation and later to run the actual serveragainst one of the given kafka broker.Next, an object of the[`FastKafka`](https://fastkafka.airt.ai/docs/api/fastkafka)class is initialized with the minimum set of arguments:- `kafka_brokers`: a dictionary used for generation of documentation``` pythonfrom fastkafka import FastKafkakafka_brokers = {    &quot;localhost&quot;: {        &quot;url&quot;: &quot;localhost&quot;,        &quot;description&quot;: &quot;local development kafka broker&quot;,        &quot;port&quot;: 9092,    },    &quot;production&quot;: {        &quot;url&quot;: &quot;kafka.airt.ai&quot;,        &quot;description&quot;: &quot;production kafka broker&quot;,        &quot;port&quot;: 9092,        &quot;protocol&quot;: &quot;kafka-secure&quot;,        &quot;security&quot;: {&quot;type&quot;: &quot;plain&quot;},    },}kafka_app = FastKafka(    title=&quot;Iris predictions&quot;,    kafka_brokers=kafka_brokers,    lifespan=lifespan,)```### Function decoratorsFastKafka provides convenient function decorators `@kafka_app.consumes`and `@kafka_app.produces` to allow you to delegate the actual process of- consuming and producing data to Kafka, and- decoding and encoding JSON encode messagesfrom user defined functions to the framework. The FastKafka frameworkdelegates these jobs to AIOKafka and Pydantic libraries.These decorators make it easy to specify the processing logic for yourKafka consumers and producers, allowing you to focus on the corebusiness logic of your application without worrying about the underlyingKafka integration.This following example shows how to use the `@kafka_app.consumes` and`@kafka_app.produces` decorators in a FastKafka application:- The `@kafka_app.consumes` decorator is applied to the `on_input_data`  function, which specifies that this function should be called whenever  a message is received on the ‚Äúinput_data‚Äù Kafka topic. The  `on_input_data` function takes a single argument which is expected to  be an instance of the `IrisInputData` message class. Specifying the  type of the single argument is instructing the Pydantic to use  `IrisInputData.parse_raw()` on the consumed message before passing it  to the user defined function `on_input_data`.- The `@produces` decorator is applied to the `to_predictions` function,  which specifies that this function should produce a message to the  ‚Äúpredictions‚Äù Kafka topic whenever it is called. The `to_predictions`  function takes a single integer argument `species_class` representing  one of three possible strign values predicted by the mdoel. It creates  a new `IrisPrediction` message using this value and then returns it.  The framework will call the `IrisPrediction.json().encode(&quot;utf-8&quot;)`  function on the returned value and produce it to the specified topic.``` python@kafka_app.consumes(topic=&quot;input_data&quot;, auto_offset_reset=&quot;latest&quot;)async def on_input_data(msg: IrisInputData):    species_class = ml_models[&quot;iris_predictor&quot;].predict(        [[msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]]    )[0]    to_predictions(species_class)@kafka_app.produces(topic=&quot;predictions&quot;)def to_predictions(species_class: int) -&gt; IrisPrediction:    iris_species = [&quot;setosa&quot;, &quot;versicolor&quot;, &quot;virginica&quot;]    prediction = IrisPrediction(species=iris_species[species_class])    return prediction```## Testing the serviceThe service can be tested using the[`Tester`](https://fastkafka.airt.ai/docs/api/fastkafka/testing/Tester)instances which internally starts InMemory implementation of Kafkabroker.The Tester will redirect your consumes and produces decorated functionsto the InMemory Kafka broker so that you can quickly test your appwithout the need for a running Kafka broker and all its dependencies.``` pythonfrom fastkafka.testing import Testermsg = IrisInputData(    sepal_length=0.1,    sepal_width=0.2,    petal_length=0.3,    petal_width=0.4,)# Start Tester app and create InMemory Kafka broker for testingasync with Tester(kafka_app) as tester:    # Send IrisInputData message to input_data topic    await tester.to_input_data(msg)    # Assert that the kafka_app responded with IrisPrediction in predictions topic    await tester.awaited_mocks.on_predictions.assert_awaited_with(        IrisPrediction(species=&quot;setosa&quot;), timeout=2    )```    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting    [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()    [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['input_data']    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['predictions']    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [INFO] fastkafka._components.aiokafka_consumer_loop: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called    [INFO] fastkafka._components.aiokafka_consumer_loop: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called    [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping### RecapWe have created a Iris classification model and encapulated it into ourfastkafka application. The app will consume the IrisInputData from the`input_data` topic and produce the predictions to `predictions` topic.To test the app we have:1.  Created the app2.  Started our Tester class which mirrors the developed app topics for    testing purposes3.  Sent IrisInputData message to `input_data` topic4.  Asserted and checked that the developed iris classification service    has reacted to IrisInputData message## Running the serviceThe service can be started using builtin faskafka run CLI command.Before we can do that, we will concatenate the code snippets from aboveand save them in a file `&quot;application.py&quot;```` python# content of the &quot;application.py&quot; filefrom contextlib import asynccontextmanagerfrom sklearn.datasets import load_irisfrom sklearn.linear_model import LogisticRegressionfrom fastkafka import FastKafkaml_models = {}@asynccontextmanagerasync def lifespan(app: FastKafka):    # Load the ML model    X, y = load_iris(return_X_y=True)    ml_models[&quot;iris_predictor&quot;] = LogisticRegression(random_state=0, max_iter=500).fit(        X, y    )    yield    # Clean up the ML models and release the resources    ml_models.clear()from pydantic import BaseModel, NonNegativeFloat, Fieldclass IrisInputData(BaseModel):    sepal_length: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Sepal length in cm&quot;    )    sepal_width: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Sepal width in cm&quot;    )    petal_length: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Petal length in cm&quot;    )    petal_width: NonNegativeFloat = Field(        ..., example=0.5, description=&quot;Petal width in cm&quot;    )class IrisPrediction(BaseModel):    species: str = Field(..., example=&quot;setosa&quot;, description=&quot;Predicted species&quot;)    from fastkafka import FastKafkakafka_brokers = {    &quot;localhost&quot;: {        &quot;url&quot;: &quot;localhost&quot;,        &quot;description&quot;: &quot;local development kafka broker&quot;,        &quot;port&quot;: 9092,    },    &quot;production&quot;: {        &quot;url&quot;: &quot;kafka.airt.ai&quot;,        &quot;description&quot;: &quot;production kafka broker&quot;,        &quot;port&quot;: 9092,        &quot;protocol&quot;: &quot;kafka-secure&quot;,        &quot;security&quot;: {&quot;type&quot;: &quot;plain&quot;},    },}kafka_app = FastKafka(    title=&quot;Iris predictions&quot;,    kafka_brokers=kafka_brokers,    lifespan=lifespan,)@kafka_app.consumes(topic=&quot;input_data&quot;, auto_offset_reset=&quot;latest&quot;)async def on_input_data(msg: IrisInputData):    species_class = ml_models[&quot;iris_predictor&quot;].predict(        [[msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]]    )[0]    to_predictions(species_class)@kafka_app.produces(topic=&quot;predictions&quot;)def to_predictions(species_class: int) -&gt; IrisPrediction:    iris_species = [&quot;setosa&quot;, &quot;versicolor&quot;, &quot;virginica&quot;]    prediction = IrisPrediction(species=iris_species[species_class])    return prediction```To run the service, you will need a running Kafka broker on localhost asspecified in the `kafka_brokers` parameter above. We can start the Kafkabroker locally using the[`ApacheKafkaBroker`](https://fastkafka.airt.ai/docs/api/fastkafka/testing/ApacheKafkaBroker).To use[`ApacheKafkaBroker`](https://fastkafka.airt.ai/docs/api/fastkafka/testing/ApacheKafkaBroker),you need to install JRE and Kafka to your environment. To simplify thisprocess, fastkafka comes with a CLI command that does just that, to runit, in your terminal execute the following:``` shfastkafka testing install_deps```Now we can run[`ApacheKafkaBroker`](https://fastkafka.airt.ai/docs/api/fastkafka/testing/ApacheKafkaBroker)that will start a Kafka broker instance for us.``` pythonfrom fastkafka.testing import ApacheKafkaBrokerbroker = ApacheKafkaBroker(apply_nest_asyncio=True)broker.start()```    [INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...    [WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (&lt;_UnixSelectorEventLoop running=True closed=False debug=False&gt;) is already running!    [WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()    [INFO] fastkafka._components.test_dependencies: Java is already installed.    [INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...    [INFO] fastkafka._components.test_dependencies: Kafka is installed.    [INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092    [INFO] fastkafka._testing.apache_kafka_broker: &lt;class 'fastkafka.testing.ApacheKafkaBroker'&gt;.start(): returning 127.0.0.1:9092    [INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.    '127.0.0.1:9092'Then, we start the FastKafka service by running the following command inthe folder where the `application.py` file is located:``` shfastkafka run --num-workers=2 --kafka-broker localhost application:kafka_app```In the above command, we use `--num-workers` option to specify how manyworkers to launch and we use `--kafka-broker` option to specify whichkafka broker configuration to use from earlier specified `kafka_brokers`    [801767]: [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to 'localhost:9092'    [801765]: [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to 'localhost:9092'    [801767]: [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [801765]: [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [801767]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'input_data'})    [801767]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'input_data'}    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.    [801765]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'input_data'})    [801765]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'input_data'}    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.    [801765]: [ERROR] aiokafka.cluster: Topic input_data not found in cluster metadata    [801765]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'input_data': 0}.     [801767]: [WARNING] aiokafka.cluster: Topic input_data is not available during auto-create initialization    [801767]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'input_data': 0}.     [801767]: [ERROR] aiokafka: Unable connect to node with id 0: [Errno 111] Connect call failed ('192.168.112.2', 9092)    [801765]: [ERROR] aiokafka: Unable connect to node with id 0: [Errno 111] Connect call failed ('192.168.112.2', 9092)    [801767]: [ERROR] aiokafka: Unable to update metadata from [0]    [801765]: [ERROR] aiokafka: Unable to update metadata from [0]    ^C    Starting process cleanup, this may take a few seconds...    [INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 801765...    [INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 801767...    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [801765]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.    [801767]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.You need to interupt running of the cell above by selecting`Runtime-&gt;Interupt execution` on the toolbar above.Finally, we can stop the local Kafka Broker:``` pythonbroker.stop()```    [INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 801303...    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 801303 was already terminated.    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 800930...    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 800930 was already terminated.    [INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.## DocumentationThe kafka app comes with builtin documentation generation using[AsyncApi HTML generator](https://www.asyncapi.com/tools/generator).AsyncApi requires Node.js to be installed and we provide the followingconvenience command line for it:``` shfastkafka docs install_deps```    [INFO] fastkafka._components.docs_dependencies: AsyncAPI generator installedTo generate the documentation programatically you just need to call thefolloving command:``` shfastkafka docs generate application:kafka_app```    [INFO] fastkafka._components.asyncapi: New async specifications generated at: '/work/fastkafka/nbs/asyncapi/spec/asyncapi.yml'    [INFO] fastkafka._components.asyncapi: Async docs generated at 'asyncapi/docs'    [INFO] fastkafka._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'    Done! ‚ú®    Check out your shiny new generated files at /work/fastkafka/nbs/asyncapi/docs.. This will generate the *asyncapi* folder in relative path where allyour documentation will be saved. You can check out the content of itwith:``` shls -l asyncapi```    total 8    drwxrwxr-x 4 kumaran kumaran 4096 Mar 21 09:14 docs    drwxrwxr-x 2 kumaran kumaran 4096 Mar 21 09:14 specIn docs folder you will find the servable static html file of yourdocumentation. This can also be served using our `fastkafka docs serve`CLI command (more on that in our guides).In spec folder you will find a asyncapi.yml file containing the asyncAPI specification of your application.We can locally preview the generated documentation by running thefollowing command:``` shfastkafka docs serve application:kafka_app```    [INFO] fastkafka._components.asyncapi: New async specifications generated at: '/work/fastkafka/nbs/asyncapi/spec/asyncapi.yml'    [INFO] fastkafka._components.asyncapi: Async docs generated at 'asyncapi/docs'    [INFO] fastkafka._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'    Done! ‚ú®    Check out your shiny new generated files at /work/fastkafka/nbs/asyncapi/docs.    Serving documentation on http://127.0.0.1:8000    ^C    Interupting serving of documentation and cleaning up...From the parameters passed to the application constructor, we get thedocumentation bellow:``` pythonfrom fastkafka import FastKafkakafka_brokers = {    &quot;localhost&quot;: {        &quot;url&quot;: &quot;localhost&quot;,        &quot;description&quot;: &quot;local development kafka broker&quot;,        &quot;port&quot;: 9092,    },    &quot;production&quot;: {        &quot;url&quot;: &quot;kafka.airt.ai&quot;,        &quot;description&quot;: &quot;production kafka broker&quot;,        &quot;port&quot;: 9092,        &quot;protocol&quot;: &quot;kafka-secure&quot;,        &quot;security&quot;: {&quot;type&quot;: &quot;plain&quot;},    },}kafka_app = FastKafka(    title=&quot;Iris predictions&quot;,    kafka_brokers=kafka_brokers,)```![Kafka_servers](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-servers.png)The following documentation snippet are for the consumer as specified inthe code above:![Kafka_consumer](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-consumer.png)The following documentation snippet are for the producer as specified inthe code above:![Kafka_producer](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-producer.png)Finally, all messages as defined as subclasses of *BaseModel* aredocumented as well:![Kafka\_![Kafka_servers](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-messages.png)](https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-messages.png)## LicenseFastKafka is licensed under the Apache License 2.0A permissive license whose main conditions require preservation ofcopyright and license notices. Contributors provide an express grant ofpatent rights. Licensed works, modifications, and larger works may bedistributed under different terms and without source code.The full text of the license can be found[here](https://raw.githubusercontent.com/airtai/fastkafka/main/LICENSE).</longdescription>
</pkgmetadata>