<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># TensorLearnTensorLearn is a Python library distributed on [Pypi](https://pypi.org) to implement tensor learning methods.This is a project under development. Yet, the available methods are final and functional. The requirment is [Numpy](https://numpy.org).    ## InstallationUse the package manager [pip](https://pip.pypa.io/en/stable/) to install tensorlearn in Python.```pythonpip install tensorlearn```## methods### Decomposition Methods- [auto_rank_tt](#autoranktt-id)- [cp_als_rand_init](#cpalsrandinit-id)### Tensor Operations for Tensor-Train - [tt_to_tensor](#tttotensor-id)- [tt_compression_ratio](#ttcr-id)### Tensor Operations for CANDECOMP/PARAFAC (CP)- [cp_to_tensor](#cptotensor-id)- [cp_compression_ratio](#cpcr-id)### Tensor Operations- [tensor_resize](#tensorresize-id)- [unfold](#unfold-id)- [tensor_frobenius_norm](#tfronorm-id)### Matrix Operations- [error_truncated_svd](#etsvd-id)- [column_wise_kronecker](#colwisekron-id)---## &lt;a name=&quot;autoranktt-id&quot;&gt;&lt;/a&gt;auto_rank_tt```pythontensorlearn.auto_rank_tt(tensor, epsilon)```This implementation of [tensor-train decomposition](https://github.com/rmsolgi/TensorLearn/tree/main/Tensor-Train%20Decomposition) determines the ranks automatically based on a given error bound according to [Oseledets (2011)](https://epubs.siam.org/doi/10.1137/090752286). Therefore the user does not need to specify the ranks. Instead the user specifies an upper error bound (epsilon) which bounds the error of the decomposition. For more information and details please see the page [tensor-train decomposition](https://github.com/rmsolgi/TensorLearn/tree/main/Tensor-Train%20Decomposition).### Arguments - tensor &lt; array &gt;: The given tensor to be decomposed.- epsilon &lt; float &gt;: [The error bound of decomposition](https://github.com/rmsolgi/TensorLearn/tree/main/Tensor-Train%20Decomposition#epsilon-id) in the range \[0,1\].### Return- TT factors &lt; list of arrays &gt;: The list includes numpy arrays of factors (or TT cores) according to TT decomposition. Length of the list equals the dimension of the given tensor to be decomposed.[Example](https://github.com/rmsolgi/TensorLearn/blob/main/Tensor-Train%20Decomposition/example_tt.py)---## &lt;a name=&quot;cpalsrandinit-id&quot;&gt;&lt;/a&gt;cp_als_rand_init```pythontensorlearn.cp_als_rand_init(tensor, rank, iteration, random_seed=None)```This is an implementation of [CANDECOMP/PARAFAC (CP) decomposition](https://github.com/rmsolgi/TensorLearn/tree/main/CP_decomposition) using [alternating least squares (ALS) algorithm](https://arxiv.org/abs/2112.10855) with random initialization of factors.### Arguments - tensor &lt; array &gt;: the given tensor to be decomposed- rank &lt; int &gt;: number of ranks- iterations &lt; int &gt;: the number of iterations of the ALS algorithm- random_seed &lt; int &gt;: the seed of random number generator for random initialization of the factor matrices ### Return- weights &lt; array &gt;: the vector of normalization weights (lambda) in CP decomposition- factors &lt; list of arrays &gt;: factor matrices of the CP decomposition[Example](https://github.com/rmsolgi/TensorLearn/blob/main/CP_decomposition/CP_example.py)---## &lt;a name=&quot;tttotensor-id&quot;&gt;&lt;/a&gt;tt_to_tensor```pythontensorlearn.tt_to_tensor(factors)```Returns the full tensor given the TT factors### Arguments- factors &lt; list of numpy arrays &gt;: TT factors### Return- full tensor &lt; numpy array &gt;[Example](https://github.com/rmsolgi/TensorLearn/blob/main/Tensor-Train%20Decomposition/example_tt.py)---## &lt;a name=&quot;ttcr-id&quot;&gt;&lt;/a&gt;tt_compression_ratio```pythontensorlearn.tt_compression_ratio(factors)```Returns [data compression ratio](https://en.wikipedia.org/wiki/Data_compression_ratio) for [tensor-train decompostion](https://github.com/rmsolgi/TensorLearn/tree/main/CP_decomposition)### Arguments- factors &lt; list of numpy arrays &gt;: TT factors### Return- Compression ratio &lt; float &gt;[Example](https://github.com/rmsolgi/TensorLearn/blob/main/Tensor-Train%20Decomposition/example_tt.py)---## &lt;a name=&quot;cptotensor-id&quot;&gt;&lt;/a&gt;cp_to_tensorReturns the full tensor given the CP factor matrices and weights```pythontensorlearn.cp_to_tensor(weights, factors)```### Arguments- weights &lt; array &gt;: the vector of normalization weights (lambda) in CP decomposition- factors &lt; list of arrays &gt;: factor matrices of the CP decomposition### Return- full tensor &lt; array &gt;[Example](https://github.com/rmsolgi/TensorLearn/blob/main/CP_decomposition/CP_example.py)---## &lt;a name=&quot;cpcr-id&quot;&gt;&lt;/a&gt;cp_compression_ratioReturns [data compression ratio](https://en.wikipedia.org/wiki/Data_compression_ratio) for [CP- decompostion](https://github.com/rmsolgi/TensorLearn/tree/main/CP_decomposition)```pythontensorlearn.cp_compression_ratio(weights, factors)```### Arguments- weights &lt; array &gt;: the vector of normalization weights (lambda) in CP decomposition- factors &lt; list of arrays &gt;: factor matrices of the CP decomposition### Return- Compression ratio &lt; float &gt;[Example](https://github.com/rmsolgi/TensorLearn/blob/main/CP_decomposition/CP_example.py)---## &lt;a name=&quot;tensorresize-id&quot;&gt;&lt;/a&gt;tensor_resize```pythontensorlearn.tensor_resize(tensor, new_shape)```This method reshapes the given tensor to a new shape. The new size must be bigger than or equal to the original shape. If the new shape results in a tensor of greater size (number of elements) the tensor fills with zeros. This works similar to [numpy.ndarray.resize()](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.resize.html)### Arguments- tensor &lt; array &gt;: the given tensor- new_shape &lt; tuple &gt;: new shape ### Return- tensor &lt; array &gt;: tensor with new given shape---## &lt;a name=&quot;unfold-id&quot;&gt;&lt;/a&gt;unfold```pythontensorlearn.unfold(tensor, n)```Unfold the tensor with respect to dimension n.### Arguments- tensor &lt; array &gt;: tensor to be unfolded- n &lt; int &gt;: dimension based on which the tensor is unfolded### Return- matrix &lt; array &gt;: unfolded tensor with respect to dimension n---## &lt;a name=&quot;tfronorm-id&quot;&gt;&lt;/a&gt;tensor_frobenius_norm```pythontensorlearn.tensor_frobenius_norm(tensor)```Calculates the [frobenius norm](https://mathworld.wolfram.com/FrobeniusNorm.html) of the given tensor.### Arguments- tensor &lt; array &gt;: the given tensor### Return- frobenius norm &lt; float &gt;[Example](https://github.com/rmsolgi/TensorLearn/blob/main/Tensor-Train%20Decomposition/example_tt.py)---## &lt;a name=&quot;etsvd-id&quot;&gt;&lt;/a&gt;error_truncated_svd```pythontensorlearn.error_truncated_svd(x, error)```This method conducts a [compact svd](https://en.wikipedia.org/wiki/Singular_value_decomposition) and return [sigma (error)-truncated SVD](https://langvillea.people.cofc.edu/DISSECTION-LAB/Emmie%27sLSI-SVDModule/p5module.html) of a given matrix. This is an implementation using [numpy.linalg.svd](https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html) with full_matrices=False. This method is used in [TT-SVD algorithm](https://github.com/rmsolgi/TensorLearn/tree/main/Tensor-Train%20Decomposition#ttsvd-id) in [auto_rank_tt](#autoranktt-id).### Arguments- x &lt; 2D array &gt;: the given matrix to be decomposed- error &lt; float &gt;: the given error in the range \[0,1\]### Return- r, u, s, vh &lt; int, numpy array, numpy array, numpy array &gt; ---## &lt;a name=&quot;colwisekron-id&quot;&gt;&lt;/a&gt;column_wise_kronecker```pythontensorlearn.column_wise_kronecker(a, b)```Returns the [column wise Kronecker product (Sometimes known as Khatri Rao)](https://en.wikipedia.org/wiki/Khatriâ€“Rao_product) of two given matrices.### Arguments- a,b &lt; 2D array &gt;: the given matrices### Return- column wise Kronecker product &lt; array &gt;</longdescription>
</pkgmetadata>