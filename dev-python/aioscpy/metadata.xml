<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![aioscpy](./doc/images/aioscpy.png)### AioscpyAn asyncio + aiolibs crawler  imitate scrapy frameworkEnglish | [中文](./doc/README_ZH.md)### OverviewAioscpy framework is base on opensource project Scrapy &amp; scrapy_redis.Aioscpy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages.Dynamic variable injection is implemented and asynchronous coroutine feature support.Distributed crawling/scraping.### Requirements- Python 3.8+- Works on Linux, Windows, macOS, BSD### InstallThe quick way:```shell# defaultpip install aioscpy# at latest versionpip install git+https://github.com/ihandmine/aioscpy# install all dependencies pip install aioscpy[all]# install extra packagespip install aioscpy[aiohttp,httpx]```### Usagecreate project spider:```shellaioscpy startproject project_quotes``````cd project_quotesaioscpy genspider quotes ```![tree](./doc/images/tree.png)quotes.py:```pythonfrom aioscpy.spider import Spiderclass QuotesSpider(Spider):    name = 'quotes'    custom_settings = {        &quot;SPIDER_IDLE&quot;: False    }    start_urls = [        'https://quotes.toscrape.com/tag/humor/',    ]    async def parse(self, response):        for quote in response.css('div.quote'):            yield {                'author': quote.xpath('span/small/text()').get(),                'text': quote.css('span.text::text').get(),            }        next_page = response.css('li.next a::attr(&quot;href&quot;)').get()        if next_page is not None:            yield response.follow(next_page, self.parse)```create single script spider:```shellaioscpy onespider single_quotes```single_quotes.py:```pythonfrom aioscpy.spider import Spiderfrom anti_header import Headerfrom pprint import pprint, pformatclass SingleQuotesSpider(Spider):    name = 'single_quotes'    custom_settings = {        &quot;SPIDER_IDLE&quot;: False    }    start_urls = [        'https://quotes.toscrape.com/',    ]    async def process_request(self, request):        request.headers = Header(url=request.url, platform='windows', connection=True).random        return request    async def process_response(self, request, response):        if response.status in [404, 503]:            return request        return response    async def process_exception(self, request, exc):        raise exc    async def parse(self, response):        for quote in response.css('div.quote'):            yield {                'author': quote.xpath('span/small/text()').get(),                'text': quote.css('span.text::text').get(),            }        next_page = response.css('li.next a::attr(&quot;href&quot;)').get()        if next_page is not None:            yield response.follow(next_page, callback=self.parse)    async def process_item(self, item):        self.logger.info(&quot;{item}&quot;, **{'item': pformat(item)})if __name__ == '__main__':    quotes = SingleQuotesSpider()    quotes.start()```run the spider:```shellaioscpy crawl quotesaioscpy runspider quotes.py```![run](./doc/images/run.png)start.py:```pythonfrom aioscpy.crawler import call_grace_instancefrom aioscpy.utils.tools import get_project_settings&quot;&quot;&quot;start spider method one:from cegex.baidu import BaiduSpiderfrom cegex.httpbin import HttpBinSpiderprocess = CrawlerProcess()process.crawl(HttpBinSpider)process.crawl(BaiduSpider)process.start()&quot;&quot;&quot;def load_file_to_execute():    process = call_grace_instance(&quot;crawler_process&quot;, get_project_settings())    process.load_spider(path='./cegex', spider_like='baidu')    process.start()def load_name_to_execute():    process = call_grace_instance(&quot;crawler_process&quot;, get_project_settings())    process.crawl('baidu', path=&quot;./cegex&quot;)    process.start()if __name__ == '__main__':    load_file_to_execute()```more commands:```shellaioscpy -h```### Ready please submit your sugguestion to owner by issue## Thanks[aiohttp](https://github.com/aio-libs/aiohttp/)[scrapy](https://github.com/scrapy/scrapy)[loguru](https://github.com/Delgan/loguru)[httpx](https://github.com/encode/httpx)</longdescription>
</pkgmetadata>