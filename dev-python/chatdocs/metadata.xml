<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># [ChatDocs](https://github.com/marella/chatdocs) [![PyPI](https://img.shields.io/pypi/v/chatdocs)](https://pypi.org/project/chatdocs/) [![tests](https://github.com/marella/chatdocs/actions/workflows/tests.yml/badge.svg)](https://github.com/marella/chatdocs/actions/workflows/tests.yml)Chat with your documents offline using AI. No data leaves your system. Internet connection is only required to install the tool and download the AI models. It is based on [PrivateGPT](https://github.com/imartinez/privateGPT) but has more features.![Web UI](https://github.com/marella/chatdocs/raw/main/docs/demo.png)**Contents**- [Features](#features)- [Installation](#installation)- [Usage](#usage)- [Configuration](#configuration)- [GPU](#gpu)## Features- Supports GGML/GGUF models via [CTransformers](https://github.com/marella/ctransformers)- Supports ðŸ¤— Transformers models- Supports GPTQ models- Web UI- GPU support- Highly configurable via `chatdocs.yml`&lt;details&gt;&lt;summary&gt;&lt;strong&gt;Show supported document types&lt;/strong&gt;&lt;/summary&gt;&lt;br&gt;| Extension       | Format                         || :-------------- | :----------------------------- || `.csv`          | CSV                            || `.docx`, `.doc` | Word Document                  || `.enex`         | EverNote                       || `.eml`          | Email                          || `.epub`         | EPub                           || `.html`         | HTML                           || `.md`           | Markdown                       || `.msg`          | Outlook Message                || `.odt`          | Open Document Text             || `.pdf`          | Portable Document Format (PDF) || `.pptx`, `.ppt` | PowerPoint Document            || `.txt`          | Text file (UTF-8)              |&lt;/details&gt;## InstallationInstall the tool using:```shpip install chatdocs```Download the AI models using:```shchatdocs download```Now it can be run offline without internet connection.## UsageAdd a directory containing documents to chat with using:```shchatdocs add /path/to/documents```&gt; The processed documents will be stored in `db` directory by default.Chat with your documents using:```shchatdocs ui```Open http://localhost:5000 in your browser to access the web UI.It also has a nice command-line interface:```shchatdocs chat```&lt;details&gt;&lt;summary&gt;&lt;strong&gt;Show preview&lt;/strong&gt;&lt;/summary&gt;&lt;br&gt;![Demo](https://github.com/marella/chatdocs/raw/main/docs/cli.png)&lt;/details&gt;## ConfigurationAll the configuration options can be changed using the `chatdocs.yml` config file. Create a `chatdocs.yml` file in some directory and run all commands from that directory. For reference, see the default [`chatdocs.yml`](https://github.com/marella/chatdocs/blob/main/chatdocs/data/chatdocs.yml) file.You don't have to copy the entire file, just add the config options you want to change as it will be merged with the default config. For example, see [`tests/fixtures/chatdocs.yml`](https://github.com/marella/chatdocs/blob/main/tests/fixtures/chatdocs.yml) which changes only some of the config options.### EmbeddingsTo change the embeddings model, add and change the following in your `chatdocs.yml`:```ymlembeddings:  model: hkunlp/instructor-large```&gt; **Note:** When you change the embeddings model, delete the `db` directory and add documents again.### CTransformersTo change the CTransformers (GGML/GGUF) model, add and change the following in your `chatdocs.yml`:```ymlctransformers:  model: TheBloke/Wizard-Vicuna-7B-Uncensored-GGML  model_file: Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0.bin  model_type: llama```&gt; **Note:** When you add a new model for the first time, run `chatdocs download` to download the model before using it.You can also use an existing local model file:```ymlctransformers:  model: /path/to/ggml-model.bin  model_type: llama```### ðŸ¤— TransformersTo use ðŸ¤— Transformers models, add the following to your `chatdocs.yml`:```ymlllm: huggingface```To change the ðŸ¤— Transformers model, add and change the following in your `chatdocs.yml`:```ymlhuggingface:  model: TheBloke/Wizard-Vicuna-7B-Uncensored-HF```&gt; **Note:** When you add a new model for the first time, run `chatdocs download` to download the model before using it.To use GPTQ models with ðŸ¤— Transformers, install the necessary packages using:```shpip install chatdocs[gptq]```## GPU### EmbeddingsTo enable GPU (CUDA) support for the embeddings model, add the following to your `chatdocs.yml`:```ymlembeddings:  model_kwargs:    device: cuda```You may have to reinstall PyTorch with CUDA enabled by following the instructions [here](https://pytorch.org/get-started/locally/).### CTransformersTo enable GPU (CUDA) support for the CTransformers (GGML/GGUF) model, add the following to your `chatdocs.yml`:```ymlctransformers:  config:    gpu_layers: 50```You may have to install the CUDA libraries using:```shpip install ctransformers[cuda]```### ðŸ¤— TransformersTo enable GPU (CUDA) support for the ðŸ¤— Transformers model, add the following to your `chatdocs.yml`:```ymlhuggingface:  device: 0```You may have to reinstall PyTorch with CUDA enabled by following the instructions [here](https://pytorch.org/get-started/locally/).## License[MIT](https://github.com/marella/chatdocs/blob/main/LICENSE)</longdescription>
</pkgmetadata>