<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;h3 align=&quot;center&quot;&gt;  &lt;img    src=&quot;https://raw.githubusercontent.com/Unstructured-IO/unstructured/main/img/unstructured_logo.png&quot;    height=&quot;200&quot;  &gt;&lt;/h3&gt;&lt;div align=&quot;center&quot;&gt;  &lt;a href=&quot;https://github.com/Unstructured-IO/unstructured/blob/main/LICENSE.md&quot;&gt;![https://pypi.python.org/pypi/unstructured/](https://img.shields.io/pypi/l/unstructured.svg)&lt;/a&gt;  &lt;a href=&quot;https://pypi.python.org/pypi/unstructured/&quot;&gt;![https://pypi.python.org/pypi/unstructured/](https://img.shields.io/pypi/pyversions/unstructured.svg)&lt;/a&gt;  &lt;a href=&quot;https://GitHub.com/unstructured-io/unstructured/graphs/contributors&quot;&gt;![https://GitHub.com/unstructured-io/unstructured.js/graphs/contributors](https://img.shields.io/github/contributors/unstructured-io/unstructured)&lt;/a&gt;  &lt;a href=&quot;https://github.com/Unstructured-IO/unstructured/blob/main/CODE_OF_CONDUCT.md&quot;&gt;![code_of_conduct.md](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg) &lt;/a&gt;  &lt;a href=&quot;https://GitHub.com/unstructured-io/unstructured/releases&quot;&gt;![https://GitHub.com/unstructured-io/unstructured.js/releases](https://img.shields.io/github/release/unstructured-io/unstructured)&lt;/a&gt;  &lt;a href=&quot;https://pypi.python.org/pypi/unstructured/&quot;&gt;![https://github.com/Naereen/badges/](https://badgen.net/badge/Open%20Source%20%3F/Yes%21/blue?icon=github)&lt;/a&gt;  [![Downloads](https://static.pepy.tech/badge/unstructured)](https://pepy.tech/project/unstructured)  [![Downloads](https://static.pepy.tech/badge/unstructured/month)](https://pepy.tech/project/unstructured)&lt;/div&gt;&lt;div&gt;  &lt;p align=&quot;center&quot;&gt;  &lt;a  href=&quot;https://join.slack.com/t/unstructuredw-kbe4326/shared_invite/zt-1x7cgo0pg-PTptXWylzPQF9xZolzCnwQ&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/JOIN US ON SLACK-4A154B?style=for-the-badge&amp;logo=slack&amp;logoColor=white&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;https://www.linkedin.com/company/unstructuredio/&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; /&gt;  &lt;/a&gt;&lt;/div&gt;&lt;h3 align=&quot;center&quot;&gt;  &lt;p&gt;API Announcement!&lt;/p&gt;&lt;/h3&gt;&lt;p&gt;While access to the hosted Unstructured API will remain free, API Keys will soon be required to make requests. To prevent any disruption, get yours &lt;a href=&quot;https://www.unstructured.io/api-key/&quot;&gt;here&lt;/a&gt; now and start using it today!&lt;/p&gt;&lt;p&gt;Checkout the &lt;a href=&quot;https://github.com/Unstructured-IO/unstructured-api#--&quot;&gt;readme&lt;/a&gt; here to get started making API calls.We'd love to hear your feedback, let us know how it goes in our  community slack. And stay tuned for improvements to both quality and performance!&lt;/p&gt;&lt;h3 align=&quot;center&quot;&gt;  &lt;p&gt;Open-Source Pre-Processing Tools for Unstructured Data&lt;/p&gt;&lt;/h3&gt;The `unstructured` library provides open-source components for pre-processing text documentssuch as **PDFs**, **HTML** and **Word** Documents. These components are packaged as *bricks* 🧱, which provideusers the building blocks they need to build pipelines targeted at the documents they careabout. Bricks in the library fall into three categories:- :jigsaw: ***Partitioning bricks*** that break raw documents down into standard, structured  elements.- :broom: ***Cleaning bricks*** that remove unwanted text from documents, such as boilerplate and  sentence  fragments.- :performing_arts: ***Staging bricks*** that format data for downstream tasks, such as ML inference  and data labeling.Unstructured also provides the capabilities from `unstructured` as an API.Checkout the [`unstructured-api` repo](https://github.com/Unstructured-IO/unstructured-api)to get started making API calls.You’ll also find instructions there about how to host your own version of the API.## :eight_pointed_black_star: Quick StartUse the following instructions to get up and running with `unstructured` and test yourinstallation. NOTE: We do not currently support python 3.11, please use an older version.- Install the Python SDK with `pip install &quot;unstructured[local-inference]&quot;`- If you do not need to process PDFs or images, you can run `pip install unstructured`- Install the following system dependencies if they are not already available on your system.  Depending on what document types you're parsing, you may not need all of these.    - `libmagic-dev` (filetype detection)    - `poppler-utils` (images and PDFs)    - `tesseract-ocr` (images and PDFs)    - `libreoffice` (MS Office docs)- If you are parsing PDFs and want to use a model from the [layoutparser model  zoo](https://github.com/Unstructured-IO/unstructured-inference#using-models-from-the-layoutparser-model-zoo),  use the instructions [here](https://github.com/Unstructured-IO/unstructured-inference#detectron2).At this point, you should be able to run the following code:```pythonfrom unstructured.partition.auto import partitionelements = partition(filename=&quot;example-docs/eml/fake-email.eml&quot;)print(&quot;\n\n&quot;.join([str(el) for el in elements]))```The following table shows the document types the `unstructured` library currently supports.`partition` will recognize each of these document types and route the document to theappropriate partitioning function. If you already know your document type, you can usethe partitioning function listed in the table directly.See our [documentation page](https://unstructured-io.github.io/unstructured/) for more detailsabout the library.| Document Type | Partition Function | Strategies | Table Support | Options || --- | --- | --- | --- | --- || CSV Files (`.csv`) | `partition_csv` | N/A | Yes | None || E-mails (`.eml`) | `partition_eml` | N/A | No | Encoding; Max Partition; Process Attachments || E-mails (`.msg`) | `partition_msg` | N/A | No | Encoding; Max Partition; Process Attachments || EPubs (`.epub`) | `partition_epub` | N/A | Yes | Include Page Breaks || Excel Documents (`.xlsx`/`.xls`) | `partition_xlsx` | N/A | Yes | None || HTML Pages (`.html`) | `partition_html` | N/A | No | Encoding; Include Page Breaks || Images (`.png`/`.jpg`) | `partition_image` | `&quot;auto&quot;`, `&quot;hi_res&quot;`, `&quot;ocr_only&quot;` | Yes | Encoding; Include Page Breaks; Infer Table Structure; OCR Languages, Strategy || Markdown (`.md`) | `partitin_md` | N/A | Yes | Include Page Breaks || Org Mode (`.org`) | `partition_org` | N/A | Yes | Include Page Breaks || Open Office Documents (`.odt`) | `partition_odt` | N/A | Yes | None || PDFs (`.pdf`) | `partition_pdf` | `&quot;auto&quot;`, `&quot;fast&quot;`, `&quot;hi_res&quot;`, `&quot;ocr_only&quot;` | Yes | Encoding; Include Page Breaks; Infer Table Structure; Max Partition; OCR Languages, Strategy || Plain Text (`.txt`) | `partition_text` | N/A | No | Encoding; Max Partition; Paragraph Grouper || Power Points (`.ppt`) | `partition_ppt` | N/A | Yes | Include Page Breaks || Power Points (`.pptx`) | `partition_pptx` | N/A | Yes | Include Page Breaks || ReStructured Text (`.rst`) | `partition_rst` | N/A | Yes | Include Page Breaks || Rich Text Files (`.rtf`) | `partition_rtf` | N/A | Yes | Include Page Breaks || TSV Files (`.tsv`) | `partition_tsv` | N/A | Yes | None || Word Documents (`.doc`) | `partition_doc` | N/A | Yes | None || Word Documents (`.docx`) | `partition_docx` | N/A | Yes | None || Word Documents (`.doc`) | `partition_doc` | N/A | Yes | Include Page Breaks || Word Documents (`.docx`) | `partition_docx` | N/A | Yes | Include Page Breaks || XML Documents (`.xml`) | `partition_xml` | N/A | No | Encoding; Max Partition; XML Keep Tags |## :dizzy: Instructions for using the docker imageThe following instructions are intended to help you get up and running using Docker to interact with `unstructured`.See [here](https://docs.docker.com/get-docker/) if you don't already have docker installed on your machine.NOTE: we build multi-platform images to support both x86_64 and Apple silicon hardware. `docker pull` should download the corresponding image for your architecture, but you can specify with `--platform` (e.g. `--platform linux/amd64`) if needed.We build Docker images for all pushes to `main`. We tag each image with the corresponding short commit hash (e.g. `fbc7a69`) and the application version (e.g. `0.5.5-dev1`). We also tag the most recent image with `latest`. To leverage this, `docker pull` from our image repository.```bashdocker pull quay.io/unstructured-io/unstructured:latest```Once pulled, you can create a container from this image and shell to it.```bash# create the containerdocker run -dt --name unstructured quay.io/unstructured-io/unstructured:latest# this will drop you into a bash shell where the Docker image is runningdocker exec -it unstructured bash```You can also build your own Docker image.If you only plan on parsing one type of data you can speed up building the image by commenting out someof the packages/requirements necessary for other data types. See Dockerfile to know which lines are necessaryfor your use case.```bashmake docker-build# this will drop you into a bash shell where the Docker image is runningmake docker-start-bash```Once in the running container, you can try things out directly in Python interpreter's interactive mode.```bash# this will drop you into a python console so you can run the below partition functionspython3&gt;&gt;&gt; from unstructured.partition.pdf import partition_pdf&gt;&gt;&gt; elements = partition_pdf(filename=&quot;example-docs/layout-parser-paper-fast.pdf&quot;)&gt;&gt;&gt; from unstructured.partition.text import partition_text&gt;&gt;&gt; elements = partition_text(filename=&quot;example-docs/fake-text.txt&quot;)```## :coffee: Installation Instructions for Local DevelopmentThe following instructions are intended to help you get up and running with `unstructured`locally if you are planning to contribute to the project.* Using `pyenv` to manage virtualenv's is recommended but not necessary* Mac install instructions. See [here](https://github.com/Unstructured-IO/community#mac--homebrew) for more detailed instructions.* `brew install pyenv-virtualenv`  * `pyenv install 3.8.17`  * Linux instructions are available [here](https://github.com/Unstructured-IO/community#linux).* Create a virtualenv to work in and activate it, e.g. for one named `unstructured`:`pyenv  virtualenv 3.8.17 unstructured` &lt;br /&gt;`pyenv activate unstructured`* Run `make install`* Optional:  * To install models and dependencies for processing images and PDFs locally, run `make install-local-inference`.  * For processing image files, `tesseract` is required. See [here](https://tesseract-ocr.github.io/tessdoc/Installation.html) for installation instructions.  * For processing PDF files, `tesseract` and `poppler` are required. The [pdf2image docs](https://pdf2image.readthedocs.io/en/latest/installation.html) have instructions on installing `poppler` across various platforms.Additionally, if you're planning to contribute to `unstructured`, we provide you an optional `pre-commit` configurationfile to ensure your code matches the formatting and linting standards used in `unstructured`.If you'd prefer not having code changes auto-tidied before every commit, you can use  `make check` to seewhether any linting or formatting changes should be applied, and `make tidy` to apply them.If using the optional `pre-commit`, you'll just need to install the hooks with `pre-commit install` since the`pre-commit` package is installed as part of `make install` mentioned above. Finally, if you decided to use `pre-commit`you can also uninstall the hooks with `pre-commit uninstall`.## :clap: Quick TourYou can run this [Colab notebook](https://colab.research.google.com/drive/1U8VCjY2-x8c6y5TYMbSFtQGlQVFHCVIW) to run the examples below.The following examples show how to get started with the `unstructured` library.You can parse over a dozen document types with one line of code!&lt;br&gt;&lt;/br&gt;See our [documentation page](https://unstructured-io.github.io/unstructured) for a full descriptionof the features in the library.### Document ParsingThe easiest way to parse a document in unstructured is to use the `partition` brick. If youuse `partition` brick, `unstructured` will detect the file type and route it to the appropriatefile-specific partitioning brick.If you are using the `partition` brick, you may need to install additional parameters via `pip install unstructured[local-inference]`. Ensure you first install `libmagic` using theinstructions outlined [here](https://unstructured-io.github.io/unstructured/installing.html#filetype-detection)`partition` will always apply the default arguments. If you needadvanced features, use a document-specific brick.See the table above for a full list of document types supported in the library.```pythonfrom unstructured.partition.auto import partitionelements = partition(&quot;example-docs/layout-parser-paper.pdf&quot;)```Run `print(&quot;\n\n&quot;.join([str(el) for el in elements]))` to get a string representation of theoutput, which looks like:```LayoutParser : A Uniﬁed Toolkit for Deep Learning Based Document Image AnalysisZejiang Shen 1 ( (cid:0) ), Ruochen Zhang 2 , Melissa Dell 3 , Benjamin Charles Germain Lee 4 , Jacob Carlson 3 , andWeining Li 5Abstract. Recent advances in document image analysis (DIA) have been primarily driven by the application of neuralnetworks. Ideally, research outcomes could be easily deployed in production and extended for further investigation.However, various factors like loosely organized codebases and sophisticated model conﬁgurations complicate the easyreuse of im- portant innovations by a wide audience. Though there have been on-going eﬀorts to improve reusability andsimplify deep learning (DL) model development in disciplines like natural language processing and computer vision, noneof them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIAis central to academic research across a wide range of disciplines in the social sciences and humanities. This paperintroduces LayoutParser , an open-source library for streamlining the usage of DL in DIA research and applica- tions.The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL modelsfor layout de- tection, character recognition, and many other document processing tasks. To promote extensibility,LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zationpipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines inreal-word use cases. The library is publicly available at https://layout-parser.github.ioKeywords: Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library ·Toolkit.IntroductionDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasksincluding document image classiﬁcation [11,```See the [partitioning](https://unstructured-io.github.io/unstructured/bricks.html#partitioning)section in our documentation for a full list of options and instructions on how to usefile-specific partitioning functions.## :guardsman: Security PolicySee our [security policy](https://github.com/Unstructured-IO/unstructured/security/policy) forinformation on how to report security vulnerabilities.## :books: Learn more| Section | Description ||-|-|| [Company Website](https://unstructured.io) | Unstructured.io product and company info || [Documentation](https://unstructured-io.github.io/unstructured) | Full API documentation || [Batch Processing](Ingest.md) | Ingesting batches of documents through Unstructured |</longdescription>
</pkgmetadata>