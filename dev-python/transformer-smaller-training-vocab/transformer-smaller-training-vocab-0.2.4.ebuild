# automatically generated by g-sorcery
# please do not edit this file

EAPI=8

REALNAME="${PN}"
REALVERSION="${PV}"
DIGEST_SOURCES="yes"
PYTHON_COMPAT=( python{3_10,3_11,3_12} )
DISTUTILS_USE_PEP517=standalone

inherit python-r1 gs-pypi

DESCRIPTION="Temporary remove unused tokens during training to save ram and speed."

HOMEPAGE="https://github.com/helpmefindaname/transformer-smaller-training-vocab"
LICENSE="MIT"
SRC_URI="https://files.pythonhosted.org/packages/4f/1b/22119b86eefc153bae07298a19b24ab8b8f3bcb2c64f200a788d4beb8718/transformer_smaller_training_vocab-${REALVERSION}.tar.gz"
SOURCEFILE="transformer_smaller_training_vocab-${REALVERSION}.tar.gz"
RESTRICT="test"

SLOT="0"
KEYWORDS="~amd64 ~x86"

IUSE=""
DEPENDENCIES="dev-python/datasets[${PYTHON_USEDEP}]
	dev-python/transformers[${PYTHON_USEDEP}]
	dev-python/torch[${PYTHON_USEDEP}]
	dev-python/sentencepiece[${PYTHON_USEDEP}]"
BDEPEND="${DEPENDENCIES}"
RDEPEND="${DEPENDENCIES}"
