<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># gs-chunked-io: Streams for Google Storage_gs-chunked-io_ provides transparently chunked io streams for google storage objects.Writable streams are managed as multipart objects, composed when the stream is closed.IO opperations are concurrent by default. The number of concurrent threads can be adjusted using the `threads`parameter, or disabled entirely with `threads=None`.```import gs_chunked_io as gsciofrom google.cloud.storage import Clientclient = Client()bucket = client.bucket(&quot;my-bucket&quot;)blob = bucket.get_blob(&quot;my-key&quot;)# Readable stream:with gscio.Reader(blob) as fh:    fh.read(size)# Writable stream:with gscio.Writer(&quot;my_new_key&quot;, bucket) as fh:    fh.write(data)# Process blob in chunks:for chunk in gscio.for_each_chunk(blob):    my_chunk_processor(chunk)# Multipart copy with processing:dst_bucket = client.bucket(&quot;my_dest_bucket&quot;)with gscio.Writer(&quot;my_dest_key&quot;, dst_bucket) as writer:    for chunk in gscio.for_each_chunk(blob)    process_my_chunk(chunk)    writer(chunk)# Extract .tar.gz on the fly:import gzipimport tarfilewith gscio.Reader(blob) as fh:    gzip_reader = gzip.GzipFile(fileobj=fh)    tf = tarfile.TarFile(fileobj=gzip_reader)    for tarinfo in tf:        process_my_tarinfo(tarinfo)```## Installation```pip install gs-chunked-io```## LinksProject home page [GitHub](https://github.com/xbrianh/gs-chunked-io)  Package distribution [PyPI](https://pypi.org/project/gs-chunked-io/)### BugsPlease report bugs, issues, feature requests, etc. on [GitHub](https://github.com/xbrianh/gs-chunked-io).![](https://travis-ci.org/xbrianh/gs-chunked-io.svg?branch=master) ![](https://badge.fury.io/py/gs-chunked-io.svg)</longdescription>
</pkgmetadata>