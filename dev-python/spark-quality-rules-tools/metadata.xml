<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># spark_quality_rules_tools[![Github License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)[![Updates](https://pyup.io/repos/github/woctezuma/google-colab-transfer/shield.svg)](pyup)[![Python 3](https://pyup.io/repos/github/woctezuma/google-colab-transfer/python-3-shield.svg)](pyup)[![Code coverage](https://codecov.io/gh/woctezuma/google-colab-transfer/branch/master/graph/badge.svg)](codecov)spark_quality_rules_tools is a Python library that implements quality rules in sandbox## InstallationThe code is packaged for PyPI, so that the installation consists in running:## Usagewrapper run hammurabies## Sandbox## Installation```sh!yes| pip uninstall spark-quality-rules-tools``````shpip install spark-quality-rules-tools --user --upgrade```## IMPORTS```shimport osimport pysparkfrom spark_quality_rules_tools import dq_path_workspacefrom spark_quality_rules_tools import dq_download_jarfrom spark_quality_rules_tools import dq_spark_sessionfrom spark_quality_rules_tools import dq_extract_parametersfrom spark_quality_rules_tools import dq_run_sandboxfrom spark_quality_rules_tools import dq_validate_conffrom spark_quality_rules_tools import dq_validate_rulesfrom spark_quality_rules_tools import show_spark_dfpyspark.sql.dataframe.DataFrame.show2 = show_spark_df```## Variables```shproject_sda=&quot;SDA_37036&quot;url_conf = &quot;http://artifactory-gdt.central-02.nextgen.igrupobbva/artifactory/gl-datio-spark-libs-maven-local/com/datiobd/cdd-hammurabi/4.0.9/DQ_LOCAL_CONFS/KCOG/KCOG_branch_MRField.conf&quot;```## Creating Workspace```shdq_path_workspace(project_sda=project_sda)```## Download haas jar```shdq_download_jar(haas_version=&quot;4.8.0&quot;, force=True)```## Spark Session```shspark, sc = dq_spark_session()```## Validate Conf```shdq_validate_conf(url_conf=url_conf)```## Extract Params```shdq_extract_parameters(url_conf=url_conf)```## Json params```shparameter_conf_list = [ {          &quot;ARTIFACTORY_UNIQUE_CACHE&quot;: &quot;http://artifactory-gdt.central-02.nextgen.igrupobbva&quot;,    &quot;ODATE_DATE&quot;: &quot;2022-11-11&quot;,    &quot;COUNTRY_ID&quot;: &quot;PE&quot;,    &quot;SCHEMA_PATH&quot;: &quot;t_kcog_branch.output.schema&quot;,    &quot;CUTOFF_DATE&quot;: &quot;2022-11-11&quot;,    &quot;SCHEMAS_REPOSITORY&quot;: &quot;gl-datio-da-generic-local/schemas/pe/kcog/master/t_kcog_branch/latest/&quot; }]```## Run ```shdq_run_sandbox(spark=spark,               sc=sc,               parameter_conf_list=parameter_conf_list,               url_conf=url_conf)```               ```sh         df = spark.read.csv(&quot;file:/var/sds/homes/P030772/workspace/data_quality_rules/data_reports/KCOG/KCOG_BRANCH_MRFIELD_202304120046_20221111.csv&quot;,                     header=True)                 df.show2(100)```## Run ```shdq_validate_rules(url_conf=url_conf)```## License[Apache License 2.0](https://www.dropbox.com/s/8t6xtgk06o3ij61/LICENSE?dl=0).## New features v1.0## BugFix- choco install visualcpp-build-tools## Reference- Jonathan Quiza [github](https://github.com/jonaqp).- Jonathan Quiza [RumiMLSpark](http://rumi-ml.herokuapp.com/).</longdescription>
</pkgmetadata>