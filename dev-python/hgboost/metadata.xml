<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># hgboost - Hyperoptimized Gradient Boosting[![Python](https://img.shields.io/pypi/pyversions/hgboost)](https://img.shields.io/pypi/pyversions/hgboost)[![PyPI Version](https://img.shields.io/pypi/v/hgboost)](https://pypi.org/project/hgboost/)[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/erdogant/hgboost/blob/master/LICENSE)[![Github Forks](https://img.shields.io/github/forks/erdogant/hgboost.svg)](https://github.com/erdogant/hgboost/network)[![GitHub Open Issues](https://img.shields.io/github/issues/erdogant/hgboost.svg)](https://github.com/erdogant/hgboost/issues)[![Project Status](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)[![Downloads](https://pepy.tech/badge/hgboost/month)](https://pepy.tech/project/hgboost/month)[![Downloads](https://pepy.tech/badge/hgboost)](https://pepy.tech/project/hgboost)[![DOI](https://zenodo.org/badge/257025146.svg)](https://zenodo.org/badge/latestdoi/257025146)[![Sphinx](https://img.shields.io/badge/Sphinx-Docs-Green)](https://erdogant.github.io/hgboost/)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://erdogant.github.io/hgboost/pages/html/Documentation.html#colab-classification-notebook)[![Medium](https://img.shields.io/badge/Medium-Blog-green)](https://erdogant.github.io/hgboost/pages/html/Documentation.html#medium-blog)&lt;!---[![BuyMeCoffee](https://img.shields.io/badge/buymea-coffee-yellow.svg)](https://www.buymeacoffee.com/erdogant)--&gt;&lt;!---[![Coffee](https://img.shields.io/badge/coffee-black-grey.svg)](https://erdogant.github.io/donate/?currency=USD&amp;amount=5)--&gt;--------------------------------------------------------------------``hgboost`` is short for **Hyperoptimized Gradient Boosting** and is a python package for hyperparameter optimization for *xgboost*, *catboost* and *lightboost* using cross-validation, and evaluating the results on an independent validation set.``hgboost`` can be applied for classification and regression tasks.``hgboost`` is fun because:    * 1. Hyperoptimization of the Parameter-space using bayesian approach.    * 2. Determines the best scoring model(s) using k-fold cross validation.    * 3. Evaluates best model on independent evaluation set.    * 4. Fit model on entire input-data using the best model.    * 5. Works for classification and regression    * 6. Creating a super-hyperoptimized model by an ensemble of all individual optimized models.    * 7. Return model, space and test/evaluation results.    * 8. Makes insightful plots.--------------------------------------------------------------------**⭐️ Star this repo if you like it ⭐️**--------------------------------------------------------------------### BlogsMedium Blog 1: [The Best Boosting Model using Bayesian Hyperparameter Tuning but without Overfitting.](https://erdogant.github.io/hgboost/pages/html/Documentation.html#medium-blog)Medium Blog 2: [Create Explainable Gradient Boosting Classification models using Bayesian Hyperparameter Optimization.](https://erdogant.github.io/hgboost/pages/html/Documentation.html#medium-blog)--------------------------------------------------------------------### [Documentation pages](https://erdogant.github.io/hgboost/)On the [documentation pages](https://erdogant.github.io/hgboost/) you can find detailed information about the working of the ``hgboost`` with many examples. --------------------------------------------------------------------## Colab Notebooks* &lt;a href=&quot;https://erdogant.github.io/hgboost/pages/html/Documentation.html#colab-regression-notebook&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open regression example In Colab&quot;/&gt; &lt;/a&gt; Regression example * &lt;a href=&quot;https://erdogant.github.io/hgboost/pages/html/Documentation.html#colab-classification-notebook&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open classification example In Colab&quot;/&gt; &lt;/a&gt; Classification example --------------------------------------------------------------------### Schematic overview of hgboost&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/schematic_overview.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;### Installation Environment```pythonconda create -n env_hgboost python=3.8conda activate env_hgboost```### Install from pypi```bashpip install hgboostpip install -U hgboost # Force update```#### Import hgboost package```pythonimport hgboost as hgboost```#### Examples* [Example: Fit catboost by hyperoptimization and cross-validation](https://erdogant.github.io/hgboost/pages/html/Examples.html#catboost)#* [Example: Fit lightboost by hyperoptimization and cross-validation](https://erdogant.github.io/hgboost/pages/html/Examples.html#lightboost)#* [Example: Fit xgboost by hyperoptimization and cross-validation](https://erdogant.github.io/hgboost/pages/html/Examples.html#xgboost-two-class)#* [Example: Plot searched parameter space](https://erdogant.github.io/hgboost/pages/html/Examples.html#plot-params)&lt;p align=&quot;left&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_params_clf_1.png&quot; width=&quot;400&quot; /&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_params_clf_2.png&quot; width=&quot;400&quot; /&gt;  &lt;/a&gt;&lt;/p&gt;#* [Example: plot summary](https://erdogant.github.io/hgboost/pages/html/Examples.html#plot-summary)&lt;p align=&quot;left&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_clf.png&quot; width=&quot;600&quot; /&gt;  &lt;/a&gt;&lt;/p&gt;#* [Example: Tree plot](https://erdogant.github.io/hgboost/pages/html/Examples.html#treeplot)&lt;p align=&quot;left&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/treeplot_clf_1.png&quot; width=&quot;400&quot; /&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/treeplot_clf_2.png&quot; width=&quot;400&quot; /&gt;  &lt;/a&gt;&lt;/p&gt;#* [Example: Plot the validation results](https://erdogant.github.io/hgboost/pages/html/Examples.html#plot-validation)&lt;p align=&quot;left&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_validation_clf_1.png&quot; width=&quot;600&quot; /&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_validation_clf_2.png&quot; width=&quot;400&quot; /&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_validation_clf_3.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;#* [Example: Plot the cross-validation results](https://erdogant.github.io/hgboost/pages/html/Examples.html#plot-cv)&lt;p align=&quot;left&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_cv_clf.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;#* [Example: use the learned model to make new predictions](https://erdogant.github.io/hgboost/pages/html/hgboost.hgboost.html?highlight=predict#hgboost.hgboost.hgboost.predict)#* [Example: Create ensemble model for Classification](https://erdogant.github.io/hgboost/pages/html/Examples.html#ensemble-classification)#* [Example: Create ensemble model for Regression](https://erdogant.github.io/hgboost/pages/html/Examples.html#ensemble-regression)##### Classification example for xgboost, catboost and lightboost:```python# Load libraryfrom hgboost import hgboost# Initializationhgb = hgboost(max_eval=10, threshold=0.5, cv=5, test_size=0.2, val_size=0.2, top_cv_evals=10, random_state=42)# Fit xgboost by hyperoptimization and cross-validationresults = hgb.xgboost(X, y, pos_label='survived')# [hgboost] &gt;Start hgboost classification..# [hgboost] &gt;Collecting xgb_clf parameters.# [hgboost] &gt;Number of variables in search space is [11], loss function: [auc].# [hgboost] &gt;method: xgb_clf# [hgboost] &gt;eval_metric: auc# [hgboost] &gt;greater_is_better: True# [hgboost] &gt;pos_label: True# [hgboost] &gt;Total dataset: (891, 204) # [hgboost] &gt;Hyperparameter optimization..#  100% |----| 500/500 [04:39&lt;05:21,  1.33s/trial, best loss: -0.8800619834710744]# [hgboost] &gt;Best performing [xgb_clf] model: auc=0.881198# [hgboost] &gt;5-fold cross validation for the top 10 scoring models, Total nr. tests: 50# 100%|██████████| 10/10 [00:42&lt;00:00,  4.27s/it]# [hgboost] &gt;Evalute best [xgb_clf] model on independent validation dataset (179 samples, 20.00%).# [hgboost] &gt;[auc] on independent validation dataset: -0.832# [hgboost] &gt;Retrain [xgb_clf] on the entire dataset with the optimal parameters settings.``````python# Plot the ensemble classification validation resultshgb.plot_validation()```&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_ensemble_clf_1.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_ensemble_clf_2.png&quot; width=&quot;400&quot; /&gt;  &lt;img src=&quot;https://github.com/erdogant/hgboost/blob/master/docs/figs/plot_ensemble_clf_3.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;&lt;hr&gt;**References**    * http://hyperopt.github.io/hyperopt/    * https://github.com/dmlc/xgboost    * https://github.com/microsoft/LightGBM    * https://github.com/catboost/catboost    **Maintainers*** Erdogan Taskesen, github: [erdogant](https://github.com/erdogant)**Contribute*** Contributions are welcome.**Licence**See [LICENSE](LICENSE) for details.**Coffee*** If you wish to buy me a &lt;a href=&quot;https://www.buymeacoffee.com/erdogant&quot;&gt;Coffee&lt;/a&gt; for this work, it is very appreciated :)</longdescription>
</pkgmetadata>