<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;docs/img/jumanji_logo.png&quot;&gt;        &lt;img src=&quot;docs/img/jumanji_logo.png&quot; alt=&quot;Jumanji logo&quot; width=&quot;50%&quot;/&gt;    &lt;/a&gt;&lt;/p&gt;[![Python Versions](https://img.shields.io/pypi/pyversions/jumanji.svg?style=flat-square)](https://www.python.org/doc/versions/)[![PyPI Version](https://badge.fury.io/py/jumanji.svg)](https://badge.fury.io/py/jumanji)[![Tests](https://github.com/instadeepai/jumanji/actions/workflows/tests_linters.yml/badge.svg)](https://github.com/instadeepai/jumanji/actions/workflows/tests_linters.yml)[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)[![MyPy](http://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)[![License](https://img.shields.io/badge/License-Apache%202.0-orange.svg)](https://opensource.org/licenses/Apache-2.0)[**Environments**](#environments-)| [**Installation**](#installation-)| [**Quickstart**](#quickstart-)| [**Training**](#training-%EF%B8%8F)| [**Citation**](#citing-jumanji-%EF%B8%8F)| [**Docs**](https://instadeepai.github.io/jumanji)---&lt;p float=&quot;left&quot; align=&quot;center&quot;&gt;  &lt;img src=&quot;docs/env_anim/connector.gif&quot; alt=&quot;Connector&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/snake.gif&quot; alt=&quot;Snake&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/cleaner.gif&quot; alt=&quot;Cleaner&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/job_shop.gif&quot; alt=&quot;JobShop&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/bin_pack.gif&quot; alt=&quot;BinPack&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/cvrp.gif&quot; alt=&quot;CVRP&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/rubiks_cube.gif&quot; alt=&quot;RubiksCube&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/game_2048.gif&quot; alt=&quot;Game2048&quot; width=&quot;30%&quot; /&gt;  &lt;img src=&quot;docs/env_anim/minesweeper.gif&quot; alt=&quot;Minesweeper&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;## Welcome to the Jungle! üå¥Jumanji is a suite of diverse and challenging reinforcement learning (RL) environments written inJAX.Jumanji is helping pioneer a new wave of hardware-accelerated research and development in thefield of RL. Jumanji's high-speed environments enable faster iteration and large-scaleexperimentation while simultaneously reducing complexity. Originating in the Research Team at[InstaDeep](https://www.instadeep.com/), Jumanji is now developed jointly with the open-sourcecommunity. To join us in these efforts, reach out, raise issues and read our[contribution guidelines](https://github.com/instadeepai/jumanji/blob/main/CONTRIBUTING.md) or just[star](https://github.com/instadeepai/jumanji) üåü to stay up to date with the latest developments!### Goals üöÄ1. Provide a simple, well-tested API for JAX-based environments.2. Make research in RL more accessible.3. Facilitate the research on RL for problems in the industry and help close the gap betweenresearch and industrial applications.4. Provide environments whose difficulty can be scaled to be arbitrarily hard.### Overview ü¶ú- ü•ë **Environment API**: core abstractions for JAX-based environments.- üïπÔ∏è **Environment Suite**: a collection of RL environments ranging from simple games to NP-hardcombinatorial problems.- üç¨ **Wrappers**: easily connect to your favourite RL frameworks and libraries such as[Acme](https://github.com/deepmind/acme),[Stable Baselines3](https://github.com/DLR-RM/stable-baselines3),[RLlib](https://docs.ray.io/en/latest/rllib/index.html), [OpenAI Gym](https://github.com/openai/gym)and [DeepMind-Env](https://github.com/deepmind/dm_env) through our `dm_env` and `gym` wrappers.- üéì **Examples**: guides to facilitate Jumanji's adoption and highlight the added value ofJAX-based environments.- üèéÔ∏è **Training:** example agents that can be used as inspiration for the agents one may implementin their research.## Environments üåçJumanji provides a diverse range of environments ranging from simple games to NP-hard combinatorialproblems.| Environment                              | Category | Registered Version(s)                                | Source                                                                                           | Description                                                            ||------------------------------------------|----------|------------------------------------------------------|--------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|| üî¢ Game2048                              | Logic  | `Game2048-v0`                                        | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/logic/game_2048/)   | [doc](https://instadeepai.github.io/jumanji/environments/game_2048/)   || üí£ Minesweeper                           | Logic    | `Minesweeper-v0`                                     | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/logic/minesweeper/) | [doc](https://instadeepai.github.io/jumanji/environments/minesweeper/) || üé≤ RubiksCube                            | Logic    | `RubiksCube-v0`&lt;br/&gt;`RubiksCube-partly-scrambled-v0` | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/logic/rubiks_cube/) | [doc](https://instadeepai.github.io/jumanji/environments/rubiks_cube/) || üì¶ BinPack (3D BinPacking Problem)       | Packing  | `BinPack-v1`                                         | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/packing/bin_pack/)  | [doc](https://instadeepai.github.io/jumanji/environments/bin_pack/)    || üè≠ JobShop (Job Shop Scheduling Problem) | Packing  | `JobShop-v0`                                         | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/packing/job_shop/)  | [doc](https://instadeepai.github.io/jumanji/environments/job_shop/)    || üéí Knapsack                              | Packing  | `Knapsack-v1`                                        | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/packing/knapsack/)  | [doc](https://instadeepai.github.io/jumanji/environments/knapsack/)    || üßπ Cleaner                               | Routing  | `Cleaner-v0`                                         | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/routing/cleaner/)   | [doc](https://instadeepai.github.io/jumanji/environments/cleaner/)     || :link: Connector                         | Routing  | `Connector-v0`                                       | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/routing/connector/) | [doc](https://instadeepai.github.io/jumanji/environments/connector/)   || üöö CVRP (Capacitated Vehicle Routing Problem)  | Routing  | `CVRP-v1`                                            | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/routing/cvrp/)      | [doc](https://instadeepai.github.io/jumanji/environments/cvrp/)        || :mag: Maze   | Routing  | `Maze-v0`                                            | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/routing/maze/)      | [doc](https://instadeepai.github.io/jumanji/environments/maze/)        || üêç Snake                                       | Routing  | `Snake-v1`                                           | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/routing/snake/)     | [doc](https://instadeepai.github.io/jumanji/environments/snake/)       || üì¨ TSP (Travelling Salesman Problem)           | Routing  | `TSP-v1`                                             | [code](https://github.com/instadeepai/jumanji/tree/main/jumanji/environments/routing/tsp/)       | [doc](https://instadeepai.github.io/jumanji/environments/tsp/)         |## Installation üé¨You can install the latest release of Jumanji from PyPI:```bashpip install jumanji```Alternatively, you can install the latest development version directly from GitHub:```bashpip install git+https://github.com/instadeepai/jumanji.git```Jumanji has been tested on Python 3.8 and 3.9.Note that because the installation of JAX differs depending on your hardware accelerator,we advise users to explicitly install the correct JAX version (see the[official installation guide](https://github.com/google/jax#installation)).**Rendering:** Matplotlib is used for rendering all the environments. To visualize the environmentsyou will need a GUI backend. For example, on Linux, you can install Tk via:`apt-get install python3-tk`, or using conda: `conda install tk`. Check out[Matplotlib backends](https://matplotlib.org/stable/users/explain/backends.html) for a list ofbackends you can use.## Quickstart ‚ö°RL practitioners will find Jumanji's interface familiar as it combines the widely adopted[OpenAI Gym](https://github.com/openai/gym) and[DeepMind Environment](https://github.com/deepmind/dm_env) interfaces. From OpenAI Gym, we adoptedthe idea of a `registry` and the `render` method, while our `TimeStep` structure is inspired byDeepMind Environment.### Basic Usage üßëüíª```pythonimport jaximport jumanji# Instantiate a Jumanji environment using the registryenv = jumanji.make('Snake-v1')# Reset your (jit-able) environmentkey = jax.random.PRNGKey(0)state, timestep = jax.jit(env.reset)(key)# (Optional) Render the env stateenv.render(state)# Interact with the (jit-able) environmentaction = env.action_spec().generate_value()          # Action selection (dummy value here)state, timestep = jax.jit(env.step)(state, action)   # Take a step and observe the next state and time step```- `state` represents the internal state of the environment: it contains all the information requiredto take a step when executing an action. This should **not** be confused with the `observation`contained in the `timestep`, which is the information perceived by the agent.- `timestep` is a dataclass containing `step_type`, `reward`, `discount`, `observation` and`extras`. This structure is similar to[`dm_env.TimeStep`](https://github.com/deepmind/dm_env/blob/master/docs/index.md) except for the`extras` field that was added to allow users to log environments metrics that are neither part ofthe agent's observation nor part of the environment's internal state.### Advanced Usage üßëüî¨Being written in JAX, Jumanji's environments benefit from many of its features includingautomatic vectorization/parallelization (`jax.vmap`, `jax.pmap`) and JIT-compilation (`jax.jit`),which can be composed arbitrarily.We provide an example of a more advanced usage in the[advanced usage guide](https://instadeepai.github.io/jumanji/guides/advanced_usage/).### Registry and Versioning üìñLike OpenAI Gym, Jumanji keeps a strict versioning of its environments for reproducibility reasons.We maintain a registry of standard environments with their configuration.For each environment, a version suffix is appended, e.g. `Snake-v1`.When changes are made to environments that might impact learning results,the version number is incremented by one to prevent potential confusion.For a full list of registered versions of each environment, check out[the documentation](https://instadeepai.github.io/jumanji/environments/tsp/).## Training üèéÔ∏èTo showcase how to train RL agents on Jumanji environments, we provide a random agent and a vanillaactor-critic (A2C) agent. These agents can be found in[jumanji/training/](https://github.com/instadeepai/jumanji/tree/main/jumanji/training/).Because the environment framework in Jumanji is so flexible, it allows pretty much any problem tobe implemented as a Jumanji environment, giving rise to very diverse observations. For this reason,environment-specific networks are required to capture the symmetries of each environment.Alongside the A2C agent implementation, we provide examples of such environment-specificactor-critic networks in[jumanji/training/networks](https://github.com/instadeepai/jumanji/tree/main/jumanji/training/networks/).&gt; ‚ö†Ô∏è The example agents in `jumanji/training` are **only** meant to serve as inspiration for how one&gt; can implement an agent. Jumanji is first and foremost a library of environments - as such, the&gt; agents and networks will **not** be maintained to a production standard.For more information on how to use the example agents, see the[training guide](https://instadeepai.github.io/jumanji/guides/training/).## Contributing ü§ùContributions are welcome! See our issue tracker for[good first issues](https://github.com/instadeepai/jumanji/labels/good%20first%20issue). Please readour [contributing guidelines](https://github.com/instadeepai/jumanji/blob/main/CONTRIBUTING.md) fordetails on how to submit pull requests, our Contributor License Agreement, and community guidelines.## Citing Jumanji ‚úèÔ∏èIf you use Jumanji in your work, please cite the library using:```@software{jumanji2023github,  author = {Cl√©ment Bonnet and Daniel Luo and Donal Byrne and Sasha Abramowitz        and Vincent Coyette and Paul Duckworth and Daniel Furelos-Blanco and        Nathan Grinsztajn and Tristan Kalloniatis and Victor Le and Omayma Mahjoub        and Laurence Midgley and Shikha Surana and Cemlyn Waters and Alexandre Laterre},  title = {Jumanji: a Suite of Diverse and Challenging Reinforcement Learning Environments in JAX},  url = {https://github.com/instadeepai/jumanji},  version = {0.2.2},  year = {2023},}```## See Also üîéOther works have embraced the approach of writing RL environments in JAX.In particular, we suggest users check out the following sister repositories:- ü§ñ [Qdax](https://github.com/adaptive-intelligent-robotics/QDax) is a library to accelerateQuality-Diversity and neuro-evolution algorithms through hardware accelerators and parallelization.- üå≥ [Evojax](https://github.com/google/evojax) provides tools to enable neuroevolution algorithmsto work with neural networks running across multiple TPU/GPUs.- ü¶æ [Brax](https://github.com/google/brax) is a differentiable physics engine that simulatesenvironments made up of rigid bodies, joints, and actuators.- üèãÔ∏è [Gymnax](https://github.com/RobertTLange/gymnax) implements classic environments includingclassic control, bsuite, MinAtar and a collection of meta RL tasks.- üé≤ [Pgx](https://github.com/sotetsuk/pgx) provides classic board game environments likeBackgammon, Shogi, and Go.## Acknowledgements üôèThe development of this library was supported with Cloud TPUsfrom Google's [TPU Research Cloud](https://sites.research.google/trc/about/) (TRC) üå§.</longdescription>
</pkgmetadata>