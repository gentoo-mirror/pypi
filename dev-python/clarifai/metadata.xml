<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;h1 align=&quot;center&quot;&gt;  &lt;a href=&quot;https://www.clarifai.com/&quot;&gt;&lt;img alt=&quot;Clarifai&quot; title=&quot;Clarifai&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/b/bc/Clarifai_Logo_FC_Web.png&quot;&gt;&lt;/a&gt;&lt;/h1&gt;&lt;h2 align=&quot;center&quot;&gt;Clarifai Python SDK&lt;/a&gt;&lt;/h2&gt;&lt;p align=&quot;center&quot;&gt;  &lt;a href=&quot;https://discord.gg/M32V7a7a&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/discord-chat-green.svg?logo=discord&amp;color=4ec528&quot; alt=&quot;Discord&quot;&gt;  &lt;/a&gt;  &lt;a href=&quot;https://pypi.org/project/clarifai&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/pypi/dm/clarifai&quot; alt=&quot;PyPI - Downloads&quot;&gt;  &lt;/a&gt;&lt;/p&gt;This is the official Python client for interacting with our powerful [API](https://docs.clarifai.com). The Clarifai Python SDK offers a comprehensive set of tools to integrate Clarifai's AI platform to leverage computer vision capabilities like classification , detection ,segementation and natural language capabilities like classification , summarisation , generation , Q&amp;A ,etc into your applications. With just a few lines of code, you can leverage cutting-edge artificial intelligence to unlock valuable insights from visual and textual content.[Website](https://www.clarifai.com/) | [Demo](https://clarifai.com/demo) | [Signup for a Free Account](https://clarifai.com/signup) | [API Docs](https://docs.clarifai.com/) | [Clarifai Community](https://clarifai.com/explore) | [Python SDK Docs](https://docs.clarifai.com/python-sdk/api-reference) | [Examples](https://github.com/Clarifai/examples) | [Colab Notebooks](https://github.com/Clarifai/colab-notebooks)---## Table Of Contents* **[Installation](#rocket-installation)*** **[Getting Started](#memo-getting-started)*** **[Interacting with Datasets](#floppy_disk-interacting-with-datasets)*** **[Interacting with Inputs](#floppy_disk-interacting-with-inputs)**  * [Input Upload](#input-upload)  * [Input Listing](#input-listing)* **[Interacting with Models](#brain-interacting-with-models)**  * [Model Predict](#model-predict)  * [Model Listing](#models-listing)* **[Interacting with Workflows](#fire-interacting-with-workflows)**  * [Workflow Predict](#workflow-predict)  * [Workflow Listing](#workflows-listing)  * [Workflow Create](#workflow-create)  * [Workflow Export](#workflow-export)* **[More Examples](#pushpin-more-examples)**## :rocket: InstallationInstall from PyPi:```bashpip install -U clarifai```Install from Source:```bashgit clone https://github.com/Clarifai/clarifai-python.gitcd clarifai-pythonpython3 -m venv envsource env/bin/activatepip3 install -r requirements.txt```## :memo: Getting startedClarifai uses **Personal Access Tokens(PATs)** to validate requests. You can create and manage PATs under your Clarifai account security settings.* ðŸ”— [Create PAT:](https://docs.clarifai.com/clarifai-basics/authentication/personal-access-tokens/) ***Log into Portal &amp;rarr; Profile Icon &amp;rarr; Security Settings &amp;rarr; Create Personal Access Token &amp;rarr; Set the scopes &amp;rarr; Confirm**** ðŸ”— [Get User ID:](https://help.clarifai.com/hc/en-us/articles/4408131912727-How-do-I-find-my-user-id-app-id-and-PAT-) ***Log into Portal &amp;rarr; Profile Icon &amp;rarr; Account &amp;rarr; Profile &amp;rarr; User-ID***Export your PAT as an environment variable. Then, import and initialize the API Client.Set PAT as environment variable through terminal:```cmdexport CLARIFAI_PAT={your personal access token}``````python# Note: CLARIFAI_PAT must be set as env variable.from clarifai.client.user import Userclient = User(user_id=&quot;user_id&quot;)# Get all appsapps_generator = client.list_apps()apps = list(apps_generator)```## :floppy_disk: Interacting with DatasetsClarifai datasets help in managing datasets used for model training and evaluation. It provides functionalities like creating datasets,uploading datasets and exporting datasets as .zip files.```python# Note: CLARIFAI_PAT must be set as env variable.# Create app and datasetapp = client.create_app(app_id=&quot;demo_app&quot;, base_workflow=&quot;Universal&quot;)dataset = app.create_dataset(dataset_id=&quot;demo_dataset&quot;)# execute data upload to Clarifai app datasetdataset.upload_dataset(task='visual_segmentation', split=&quot;train&quot;, dataset_loader='coco_segmentation')#upload text from csvdataset.upload_from_csv(csv_path='csv_path', input_type='text', csv_type='raw', labels=True)#upload data from folderdataset.upload_from_folder(folder_path='folder_path', input_type='text', labels=True)# Export Datasetfrom clarifai.client.dataset import Dataset# Note: clarifai-data-protobuf.zip is acquired through exporting datasets within the Clarifai Platform.Dataset().export(save_path='output.zip', local_archive_path='clarifai-data-protobuf.zip')```## :floppy_disk: Interacting with InputsYou can use ***inputs()*** for adding and interacting with input data. Inputs can be uploaded directly from a URL or a file. You can also view input annotations and concepts.#### Input Upload```python# Note: CLARIFAI_PAT must be set as env variable.from clarifai.client.user import Userapp = User(user_id=&quot;user_id&quot;).app(app_id=&quot;app_id&quot;)input_obj = app.inputs()#input upload from urlinput_obj.upload_from_url(input_id = 'demo', image_url='https://samples.clarifai.com/metro-north.jpg')#input upload from filenameinput_obj.upload_from_file(input_id = 'demo', video_file='demo.mp4')# text uploadinput_obj.upload_text(input_id = 'demo', raw_text = 'This is a test')```#### Input Listing```python#listing inputsinput_generator = input_obj.list_inputs(page_no=1,per_page=10,input_type='image')inputs_list = list(input_generator)#listing annotationsannotation_generator = input_obj.list_annotations(batch_input=inputs_list)annotations_list = list(annotation_generator)#listing conceptsall_concepts = list(app.list_concepts())```## :brain: Interacting with ModelsThe **Model** Class allows you to perform predictions using Clarifai models. You can specify which model to use by providing the model URL or ID. This gives you flexibility in choosing models. The **App** Class also allows listing of all available Clarifai models for discovery.For greater control over model predictions, you can pass in an `output_config` to modify the model output as demonstrated below.#### Model Predict```python# Note: CLARIFAI_PAT must be set as env variable.from clarifai.client.model import Model&quot;&quot;&quot;Get Model information on details of model(description, usecases..etc) and info on training or# other inference parameters(eg: temperature, top_k, max_tokens..etc for LLMs)&quot;&quot;&quot;gpt_4_model = Model(&quot;https://clarifai.com/openai/chat-completion/models/GPT-4&quot;)print(gpt_4_model)# Model Predictmodel_prediction = Model(&quot;https://clarifai.com/anthropic/completion/models/claude-v2&quot;).predict_by_bytes(b&quot;Write a tweet on future of AI&quot;, input_type=&quot;text&quot;)# Customizing Model Inference Outputmodel_prediction = gpt_4_model.predict_by_bytes(b&quot;Write a tweet on future of AI&quot;, &quot;text&quot;, inference_params=dict(temperature=str(0.7), max_tokens=30))# Return predictions having prediction confidence &gt; 0.98model_prediction = model.predict_by_filepath(filepath=&quot;local_filepath&quot;, input_type, output_config={&quot;min_value&quot;: 0.98}) # Supports image, text, audio, video# Supports prediction by urlmodel_prediction = model.predict_by_url(url=&quot;url&quot;, input_type) # Supports image, text, audio, video# Return predictions for specified interval of videovideo_input_proto = [input_obj.get_input_from_url(&quot;Input_id&quot;, video_url=BEER_VIDEO_URL)]model_prediction = model.predict(video_input_proto, input_type=&quot;video&quot;, output_config={&quot;sample_ms&quot;: 2000})```#### Models Listing```python# Note: CLARIFAI_PAT must be set as env variable.# List all model versionsall_model_versions = list(model.list_versions())# Go to specific model versionmodel_v1 = client.app(&quot;app_id&quot;).model(model_id=&quot;model_id&quot;, model_version_id=&quot;model_version_id&quot;)# List all models in an appall_models = list(app.list_models())# List all models in community filtered by model_type, descriptionall_llm_community_models = App().list_models(filter_by={&quot;query&quot;: &quot;LLM&quot;,                                                        &quot;model_type_id&quot;: &quot;text-to-text&quot;}, only_in_app=False)all_llm_community_models = list(all_llm_community_models)```## :fire: Interacting with WorkflowsWorkflows offer a versatile framework for constructing the inference pipeline, simplifying the integration of diverse models. You can use the **Workflow** class to create and manage workflows using **YAML** configuration.For starting or making quick adjustments to existing Clarifai community workflows using an initial YAML configuration, the SDK provides an export feature.#### Workflow Predict```python# Note: CLARIFAI_PAT must be set as env variable.from clarifai.client.workflow import Workflow# Workflow Predictworkflow = Workflow(&quot;workflow_url&quot;) # Example: https://clarifai.com/clarifai/main/workflows/Face-Sentimentworkflow_prediction = workflow.predict_by_url(url=&quot;url&quot;, input_type=&quot;image&quot;) # Supports image, text, audio, video# Customizing Workflow Inference Outputworkflow = Workflow(user_id=&quot;user_id&quot;, app_id=&quot;app_id&quot;, workflow_id=&quot;workflow_id&quot;,                  output_config={&quot;min_value&quot;: 0.98}) # Return predictions having prediction confidence &gt; 0.98workflow_prediction = workflow.predict_by_filepath(filepath=&quot;local_filepath&quot;, input_type=&quot;text&quot;) # Supports image, text, audio, video```#### Workflows Listing```python# Note: CLARIFAI_PAT must be set as env variable.# List all workflow versionsall_workflow_versions = list(workflow.list_versions())# Go to specific workflow versionworkflow_v1 = Workflow(workflow_id=&quot;workflow_id&quot;, workflow_version=dict(id=&quot;workflow_version_id&quot;), app_id=&quot;app_id&quot;, user_id=&quot;user_id&quot;)# List all workflow in an appall_workflow = list(app.list_workflow())# List all workflow in community filtered by descriptionall_face_community_workflows = App().list_workflows(filter_by={&quot;query&quot;: &quot;face&quot;}, only_in_app=False) # Get all face related workflowsall_face_community_workflows = list(all_face_community_workflows)```#### Workflow CreateCreate a new workflow specified by a yaml config file.```python# Note: CLARIFAI_PAT must be set as env variable.from clarifai.client.app import Appapp = App(app_id=&quot;app_id&quot;, user_id=&quot;user_id&quot;)workflow = app.create_workflow(config_filepath=&quot;config.yml&quot;)```#### Workflow ExportExport an existing workflow from Clarifai as a local yaml file.```python# Note: CLARIFAI_PAT must be set as env variable.from clarifai.client.workflow import Workflowworkflow = Workflow(&quot;https://clarifai.com/clarifai/main/workflows/Demographics&quot;)workflow.export('demographics_workflow.yml')```## :pushpin: More ExamplesSee many more code examples in this [repo](https://github.com/Clarifai/examples).Also see the official [Python SDK docs](https://clarifai-python.readthedocs.io/en/latest/index.html)</longdescription>
</pkgmetadata>