<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># OpenAI Python LibraryThe OpenAI Python library provides convenient access to the OpenAI APIfrom applications written in the Python language. It includes apre-defined set of classes for API resources that initializethemselves dynamically from API responses which makes it compatiblewith a wide range of versions of the OpenAI API.You can find usage examples for the OpenAI Python library in our [API reference](https://beta.openai.com/docs/api-reference?lang=python) and the [OpenAI Cookbook](https://github.com/openai/openai-cookbook/).## InstallationYou don't need this source code unless you want to modify the package. If you justwant to use the package, just run:```shpip install --upgrade openai```Install from source with:```shpython setup.py install```### Optional dependenciesInstall dependencies for [`openai.embeddings_utils`](openai/embeddings_utils.py):```shpip install openai[embeddings]```Install support for [Weights &amp; Biases](https://wandb.me/openai-docs):```pip install openai[wandb]```Data libraries like `numpy` and `pandas` are not installed by default due to their size. They’re needed for some functionality of this library, but generally not for talking to the API. If you encounter a `MissingDependencyError`, install them with:```shpip install openai[datalib]```## UsageThe library needs to be configured with your account's secret key which is available on the [website](https://platform.openai.com/account/api-keys). Either set it as the `OPENAI_API_KEY` environment variable before using the library:```bashexport OPENAI_API_KEY='sk-...'```Or set `openai.api_key` to its value:```pythonimport openaiopenai.api_key = &quot;sk-...&quot;# list modelsmodels = openai.Model.list()# print the first model's idprint(models.data[0].id)# create a chat completionchat_completion = openai.ChatCompletion.create(model=&quot;gpt-3.5-turbo&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello world&quot;}])# print the chat completionprint(chat_completion.choices[0].message.content)```### ParamsAll endpoints have a `.create` method that supports a `request_timeout` param. This param takes a `Union[float, Tuple[float, float]]` and will raise an `openai.error.Timeout` error if the request exceeds that time in seconds (See: https://requests.readthedocs.io/en/latest/user/quickstart/#timeouts).### Microsoft Azure EndpointsIn order to use the library with Microsoft Azure endpoints, you need to set the `api_type`, `api_base` and `api_version` in addition to the `api_key`. The `api_type` must be set to 'azure' and the others correspond to the properties of your endpoint.In addition, the deployment name must be passed as the engine parameter.```pythonimport openaiopenai.api_type = &quot;azure&quot;openai.api_key = &quot;...&quot;openai.api_base = &quot;https://example-endpoint.openai.azure.com&quot;openai.api_version = &quot;2023-05-15&quot;# create a chat completionchat_completion = openai.ChatCompletion.create(deployment_id=&quot;deployment-name&quot;, model=&quot;gpt-3.5-turbo&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello world&quot;}])# print the completionprint(completion.choices[0].message.content)```Please note that for the moment, the Microsoft Azure endpoints can only be used for completion, embedding, and fine-tuning operations.For a detailed example of how to use fine-tuning and other operations using Azure endpoints, please check out the following Jupyter notebooks:- [Using Azure completions](https://github.com/openai/openai-cookbook/tree/main/examples/azure/completions.ipynb)- [Using Azure fine-tuning](https://github.com/openai/openai-cookbook/tree/main/examples/azure/finetuning.ipynb)- [Using Azure embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/azure/embeddings.ipynb)### Microsoft Azure Active Directory AuthenticationIn order to use Microsoft Active Directory to authenticate to your Azure endpoint, you need to set the `api_type` to &quot;azure_ad&quot; and pass the acquired credential token to `api_key`. The rest of the parameters need to be set as specified in the previous section.```pythonfrom azure.identity import DefaultAzureCredentialimport openai# Request credentialdefault_credential = DefaultAzureCredential()token = default_credential.get_token(&quot;https://cognitiveservices.azure.com/.default&quot;)# Setup parametersopenai.api_type = &quot;azure_ad&quot;openai.api_key = token.tokenopenai.api_base = &quot;https://example-endpoint.openai.azure.com/&quot;openai.api_version = &quot;2023-05-15&quot;# ...```### Command-line interfaceThis library additionally provides an `openai` command-line utilitywhich makes it easy to interact with the API from your terminal. Run`openai api -h` for usage.```sh# list modelsopenai api models.list# create a chat completion (gpt-3.5-turbo, gpt-4, etc.)openai api chat_completions.create -m gpt-3.5-turbo -g user &quot;Hello world&quot;# create a completion (text-davinci-003, text-davinci-002, ada, babbage, curie, davinci, etc.)openai api completions.create -m ada -p &quot;Hello world&quot;# generate images via DALL·E APIopenai api image.create -p &quot;two dogs playing chess, cartoon&quot; -n 1# using openai through a proxyopenai --proxy=http://proxy.com api models.list```## Example codeExamples of how to use this Python library to accomplish various tasks can be found in the [OpenAI Cookbook](https://github.com/openai/openai-cookbook/). It contains code examples for:- Classification using fine-tuning- Clustering- Code search- Customizing embeddings- Question answering from a corpus of documents- Recommendations- Visualization of embeddings- And morePrior to July 2022, this OpenAI Python library hosted code examples in its examples folder, but since then all examples have been migrated to the [OpenAI Cookbook](https://github.com/openai/openai-cookbook/).### Chat CompletionsConversational models such as `gpt-3.5-turbo` can be called using the chat completions endpoint.```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you choosecompletion = openai.ChatCompletion.create(model=&quot;gpt-3.5-turbo&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello world&quot;}])print(completion.choices[0].message.content)```### CompletionsText models such as `text-davinci-003`, `text-davinci-002` and earlier (`ada`, `babbage`, `curie`, `davinci`, etc.) can be called using the completions endpoint.```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you choosecompletion = openai.Completion.create(model=&quot;text-davinci-003&quot;, prompt=&quot;Hello world&quot;)print(completion.choices[0].text)```### EmbeddingsIn the OpenAI Python library, an embedding represents a text string as a fixed-length vector of floating point numbers. Embeddings are designed to measure the similarity or relevance between text strings.To get an embedding for a text string, you can use the embeddings method as follows in Python:```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you choose# choose text to embedtext_string = &quot;sample text&quot;# choose an embeddingmodel_id = &quot;text-similarity-davinci-001&quot;# compute the embedding of the textembedding = openai.Embedding.create(input=text_string, model=model_id)['data'][0]['embedding']```An example of how to call the embeddings method is shown in this [get embeddings notebook](https://github.com/openai/openai-cookbook/blob/main/examples/Get_embeddings.ipynb).Examples of how to use embeddings are shared in the following Jupyter notebooks:- [Classification using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Classification_using_embeddings.ipynb)- [Clustering using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Clustering.ipynb)- [Code search using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Code_search.ipynb)- [Semantic text search using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Semantic_text_search_using_embeddings.ipynb)- [User and product embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/User_and_product_embeddings.ipynb)- [Zero-shot classification using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Zero-shot_classification_with_embeddings.ipynb)- [Recommendation using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Recommendation_using_embeddings.ipynb)For more information on embeddings and the types of embeddings OpenAI offers, read the [embeddings guide](https://beta.openai.com/docs/guides/embeddings) in the OpenAI documentation.### Fine-tuningFine-tuning a model on training data can both improve the results (by giving the model more examples to learn from) and reduce the cost/latency of API calls (chiefly through reducing the need to include training examples in prompts).Examples of fine-tuning are shared in the following Jupyter notebooks:- [Classification with fine-tuning](https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb) (a simple notebook that shows the steps required for fine-tuning)- Fine-tuning a model that answers questions about the 2020 Olympics  - [Step 1: Collecting data](https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-1-collect-data.ipynb)  - [Step 2: Creating a synthetic Q&amp;A dataset](https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-2-create-qa.ipynb)  - [Step 3: Train a fine-tuning model specialized for Q&amp;A](https://github.com/openai/openai-cookbook/blob/main/examples/fine-tuned_qa/olympics-3-train-qa.ipynb)Sync your fine-tunes to [Weights &amp; Biases](https://wandb.me/openai-docs) to track experiments, models, and datasets in your central dashboard with:```bashopenai wandb sync```For more information on fine-tuning, read the [fine-tuning guide](https://beta.openai.com/docs/guides/fine-tuning) in the OpenAI documentation.### ModerationOpenAI provides a Moderation endpoint that can be used to check whether content complies with the OpenAI [content policy](https://platform.openai.com/docs/usage-policies)```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you choosemoderation_resp = openai.Moderation.create(input=&quot;Here is some perfectly innocuous text that follows all OpenAI content policies.&quot;)```See the [moderation guide](https://platform.openai.com/docs/guides/moderation) for more details.## Image generation (DALL·E)```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you chooseimage_resp = openai.Image.create(prompt=&quot;two dogs playing chess, oil painting&quot;, n=4, size=&quot;512x512&quot;)```## Audio transcription (Whisper)```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you choosef = open(&quot;path/to/file.mp3&quot;, &quot;rb&quot;)transcript = openai.Audio.transcribe(&quot;whisper-1&quot;, f)```## Async APIAsync support is available in the API by prepending `a` to a network-bound method:```pythonimport openaiopenai.api_key = &quot;sk-...&quot;  # supply your API key however you chooseasync def create_chat_completion():    chat_completion_resp = await openai.ChatCompletion.acreate(model=&quot;gpt-3.5-turbo&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello world&quot;}])```To make async requests more efficient, you can pass in your own`aiohttp.ClientSession`, but you must manually close the client session at the endof your program/event loop:```pythonimport openaifrom aiohttp import ClientSessionopenai.aiosession.set(ClientSession())# At the end of your program, close the http sessionawait openai.aiosession.get().close()```See the [usage guide](https://platform.openai.com/docs/guides/images) for more details.## Requirements- Python 3.7.1+In general, we want to support the versions of Python that ourcustomers are using. If you run into problems with any versionissues, please let us know on our [support page](https://help.openai.com/en/).## CreditThis library is forked from the [Stripe Python Library](https://github.com/stripe/stripe-python).</longdescription>
</pkgmetadata>