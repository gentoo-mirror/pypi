<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># SAQSAQ (Simple Async Queue) is a simple and performant job queueing framework built on top of asyncio and redis. It can be used for processing background jobs with workers. For example, you could use SAQ to schedule emails, execute long queries, or do expensive data analysis.[Documentation](https://saq-py.readthedocs.io/)It uses [redis-py](https://github.com/redis/redis-py) &gt;= 4.2.It is similar to [RQ](https://github.com/rq/rq) and heavily inspired by [ARQ](https://github.com/samuelcolvin/arq). Unlike RQ, it is async and thus [significantly faster](benchmarks) if your jobs are async. Even if they are not, SAQ is still considerably faster due to lower overhead.SAQ optionally comes with a simple UI for monitor workers and jobs.&lt;img src=&quot;docs/web.png&quot; alt=&quot;SAQ Web UI&quot; style=&quot;width:100%;&quot;/&gt;## Install```# minimal installpip install saq# web + hiredispip install saq[web,hiredis]```## Usage```usage: saq [-h] [--workers WORKERS] [--verbose] [--web]           [--extra-web-settings EXTRA_WEB_SETTINGS]           [--port PORT] [--check]           settingsStart Simple Async Queue Workerpositional arguments:  settings              Namespaced variable containing                        worker settings eg: eg                        module_a.settingsoptions:  -h, --help            show this help message and exit  --workers WORKERS     Number of worker processes  --verbose, -v         Logging level: 0: ERROR, 1: INFO,                        2: DEBUG  --web                 Start web app. By default, this                        only monitors the current                        worker's queue. To monitor                        multiple queues, see '--extra-                        web-settings'  --extra-web-settings EXTRA_WEB_SETTINGS, -e EXTRA_WEB_SETTINGS                        Additional worker settings to                        monitor in the web app  --port PORT           Web app port, defaults to 8080  --check               Perform a health checkenvironment variables:  AUTH_USER     basic auth user, defaults to admin  AUTH_PASSWORD basic auth password, if not specified, no auth will be used```## Example```pythonimport asynciofrom saq import CronJob, Queue# all functions take in context dict and kwargsasync def test(ctx, *, a):    await asyncio.sleep(0.5)    # result should be json serializable    # custom serializers and deserializers can be used through Queue(dump=,load=)    return {&quot;x&quot;: a}async def cron(ctx):  print(&quot;i am a cron job&quot;)async def startup(ctx):    ctx[&quot;db&quot;] = await create_db()async def shutdown(ctx):    await ctx[&quot;db&quot;].disconnect()async def before_process(ctx):    print(ctx[&quot;job&quot;], ctx[&quot;db&quot;])async def after_process(ctx):    passqueue = Queue.from_url(&quot;redis://localhost&quot;)settings = {    &quot;queue&quot;: queue,    &quot;functions&quot;: [test],    &quot;concurrency&quot;: 10,    &quot;cron_jobs&quot;: [CronJob(cron, cron=&quot;* * * * * */5&quot;)], # run every 5 seconds    &quot;startup&quot;: startup,    &quot;shutdown&quot;: shutdown,    &quot;before_process&quot;: before_process,    &quot;after_process&quot;: after_process,}```To start the worker, assuming the previous is available in the python path```saq module.file.settings```To enqueue jobs```python# schedule a job normallyjob = await queue.enqueue(&quot;test&quot;, a=1)# wait 1 second for the job to completeawait job.refresh(1)print(job.results)# run a job and return the resultprint(await queue.apply(&quot;test&quot;, a=2))# schedule a job in 10 secondsawait queue.enqueue(&quot;test&quot;, a=1, scheduled=time.time() + 10)```## DemoStart the worker```python -m saq examples.simple.settings --web```Navigate to the [web ui](http://localhost:8080])Enqueue jobs```python examples/simple.py```## Comparison to ARQSAQ is heavily inspired by [ARQ](https://github.com/samuelcolvin/arq) but has several enhancements.1. Avoids polling by leveraging [BLMOVE](https://redis.io/commands/blmove) or [RPOPLPUSH](https://redis.io/commands/rpoplpush) and NOTIFY    1. SAQ has much lower latency than ARQ, with delays of &lt; 5ms. ARQ's default polling frequency is 0.5 seconds  2. SAQ is up to [8x faster](benchmarks) than ARQ2. Web interface for monitoring queues and workers3. Heartbeat monitor for abandoned jobs4. More robust failure handling    1. Storage of stack traces    2. Sweeping stuck jobs    3. Handling of cancelled jobs different from failed jobs (machine redeployments)5. Before and after job hooks6. Easily run multiple workers to leverage more cores## Development```python -m venv envsource env/bin/activatepip install -e &quot;.[dev,web]&quot;docker run -p 6379:6379 redis./run_checks.sh```</longdescription>
</pkgmetadata>