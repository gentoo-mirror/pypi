<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># skweak: Weak supervision for NLP[![GitHub license](https://img.shields.io/github/license/NorskRegnesentral/skweak)](https://github.com/NorskRegnesentral/skweak/blob/main/LICENSE.txt)[![GitHub stars](https://img.shields.io/github/stars/NorskRegnesentral/skweak)](https://github.com/NorskRegnesentral/skweak/stargazers)![PyPI](https://img.shields.io/pypi/v/skweak)![Testing](https://github.com/NorskRegnesentral/skweak/actions/workflows/testing.yml/badge.svg)&lt;br&gt;&lt;p align=&quot;center&quot;&gt;   &lt;img alt=&quot;skweak logo&quot; src=&quot;https://raw.githubusercontent.com/NorskRegnesentral/skweak/main/data/skweak_logo.jpg&quot;/&gt;&lt;/p&gt;&lt;br&gt;Labelled data remains a scarce resource in many practical NLP scenarios. This is especially the case when working with resource-poor languages (or text domains), or when using task-specific labels without pre-existing datasets. The only available option is often to collect and annotate texts by hand, which is expensive and time-consuming. `skweak` (pronounced `/skwi:k/`) is a Python-based software toolkit that provides a concrete solution to this problem using weak supervision. `skweak` is built around a very simple idea: Instead of annotating texts by hand, we define a set of _labelling functions_ to automatically label our documents, and then _aggregate_ their results to obtain a labelled version of our corpus. The labelling functions may take various forms, such as domain-specific heuristics (like pattern-matching rules), gazetteers (based on large dictionaries), machine learning models, or even annotations from crowd-workers. The aggregation is done using a statistical model that automatically estimates the relative accuracy (and confusions) of each labelling function by comparing their predictions with one another.`skweak` can be applied to both sequence labelling and text classification, and comes with a complete API that makes it possible to create, apply and aggregate labelling functions with just a few lines of code. The toolkit is also tightly integrated with [SpaCy](http://www.spacy.io), which makes it easy to incorporate into existing NLP pipelines. Give it a try!&lt;br&gt;**Full Paper**:&lt;br&gt;Pierre Lison, Jeremy Barnes and Aliaksandr Hubin (2021), &quot;[skweak: Weak Supervision Made Easy for NLP](https://aclanthology.org/2021.acl-demo.40/)&quot;, *ACL 2021 (System demonstrations)*.**Documentation &amp; API**: See the [Wiki](https://github.com/NorskRegnesentral/skweak/wiki) for details on how to use `skweak`. &lt;br&gt;https://user-images.githubusercontent.com/11574012/114999146-e0995300-9ea1-11eb-8288-2bb54dc043e7.mp4&lt;br&gt;## Dependencies- `spacy` &gt;= 3.0.0- `hmmlearn` &gt;= 0.2.4- `pandas` &gt;= 0.23- `numpy` &gt;= 1.18You also need Python &gt;= 3.6. ## InstallThe easiest way to install `skweak` is through `pip`:```shellpip install skweak```or if you want to install from the repo:```shellpip install --user git+https://github.com/NorskRegnesentral/skweak```The above installation only includes the core library (not the additional examples in `examples`).Note: some examples and tests may require trained spaCy pipelines. These can be downloaded automatically using the syntax (for the pipeline `en_core_web_sm`)```shellpython -m spacy download en_core_web_sm```## Basic Overview&lt;br&gt;&lt;p align=&quot;center&quot;&gt;   &lt;img alt=&quot;Overview of skweak&quot; src=&quot;https://raw.githubusercontent.com/NorskRegnesentral/skweak/main/data/skweak_procedure.png&quot;/&gt;&lt;/p&gt;&lt;br&gt;Weak supervision with `skweak` goes through the following steps:- **Start**: First, you need raw (unlabelled) data from your text domain. `skweak` is build on top of [SpaCy](http://www.spacy.io), and operates with Spacy `Doc` objects, so you first need to convert your documents to `Doc` objects using SpaCy.- **Step 1**: Then, we need to define a range of labelling functions that will take those documents and annotate spans with labels. Those labelling functions can comes from heuristics, gazetteers, machine learning models, etc. See the ![documentation](https://github.com/NorskRegnesentral/skweak/wiki) for more details. - **Step 2**: Once the labelling functions have been applied to your corpus, you need to _aggregate_ their results in order to obtain a single annotation layer (instead of the multiple, possibly conflicting annotations from the labelling functions). This is done in `skweak` using a generative model that automatically estimates the relative accuracy and possible confusions of each labelling function. - **Step 3**: Finally, based on those aggregated labels, we can train our final model. Step 2 gives us a labelled corpus that (probabilistically) aggregates the outputs of all labelling functions, and you can use this labelled data to estimate any kind of machine learning model. You are free to use whichever model/framework you prefer. ## QuickstartHere is a minimal example with three labelling functions (LFs) applied on a single document:```pythonimport spacy, refrom skweak import heuristics, gazetteers, generative, utils# LF 1: heuristic to detect occurrences of MONEY entitiesdef money_detector(doc):   for tok in doc[1:]:      if tok.text[0].isdigit() and tok.nbor(-1).is_currency:          yield tok.i-1, tok.i+1, &quot;MONEY&quot;lf1 = heuristics.FunctionAnnotator(&quot;money&quot;, money_detector)# LF 2: detection of years with a regexlf2= heuristics.TokenConstraintAnnotator(&quot;years&quot;, lambda tok: re.match(&quot;(19|20)\d{2}$&quot;,                                                   tok.text), &quot;DATE&quot;)# LF 3: a gazetteer with a few namesNAMES = [(&quot;Barack&quot;, &quot;Obama&quot;), (&quot;Donald&quot;, &quot;Trump&quot;), (&quot;Joe&quot;, &quot;Biden&quot;)]trie = gazetteers.Trie(NAMES)lf3 = gazetteers.GazetteerAnnotator(&quot;presidents&quot;, {&quot;PERSON&quot;:trie})# We create a corpus (here with a single text)nlp = spacy.load(&quot;en_core_web_sm&quot;)doc = nlp(&quot;Donald Trump paid $750 in federal income taxes in 2016&quot;)# apply the labelling functionsdoc = lf3(lf2(lf1(doc)))# create and fit the HMM aggregation modelhmm = generative.HMM(&quot;hmm&quot;, [&quot;PERSON&quot;, &quot;DATE&quot;, &quot;MONEY&quot;])hmm.fit([doc]*10)# once fitted, we simply apply the model to aggregate all functionsdoc = hmm(doc)# we can then visualise the final result (in Jupyter)utils.display_entities(doc, &quot;hmm&quot;)```Obviously, to get the most out of `skweak`, you will need more than three labelling functions. And, most importantly, you will need a larger corpus including as many documents as possible from your domain, so that the model can derive good estimates of the relative accuracy of each labelling function. ## DocumentationSee the [Wiki](https://github.com/NorskRegnesentral/skweak/wiki). ## License`skweak` is released under an MIT License. The MIT License is a short and simple permissive license allowing both commercial and non-commercial use of the software. The only requirement is to preservethe copyright and license notices (see file [License](https://github.com/NorskRegnesentral/skweak/blob/main/LICENSE.txt)). Licensed works, modifications, and larger works may be distributed under different terms and without source code.## CitationSee our paper describing the framework: Pierre Lison, Jeremy Barnes and Aliaksandr Hubin (2021), &quot;[skweak: Weak Supervision Made Easy for NLP](https://aclanthology.org/2021.acl-demo.40/)&quot;, *ACL 2021 (System demonstrations)*. ```bibtex@inproceedings{lison-etal-2021-skweak,    title = &quot;skweak: Weak Supervision Made Easy for {NLP}&quot;,    author = &quot;Lison, Pierre  and      Barnes, Jeremy  and      Hubin, Aliaksandr&quot;,    booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations&quot;,    month = aug,    year = &quot;2021&quot;,    address = &quot;Online&quot;,    publisher = &quot;Association for Computational Linguistics&quot;,    url = &quot;https://aclanthology.org/2021.acl-demo.40&quot;,    doi = &quot;10.18653/v1/2021.acl-demo.40&quot;,    pages = &quot;337--346&quot;,}```</longdescription>
</pkgmetadata>