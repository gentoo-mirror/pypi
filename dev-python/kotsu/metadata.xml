<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># kotsu: lightweight framework for structuring model validation[![PyPI version](https://img.shields.io/pypi/v/kotsu.svg)](https://pypi.org/project/kotsu/)![lint-test status](https://github.com/datavaluepeople/kotsu/actions/workflows/run-ci.yml/badge.svg?branch=main)[![codecov](https://codecov.io/gh/datavaluepeople/kotsu/branch/main/graph/badge.svg?token=3W8T5OSRZZ)](https://codecov.io/gh/datavaluepeople/kotsu)## What is it?**kotsu** is Python package that provides a lightweight and flexible framework to structurevalidating and comparing machine learning models. It aims to provide the skeleton on which todevelop models and to validate them in a robust and repeatable way, **minimizingbloat or overhead**. Its flexibility allows usage with **any model interface** and anyvalidation technique, no matter how complex. The structure it provides **avoidscommon pitfalls** that occur when attempting to make fair comparisons between models.## Main Features  - Register a model with hyperparameters to a unique ID  - Register validations to a unique ID  - Run all registered models through all registered validations, and have the results compiled and    stored as a CSV  - Optionally passes an `artefacts_store_dir` to your validations, for storing of outputs    for further analysis, e.g. trained models or model predictions on test data sets  - Doesn't enforce any constraints or requirements on your models' interfaces  - Pure Python package, with no other setup or configuration of other systems required## Where to get itThe source code is currently hosted on GitHub at: https://github.com/datavaluepeople/kotsuThe latest released version of the package can be installed from PyPI with:```shpip install kotsu```## UsageThe following demonstrates a simple usage of kotsu to register and validate multiple models overmultiple validations.**Import kotsu and your packages for modelling:**```pythonimport kotsufrom sklearn import datasets, svmfrom sklearn.model_selection import cross_val_score```**Register your competing models:**Here we register two Support Vector Classifiers with different hyper-parameters.```pythonmodel_registry = kotsu.registration.ModelRegistry()model_registry.register(    id=&quot;SVC-v1&quot;,    entry_point=svm.SVC,    kwargs={&quot;kernel&quot;: &quot;linear&quot;, &quot;C&quot;: 1, &quot;random_state&quot;: 1},)model_registry.register(    id=&quot;SVC-v2&quot;,    entry_point=svm.SVC,    kwargs={&quot;kernel&quot;: &quot;linear&quot;, &quot;C&quot;: 0.5, &quot;random_state&quot;: 1},)```**Register your validations:**You can register multiple validations if you want to compare models in different scenarios, e.g. ondifferent datasets. Your validations should take an instance of your models as an argument, thenreturn a dictionary containing the results from validation of that model. Here we register twoCross-Validation validations with different numbers of folds.```pythonvalidation_registry = kotsu.registration.ValidationRegistry()def factory_iris_cross_validation(folds: int):    &quot;&quot;&quot;Factory for iris cross validation.&quot;&quot;&quot;    def iris_cross_validation(model) -&gt; dict:        &quot;&quot;&quot;Iris classification cross validation.&quot;&quot;&quot;        X, y = datasets.load_iris(return_X_y=True)        scores = cross_val_score(model, X, y, cv=folds)        results = {f&quot;fold_{i}_score&quot;: score for i, score in enumerate(scores)}        results[&quot;mean_score&quot;] = scores.mean()        results[&quot;std_score&quot;] = scores.std()        return results    return iris_cross_validationvalidation_registry.register(    id=&quot;iris_cross_validation-v1&quot;,    entry_point=factory_iris_cross_validation,    kwargs={&quot;folds&quot;: 5},)validation_registry.register(    id=&quot;iris_cross_validation-v2&quot;,    entry_point=factory_iris_cross_validation,    kwargs={&quot;folds&quot;: 10},)```**Run the models through the validations:**We choose the current directory as the location for writing the results.```pythonkotsu.run(model_registry, validation_registry)```Then find the results from each model-validation combination in a CSV written to the currentdirectory.### Documentation on interfacesSee [kotsu.typing](https://github.com/datavaluepeople/kotsu/blob/main/kotsu/typing.py) fordocumentation on the main entities; Models, Validations, and Results, and their interfaces.### Comprehensive exampleSee the [end to end test](https://github.com/datavaluepeople/kotsu/blob/main/tests/test_end_to_end.py)for a more comprehensive example usage of kotsu, which includes storing the trained models fromeach model-validation run.## License[MIT](LICENSE.txt)</longdescription>
</pkgmetadata>