<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;  &lt;a href=&quot;https://github.com/logicalclocks/maggy&quot;&gt;    &lt;img src=&quot;https://raw.githubusercontent.com/moritzmeister/maggy/mkdocs/docs/assets/images/maggy.png&quot; width=&quot;320&quot; alt=&quot;Maggy&quot;&gt;  &lt;/a&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;  &lt;a href=&quot;https://community.hopsworks.ai&quot;&gt;&lt;img    src=&quot;https://img.shields.io/discourse/users?label=Hopsworks%20Community&amp;server=https%3A%2F%2Fcommunity.hopsworks.ai&quot;    alt=&quot;Hopsworks Community&quot;  /&gt;&lt;/a&gt;    &lt;a href=&quot;https://maggy.ai&quot;&gt;&lt;img    src=&quot;https://img.shields.io/badge/docs-MAGGY-orange&quot;    alt=&quot;Maggy Documentation&quot;  /&gt;&lt;/a&gt;  &lt;a href=&quot;https://pypi.org/project/maggy/&quot;&gt;&lt;img    src=&quot;https://img.shields.io/pypi/v/maggy?color=blue&quot;    alt=&quot;PyPiStatus&quot;  /&gt;&lt;/a&gt;  &lt;a href=&quot;https://pepy.tech/project/maggy/month&quot;&gt;&lt;img    src=&quot;https://pepy.tech/badge/maggy/month&quot;    alt=&quot;Downloads&quot;  /&gt;&lt;/a&gt;  &lt;a href=&quot;https://github.com/psf/black&quot;&gt;&lt;img    src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot;    alt=&quot;CodeStyle&quot;  /&gt;&lt;/a&gt;  &lt;a&gt;&lt;img    src=&quot;https://img.shields.io/pypi/l/maggy?color=green&quot;    alt=&quot;License&quot;  /&gt;&lt;/a&gt;&lt;/p&gt;Maggy is a framework for **distribution transparent** machine learning experiments on [Apache Spark](https://spark.apache.org/).In this post, we introduce a new unified framework for writing core ML training logic as **oblivious training functions**.Maggy enables you to reuse the same training code whether training small models on your laptop or reusing the same code to scale out hyperparameter tuning or distributed deep learning on a cluster.Maggy enables the replacement of the current waterfall development process for distributed ML applications, where code is rewritten at every stage to account for the different distribution context.&lt;p align=&quot;center&quot;&gt;  &lt;figure&gt;    &lt;a href=&quot;https://github.com/logicalclocks/maggy&quot;&gt;      &lt;img src=&quot;https://raw.githubusercontent.com/moritzmeister/maggy/mkdocs/docs/assets/images/firstgraph.png&quot; alt=&quot;Maggy&quot;&gt;    &lt;/a&gt;    &lt;figcaption&gt;Maggy uses the same distribution transparent training function in all steps of the machine learning development process.&lt;/figcaption&gt;  &lt;/figure&gt;&lt;/p&gt;## Quick StartMaggy uses PySpark as an engine to distribute the training processes. To get started, install Maggy in the Python environment used by your Spark Cluster, or install Maggy in your local Python environment with the `'spark'` extra, to run on Spark in local mode:```pythonpip install maggy```The programming model consists of wrapping the code containing the model traininginside a function. Inside that wrapper function provide all imports andparts that make up your experiment.Single run experiment:```pythondef train_fn():    # This is your training iteration loop    for i in range(number_iterations):        ...        # add the maggy reporter to report the metric to be optimized        reporter.broadcast(metric=accuracy)         ...    # Return metric to be optimized or any metric to be logged    return accuracyfrom maggy import experimentresult = experiment.lagom(train_fn=train_fn, name='MNIST')```**lagom** is a Swedish word meaning &quot;just the right amount&quot;. This is how MAggyuses your resources.## DocumentationFull documentation is available at [maggy.ai](https://maggy.ai/)## ContributingThere are various ways to contribute, and any contribution is welcome, please follow theCONTRIBUTING guide to get started.## IssuesIssues can be reported on the official [GitHub repo](https://github.com/logicalclocks/maggy/issues) of Maggy.## CitationPlease see our publications on [maggy.ai](https://maggy.ai/publications) to find out how to cite our work.</longdescription>
</pkgmetadata>