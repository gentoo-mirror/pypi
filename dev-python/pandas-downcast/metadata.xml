<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Pandas Downcast===============[![image](https://img.shields.io/pypi/v/pandas-downcast.svg)](https://pypi.python.org/pypi/pandas-downcast)[![PyPI pyversions](https://img.shields.io/pypi/pyversions/pandas-downcast.svg)](https://pypi.python.org/pypi/pandas-downcast/)[![Build Status](https://github.com/domvwt/esparto/actions/workflows/lint-and-test.yml/badge.svg)](https://github.com/domvwt/pandas-downcast/actions/workflows/lint-and-test.yml)[![codecov](https://codecov.io/gh/domvwt/pandas-downcast/branch/main/graph/badge.svg?token=TQPLURKQ9Z)](https://codecov.io/gh/domvwt/pandas-downcast)Shrink [Pandas](https://pandas.pydata.org/) DataFrames with precision safe schema inference.`pandas-downcast` finds the minimum viable type for each column, ensuring that resulting valuesare within tolerance of original values.## Installation```bashpip install pandas-downcast```## Dependencies* python &gt;= 3.6* pandas* numpy## License[MIT](https://opensource.org/licenses/MIT)## Usage```pythonimport pdcast as pdcimport numpy as npimport pandas as pddata = {    &quot;integers&quot;: np.linspace(1, 100, 100),    &quot;floats&quot;: np.linspace(1, 1000, 100).round(2),    &quot;booleans&quot;: np.random.choice([1, 0], 100),    &quot;categories&quot;: np.random.choice([&quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;], 100),}df = pd.DataFrame(data)# Downcast DataFrame to minimum viable schema.df_downcast = pdc.downcast(df)# Infer minimum schema for DataFrame.schema = pdc.infer_schema(df)# Coerce DataFrame to schema - required if converting float to Pandas Integer.df_new = pdc.coerce_df(df, schema)```Smaller data types $\Rightarrow$ smaller memory footprint.```pythondf.info()# &lt;class 'pandas.core.frame.DataFrame'&gt;# RangeIndex: 100 entries, 0 to 99# Data columns (total 4 columns):#  #   Column      Non-Null Count  Dtype  # ---  ------      --------------  -----  #  0   integers    100 non-null    float64#  1   floats      100 non-null    float64#  2   booleans    100 non-null    int64  #  3   categories  100 non-null    object # dtypes: float64(2), int64(1), object(1)# memory usage: 3.2+ KBdf_downcast.info()# &lt;class 'pandas.core.frame.DataFrame'&gt;# RangeIndex: 100 entries, 0 to 99# Data columns (total 4 columns):#  #   Column      Non-Null Count  Dtype   # ---  ------      --------------  -----   #  0   integers    100 non-null    uint8   #  1   floats      100 non-null    float32 #  2   booleans    100 non-null    bool    #  3   categories  100 non-null    category# dtypes: bool(1), category(1), float32(1), uint8(1)# memory usage: 932.0 bytes```Numerical data types will be downcast if the resulting values are within tolerance of the original values.For details on tolerance for numeric comparison, see the notes on [`np.allclose`](https://numpy.org/doc/stable/reference/generated/numpy.allclose.html).```pythonprint(df.head())#    integers  floats  booleans categories# 0       1.0    1.00         1        foo# 1       2.0   11.09         0        baz# 2       3.0   21.18         1        bar# 3       4.0   31.27         0        bar# 4       5.0   41.36         0        fooprint(df_downcast.head())#    integers     floats  booleans categories# 0         1   1.000000      True        foo# 1         2  11.090000     False        baz# 2         3  21.180000      True        bar# 3         4  31.270000     False        bar# 4         5  41.360001     False        fooprint(pdc.options.ATOL)# &gt;&gt;&gt; 1e-08print(pdc.options.RTOL)# &gt;&gt;&gt; 1e-05```Tolerance can be set at the module level or passed in function arguments.```pythonpdc.options.ATOL = 1e-10pdc.options.RTOL = 1e-10df_downcast_new = pdc.downcast(df)```Or```pythoninfer_dtype_kws = {    &quot;ATOL&quot;: 1e-10,    &quot;RTOL&quot;: 1e-10}df_downcast_new = pdc.downcast(df, infer_dtype_kws=infer_dtype_kws)```The `floats` column is now kept as `float64` to meet the tolerance requirement.Values in the `integers` column are still safely cast to `uint8`.```pythondf_downcast_new.info()# &lt;class 'pandas.core.frame.DataFrame'&gt;# RangeIndex: 100 entries, 0 to 99# Data columns (total 4 columns):#  #   Column      Non-Null Count  Dtype   # ---  ------      --------------  -----   #  0   integers    100 non-null    uint8   #  1   floats      100 non-null    float64 #  2   booleans    100 non-null    bool    #  3   categories  100 non-null    category# dtypes: bool(1), category(1), float64(1), uint8(1)# memory usage: 1.3 KB```Inferred schemas can be restricted to Numpy data types only.```python# Downcast DataFrame to minimum viable Numpy schema.df_downcast = pdc.downcast(df, numpy_dtypes_only=True)# Infer minimum Numpy schema for DataFrame.schema = pdc.infer_schema(df, numpy_dtypes_only=True)```## ExampleThe following example shows how downcasting data often leads to size reductions of **greater than 70%**, depending on the original types.```pythonimport pdcast as pdcimport pandas as pdimport seaborn as snsdf_dict = {df: sns.load_dataset(df) for df in sns.get_dataset_names()}results = []for name, df in df_dict.items():    size_pre = df.memory_usage(deep=True).sum()    df_post = pdc.downcast(df)    size_post = df_post.memory_usage(deep=True).sum()    shrinkage = int((1 - (size_post / size_pre)) * 100)    results.append(        {&quot;dataset&quot;: name, &quot;size_pre&quot;: size_pre, &quot;size_post&quot;: size_post, &quot;shrink_pct&quot;: shrinkage}    )results_df = pd.DataFrame(results).sort_values(&quot;shrink_pct&quot;, ascending=False).reset_index(drop=True)print(results_df)``````           dataset  size_pre  size_post  shrink_pct0             fmri    213232      14776          931          titanic    321240      28162          912        attention      5888        696          883         penguins     75711       9131          874             dots    122240      17488          855           geyser     21172       3051          856           gammas    500128     108386          787         anagrams      2048        456          778          planets    112663      30168          739         anscombe      3428        964          7110            iris     14728       5354          6311        exercise      3302       1412          5712         flights      3616       1888          4713             mpg     75756      43842          4214            tips      7969       6261          2115        diamonds   3184588    2860948          1016  brain_networks   4330642    4330642           017     car_crashes      5993       5993           0```</longdescription>
</pkgmetadata>