<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Python Word Segmentation========================`WordSegment`_ is an Apache2 licensed module for English wordsegmentation, written in pure-Python, and based on a trillion-word corpus.Based on code from the chapter &quot;`Natural Language Corpus Data`_&quot; by PeterNorvig from the book &quot;`Beautiful Data`_&quot; (Segaran and Hammerbacher, 2009).Data files are derived from the `Google Web Trillion Word Corpus`_, asdescribed by Thorsten Brants and Alex Franz, and `distributed`_ by theLinguistic Data Consortium. This module contains only a subset of thatdata. The unigram data includes only the most common 333,000 words. Similarly,bigram data includes only the most common 250,000 phrases. Every word andphrase is lowercased with punctuation removed... _`WordSegment`: http://www.grantjenks.com/docs/wordsegment/.. _`Natural Language Corpus Data`: http://norvig.com/ngrams/.. _`Beautiful Data`: http://oreilly.com/catalog/9780596157111/.. _`Google Web Trillion Word Corpus`: http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html.. _`distributed`: https://catalog.ldc.upenn.edu/LDC2006T13Features--------- Pure-Python- Fully documented- 100% Test Coverage- Includes unigram and bigram data- Command line interface for batch processing- Easy to hack (e.g. different scoring, new data, different language)- Developed on Python 2.7- Tested on CPython 2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6 and PyPy, PyPy3- Tested on Windows, Mac OS X, and Linux- Tested using Travis CI and AppVeyor CI.. image:: https://api.travis-ci.org/grantjenks/python-wordsegment.svg    :target: http://www.grantjenks.com/docs/wordsegment/.. image:: https://ci.appveyor.com/api/projects/status/github/grantjenks/python-wordsegment?branch=master&amp;svg=true    :target: http://www.grantjenks.com/docs/wordsegment/Quickstart----------Installing `WordSegment`_ is simple with`pip &lt;http://www.pip-installer.org/&gt;`_::    $ pip install wordsegmentYou can access documentation in the interpreter with Python's built-in helpfunction::    &gt;&gt;&gt; import wordsegment    &gt;&gt;&gt; help(wordsegment)Tutorial--------In your own Python programs, you'll mostly want to use `segment` to divide aphrase into a list of its parts::    &gt;&gt;&gt; from wordsegment import load, segment    &gt;&gt;&gt; load()    &gt;&gt;&gt; segment('thisisatest')    ['this', 'is', 'a', 'test']The `load` function reads and parses the unigrams and bigrams data fromdisk. Loading the data only needs to be done once.`WordSegment`_ also provides a command-line interface for batchprocessing. This interface accepts two arguments: in-file and out-file. Linesfrom in-file are iteratively segmented, joined by a space, and written toout-file. Input and output default to stdin and stdout respectively. ::    $ echo thisisatest | python -m wordsegment    this is a testIf you want to run `WordSegment`_ as a kind of server process then use Python's``-u`` option for unbuffered output. You can also set ``PYTHONUNBUFFERED=1`` inthe environment. ::    &gt;&gt;&gt; import subprocess as sp    &gt;&gt;&gt; wordsegment = sp.Popen(            ['python', '-um', 'wordsegment'],            stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.STDOUT)    &gt;&gt;&gt; wordsegment.stdin.write('thisisatest\n')    &gt;&gt;&gt; wordsegment.stdout.readline()    'this is a test\n'    &gt;&gt;&gt; wordsegment.stdin.write('workswithotherlanguages\n')    &gt;&gt;&gt; wordsegment.stdout.readline()    'works with other languages\n'    &gt;&gt;&gt; wordsegment.stdin.close()    &gt;&gt;&gt; wordsegment.wait()  # Process exit code.    0The maximum segmented word length is 24 characters. Neither the unigram norbigram data contain words exceeding that length. The corpus also excludespunctuation and all letters have been lowercased. Before segmenting text,`clean` is called to transform the input to a canonical form::    &gt;&gt;&gt; from wordsegment import clean    &gt;&gt;&gt; clean('She said, &quot;Python rocks!&quot;')    'shesaidpythonrocks'    &gt;&gt;&gt; segment('She said, &quot;Python rocks!&quot;')    ['she', 'said', 'python', 'rocks']Sometimes its interesting to explore the unigram and bigram countsthemselves. These are stored in Python dictionaries mapping word to count. ::    &gt;&gt;&gt; import wordsegment as ws    &gt;&gt;&gt; ws.load()    &gt;&gt;&gt; ws.UNIGRAMS['the']    23135851162.0    &gt;&gt;&gt; ws.UNIGRAMS['gray']    21424658.0    &gt;&gt;&gt; ws.UNIGRAMS['grey']    18276942.0Above we see that the spelling `gray` is more common than the spelling `grey`.Bigrams are joined by a space::    &gt;&gt;&gt; import heapq    &gt;&gt;&gt; from pprint import pprint    &gt;&gt;&gt; from operator import itemgetter    &gt;&gt;&gt; pprint(heapq.nlargest(10, ws.BIGRAMS.items(), itemgetter(1)))    [('of the', 2766332391.0),     ('in the', 1628795324.0),     ('to the', 1139248999.0),     ('on the', 800328815.0),     ('for the', 692874802.0),     ('and the', 629726893.0),     ('to be', 505148997.0),     ('is a', 476718990.0),     ('with the', 461331348.0),     ('from the', 428303219.0)]Some bigrams begin with `&lt;s&gt;`. This is to indicate the start of a bigram::    &gt;&gt;&gt; ws.BIGRAMS['&lt;s&gt; where']    15419048.0    &gt;&gt;&gt; ws.BIGRAMS['&lt;s&gt; what']    11779290.0The unigrams and bigrams data is stored in the `wordsegment` directory inthe `unigrams.txt` and `bigrams.txt` files respectively.User Guide----------* `Word Segment API Reference`_* `Using a Different Corpus`_* `Python: Load dict Fast From File`_.. _`Word Segment API Reference`: http://www.grantjenks.com/docs/wordsegment/api.html.. _`Using a Different Corpus`: http://www.grantjenks.com/docs/wordsegment/using-a-different-corpus.html.. _`Python: Load dict Fast From File`: http://www.grantjenks.com/docs/wordsegment/python-load-dict-fast-from-file.htmlReferences----------* `WordSegment Documentation`_* `WordSegment at PyPI`_* `WordSegment at Github`_* `WordSegment Issue Tracker`_.. _`WordSegment Documentation`: http://www.grantjenks.com/docs/wordsegment/.. _`WordSegment at PyPI`: https://pypi.python.org/pypi/wordsegment.. _`WordSegment at Github`: https://github.com/grantjenks/python-wordsegment.. _`WordSegment Issue Tracker`: https://github.com/grantjenks/python-wordsegment/issuesWordSegment License-------------------Copyright 2018 Grant JenksLicensed under the Apache License, Version 2.0 (the &quot;License&quot;);you may not use this file except in compliance with the License.You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an &quot;AS IS&quot; BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.</longdescription>
</pkgmetadata>