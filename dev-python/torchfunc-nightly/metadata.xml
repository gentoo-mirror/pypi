<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;img align=&quot;left&quot; width=&quot;256&quot; height=&quot;256&quot; src=&quot;https://github.com/szymonmaszke/torchfunc/blob/master/assets/logos/medium.png&quot;&gt;* Improve and analyse performance of your neural network (e.g. Tensor Cores compatibility)* Record/analyse internal state of `torch.nn.Module` as data passes through it* Do the above based on external conditions (using single `Callable` to specify it)* Day-to-day neural network related duties (model size, seeding, time measurements etc.)* Get information about your host operating system, `torch.nn.Module` device, CUDAcapabilities etc.| Version | Docs | Tests | Coverage | Style | PyPI | Python | PyTorch | Docker | Roadmap ||---------|------|-------|----------|-------|------|--------|---------|--------|---------|| [![Version](https://img.shields.io/static/v1?label=&amp;message=0.2.0&amp;color=377EF0&amp;style=for-the-badge)](https://github.com/szymonmaszke/torchfunc/releases) | [![Documentation](https://img.shields.io/static/v1?label=&amp;message=docs&amp;color=EE4C2C&amp;style=for-the-badge)](https://szymonmaszke.github.io/torchfunc/)  | ![Tests](https://github.com/szymonmaszke/torchfunc/workflows/test/badge.svg) | ![Coverage](https://img.shields.io/codecov/c/github/szymonmaszke/torchfunc?label=%20&amp;logo=codecov&amp;style=for-the-badge) | [![codebeat](https://img.shields.io/static/v1?label=&amp;message=CB&amp;color=27A8E0&amp;style=for-the-badge)](https://codebeat.co/projects/github-com-szymonmaszke-torchfunc-master) | [![PyPI](https://img.shields.io/static/v1?label=&amp;message=PyPI&amp;color=377EF0&amp;style=for-the-badge)](https://pypi.org/project/torchfunc/) | [![Python](https://img.shields.io/static/v1?label=&amp;message=3.6&amp;color=377EF0&amp;style=for-the-badge&amp;logo=python&amp;logoColor=F8C63D)](https://www.python.org/) | [![PyTorch](https://img.shields.io/static/v1?label=&amp;message=&gt;=1.2.0&amp;color=EE4C2C&amp;style=for-the-badge)](https://pytorch.org/) | [![Docker](https://img.shields.io/static/v1?label=&amp;message=docker&amp;color=309cef&amp;style=for-the-badge)](https://hub.docker.com/r/szymonmaszke/torchfunc) | [![Roadmap](https://img.shields.io/static/v1?label=&amp;message=roadmap&amp;color=009688&amp;style=for-the-badge)](https://github.com/szymonmaszke/torchfunc/blob/master/ROADMAP.md) |# :bulb: Examples__Check documentation here:__ [https://szymonmaszke.github.io/torchfunc](https://szymonmaszke.github.io/torchfunc)## 1. Getting performance tips- __Get instant performance tips about your module. All problems described by commentswill be shown by `torchfunc.performance.tips`:__```pythonclass Model(torch.nn.Module):    def __init__(self):        super().__init__()        self.convolution = torch.nn.Sequential(            torch.nn.Conv2d(1, 32, 3),            torch.nn.ReLU(inplace=True),  # Inplace may harm kernel fusion            torch.nn.Conv2d(32, 128, 3, groups=32),  # Depthwise is slower in PyTorch            torch.nn.ReLU(inplace=True),  # Same as before            torch.nn.Conv2d(128, 250, 3),  # Wrong output size for TensorCores        )        self.classifier = torch.nn.Sequential(            torch.nn.Linear(250, 64),  # Wrong input size for TensorCores            torch.nn.ReLU(),  # Fine, no info about this layer            torch.nn.Linear(64, 10),  # Wrong output size for TensorCores        )    def forward(self, inputs):        convolved = torch.nn.AdaptiveAvgPool2d(1)(self.convolution(inputs)).flatten()        return self.classifier(convolved)# All you have to doprint(torchfunc.performance.tips(Model()))```## 2. Seeding, weight freezing and others- __Seed globaly (including `numpy` and `cuda`), freeze weights, check inference time and model size:__```python# Inb4 MNIST, you can use any module with those functionsmodel = torch.nn.Linear(784, 10)torchfunc.seed(0)frozen = torchfunc.module.freeze(model, bias=False)with torchfunc.Timer() as timer:  frozen(torch.randn(32, 784)  print(timer.checkpoint()) # Time since the beginning  frozen(torch.randn(128, 784)  print(timer.checkpoint()) # Since last checkpointprint(f&quot;Overall time {timer}; Model size: {torchfunc.sizeof(frozen)}&quot;)```## 3. Record `torch.nn.Module` internal state- __Record and sum per-layer activation statistics as data passes through network:__```python# Still MNIST but any module can be put in it's placemodel = torch.nn.Sequential(    torch.nn.Linear(784, 100),    torch.nn.ReLU(),    torch.nn.Linear(100, 50),    torch.nn.ReLU(),    torch.nn.Linear(50, 10),)# Recorder which sums all inputs to layersrecorder = torchfunc.hooks.recorders.ForwardPre(reduction=lambda x, y: x+y)# Record only for torch.nn.Linearrecorder.children(model, types=(torch.nn.Linear,))# Train your network normally (or pass data through it)...# Activations of all neurons of first layer!print(recorder[1]) # You can also post-process this data easily with apply```For other examples (and how to use condition), see [documentation](https://szymonmaszke.github.io/torchfunc/)# :wrench: Installation## :snake: [pip](&lt;https://pypi.org/project/torchfunc/&gt;)### Latest release:```shellpip install --user torchfunc```### Nightly:```shellpip install --user torchfunc-nightly```## :whale2: [Docker](https://hub.docker.com/r/szymonmaszke/torchfunc)__CPU standalone__ and various versions of __GPU enabled__ images are availableat [dockerhub](https://hub.docker.com/r/szymonmaszke/torchfunc/tags).For CPU quickstart, issue:```shelldocker pull szymonmaszke/torchfunc:18.04```Nightly builds are also available, just prefix tag with `nightly_`. If you are going for `GPU` image make sure you have[nvidia/docker](https://github.com/NVIDIA/nvidia-docker) installed and it's runtime set.# :question: ContributingIf you find any issue or you think some functionality may be useful to others and fits this library, please [open new Issue](https://help.github.com/en/articles/creating-an-issue) or [create Pull Request](https://help.github.com/en/articles/creating-a-pull-request-from-a-fork).To get an overview of things one can do to help this project, see [Roadmap](https://github.com/szymonmaszke/torchfunc/blob/master/ROADMAP.md).</longdescription>
</pkgmetadata>