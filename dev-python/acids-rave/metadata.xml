<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![rave_logo](docs/rave.png)# RAVE: Realtime Audio Variational autoEncoderOfficial implementation of _RAVE: A variational autoencoder for fast and high-quality neural audio synthesis_ ([article link](https://arxiv.org/abs/2111.05011)) by Antoine Caillon and Philippe Esling.If you use RAVE as a part of a music performance or installation, be sure to cite either this repository or the article !If you want to share / discuss / ask things about RAVE you can do so in our [discord server](https://discord.gg/dhX73sPTBb) !## Previous versionsThe original implementation of the RAVE model can be restored using```bashgit checkout v1```## InstallationInstall RAVE using```bashpip install acids-rave```You will need **ffmpeg** on your computer. You can install it locally inside your virtual environment using```bashconda install ffmpeg```&lt;!-- Detailed instructions to setup a training station for this project are available [here](docs/training_setup.md). --&gt;## ColabA colab to train RAVEv2 is now available thanks to [hexorcismos](https://github.com/moiseshorta) ![![colab_badge](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ih-gv1iHEZNuGhHPvCHrleLNXvooQMvI?usp=sharing)## UsageTraining a RAVE model usually involves 3 separate steps, namely _dataset preparation_, _training_ and _export_.### Dataset preparationYou can know prepare a dataset using two methods: regular and lazy. Lazy preprocessing allows RAVE to be trained directly on the raw files (i.e. mp3, ogg), without converting them first. **Warning**: lazy dataset loading will increase your CPU load by a large margin during training, especially on Windows. This can however be useful when training on large audio corpus which would not fit on a hard drive when uncompressed. In any case, prepare your dataset using```bashrave preprocess --input_path /audio/folder --output_path /dataset/path (--lazy)```### TrainingRAVEv2 has many different configurations. The improved version of the v1 is called `v2`, and can therefore be trained with```bashrave train --config v2 --db_path /dataset/path --name give_a_name```We also provide a discrete configuration, similar to SoundStream or EnCodec```bashrave train --config discrete ...```By default, RAVE is built with non-causal convolutions. If you want to make the model causal (hence lowering the overall latency of the model), you can use the causal mode```bashrave train --config discrete --config causal ...```Many other configuration files are available in `rave/configs` and can be combined. Here is a list of all the available configurations&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Type&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=5&gt;Architecture&lt;/td&gt;&lt;td&gt;v1&lt;/td&gt;&lt;td&gt;Original continuous model&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;v2&lt;/td&gt;&lt;td&gt;Improved continuous model (faster, higher quality)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;discrete&lt;/td&gt;&lt;td&gt;Discrete model (similar to SoundStream or EnCodec)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;onnx&lt;/td&gt;&lt;td&gt;Noiseless v1 configuration for onnx usage&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;raspberry&lt;/td&gt;&lt;td&gt;Lightweight configuration compatible with realtime RaspberryPi 4 inference&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=3&gt;Regularization (v2 only)&lt;/td&gt;&lt;td&gt;default&lt;/td&gt;&lt;td&gt;Variational Auto Encoder objective (ELBO)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;wasserstein&lt;/td&gt;&lt;td&gt;Wasserstein Auto Encoder objective (MMD)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;spherical&lt;/td&gt;&lt;td&gt;Spherical Auto Encoder objective&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=1&gt;Discriminator&lt;/td&gt;&lt;td&gt;spectral_discriminator&lt;/td&gt;&lt;td&gt;Use the MultiScale discriminator from EnCodec.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=1&gt;Others&lt;/td&gt;&lt;td&gt;causal&lt;/td&gt;&lt;td&gt;Use causal convolutions&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;### ExportOnce trained, export your model to a torchscript file using```bashrave export --run /path/to/your/run (--streaming)```Setting the `--streaming` flag will enable cached convolutions, making the model compatible with realtime processing. **If you forget to use the streaming mode and try to load the model in Max, you will hear clicking artifacts.**## Pretrained modelsSeveral pretrained streaming models [are available here](https://acids-ircam.github.io/rave_models_download). We'll keep the list updated with new models.## Where is the prior ?The prior model was an experimental feature from RAVEv1 and has been removed from this repository. **However**, we will release a new improved version of the prior soon (very soon in fact).## DiscussionIf you have questions, want to share your experience with RAVE or share musical pieces done with the model, you can use the [Discussion tab](https://github.com/acids-ircam/RAVE/discussions) !## Demonstration### RAVE x nn~Demonstration of what you can do with RAVE and the nn~ external for maxmsp ![![RAVE x nn~](http://img.youtube.com/vi/dMZs04TzxUI/mqdefault.jpg)](https://www.youtube.com/watch?v=dMZs04TzxUI)### embedded RAVEUsing nn~ for puredata, RAVE can be used in realtime on embedded platforms ![![RAVE x nn~](http://img.youtube.com/vi/jAIRf4nGgYI/mqdefault.jpg)](https://www.youtube.com/watch?v=jAIRf4nGgYI)</longdescription>
</pkgmetadata>