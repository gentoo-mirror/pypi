<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Getting Started`edb-deployment` tool is an easy way to provision Cloud resources and deployPostgreSQL, EDB Postgres Advanced Server and tools (high availability,backup/recovery, monitoring, connection poolers). `edb-deployment` can also beused to deploy Postgres architectures on existing infrastructure like physicalservers (baremetal) or local Virtual Machines.Supported Cloud providers are **AWS**, **Azure** and **Google Cloud**.`edb-deployment` helps user to deploy Postgres Reference Architectures. Listand details of the Reference Architecture can be find [here](https://github.com/EnterpriseDB/edb-ref-archs/blob/main/edb-reference-architecture-codes/README.md).`edb-deployment` is an open source tool and is not officially supported by EDBSupport. It is maintained and supported by the GitHub members of thisrepository. Please provide feedback by posting issues and providing pullrequests.Before starting to delve into this repository, it is best to get familiar withthe steps in the deployment process of a specific cloud (AWS, Azure and GoogleCloud).# Pre-Requisites`edb-deployment` is dependent on following components. Install the followingcomponents before using it.1. Python 32. `pip3`Third party pre-requisites:1. **Latest vendor** Cloud CLI or SDK ( AWS, Azure or Google Cloud )   Depending on the cloud provider, install the **latest version** for: AWS   CLI, Azure CLI or Google Cloud SDK on the system.2. **Terraform** &gt;= 1.3.63. **Ansible** &gt;= 2.10.84. **AWS CLI** &gt;= 2.0.455. **Azure CLI** &gt;= 2.23.06. **Google Cloud CLI** &gt;= 329.0.0To help the installation of the third party pre-requisites listed above,`edb-deployment` provides the `setup` sub-command working for Linux and Darwin(macOS).Please refer to section [Pre-Requisites installation](#pre-requisites-installation).# Installation## From source codeInstallation is done using the `pip3` command. Once the code has beendownloaded, either by cloning the repository or downloading a release, go tothe created folder and run the command `pip3 install`:```shell$ cd postgres-deployment$ sudo pip3 install . --upgrade```## From Pypi```shell$ sudo pip3 install edb-deployment```Make sure the tool is well installed by running the command:```shell$ edb-deployment --version```## Shell auto-completion`edb-deployment` supports command line auto-completion with the `tab` key.Supported shells are `bash` ans `zsh`.To enable auto-completion in current session, the following command must beran:```shell$ eval &quot;$(register-python-argcomplete edb-deployment)&quot;```To enable auto-completion for all the sessions, the command above must be addedat the end of your `~/.bashrc` file or `~/.zshrc` file, depending on the shellyou use.## Pre-Requisites installationTo ease installation of the third party pre-requisites tools like `aws`,`terraform`, `ansible`, etc.. `edb-deployment` provides the `setup`sub-command.The following packages are required in order to execute the `setup`sub-command: `gcc` (Linux only), `python3-devel` (Linux only), `unzip`, `wget`,`tar`.These packages should be installed through usual package manager (`dnf`,`apt`, `brew`, etc..).Note for Debian users: the package `libffi-dev` must be present.Finally, Python `virtualenv` must be installed with `root` privileges:```shell$ sudo pip3 install virtualenv```Pre-requisites automated installation:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; setup```# UsageEach new deployment will be done under a dedicated name space, this the`&lt;PROJECT_NAME&gt;`.`edb-deployment` CLI features are implemented through sub-commands. Eachsub-command can be executed like this:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; &lt;SUB_COMMAND&gt; [&lt;PROJECT_NAME&gt;]```## Cloud vendor list  * `aws`: Amazon Web Services  * `aws-pot`: EDB POT (Proof Of Technology) on AWS Cloud  * `aws-rds`: Amazon Web Services RDS for PostgreSQL  * `aws-rds-aurora`: Amazon Aurora  * `azure`: Microsoft Azure Cloud  * `azure-pot`: EDB POT (Proof Of Technology) on Azure Cloud  * `azure-db`: Microsoft Azure Database  * `gcloud`: Google Cloud  * `gcloud-pot`: EDB POT (Proof Of Technology) on Google Cloud  * `gcloud-sql`: Google Cloud SQL for PostgreSQL### Local Testing  * `baremetal`: Baremetal servers and VMs  * `vmware`: [VMWare Workstation](./VMWARE.md)  * `virtualbox`: [Virtualbox](./VIRTUALBOX.md)    * [Windows Support through WSL2](./README-WIN.md)## Sub-commands  * `configure`: New project initialization and configuration  * `provision`: Cloud resources provisioning  * `destroy`: Cloud resources destruction  * `deploy`: Postgres and tools deployment  * `show`: Show configuration  * `display`: Display project inventory  * `passwords`: Display project passwords  * `list`: List projects  * `specs`: Show Cloud Vendor default specifications  * `logs`: Show project logs  * `remove`: Remove project# How to UseDeployment of new project should follow the work flow below:  1. [Configure Cloud credentials](#configure-cloud-credentials)  2. [Project configuration](#project-configuration)  3. [Cloud resources provisioning](#cloud-resources-provisioning)  4. [Postgres and tools deployment](#postgres-and-tools-deployment)## Configure Cloud credentialsThis step depends on the target Cloud vendor.If the Cloud tools have been installed with the help of the `setup`sub-command, it's recommended to update the value of the `PATH` environmentvariable to include tools binary location:```shell$ export PATH=$PATH:$HOME/.edb-cloud-tools/bin```### AWS credentials configurationAWS credentials configuration will be done through `aws` tool. For this step,we need to get your **AWS Access Key ID** and **AWS Secret Access Key**. Formore information about Amazon Access Key management, please go to[official documentation page](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey).Run the following command and enter the Access Key ID and Secret Access Key:```shell$ aws configure```### Azure credentials configurationAzure Cloud credentials configuration can be achieved using the `az` tool withthe following command:```shell$ az login --use-device-code```### GCloud credentials configurationGCloud credentials configuration includes more steps than the other Cloudvendors. **GCloud project ID** is required.  1. Login with your email address:  ```shell$ gcloud auth login &lt;LOGIN_EMAIL&gt; --no-launch-browser  ```  2. Open the link in your browser and copy the given verification code.  3. Project configuration  ```shell$ gcloud config set project &lt;PROJECT_ID&gt;  ```  4. To find the IAM account of the service, please enter the following command     to list service accounts:  ```shell$ gcloud iam service-accounts list  ```  5. Finally, to create and download a new service account key:  ```shell$ gcloud iam service-accounts keys create ~/accounts.json --iam-account=&lt;IAM_ACCOUNT&gt;  ```The JSON file `$HOME/accounts.json` must be kept and will be required by`edb-deployment`.## Project configurationOnce Cloud vendor credentials have been configured, you can proceed withproject configuration step.### Cloud vendor specifications`edb-deployment` brings default configuration values for the Cloud resourcesto be provisioned, like **instance type**, **disk size**, **OS image**,**additional volumes**, etc..To change these configuration values, you need first to dump the default valueswith:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; specs &gt; my_configuration.json```When deploying on baremetal servers, IP address and SSH user configuration mustbe done through the specifications:```shell$ edb-deployment baremetal specs --reference-architecture EDB-RA-1 &gt; baremetal-edb-ra-1.json```The `baremetal-edb-ra-1.json` file will contain:```json{  &quot;ssh_user&quot;: null,  &quot;pg_data&quot;: null,  &quot;pg_wal&quot;: null,  &quot;postgres_server_1&quot;: {    &quot;name&quot;: &quot;pg1&quot;,    &quot;public_ip&quot;: null,    &quot;private_ip&quot;: null  },  &quot;pem_server_1&quot;: {    &quot;name&quot;: &quot;pem1&quot;,    &quot;public_ip&quot;: null,    &quot;private_ip&quot;: null  },  &quot;backup_server_1&quot;: {    &quot;name&quot;: &quot;backup1&quot;,    &quot;public_ip&quot;: null,    &quot;private_ip&quot;: null  }}```Then, you can edit and update resources configuration stored in the JSON file.### Project initializationProject initialialization will done using the `configure` sub-command:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; configure &lt;PROJECT_NAME&gt; \  -a &lt;REFERENCE_ARCHITECTURE_CODE&gt; \  -o &lt;OPERATING_SYSTEM&gt; \  -t &lt;PG_ENGINE_TYPE&gt; \  -v &lt;PG_VERSION&gt; \  -u &quot;&lt;EDB_REPO_USERNAME&gt;:&lt;EDB_REPO_PASSWORD&gt;&quot; \  -r &lt;CLOUD_REGION&gt; \  -s my_configuration.json```Notes:  * `REFERENCE_ARCHITECTURE_CODE`    Reference architecture code name. Allowed values are: **EDB-RA-1** for a    single Postgres node deployment with one backup server and one PEM    monitoring server, **EDB-RA-2** for a 3 Postgres nodes deployment with    quorum base synchronous replication and automatic failover, one backup    server and one PEM monitoring server, **EDB-RA-3** for extending    **EDB-RA-2** with 3 PgPoolII nodes,  and **HammerDB-TPROC-C** for setting up    a 2-tier configuration for benchmarking with an OLTP workload.  Default:    **EDB-RA-1**  * `OPERATING_SYSTEM`    Operating system. Allowed values are: **CentOS7**, **RockyLinux8**, **RedHat7**    and **RedHat8**. Default: **RockyLinux8**  * `PG_ENGINE_TYPE`     Postgres engine type. Allowed values are: **PG** for PostgreSQL, **EPAS**     for EDB Postgres Advanced Server. Default: **PG**  * `PG_VERSION`    PostgreSQL or EPAS version. Allowed values are: **11**, **12**, **13** and **14**.    Default: **14**  * `&quot;EDB_REPO_USERNAME:EDB_REPO_PASSWORD&quot;`    EDB Packages repository credentials. **Required**.  * `CLOUD_REGION`    Cloud vendor region. Default value depends on Cloud vendor.For more details, please use:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; configure --help```## Cloud resources provisioningAfter project configuration, we can proceed to Cloud resources provisioning:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; provision &lt;PROJECT_NAME&gt;```## Components deploymentFinally, we can deploy the components with the `deploy` sub-command:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; deploy &lt;PROJECT_NAME&gt;```## Other featuresList of projects:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; list```Execute Ansible pre deployment playbook```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; deploy --pre-deploy-ansible pre_deploy_playbook.yml &lt;PROJECT_NAME&gt;```Execute Ansible post deployment playbook```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; deploy --post-deploy-ansible post_deploy_playbook.yml &lt;PROJECT_NAME&gt;```Display of projects inventory:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; display &lt;PROJECT_NAME&gt;```Display of projects passwords:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; passwords &lt;PROJECT_NAME&gt;```Cloud resources destruction:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; destroy &lt;PROJECT_NAME&gt;```Project tree deletion:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; remove &lt;PROJECT_NAME&gt;```Open SSH connection to one host of the project:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; ssh &lt;PROJECT_NAME&gt; &lt;NODE_NAME&gt;```Note: the node name list can be found by executing the `display` sub-command.It can be: `epas1`, `epas2`, `pemserver1`, etc...Get a copy of the SSH keys and the ssh_config file. The files are copied intothe current directory:```shell$ edb-deployment &lt;CLOUD_VENDOR&gt; get_ssh_keys &lt;PROJECT_NAME&gt;```Note: This sub-command is only available for `aws-pot`, `azure-pot` and`gcloud-pot`.# LicenseOriginal work Copyright 2019-2020, EnterpriseDB CorporationAll rights reserved.Redistribution and use in source and binary forms, with or withoutmodification, are permitted provided that the following conditions are met:1. Redistributions of source code must retain the above copyright notice, thislist of conditions and the following disclaimer.2. Redistributions in binary form must reproduce the above copyright notice,this list of conditions and the following disclaimer in the documentationand/or other materials provided with the distribution.3. Neither the name of EnterpriseDB nor the names of its contributors may beused to endorse or promote products derived from this software without specificprior written permission.THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot; ANDANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIEDWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE AREDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FORANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ONANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE.</longdescription>
</pkgmetadata>