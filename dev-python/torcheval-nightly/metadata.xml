<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># TorchEval&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/pytorch/torcheval/actions?query=branch%3Amain&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/pytorch/torcheval/.github/workflows/unit_test.yaml?branch=main&quot; alt=&quot;build status&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://pypi.org/project/torcheval&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/torcheval&quot; alt=&quot;pypi version&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://pypi.org/project/torcheval-nightly&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/torcheval-nightly?label=nightly&quot; alt=&quot;pypi nightly version&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pytorch/torcheval/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/l/torcheval&quot; alt=&quot;bsd license&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;a href=&quot;https://pytorch.github.io/torcheval&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-main-brightgreen&quot; alt=&quot;docs&quot;&gt;&lt;/a&gt;&lt;p&gt;**This library is currently in Alpha and currently does not have a stable release. The API may change and may not be backward compatible. If you have suggestions for improvements, please open a GitHub issue. We'd love to hear your feedback.**A library that contains a rich collection of performant PyTorch model metrics, a simple interface to create new metrics, a toolkit to facilitate metric computation in distributed training and tools for PyTorch model evaluations.## Installing TorchEvalRequires Python &gt;= 3.7 and PyTorch &gt;= 1.11From pip:```bashpip install torcheval```For nighly build version```bashpip install --pre torcheval-nightly```From source:```bashgit clone https://github.com/pytorch/torchevalcd torchevalpip install -r requirements.txtpython setup.py install```## Quick StartTake a look at the [quickstart notebook](https://github.com/pytorch/torcheval/blob/main/examples/Introducing_TorchEval.ipynb), or fork it on [Colab](https://colab.research.google.com/github/pytorch/torcheval/blob/main/examples/Introducing_TorchEval.ipynb).There are more examples in the [examples](https://github.com/pytorch/torcheval/blob/main/examples) directory:```bashcd torchevalpython examples/simple_example.py```## DocumentationDocumentation can be found at at [pytorch.org/torcheval](https://pytorch.org/torcheval)## Using TorchEvalTorchEval can be run on CPU, GPU, and in a multi-process or multi-GPU setting. Metrics are provided in two interfaces, functional and class based. The functional interfaces can be found in `torcheval.metrics.functional` and are useful when your program runs in a single process setting. To use multi-process or multi-gpu configurations, the class-based interfaces, found in `torcheval.metrics` provide a much simpler experience. The class based interfaces also allow you to defer some of the computation of the metric by calling `update()` multiple times before `compute()`. This can be advantageous even in a single process setting due to saved computation overhead.### Single ProcessFor use in a single process program, the simplest use case utilizes a functional metric. We simply import the metric function and feed in our outputs and targets. The example below shows a minimal PyTorch training loop that evaluates the multiclass accuracy of every fourth batch of data.#### Functional Version (immediate computation of metric)```pythonimport torchfrom torcheval.metrics.functional import multiclass_accuracyNUM_BATCHES = 16BATCH_SIZE = 8INPUT_SIZE = 10NUM_CLASSES = 6eval_frequency = 4model = torch.nn.Sequential(torch.nn.Linear(INPUT_SIZE, NUM_CLASSES), torch.nn.ReLU())optim = torch.optim.Adagrad(model.parameters(), lr=0.001)loss_fn = torch.nn.CrossEntropyLoss()metric_history = []for batch in range(NUM_BATCHES):    input = torch.rand(size=(BATCH_SIZE, INPUT_SIZE))    target = torch.randint(size=(BATCH_SIZE,), high=NUM_CLASSES)    outputs = model(input)    loss = loss_fn(outputs, target)    optim.zero_grad()    loss.backward()    optim.step()    # metric only computed every 4 batches,    # data from previous three batches is lost    if (batch + 1) % eval_frequency == 0:        metric_history.append(multiclass_accuracy(outputs, target))```### Single Process with Deferred Computation#### Class Version (enables deferred computation of metric)```pythonimport torchfrom torcheval.metrics import MulticlassAccuracyNUM_BATCHES = 16BATCH_SIZE = 8INPUT_SIZE = 10NUM_CLASSES = 6eval_frequency = 4model = torch.nn.Sequential(torch.nn.Linear(INPUT_SIZE, NUM_CLASSES), torch.nn.ReLU())optim = torch.optim.Adagrad(model.parameters(), lr=0.001)loss_fn = torch.nn.CrossEntropyLoss()metric = MulticlassAccuracy()metric_history = []for batch in range(NUM_BATCHES):    input = torch.rand(size=(BATCH_SIZE, INPUT_SIZE))    target = torch.randint(size=(BATCH_SIZE,), high=NUM_CLASSES)    outputs = model(input)    loss = loss_fn(outputs, target)    optim.zero_grad()    loss.backward()    optim.step()    # metric only computed every 4 batches,    # data from previous three batches is included    metric.update(input, target)    if (batch + 1) % eval_frequency == 0:        metric_history.append(metric.compute())        # remove old data so that the next call        # to compute is only based off next 4 batches        metric.reset()```### Multi-Process or Multi-GPUFor usage on multiple devices a minimal example is given below. In the normal `torch.distributed` paradigm, each device is allocated its own process gets a unique numerical ID called a &quot;global rank&quot;, counting up from 0.#### Class Version (enables deferred computation and multi-processing)```pythonimport torchfrom torcheval.metrics.toolkit import sync_and_computefrom torcheval.metrics import MulticlassAccuracy# Using torch.distributedlocal_rank = int(os.environ[&quot;LOCAL_RANK&quot;]) #rank on local machine, i.e. unique ID within a machineglobal_rank = int(os.environ[&quot;RANK&quot;]) #rank in global pool, i.e. unique ID within the entire process groupworld_size  = int(os.environ[&quot;WORLD_SIZE&quot;]) #total number of processes or &quot;ranks&quot; in the entire process groupdevice = torch.device(    f&quot;cuda:{local_rank}&quot;    if torch.cuda.is_available() and torch.cuda.device_count() &gt;= world_size    else &quot;cpu&quot;)metric = MulticlassAccuracy(device=device)num_epochs, num_batches = 4, 8for epoch in range(num_epochs):    for i in range(num_batches):        input = torch.randint(high=5, size=(10,), device=device)        target = torch.randint(high=5, size=(10,), device=device)        # Add data to metric locally        metric.update(input, target)        # metric.compute() will returns metric value from        # all seen data on the local process since last reset()        local_compute_result = metric.compute()        # sync_and_compute(metric) sends metric data across all processes to the process with rank 0,        # the output on rank 0 is the computed metric for the entire process group, on other ranks None is returned.        global_compute_result = sync_and_compute(metric)        if global_rank == 0:            print(global_compute_result)        # if sync_and_compute(metric, recipient_rank=&quot;all&quot;) is called, the computation is done on rank 0, and the output is synced        # across processes so that each rank returns the computed metric.    # metric.reset() clears the data on each process so that subsequent    # calls to compute() only act on new data    metric.reset()```See the [example directory](https://github.com/pytorch/torcheval/tree/main/examples) for more examples.## ContributingWe welcome PRs! See the [CONTRIBUTING](CONTRIBUTING.md) file.## LicenseTorchEval is BSD licensed, as found in the [LICENSE](LICENSE) file.</longdescription>
</pkgmetadata>