<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Scikit-Learn runtime for MLServerThis package provides a MLServer runtime compatible with Scikit-Learn.## UsageYou can install the runtime, alongside `mlserver`, as:```bashpip install mlserver mlserver-sklearn```For further information on how to use MLServer with Scikit-Learn, you can checkout this [worked out example](../../docs/examples/sklearn/README.md).## Content TypesIf no [content type](../../docs/user-guide/content-type) is present on therequest or metadata, the Scikit-Learn runtime will try to decode the payload asa [NumPy Array](../../docs/user-guide/content-type).To avoid this, either send a different content type explicitly, or define thecorrect one as part of your [model'smetadata](../../docs/reference/model-settings).## Model OutputsThe Scikit-Learn inference runtime exposes a number of outputs depending on themodel type.These outputs match to the `predict`, `predict_proba` and `transform` methodsof the Scikit-Learn model.| Output          | Returned By Default | Availability                                                                                                         || --------------- | ------------------- | -------------------------------------------------------------------------------------------------------------------- || `predict`       | ✅                  | Available on most models, but not in [Scikit-Learn pipelines](https://scikit-learn.org/stable/modules/compose.html). || `predict_proba` | ❌                  | Only available on non-regressor models.                                                                              || `transform`     | ❌                  | Only availabe on [Scikit-Learn pipelines](https://scikit-learn.org/stable/modules/compose.html).                     |By default, the runtime will only return the output of `predict`.However, you are able to control which outputs you want back through the`outputs` field of your {class}`InferenceRequest&lt;mlserver.types.InferenceRequest&gt;` payload.For example, to only return the model's `predict_proba` output, you coulddefine a payload such as:```{code-block} json---emphasize-lines: 10-12---{  &quot;inputs&quot;: [    {      &quot;name&quot;: &quot;my-input&quot;,      &quot;datatype&quot;: &quot;INT32&quot;,      &quot;shape&quot;: [2, 2],      &quot;data&quot;: [1, 2, 3, 4]    }  ],  &quot;outputs&quot;: [    { &quot;name&quot;: &quot;predict_proba&quot; }  ]}```</longdescription>
</pkgmetadata>