<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Backup Postgres Database[![Downloads](https://static.pepy.tech/personalized-badge/postgres-backup?period=month&amp;units=none&amp;left_color=grey&amp;right_color=blue&amp;left_text=Downloads)](https://pepy.tech/project/postgres-backup) ![Version](https://img.shields.io/badge/version-0.1.1-blue) ![Python-Version](https://img.shields.io/badge/python-3.9-blue) ![issues](https://img.shields.io/github/issues/Nil-Andreu/postgres-backup) ![PyPI - Status](https://img.shields.io/pypi/status/postgres-backup) ![License](https://img.shields.io/github/license/Nil-Andreu/postgres-backup)## Basic UsageThis simple Python package allows you to create easily the database backup of Postgres databases.You can upload them to cloud storage buckets by creating a cron job.```python    from postgres_backup import Backup    # Instantiate the backup object with Postgres database_uri    backup = Backup()    # Create the file for backup    backup.create()```You should have as environment variable `DATABASE_URL`, which is the URI of the Postgres database.This URI has the following structure: `db:engine:[//[user[:password]@][host][:port]/][dbname]`.Can also specify a list of the tables for which you want to create the backup:```python    backup.create(table_names=['table1', 'table2', ...]```## Why?This package has proved experience of working well for databases of small-mid size.Doing this, you make sure you can store your database backups without relying in only one cloud provider or region.## Bucket StorageHave provided the ability to store those backups in cloud buckets.### Google Cloud StorageFor using this functionality, you need to install the dependencies needed of the package:```bash    pip3 install &quot;postgres-backup[gcs]&quot;```This basically will install also the `google` package.And then after we have the backup created, we would keep following with:```python    # Upload it to google cloud storage    backup.upload(        provider=CloudProviders.gcs.value,    )```Where the `google_cloud_certification` is a dictionary, with the key-values of the client api keys:```python    google_cloud_credentials = {      &quot;type&quot;: &quot;service_account&quot;,      &quot;project_id&quot;: &quot;xxx-saas&quot;,      &quot;private_key_id&quot;: &quot;xxxxxxxx&quot;,      &quot;private_key&quot;: &quot;-----BEGIN PRIVATE KEY-----\nxxxxxxxxxx\n-----END PRIVATE KEY-----\n&quot;,      &quot;client_email&quot;: &quot;xxx@xxx-saas.iam.gserviceaccount.com&quot;,      &quot;client_id&quot;: &quot;xxx&quot;,      &quot;auth_uri&quot;: &quot;https://accounts.google.com/o/oauth2/auth&quot;,      &quot;token_uri&quot;: &quot;https://oauth2.googleapis.com/token&quot;,      &quot;auth_provider_x509_cert_url&quot;: &quot;https://www.googleapis.com/oauth2/v1/certs&quot;,      &quot;client_x509_cert_url&quot;: &quot;https://www.googleapis.com/robot/v1/metadata/x509/xxx%xxx-saas.iam.gserviceaccount.com&quot;    }```Recommended to provide each key as an environmental variable:- GOOGLE_CLOUD_TYPE -&gt; type- GOOGLE_CLOUD_PROJECT_ID -&gt; project_id- GOOGLE_CLOUD_PRIVATE_KEY_ID -&gt; private_key_id- GOOGLE_CLOUD_PRIVATE_KEY -&gt; private_key- GOOGLE_CLOUD_CLIENT_EMAIL -&gt; client_email- GOOGLE_CLOUD_CLIENT_ID -&gt; client_id- GOOGLE_CLOUD_AUTH_URI -&gt; auth_uri- GOOGLE_CLOUD_TOKEN_URI -&gt; token_uri- GOOGLE_CLOUD_AUTH_PROVIDER_X509_CERT_URL -&gt; auth_provider_x509_cert_url- GOOGLE_CLOUD_CLIENT_X509_CERT_URL -&gt; client_x509_cert_urlMoreover `PROJECT_NAME` and `BUCKET_NAME` of the google bucket, and finally `DATABASE_URL` of Postgres database.In the case that we do not have a bucket already created for storing the backups, we could add additional parameters to create it:```python    from postgres_backup.schemas import CloudStorageType, CloudProviders    backup.upload(        provider=CloudProviders.gcs.value,        bucket_name=bucket_name,        create_bucket=True,        storage_class=CloudStorageType.NEARLINE.value    )```### Amazon Web ServicesFor uploading into AWS after having created the backup, you need first to install the optional dependencies:```bash    pip3 install &quot;postgres-backup[aws]&quot;```After that, you can use the method of `upload` of the Backup as:```python    # Upload it to aws storage    backup.upload(        provider=CloudProviders.aws.value,    )```It requires you to have as environmental variables `AWS_SERVER_PUBLIC_KEY`, `AWS_SERVER_PRIVATE_KEY` and `REGION_NAME`.</longdescription>
</pkgmetadata>