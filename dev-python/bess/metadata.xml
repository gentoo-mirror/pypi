<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># bess: A Python Package for Best Subset Selection## IntroductionOne of the main tasks of statistical modeling is to exploit the association betweena response variable and multiple predictors. Linear model (LM), as a simple parametricregression model, is often used to capture linear dependence between response andpredictors. Generalized linear model (GLM) can be considered asthe extensions of linear model, depending on the types of responses. Parameter estimation in these modelscan be computationally intensive when the number of predictors is large. Meanwhile,Occam's razor is widely accepted as a heuristic rule for statistical modeling,which balances goodness of fit and model complexity. This rule leads to a relative small subset of important predictors. **bess** package provides solutions for best subset selection problem for sparse LM,and GLM models.We consider a primal-dual active set (PDAS) approach to exactly solve the best subsetselection problem for sparse LM and GLM models. The PDAS algorithm for linear least squares problems was first introduced by [Ito and Kunisch (2013)](https://iopscience.iop.org/article/10.1088/0266-5611/30/1/015001)and later discussed by [Jiao, Jin, and Lu (2015)](https://arxiv.org/abs/1403.0515) and [Huang, Jiao, Liu, and Lu (2017)](https://arxiv.org/abs/1701.05128). It utilizes an active set updating strategy and fits the sub-models through use ofcomplementary primal and dual variables. We generalize the PDAS algorithm for general convex loss functions with the best subset constraint, and further extend it to support both sequential and golden section search strategiesfor optimal k determination. ## InstallPython Version- python &gt;= 3.5Modules needed- numpy The package has been publish in PyPI. You can easy install by:```sh$ pip install bess```## Example```python### PdasLm samplefrom bess.linear import *import numpy as npnp.random.seed(12345)   # fix seed to get the same resultx = np.random.normal(0, 1, 100 * 150).reshape((100, 150))beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))noise = np.random.normal(0, 1, 100)y = np.matmul(x, beta) + noise### Sparsity knownmodel = PdasLm(path_type=&quot;seq&quot;, sequence=[5])model.fit(X=x, y=y)model.predict(x)### Sparsity unknown# path_type=&quot;seq&quot;, Default:sequence=[1,2,...,min(x.shape[0], x.shape[1])]model = PdasLm(path_type=&quot;seq&quot;, sequence=range(1,10))model.fit(X=x, y=y)model.predict(x)# path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))model = PdasLm(path_type=&quot;pgs&quot;, s_max=20)model.fit(X=x, y=y)model.predict(x)### PdasLogistic samplenp.random.seed(12345)x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))xbeta = np.matmul(x, beta)p = np.exp(xbeta)/(1+np.exp(xbeta))y = np.random.binomial(1, p)### Sparsity knownmodel = PdasLogistic(path_type=&quot;seq&quot;, sequence=[5])model.fit(X=x, y=y)model.predict(x)### Sparsity unknown# path_type=&quot;seq&quot;, Default:sequence=[1,2,...,min(x.shape[0], x.shape[1])]model = PdasLogistic(path_type=&quot;seq&quot;, sequence=range(1,10))model.fit(X=x, y=y)model.predict(x)# path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))model = PdasLogistic(path_type=&quot;pgs&quot;)model.fit(X=x, y=y)model.predict(x)### PdasPoisson samplenp.random.seed(12345)x = np.random.normal(0, 1, 100 * 150).reshape((100, 150))beta = np.hstack((np.array([1, 1, -1, -1, -1]), np.zeros(145)))lam = np.exp(np.matmul(x, beta))y = np.random.poisson(lam=lam)### Sparsity knownmodel = PdasPoisson(path_type=&quot;seq&quot;, sequence=[5])model.fit(X=x, y=y)model.predict(x)### Sparsity unknown# path_type=&quot;seq&quot;, Default:sequence=[1,2,...,min(x.shape[0], x.shape[1])]model = PdasPoisson(path_type=&quot;seq&quot;, sequence=range(1,10))model.fit(X=x, y=y)model.predict(x)# path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))model = PdasPoisson(path_type=&quot;pgs&quot;)model.fit(X=x, y=y)model.predict(x)### PdasCox samplefrom bess.gen_data import gen_datanp.random.seed(12345)data = gen_data(100, 200, family=&quot;cox&quot;, k=5, rho=0, sigma=1, c=10)### Sparsity knownmodel = PdasCox(path_type=&quot;seq&quot;, sequence=[5])model.fit(data.x, data.y, is_normal=True)model.predict(data.x)### Sparsity unknown# path_type=&quot;seq&quot;, Default:sequence=[1,2,...,min(x.shape[0], x.shape[1])]model = PdasCox(path_type=&quot;seq&quot;, sequence=range(1,10))model.fit(data.x, data.y)model.predict(data.x)# path_type=&quot;pgs&quot;, Default:s_min=1, s_max=X.shape[1], K_max = int(math.log(p, 2/(math.sqrt(5) - 1)))model = PdasCox(path_type=&quot;pgs&quot;)model.fit(data.x, data.y)model.predict(data.x)```## Reference- Wen, C. , Zhang, A. , Quan, S. , &amp; Wang, X. . (2017). [Bess: an r package for best subset selection in linear, logistic and coxph models](https://arxiv.org/pdf/1709.06254.pdf)## Bug reportConnect to [@Jiang-Kangkang](https://github.com/Jiang-Kangkang), or send an email to Jiang Kangkang(jiangkk3@mail2.sysu.edu.cn)</longdescription>
</pkgmetadata>