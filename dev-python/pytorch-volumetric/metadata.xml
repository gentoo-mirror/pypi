<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>## Pytorch Volumetric- signed distance field (SDF) pytorch implementation with parallelized query for value and gradients- voxel grids with automatic expanding range- unidirectional chamfer distance (points to mesh)- robot model to SDF with parallelized query over robot configurations and points## Installation```shellpip install pytorch-volumetric```For development, clone repository somewhere, then `pip3 install -e .` to install in editable mode.For testing, run `pytest` in the root directory.## UsageSee `tests` for code samples; some are also shown here### SDF from mesh```pythonimport pytorch_volumetric as pv# supposing we have an object mesh (most formats supported) - from https://github.com/eleramp/pybullet-object-modelsobj = pv.MeshObjectFactory(&quot;YcbPowerDrill/textured_simple_reoriented.obj&quot;)sdf = pv.MeshSDF(obj)```### Cached SDF```pythonimport pytorch_volumetric as pvobj = pv.MeshObjectFactory(&quot;YcbPowerDrill/textured_simple_reoriented.obj&quot;)sdf = pv.MeshSDF(obj)# caching the SDF via a voxel grid to accelerate queriescached_sdf = pv.CachedSDF('drill', resolution=0.01, range_per_dim=obj.bounding_box(padding=0.1), gt_sdf=sdf)```### SDF value and gradient queriesSuppose we have an `ObjectFrameSDF` (such as created from above)```pythonimport numpy as npimport pytorch_volumetric as pv# get points in a grid in the object framequery_range = np.array([    [-1, 0.5],    [-0.5, 0.5],    [-0.2, 0.8],])coords, pts = pv.get_coordinates_and_points_in_grid(0.01, query_range)# N x 3 points # we can also query with batched points B x N x 3, B can be any number of batch dimensionssdf_val, sdf_grad = sdf(pts)# sdf_val is N, or B x N, the SDF value in meters# sdf_grad is N x 3 or B x N x 3, the normalized SDF gradient (points along steepest increase in SDF)```### Plotting SDF Slice```pythonimport pytorch_volumetric as pvimport numpy as np# supposing we have an object mesh (most formats supported) - from https://github.com/eleramp/pybullet-object-modelsobj = pv.MeshObjectFactory(&quot;YcbPowerDrill/textured_simple_reoriented.obj&quot;)sdf = pv.MeshSDF(obj)# need a dimension with no range to slice; here it's yquery_range = np.array([    [-0.15, 0.2],    [0, 0],    [-0.1, 0.2],])pv.draw_sdf_slice(sdf, query_range)```![drill SDF](https://i.imgur.com/TFaGmx6.png)### Robot Model to SDFFor many applications such as collision checking, it is useful to have theSDF of a multi-link robot in certain configurations.First, we create the robot model (loaded from URDF, SDF, MJCF, ...) with[pytorch kinematics](https://github.com/UM-ARM-Lab/pytorch_kinematics).For example, we will be using the KUKA 7 DOF arm model from pybullet data```pythonimport osimport torchimport pybullet_dataimport pytorch_kinematics as pkimport pytorch_volumetric as pvurdf = &quot;kuka_iiwa/model.urdf&quot;search_path = pybullet_data.getDataPath()full_urdf = os.path.join(search_path, urdf)chain = pk.build_serial_chain_from_urdf(open(full_urdf).read(), &quot;lbr_iiwa_link_7&quot;)d = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;chain = chain.to(device=d)# paths to the link meshes are specified with their relative path inside the URDF# we need to give them the path prefix as we need their absolute path to loads = pv.RobotSDF(chain, path_prefix=os.path.join(search_path, &quot;kuka_iiwa&quot;))```By default, each link will have a `MeshSDF`. To instead use `CachedSDF` for faster queries```pythons = pv.RobotSDF(chain, path_prefix=os.path.join(search_path, &quot;kuka_iiwa&quot;),                link_sdf_cls=pv.cache_link_sdf_factory(resolution=0.02, padding=1.0, device=d))```Which when the `y=0.02` SDF slice is visualized:![sdf slice](https://i.imgur.com/Putw72A.png)With surface points corresponding to:![wireframe](https://i.imgur.com/L3atG9h.png)![solid](https://i.imgur.com/XiAks7a.png)Queries on this SDF is dependent on the joint configurations (by default all zero).**Queries are batched across configurations and query points**. For example, we have a batch ofjoint configurations to query```pythonth = torch.tensor([0.0, -math.pi / 4.0, 0.0, math.pi / 2.0, 0.0, math.pi / 4.0, 0.0], device=d)N = 200th_perturbation = torch.randn(N - 1, 7, device=d) * 0.1# N x 7 joint valuesth = torch.cat((th.view(1, -1), th_perturbation + th))```And also a batch of points to query (same points for each configuration):```pythony = 0.02query_range = np.array([    [-1, 0.5],    [y, y],    [-0.2, 0.8],])# M x 3 pointscoords, pts = pv.get_coordinates_and_points_in_grid(0.01, query_range, device=s.device)```We set the batch of joint configurations and query:```pythons.set_joint_configuration(th)# N x M SDF value# N x M x 3 SDF gradientsdf_val, sdf_grad = s(pts)```Queries are reasonably quick. For the 7 DOF Kuka arm (8 links), using `CachedSDF` on a RTX 2080 Ti,and using CUDA, we get```shellN=20, M=15251, elapsed: 37.688577ms time per config and point: 0.000124msN=200, M=15251, elapsed: elapsed: 128.645445ms time per config and point: 0.000042ms```</longdescription>
</pkgmetadata>