<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># udata-hydra ðŸ¦€`udata-hydra` is an async metadata crawler for [data.gouv.fr](https://www.data.gouv.fr).URLs are crawled via _aiohttp_, catalog and crawled metadata are stored in a _PostgreSQL_ database.## CLI### Create database structureInstall udata-hydra dependencies and cli.`poetry install``poetry run udata-hydra migrate`### Load (UPSERT) latest catalog version from data.gouv.fr`udata-hydra load-catalog`## Crawler`udata-hydra-crawl`It will crawl (forever) the catalog according to config set in `config.py`.`BATCH_SIZE` URLs are queued at each loop run.The crawler will start with URLs never checked and then proceed with URLs crawled before `SINCE` interval. It will then wait until something changes (catalog or time).There's a by-domain backoff mecanism. The crawler will wait when, for a given domain in a given batch, `BACKOFF_NB_REQ` is exceeded in a period of `BACKOFF_PERIOD` seconds. It will retry until the backoff is lifted.If an URL matches one of the `EXCLUDED_PATTERNS`, it will never be checked.## WorkerA job queuing system is used to process long-running tasks. Launch the worker with the following command:`poetry run rq worker -c udata_hydra.worker`## API### Run```poetry installpoetry run adev runserver udata_hydra/app.py```### Get latest checkWorks with `?url={url}` and `?resource_id={resource_id}`.```$ curl -s &quot;http://localhost:8000/api/checks/latest/?url=http://opendata-sig.saintdenis.re/datasets/661e19974bcc48849bbff7c9637c5c28_1.csv&quot; | json_pp{   &quot;status&quot; : 200,   &quot;catalog_id&quot; : 64148,   &quot;deleted&quot; : false,   &quot;error&quot; : null,   &quot;created_at&quot; : &quot;2021-02-06T12:19:08.203055&quot;,   &quot;response_time&quot; : 0.830198049545288,   &quot;url&quot; : &quot;http://opendata-sig.saintdenis.re/datasets/661e19974bcc48849bbff7c9637c5c28_1.csv&quot;,   &quot;domain&quot; : &quot;opendata-sig.saintdenis.re&quot;,   &quot;timeout&quot; : false,   &quot;id&quot; : 114750,   &quot;dataset_id&quot; : &quot;5c34944606e3e73d4a551889&quot;,   &quot;resource_id&quot; : &quot;b3678c59-5b35-43ad-9379-fce29e5b56fe&quot;,   &quot;headers&quot; : {      &quot;content-disposition&quot; : &quot;attachment; filename=\&quot;xn--Dlimitation_des_cantons-bcc.csv\&quot;&quot;,      &quot;server&quot; : &quot;openresty&quot;,      &quot;x-amz-meta-cachetime&quot; : &quot;191&quot;,      &quot;last-modified&quot; : &quot;Wed, 29 Apr 2020 02:19:04 GMT&quot;,      &quot;content-encoding&quot; : &quot;gzip&quot;,      &quot;content-type&quot; : &quot;text/csv&quot;,      &quot;cache-control&quot; : &quot;must-revalidate&quot;,      &quot;etag&quot; : &quot;\&quot;20415964703d9ccc4815d7126aa3a6d8\&quot;&quot;,      &quot;content-length&quot; : &quot;207&quot;,      &quot;date&quot; : &quot;Sat, 06 Feb 2021 12:19:08 GMT&quot;,      &quot;x-amz-meta-contentlastmodified&quot; : &quot;2018-11-19T09:38:28.490Z&quot;,      &quot;connection&quot; : &quot;keep-alive&quot;,      &quot;vary&quot; : &quot;Accept-Encoding&quot;   }}```### Get all checks for an URL or resourceWorks with `?url={url}` and `?resource_id={resource_id}`.```$ curl -s &quot;http://localhost:8000/api/checks/all/?url=http://www.drees.sante.gouv.fr/IMG/xls/er864.xls&quot; | json_pp[   {      &quot;domain&quot; : &quot;www.drees.sante.gouv.fr&quot;,      &quot;dataset_id&quot; : &quot;53d6eadba3a72954d9dd62f5&quot;,      &quot;timeout&quot; : false,      &quot;deleted&quot; : false,      &quot;response_time&quot; : null,      &quot;error&quot; : &quot;Cannot connect to host www.drees.sante.gouv.fr:443 ssl:True [SSLCertVerificationError: (1, \&quot;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.drees.sante.gouv.fr'. (_ssl.c:1122)\&quot;)]&quot;,      &quot;catalog_id&quot; : 232112,      &quot;url&quot; : &quot;http://www.drees.sante.gouv.fr/IMG/xls/er864.xls&quot;,      &quot;headers&quot; : {},      &quot;id&quot; : 165107,      &quot;created_at&quot; : &quot;2021-02-06T14:32:47.675854&quot;,      &quot;resource_id&quot; : &quot;93dfd449-9d26-4bb0-a6a9-ee49b1b8a4d7&quot;,      &quot;status&quot; : null   },   {      &quot;timeout&quot; : false,      &quot;deleted&quot; : false,      &quot;response_time&quot; : null,      &quot;error&quot; : &quot;Cannot connect to host www.drees.sante.gouv.fr:443 ssl:True [SSLCertVerificationError: (1, \&quot;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.drees.sante.gouv.fr'. (_ssl.c:1122)\&quot;)]&quot;,      &quot;domain&quot; : &quot;www.drees.sante.gouv.fr&quot;,      &quot;dataset_id&quot; : &quot;53d6eadba3a72954d9dd62f5&quot;,      &quot;created_at&quot; : &quot;2020-12-24T17:06:58.158125&quot;,      &quot;resource_id&quot; : &quot;93dfd449-9d26-4bb0-a6a9-ee49b1b8a4d7&quot;,      &quot;status&quot; : null,      &quot;catalog_id&quot; : 232112,      &quot;url&quot; : &quot;http://www.drees.sante.gouv.fr/IMG/xls/er864.xls&quot;,      &quot;headers&quot; : {},      &quot;id&quot; : 65092   }]```### Get crawling status```$ curl -s &quot;http://localhost:8000/api/status/crawler/&quot; | json_pp{   &quot;fresh_checks_percentage&quot; : 0.4,   &quot;pending_checks&quot; : 142153,   &quot;total&quot; : 142687,   &quot;fresh_checks&quot; : 534,   &quot;checks_percentage&quot; : 0.4}```### Get worker status```$ curl -s &quot;http://localhost:8000/api/status/worker/&quot; | json_pp{   &quot;queued&quot; : {      &quot;default&quot; : 0,      &quot;high&quot; : 825,      &quot;low&quot; : 655   }}```### Get crawling stats```$ curl -s &quot;http://localhost:8000/api/stats/&quot; | json_pp{   &quot;status&quot; : [      {         &quot;count&quot; : 525,         &quot;percentage&quot; : 98.3,         &quot;label&quot; : &quot;ok&quot;      },      {         &quot;label&quot; : &quot;error&quot;,         &quot;percentage&quot; : 1.3,         &quot;count&quot; : 7      },      {         &quot;label&quot; : &quot;timeout&quot;,         &quot;percentage&quot; : 0.4,         &quot;count&quot; : 2      }   ],   &quot;status_codes&quot; : [      {         &quot;code&quot; : 200,         &quot;count&quot; : 413,         &quot;percentage&quot; : 78.7      },      {         &quot;code&quot; : 501,         &quot;percentage&quot; : 12.4,         &quot;count&quot; : 65      },      {         &quot;percentage&quot; : 6.1,         &quot;count&quot; : 32,         &quot;code&quot; : 404      },      {         &quot;code&quot; : 500,         &quot;percentage&quot; : 2.7,         &quot;count&quot; : 14      },      {         &quot;code&quot; : 502,         &quot;count&quot; : 1,         &quot;percentage&quot; : 0.2      }   ]}```## Using Webhook integration** Set the config values**Create a `config.toml` where your service and commands are launched, or specify a path to a TOML file via the `HYDRA_SETTINGS` environment variable. `config.toml` or equivalent will override values from `udata_hydra/config_default.toml`, lookup there for values that can/need to be defined.```tomlUDATA_URI = &quot;https://dev.local:7000/api/2&quot;UDATA_URI_API_KEY = &quot;example.api.key&quot;SENTRY_DSN = &quot;https://{my-sentry-dsn}&quot;```The webhook integration sends HTTP messages to `udata` when resources are analyzed or checked to fill resources extras.Regarding analysis, there is a phase called &quot;change detection&quot;. It will try to guess if a resource has been modified based on different criterions:- harvest modified date in catalog- content-length and last-modified headers- checksum comparison over timeThe payload should look something like:```json{   &quot;analysis:filesize&quot;: 91661,   &quot;analysis:mime-type&quot;: &quot;application/zip&quot;,   &quot;analysis:checksum&quot;: &quot;bef1de04601dedaf2d127418759b16915ba083be&quot;,   &quot;analysis:last-modified-at&quot;: &quot;2022-11-27T23:00:54.762000&quot;,   &quot;analysis:last-modified-detection&quot;: &quot;harvest-resource-metadata&quot;,}```## Development### docker-composeMultiple docker-compose files are provided:- a minimal `docker-compose.yml` with PostgreSQL- `docker-compose.broker.yml` adds a Redis broker- `docker-compose.test.yml` launches a test DB, needed to run testsNB: you can launch compose from multiple files like this: `docker-compose -f docker-compose.yml -f docker-compose.test.yml up`### Logging &amp; DebuggingThe log level can be adjusted using the environment variable LOG_LEVEL.For example, to set the log level to `DEBUG` when initializing the database, use `LOG_LEVEL=&quot;DEBUG&quot; udata-hydra init_db `.### Writing a migration1. Add a file named `migrations/{YYYYMMDD}_{from}_up_{to}.sql` and write the SQL you need to perform migration. `from` should be the revision from before (eg `rev1`), `to` the revision you're aiming at (eg `rev2`)2. Modify the latest revision (eg `rev2`) in `migrations/_LATEST_REVISION`3. `udata-hydra migrate` will use the info from `_LATEST_REVISION` to upgrade to `rev2`. You can also specify `udata-hydra migrate --revision rev2`## Deployment3 services need to be deployed for the full stack to run:- worker- api / app- crawlerRefer to each section to learn how to launch them. The only differences from dev to prod are:- use `HYDRA_SETTINGS` env var to point to your custom `config.toml`- use `HYDRA_APP_SOCKET_PATH` to configure where aiohttp should listen to a [reverse proxy connection (eg nginx)](https://docs.aiohttp.org/en/stable/deployment.html#nginx-configuration) and use `udata-hydra-app` to launch the app server</longdescription>
</pkgmetadata>