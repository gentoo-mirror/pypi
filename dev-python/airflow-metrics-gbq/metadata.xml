<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Airflow Metrics to BigQuery===&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://github.com/abyssnlp/airflow-metrics-gbq/actions/workflows/ci.yaml&quot;&gt;&lt;img alt=&quot;build&quot; src=&quot;https://github.com/abyssnlp/airflow-metrics-gbq/actions/workflows/ci.yaml/badge.svg&quot;/&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/abyssnlp/airflow-metrics-gbq/actions/workflows/release.yaml&quot;&gt;&lt;img alt=&quot;release&quot; src=&quot;https://github.com/abyssnlp/airflow-metrics-gbq/actions/workflows/release.yaml/badge.svg&quot;/&gt;&lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/airflow-metrics-gbq&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/airflow-metrics-gbq?style=plastic&quot;&gt;&lt;/a&gt;    &lt;img alt=&quot;PyPI - License&quot; src=&quot;https://img.shields.io/pypi/l/airflow-metrics-gbq?color=blue&amp;style=plastic&quot;&gt;&lt;/p&gt;Sends airflow metrics to Bigquery---### Installation```bashpip install airflow-metrics-gbq```### Usage1. Activate statsd metrics in `airflow.cfg````ini[metrics]statsd_on = Truestatsd_host = localhoststatsd_port = 8125statsd_prefix = airflow```2. Restart the webserver and the scheduler```bashsystemctl restart airflow-webserver.servicesystemctl restart airflow-scheduler.service```3. Check that airflow is sending out metrics:```bashnc -l -u localhost 8125```4. Install this package5. Create required tables (counters, gauges and timers), an example is shared [here](./scripts/sql/create_monitoring_tables.sql)6. Create materialized views which refresh when the base table changes, as describe [here](./scripts/sql/mat_views.sql)7. Create a simple python script `monitor.py` to provide configuration:```pythonfrom airflow_metrics_gbq.metrics import AirflowMonitorif __name__ == '__main__':    monitor = AirflowMonitor(        host=&quot;localhost&quot;, # Statsd host (airflow.cfg)        port=8125, # Statsd port (airflow.cfg)        gcp_credentials=&quot;path/to/service/account.json&quot;,        dataset_id=&quot;monitoring&quot;, # dataset where the monitoring tables are        counts_table=&quot;counts&quot;, # counters table        last_table=&quot;last&quot;, # gauges table        timers_table=&quot;timers&quot; # timers table    )    monitor.run()```8. Run the program, ideally in the background to start sending metrics to BigQuery:```bashpython monitor.py &amp;```9. The logs can be viewed in the GCP console under the `airflow_monitoring` app_name in Google Cloud Logging.**Future releases**- [ ] Increase test coverage (unit and integration tests)- [ ] Add proper typing and mypy support and checks- [ ] Provide more configurable options- [ ] Provide better documentation</longdescription>
</pkgmetadata>