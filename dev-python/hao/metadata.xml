<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># haoconfigurations, logs and others.## install```bashpip install hao```## preconditionThe folder contained any of the following files (searched in this very order) will be treated as **project root path**.- pyproject.toml- requirements.txt- setup.py- LICENSE- .idea- .git- .vscode**If your project structure does NOT conform to this, it will not work as expected.**## features### configIt will try to load YAML config file from `conf` folder```.                               # project root├── conf│   ├── config-{env}.yml        # if `export env=abc`, will raise error if not found│   ├── config-{hostname}.yml   # try to load this file, then the default `config.yml`│   └── config.yml              # the default config file that should always exist├── pyproject.toml              # or requirements.txt├── .git```In following order:```pythonif os.environ.get(&quot;env&quot;) is not None:    try_to_load(f'config-{env}.yml', fallback='config.yml')                   # echo $envelse:    try_to_load(f'config-{socket.gethostname()}.yml', fallback='config.yml')  # echo hostname```Say you have the following content in your config file:```yaml# config.ymles:  default:    host: 172.23.3.3    port: 9200    indices:      - news      - papers```The get the configured values in your code:```pythonimport haoes_host = hao.config.get('es.default.host')          # stres_port = hao.config.get('es.default.port')          # intindices = hao.config.get('es.default.indices')       # list...```### logsSet the logger levels to filter logse.g.```yaml# config.ymllogging:  __main__: DEBUG  transformers: WARNING  lightning: INFO  pytorch_lightning: INFO  elasticsearch: WARNING  tests: DEBUG  root: INFO                        # root level```Settings for logger:```yaml# config.ymllogger:  format: &quot;%(asctime)s %(levelname)-7s %(name)s:%(lineno)-4d - %(message)s&quot;   # overwrite to change to other format  handlers:    TimedRotatingFileHandler:    # any Handlers in `logging` and `logging.handlers` with it's config      when: d      backupCount: 3```Declare and user the logger```pythonimport haoLOGGER = hao.logs.get_logger(__name__)LOGGER.debug('message')LOGGER.info('message')LOGGER.warnning('message')LOGGER.error('message')LOGGER.exception(err)```### namespaces```pythonimport haofrom hao.namespaces import from_args, attr@from_argsclass ProcessConf(object):    file_in = attr(str, required=True, help=&quot;file path to process&quot;)    file_out = attr(str, required=True, help=&quot;file path to save&quot;)    tokenizer = attr(str, required=True, choice=('wordpiece', 'bpe'))from argparse import Namespacefrom pytorch_lightning import Trainer@from_args(adds=Trainer.add_argparse_args)class TrainConf(Namespace):    root_path_checkpoints = attr(str, default=hao.paths.get_path('data/checkpoints/'))    dataset_train = attr(str, default='train.txt')    dataset_val = attr(str, default='val.txt')    dataset_test = attr(str, default='test.txt')    batch_size = attr(int, default=128, key='train.batch_size')                          # key means try to load from config.yml by the key    task = attr(str, choices=('ner', 'nmt'), default='ner')    seed = attr(int)    epochs = attr(int, default=5)```Where `attr` is a wrapper for `argpars.add_argument()`Usage 1: overwrite the default value from command line```shellpython -m your_module --task=nmt```Usage 2: overwrite the default value from constructor```pythontrain_conf = TrainConf(task='nmt')```Value lookup order:- command line- constructor- config yml if `key` specified in `attr`- `default` if specified in `attr`</longdescription>
</pkgmetadata>