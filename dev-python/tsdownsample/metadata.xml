<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># tsdownsample[![PyPI Latest Release](https://img.shields.io/pypi/v/tsdownsample.svg)](https://pypi.org/project/tsdownsample/)[![support-version](https://img.shields.io/pypi/pyversions/tsdownsample)](https://img.shields.io/pypi/pyversions/tsdownsample)[![Downloads](https://pepy.tech/badge/tsdownsample)](https://pepy.tech/project/tsdownsample)[![Testing](https://github.com/predict-idlab/tsdownsample/actions/workflows/ci-downsample_rs.yml/badge.svg)](https://github.com/predict-idlab/tsdownsample/actions/workflows/ci-downsample_rs.yml)[![Testing](https://github.com/predict-idlab/tsdownsample/actions/workflows/ci-tsdownsample.yml/badge.svg)](https://github.com/predict-idlab/tsdownsample/actions/workflows/ci-tsdownsample.yml)&lt;!-- TODO: codecov --&gt;Extremely fast **time series downsampling üìà** for visualization, written in Rust.## Features ‚ú®* **Fast**: written in rust with PyO3 bindings    - leverages optimized [argminmax](https://github.com/jvdd/argminmax) - which is SIMD accelerated with runtime feature detection  - scales linearly with the number of data points  &lt;!-- TODO check if it scales sublinearly --&gt;  - multithreaded with Rayon (in Rust)    &lt;details&gt;      &lt;summary&gt;&lt;i&gt;Why we do not use Python multiprocessing&lt;/i&gt;&lt;/summary&gt;      Citing the &lt;a href=&quot;https://pyo3.rs/v0.17.3/parallelism.html&quot;&gt;PyO3 docs on parallelism&lt;/a&gt;:&lt;br&gt;      &lt;blockquote&gt;          CPython has the infamous Global Interpreter Lock, which prevents several threads from executing Python bytecode in parallel. This makes threading in Python a bad fit for CPU-bound tasks and often forces developers to accept the overhead of multiprocessing.      &lt;/blockquote&gt;      In Rust - which is a compiled language - there is no GIL, so CPU-bound tasks can be parallelized (with &lt;a href=&quot;https://github.com/rayon-rs/rayon&quot;&gt;Rayon&lt;/a&gt;) with little to no overhead.    &lt;/details&gt;* **Efficient**: memory efficient  - works on views of the data (no copies)  - no intermediate data structures are created* **Flexible**: works on any type of data    - supported datatypes are       - for `x`: `f32`, `f64`, `i16`, `i32`, `i64`, `u16`, `u32`, `u64`, `datetime64`, `timedelta64`      - for `y`: `f16`, `f32`, `f64`, `i8`, `i16`, `i32`, `i64`, `u8`, `u16`, `u32`, `u64`, `datetime64`, `timedelta64`, `bool`    &lt;details&gt;      &lt;summary&gt;&lt;i&gt;!! üöÄ &lt;code&gt;f16&lt;/code&gt; &lt;a href=&quot;https://github.com/jvdd/argminmax&quot;&gt;argminmax&lt;/a&gt; is 200-300x faster than numpy&lt;/i&gt;&lt;/summary&gt;      In contrast with all other data types above, &lt;code&gt;f16&lt;/code&gt; is *not* hardware supported (i.e., no instructions for f16) by most modern CPUs!! &lt;br&gt;      üêå Programming languages facilitate support for this datatype by either (i) upcasting to &lt;u&gt;f32&lt;/u&gt; or (ii) using a software implementation. &lt;br&gt;      üí° As for argminmax, only comparisons are needed - and thus no arithmetic operations - creating a &lt;u&gt;symmetrical ordinal mapping from &lt;code&gt;f16&lt;/code&gt; to &lt;code&gt;i16&lt;/code&gt;&lt;/u&gt; is sufficient. This mapping allows to use the hardware supported scalar and SIMD &lt;code&gt;i16&lt;/code&gt; instructions - while not producing any memory overhead üéâ &lt;br&gt;      &lt;i&gt;More details are described in &lt;a href=&quot;https://github.com/jvdd/argminmax/pull/1&quot;&gt;argminmax PR #1&lt;/a&gt;.&lt;/i&gt;    &lt;/details&gt;* **Easy to use**: simple &amp; flexible API## Install```bashpip install tsdownsample```## Usage```pythonfrom tsdownsample import MinMaxLTTBDownsamplerimport numpy as np# Create a time seriesy = np.random.randn(10_000_000)x = np.arange(len(y))# Downsample to 1000 points (assuming constant sampling rate)s_ds = MinMaxLTTBDownsampler().downsample(y, n_out=1000)# Downsample to 1000 points using the (possible irregularly spaced) x-datas_ds = MinMaxLTTBDownsampler().downsample(x, y, n_out=1000)```## Downsampling algorithms &amp; API ### Downsampling API üìëEach downsampling algorithm is implemented as a class that implements a `downsample` method.  The signature of the `downsample` method:```downsample([x], y, n_out, **kwargs) -&gt; ndarray[uint64]```**Arguments**:- `x` is optional- `x` and `y` are both positional arguments- `n_out` is a mandatory keyword argument that defines the number of output values&lt;sup&gt;*&lt;/sup&gt;- `**kwargs` are optional keyword arguments *(see [table below](#downsampling-algorithms-üìà))*:  - `parallel`: whether to use multi-threading (default: `False`)&lt;sup&gt;**&lt;/sup&gt;  - ...**Returns**: a `ndarray[uint64]` of indices that can be used to index the original data.&lt;sup&gt;*&lt;/sup&gt;&lt;i&gt;When there are gaps in the time series, fewer than `n_out` indices may be returned.&lt;/i&gt;  &lt;sup&gt;**&lt;/sup&gt;&lt;i&gt;`parallel` is not supported for `LTTBDownsampler`.&lt;/i&gt;### Downsampling algorithms üìàThe following downsampling algorithms (classes) are implemented:| Downsampler | Description | `**kwargs` || ---:| --- |--- || `MinMaxDownsampler` | selects the **min and max** value in each bin | `parallel` || `M4Downsampler` | selects the [**min, max, first and last**](https://dl.acm.org/doi/pdf/10.14778/2732951.2732953) value in each bin | `parallel` || `LTTBDownsampler` | performs the [**Largest Triangle Three Buckets**](https://skemman.is/bitstream/1946/15343/3/SS_MSthesis.pdf) algorithm || `MinMaxLTTBDownsampler` | (*new two-step algorithm üéâ*) first selects `n_out` * `minmax_ratio` **min and max** values, then further reduces these to `n_out` values using the **Largest Triangle Three Buckets** algorithm | `parallel`, `minmax_ratio`&lt;sup&gt;*&lt;/sup&gt; |&lt;sup&gt;*&lt;/sup&gt;&lt;i&gt;Default value for `minmax_ratio` is 30, which is empirically proven to be a good default. (More details in our upcomming paper)&lt;/i&gt;## Limitations &amp; assumptions üö®Assumes;1. `x`-data is (non-strictly) monotonic increasing (i.e., sorted)2. no `NaNs` in the data---&lt;p align=&quot;center&quot;&gt;üë§ &lt;i&gt;Jeroen Van Der Donckt&lt;/i&gt;&lt;/p&gt;</longdescription>
</pkgmetadata>