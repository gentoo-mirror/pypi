<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Scrapple========|Join the chat at https://gitter.im/AlexMathew/scrapple| |Scrapple onPyPI| |Build Status|`Scrapple &lt;http://scrappleapp.github.io/scrapple&gt;`__ is a framework forcreating web scrapers and web crawlers according to a key-value basedconfiguration file. It provides a command line interface to run thescript on a given JSON-based configuration input, as well as a webinterface to provide the necessary input.The primary goal of Scrapple is to abstract the process of designing webcontent extractors. The focus is laid on what to extract, rather thanhow to do it. The user-specified configuration file contains selectorexpressions (XPath expressions or CSS selectors) and the attribute to beselected. Scrapple does the work of running this extractor, without theuser worrying about writing a program. Scrapple can also be used togenerate a Python script that implements the desired extractor.Installation------------You can install Scrapple by using::    $ sudo apt-get install libxml2-dev libxslt-dev python-dev lib32z1-dev    $ pip install scrappleOtherwise, you could clone this repository and install the package.::    $ git clone http://github.com/scrappleapp/scrapple scrapple    $ cd scrapple    $ pip install -r requirements.txt    $ python setup.py installHow to use Scrapple-------------------Scrapple provides 4 commands to create and implement extractors.-  `genconfig &lt;http://scrapple.readthedocs.org/en/latest/framework/commands.html#genconfig&gt;`__-  `generate &lt;http://scrapple.readthedocs.org/en/latest/framework/commands.html#generate&gt;`__-  `run &lt;http://scrapple.readthedocs.org/en/latest/framework/commands.html#run&gt;`__-  `web &lt;http://scrapple.readthedocs.org/en/latest/framework/commands.html#web&gt;`__Scrapple implements the desired extractor on the basis of theuser-specified configuration file. There are guidelines regarding how towrite these configuration files.The configuration file is the basic specification of the extractorrequired. It contains the URL for the web page to be loaded, theselector expressions for the data to be extracted and in the case ofcrawlers, the selector expression for the links to be crawled through.The keys used in the configuration file are :-  **project\_name** : Specifies the name of the project with which the   configuration file is associated.-  **selector\_type** : Specifies the type of selector expressions used.   This could be &quot;xpath&quot; or &quot;css&quot;.-  **scraping** : Specifies parameters for the extractor to be created.   -  **url** : Specifies the URL of the base web page to be loaded.   -  **data** : Specifies a list of selectors for the data to be      extracted.      -  **selector** : Specifies the selector expression.      -  **attr** : Specifies the attribute to be extracted from the         result of the selector expression.      -  **field** : Specifies the field name under which this data is         to stored.      -  **default** : Specifies the default value to be used if the         selector expression fails.   -  **table** : Specifies a description for scraping tabular data.      -  **table\_type** : Specifies the type of table (&quot;rows&quot; or         &quot;columns&quot;). This determines the type of table to be extracted.         A row extraction is when there is a single row to be extracted         and mapped to a set of headers. A column extraction is when a         set of rows have to be extracted, giving a list of header-value         mappings.      -  **header** : Specifies the headers to be used for the table.         This can be a list of headers, or a selector that gives the         list of headers.      -  **prefix** : Specifies a prefix to be added to each header.      -  **suffix** : Specifies a suffix to be added to each header.      -  **selector** : Specifies the selector for the data. For row         extraction, this is a selector that gives the row to be         extracted. For column extraction, this is a list of selectors         for each column.      -  **attr** : Specifies the attribute to be extracted from the         selected tag.      -  **default** : Specifies the default value to be used if the         selector does not return any data.   -  **next** : Specifies the crawler implementation.      -  **follow\_link** : Specifies the selector expression for the         ``&lt;a&gt;`` tags to be crawled through.The main objective of the configuration file is to specify extractionrules in terms of selector expressions and the attribute to beextracted. There are certain set forms of selector/attribute value pairsthat perform various types of content extraction.Selector expressions :-  CSS selector or XPath expressions that specify the tag to be   selected.-  &quot;url&quot; to take the URL of the current page on which extraction is   being performed.Attribute selectors :-  &quot;text&quot; to extract the textual content from that tag.-  &quot;href&quot;, &quot;src&quot; etc., to extract any of the other attributes of the   selected tag.Tutorials---------[For a more detailed tutorial, check out the `tutorial in thedocumentation &lt;http://scrapple.readthedocs.org/en/latest/#experimentation-results&gt;`__]In this simple example for using Scrapple, we'll extract NBA playerinformation from `the ESPN website &lt;http://espn.go.com/nba/teams&gt;`__.To first create the skeleton configuration file, we use the genconfigcommand.::    $ scrapple genconfig nba http://espn.go.com/nba/teams --type=crawler --levels=2This creates nba.json - a sample Scrapple configuration file for acrawler, which uses XPath expressions as selectors. This can be editedand the required follow link selector, data selectors and attributes canbe specified... code:: javascript    {        &quot;project_name&quot;: &quot;nba&quot;,        &quot;selector_type&quot;: &quot;xpath&quot;,        &quot;scraping&quot;: {            &quot;url&quot;: &quot;http://espn.go.com/nba/teams&quot;,            &quot;data&quot;: [                {                    &quot;field&quot;: &quot;&quot;,                    &quot;selector&quot;: &quot;&quot;,                    &quot;attr&quot;: &quot;&quot;,                    &quot;default&quot;: &quot;&quot;                }            ],            &quot;next&quot;: [                {                    &quot;follow_link&quot;: &quot;//*[@class='mod-content']//a[3]&quot;,                    &quot;scraping&quot;: {                        &quot;data&quot;: [                            {                                &quot;field&quot;: &quot;team&quot;,                                &quot;selector&quot;: &quot;//h2&quot;,                                &quot;attr&quot;: &quot;text&quot;,                                &quot;default&quot;: &quot;&lt;no_team&gt;&quot;                            }                        ],                        &quot;next&quot;: [                            {                                &quot;follow_link&quot;: &quot;//*[@class='mod-content']/table[1]//tr[@class!='colhead']//a&quot;,                                &quot;scraping&quot;: {                                    &quot;data&quot;: [                                        {                                            &quot;field&quot;: &quot;name&quot;,                                            &quot;selector&quot;: &quot;//h1&quot;,                                            &quot;attr&quot;: &quot;text&quot;,                                            &quot;default&quot;: &quot;&lt;no_name&gt;&quot;                                        },                                        {                                            &quot;field&quot;: &quot;headshot_link&quot;,                                            &quot;selector&quot;: &quot;//*[@class='main-headshot']/img&quot;,                                            &quot;attr&quot;: &quot;src&quot;,                                            &quot;default&quot;: &quot;&lt;no_image&gt;&quot;                                        },                                        {                                            &quot;field&quot;: &quot;number &amp; position&quot;,                                            &quot;selector&quot;: &quot;//ul[@class='general-info']/li[1]&quot;,                                            &quot;attr&quot;: &quot;text&quot;,                                            &quot;default&quot;: &quot;&lt;00&gt; #&lt;GFC&gt;&quot;                                        }                                    ],                                    &quot;table&quot;: [                                        {                                            &quot;table_type&quot;: &quot;rows&quot;,                                            &quot;header&quot;: &quot;//div[@class='player-stats']//table//th&quot;,                                            &quot;prefix&quot;: &quot;season_&quot;,                                            &quot;suffix&quot;: &quot;&quot;,                                            &quot;selector&quot;: &quot;//div[@class='player-stats']//table//tr[1]/td&quot;,                                            &quot;attr&quot;: &quot;text&quot;,                                            &quot;default&quot;: &quot;&quot;                                        },                                        {                                            &quot;table_type&quot;: &quot;rows&quot;,                                            &quot;header&quot;: &quot;//div[@class='player-stats']//table//th&quot;,                                            &quot;prefix&quot;: &quot;career_&quot;,                                            &quot;suffix&quot;: &quot;&quot;,                                            &quot;selector&quot;: &quot;//div[@class='player-stats']//table//tr[@class='career']/td&quot;,                                            &quot;attr&quot;: &quot;text&quot;,                                            &quot;default&quot;: &quot;&quot;                                        }                                    ]                                }                            }                        ]                    }                }            ]        }    }The extractor can be run using the run command -::    $ scrapple run nba nba_players -o jsonThis creates nba\_players.json which contains the extracted data. Anexample snippet of this data :.. code:: javascript    {        &quot;project&quot;: &quot;nba&quot;,        &quot;data&quot;: [            # nba_players.json continues            {                &quot;career_APG&quot; : &quot;9.9&quot;,                &quot;career_PER&quot; : &quot;&quot;,                &quot;career_PPG&quot; : &quot;18.6&quot;,                &quot;career_RPG&quot; : &quot;4.4&quot;,                &quot;headshot_link&quot; : &quot;http://a.espncdn.com/combiner/i?img=/i/headshots/nba/players/full/2779.png&amp;w=350&amp;h=254&quot;,                &quot;name&quot; : &quot;Chris Paul&quot;,                &quot;number &amp; position&quot; : &quot;#3 PG&quot;,                &quot;season_APG&quot; : &quot;9.2&quot;,                &quot;season_PER&quot; : &quot;23.49&quot;,                &quot;season_PPG&quot; : &quot;17.6&quot;,                &quot;season_RPG&quot; : &quot;3.5&quot;,                &quot;team&quot; : &quot;Los Angeles Clippers&quot;            },            {                &quot;career_APG&quot; : &quot;3.6&quot;,                &quot;career_PER&quot; : &quot;&quot;,                &quot;career_PPG&quot; : &quot;20.3&quot;,                &quot;career_RPG&quot; : &quot;5.8&quot;,                &quot;headshot_link&quot; : &quot;http://a.espncdn.com/combiner/i?img=/i/headshots/nba/players/full/662.png&amp;w=350&amp;h=254&quot;,                &quot;name&quot; : &quot;Paul Pierce&quot;,                &quot;number &amp; position&quot; : &quot;#34 SF&quot;,                &quot;season_APG&quot; : &quot;0.9&quot;,                &quot;season_PER&quot; : &quot;7.55&quot;,                &quot;season_PPG&quot; : &quot;5.0&quot;,                &quot;season_RPG&quot; : &quot;2.6&quot;,                &quot;team&quot; : &quot;Los Angeles Clippers&quot;            },            {                &quot;career_APG&quot; : &quot;2.9&quot;,                &quot;career_PER&quot; : &quot;&quot;,                &quot;career_PPG&quot; : &quot;3.7&quot;,                &quot;career_RPG&quot; : &quot;1.8&quot;,                &quot;headshot_link&quot; : &quot;http://a.espncdn.com/combiner/i?img=/i/headshots/nba/players/full/4182.png&amp;w=350&amp;h=254&quot;,                &quot;name&quot; : &quot;Pablo Prigioni&quot;,                &quot;number &amp; position&quot; : &quot;#9 PG&quot;,                &quot;season_APG&quot; : &quot;1.9&quot;,                &quot;season_PER&quot; : &quot;8.72&quot;,                &quot;season_PPG&quot; : &quot;2.3&quot;,                &quot;season_RPG&quot; : &quot;1.5&quot;,                &quot;team&quot; : &quot;Los Angeles Clippers&quot;            },            {                &quot;career_APG&quot; : &quot;2.0&quot;,                &quot;career_PER&quot; : &quot;&quot;,                &quot;career_PPG&quot; : &quot;11.1&quot;,                &quot;career_RPG&quot; : &quot;1.9&quot;,                &quot;headshot_link&quot; : &quot;http://a.espncdn.com/combiner/i?img=/i/headshots/nba/players/full/3024.png&amp;w=350&amp;h=254&quot;,                &quot;name&quot; : &quot;J.J. Redick&quot;,                &quot;number &amp; position&quot; : &quot;#4 SG&quot;,                &quot;season_APG&quot; : &quot;1.6&quot;,                &quot;season_PER&quot; : &quot;18.10&quot;,                &quot;season_PPG&quot; : &quot;15.9&quot;,                &quot;season_RPG&quot; : &quot;1.5&quot;,                &quot;team&quot; : &quot;Los Angeles Clippers&quot;            },            # nba_players.json continues        ]    }The run command can also be used to create a CSV file with the extracteddata, using the --output\_type=csv argument.The generate command can be used to generate a Python script thatimplements this extractor. In essence, it replicates the execution ofthe run command.::    $ scrapple generate nba nba_script -o jsonThis creates nba\_script.py, which extracts the required data and storesthe data in a JSON document.Documentation-------------You can read the `complete documentation &lt;http://scrapple.rtfd.org&gt;`__for an extensive coverage on the background behind Scrapple, a thoroughexplanation on the Scrapple package implementation and a completecoverage of tutorials on how to use Scrapple to run your scraper/crawlerjobs.Authors-------Scrapple is maintained by `Alex Mathew &lt;http://github.com/AlexMathew&gt;`__and `Harish Balakrishnan &lt;http://github.com/harishb93&gt;`__... |Join the chat at https://gitter.im/AlexMathew/scrapple| image:: https://badges.gitter.im/AlexMathew/scrapple.svg   :target: https://gitter.im/AlexMathew/scrapple?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge.. |Scrapple on PyPI| image:: https://badge.fury.io/py/scrapple.svg   :target: https://badge.fury.io/py/scrapple.. |Build Status| image:: https://travis-ci.org/AlexMathew/scrapple.svg?branch=master   :target: https://travis-ci.org/AlexMathew/scrappleHistory=======0.3.0 - 2016-09-23------------------* Set up table scraping parameters and execution* Fix json configuration generation0.2.6 - 2015-11-27------------------* Edit requirements0.2.5 - 2015-05-28------------------* Add levels argument for genconfig command, to create crawler config files for a specific depth0.2.4 - 2015-04-13------------------* Update documentation* Minor fixes0.2.3 - 2015-03-11------------------* Include implementation to use csv as the output format0.2.2 - 2015-02-22------------------* Fix bug in generate script template0.2.1 - 2015-02-21------------------* Update tests0.2.0 - 2015-02-20------------------* Include implementation for ``scrapple run`` and ``scrapple generate`` for crawlers* Modify web interface for editing scraper config files* Revise skeleton configuration files0.1.1 - 2015-02-10------------------* Release on PyPI with revisions* Include web interface for editing scraper config files* Modified implementations of certain functions0.1.0 - 2015-02-04------------------* First release on PyPI</longdescription>
</pkgmetadata>