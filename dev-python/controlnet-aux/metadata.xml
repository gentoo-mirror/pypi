<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># ControlNet auxiliary modelsThis is a PyPi installable package of [lllyasviel's ControlNet Annotators](https://github.com/lllyasviel/ControlNet/tree/main/annotator)The code is copy-pasted from the respective folders in https://github.com/lllyasviel/ControlNet/tree/main/annotator and connected to [the ðŸ¤— Hub](https://huggingface.co/lllyasviel/Annotators).All credit &amp; copyright goes to https://github.com/lllyasviel .## Install```pip install controlnet-aux==0.0.5```## UsageYou can use the processor class, which can load each of the auxiliary models with the following code```pythonimport requestsfrom PIL import Imagefrom io import BytesIOfrom controlnet_aux.processor import Processor# load imageurl = &quot;https://huggingface.co/lllyasviel/sd-controlnet-openpose/resolve/main/images/pose.png&quot;response = requests.get(url)img = Image.open(BytesIO(response.content)).convert(&quot;RGB&quot;).resize((512, 512))# load processor from processor_id# options are:# [&quot;canny&quot;, &quot;depth_leres&quot;, &quot;depth_leres++&quot;, &quot;depth_midas&quot;, &quot;depth_zoe&quot;, &quot;lineart_anime&quot;,#  &quot;lineart_coarse&quot;, &quot;lineart_realistic&quot;, &quot;mediapipe_face&quot;, &quot;mlsd&quot;, &quot;normal_bae&quot;, &quot;normal_midas&quot;,#  &quot;openpose&quot;, &quot;openpose_face&quot;, &quot;openpose_faceonly&quot;, &quot;openpose_full&quot;, &quot;openpose_hand&quot;,#  &quot;scribble_hed, &quot;scribble_pidinet&quot;, &quot;shuffle&quot;, &quot;softedge_hed&quot;, &quot;softedge_hedsafe&quot;,#  &quot;softedge_pidinet&quot;, &quot;softedge_pidsafe&quot;]processor_id = 'scribble_hed'processor = Processor(processor_id)processed_image = processor(img, to_pil=True)```Each model can be loaded individually by importing and instantiating them as follows```pythonfrom PIL import Imageimport requestsfrom io import BytesIOfrom controlnet_aux import HEDdetector, MidasDetector, MLSDdetector, OpenposeDetector, PidiNetDetector, NormalBaeDetector, LineartDetector, LineartAnimeDetector, CannyDetector, ContentShuffleDetector, ZoeDetector, MediapipeFaceDetector, SamDetector, LeresDetector# load imageurl = &quot;https://huggingface.co/lllyasviel/sd-controlnet-openpose/resolve/main/images/pose.png&quot;response = requests.get(url)img = Image.open(BytesIO(response.content)).convert(&quot;RGB&quot;).resize((512, 512))# load checkpointshed = HEDdetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)midas = MidasDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)mlsd = MLSDdetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)open_pose = OpenposeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)pidi = PidiNetDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)normal_bae = NormalBaeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)lineart = LineartDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)lineart_anime = LineartAnimeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)zoe = ZoeDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)sam = SamDetector.from_pretrained(&quot;ybelkada/segment-anything&quot;, subfolder=&quot;checkpoints&quot;)leres = LeresDetector.from_pretrained(&quot;lllyasviel/Annotators&quot;)# instantiatecanny = CannyDetector()content = ContentShuffleDetector()face_detector = MediapipeFaceDetector()# processprocessed_image_hed = hed(img)processed_image_midas = midas(img)processed_image_mlsd = mlsd(img)processed_image_open_pose = open_pose(img, hand_and_face=True)processed_image_pidi = pidi(img, safe=True)processed_image_normal_bae = normal_bae(img)processed_image_lineart = lineart(img, coarse=True)processed_image_lineart_anime = lineart_anime(img)processed_image_zoe = zoe(img)processed_image_sam = sam(img)processed_image_leres = leres(img)processed_image_canny = canny(img)processed_image_content = content(img)processed_image_mediapipe_face = face_detector(img)```</longdescription>
</pkgmetadata>