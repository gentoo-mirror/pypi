<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>#### nfl_data_pynfl_data_py is a Python library for interacting with NFL data sourced from [nflfastR](https://github.com/nflverse/nflfastR-data/), [nfldata](https://github.com/nflverse/nfldata/), [dynastyprocess](https://raw.githubusercontent.com/dynastyprocess/), and [Draft Scout](https://draftscout.com/).Includes import functions for play-by-play data, weekly data, seasonal data, rosters, win totals, scoring lines, officials, draft picks, draft pick values, schedules, team descriptive info, combine results and id mappings across various sites.### InstallationUse the package manager [pip](https://pip.pypa.io/en/stable/) to install nfl_data_py.```bashpip install nfl_data_py```## Usage```pythonimport nfl_data_py as nfl```**Working with play-by-play data**```pythonnfl.import_pbp_data(years, columns, downcast=True, cache=False, alt_path=None)```Returns play-by-play data for the years and columns specifiedyears: required, list of years to pull data for (earliest available is 1999)columns: optional, list of columns to pull data fordowncast: optional, converts float64 columns to float32, reducing memory usage by ~30%. Will slow down initial load speed ~50%cache: optional, determines whether to pull pbp data from github repo or local cache generated by nfl.cache_pbp()alt_path: optional, required if nfl.cache_pbp() is called using an alternate path to the default cache```pythonnfl.see_pbp_cols()```returns list of columns available in play-by-play dataset**Working with weekly data**```pythonnfl.import_weekly_data(years, columns, downcast)```Returns weekly data for the years and columns specifiedyears: required, list of years to pull data for (earliest available is 1999)columns: optional, list of columns to pull data fordowncast: converts float64 columns to float32, reducing memory usage by ~30%. Will slow down initial load speed ~50%```pythonnfl.see_weekly_cols()```returns list of columns available in weekly dataset**Working with seasonal data**```pythonnfl.import_seasonal_data(years)```Returns seasonal data, including various calculated market share statsyears: required, list of years to pull data for (earliest available is 1999)**Additional data imports**```pythonnfl.import_rosters(years, columns)```Returns roster information for years and columns specifiedyears: required, list of years to pull data for (earliest available is 1999)columns: optional, list of columns to pull data for```pythonnfl.import_win_totals(years)```Returns win total lines for years specifiedyears: optional, list of years to pull```pythonnfl.import_sc_lines(years)```Returns scoring lines for years specifiedyears: optional, list of years to pull```pythonnfl.import_officials(years)```Returns official information by game for the years specifiedyears: optional, list of years to pull```pythonnfl.import_draft_picks(years)```Returns list of draft picks for the years specifiedyears: optional, list of years to pull```pythonnfl.import_draft_values()```Returns relative values by generic draft pick according to various popular valuation methods```pythonnfl.import_team_desc()```Returns dataframe with color/logo/etc information for all NFL team```pythonnfl.import_schedules(years)```Returns dataframe with schedule information for years specifiedyears: required, list of years to pull data for (earliest available is 1999)```pythonnfl.import_combine_data(years, positions)```Returns dataframe with combine results for years and positions specifiedyears: optional, list or range of years to pull data frompositions: optional, list of positions to be pulled (standard format - WR/QB/RB/etc.)```pythonnfl.import_ids(columns, ids)```Returns dataframe with mapped ids for all players across most major NFL and fantasy football data platformscolumns: optional, list of columns to returnids: optional, list of ids to return```pythonnfl.import_ngs_data(stat_type, years)```Returns dataframe with specified NGS datacolumns: required, type of data (passing, rushing, receiving)years: optional, list of years to return data for```pythonnfl.import_depth_charts(years)```Returns dataframe with depth chart datayears: optional, list of years to return data for```pythonnfl.import_injuries(years)```Returns dataframe of injury reportsyears: optional, list of years to return data for```pythonnfl.import_qbr(years, level, frequency)```Returns dataframe with QBR historyyears: optional, years to return data forlevel: optional, competition level to return data for, nfl or college, default nflfrequency: optional, frequency to return data for, weekly or season, default season```pythonnfl.import_pfr_passing(years)```Returns dataframe of PFR passing datayears: optional, years to return data for```pythonnfl.import_snap_counts(years)```Returns dataframe with snap count recordsyears: optional, list of years to return data for**Additional features**```pythonnfl.cache_pbp(years, downcast=True, alt_path=None)```Caches play-by-play data locally to speed up download time. If years specified have already been cached they will be overwritten, so if using in-season must cache 1x per week to catch most recent datayears: required, list or range of years to cachedowncast: optional, converts float64 columns to float32, reducing memory usage by ~30%. Will slow down initial load speed ~50%alt_path:optional, alternate path to store pbp cache - default is in program created user Local folder```pythonnfl.clean_nfl_data(df)```Runs descriptive data (team name, player name, etc.) through various cleaning processesdf: required, dataframe to be cleaned## RecognitionI'd like to recognize all of [Ben Baldwin](https://twitter.com/benbbaldwin), [Sebastian Carl](https://twitter.com/mrcaseb), and [Lee Sharpe](https://twitter.com/LeeSharpeNFL) for making this data freely available and easy to access. I'd also like to thank [Tan Ho](https://twitter.com/_TanH), who has been an invaluable resource as I've worked through this project, and Josh Kazan for the resources and assistance he's provided.## ContributingPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.## License[MIT](https://choosealicense.com/licenses/mit/)</longdescription>
</pkgmetadata>