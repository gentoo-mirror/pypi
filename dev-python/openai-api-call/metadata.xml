<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&gt; **中文文档移步[这里](README_zh_CN.md)。**# Openai API call[![PyPI version](https://img.shields.io/pypi/v/openai_api_call.svg)](https://pypi.python.org/pypi/openai_api_call)[![Tests](https://github.com/cubenlp/openai_api_call/actions/workflows/test.yml/badge.svg)](https://github.com/cubenlp/openai_api_call/actions/workflows/test.yml/)[![Documentation Status](https://img.shields.io/badge/docs-github_pages-blue.svg)](https://apicall.wzhecnu.cn)[![Coverage](https://codecov.io/gh/cubenlp/openai_api_call/branch/master/graph/badge.svg)](https://codecov.io/gh/cubenlp/openai_api_call.jl)&lt;!-- [![Updates](https://pyup.io/repos/github/cubenlp/openai_api_call/shield.svg)](https://pyup.io/repos/github/cubenlp/openai_api_call/) --&gt;A Python wrapper for OpenAI API, supporting multi-turn dialogue, proxy, and asynchronous data processing.## Installation```bashpip install openai-api-call --upgrade```## Usage### Set API Key and Base URLMethod 1, write in Python code:```pythonimport openai_api_callopenai_api_call.api_key = &quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;openai_api_call.base_url = &quot;https://api.example.com&quot;```Method 2, set environment variables in `~/.bashrc` or `~/.zshrc`:```bashexport OPENAI_API_KEY=&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;export OPENAI_BASE_URL=&quot;https://api.example.com&quot;```## ExamplesExample 1, simulate multi-turn dialogue:```python# first chatchat = Chat(&quot;Hello, GPT-3.5!&quot;)resp = chat.getresponse()# continue the chatchat.user(&quot;How are you?&quot;)next_resp = chat.getresponse()# add response manuallychat.user(&quot;What's your name?&quot;)chat.assistant(&quot;My name is GPT-3.5.&quot;)# save the chat historychat.save(&quot;chat.json&quot;, mode=&quot;w&quot;) # default to &quot;a&quot;# print the chat historychat.print_log()```Example 2, process data in batch, and use a checkpoint file `checkpoint`:```python# write a function to process the datadef msg2chat(msg):    chat = Chat(api_key=api_key)    chat.system(&quot;You are a helpful translator for numbers.&quot;)    chat.user(f&quot;Please translate the digit to Roman numerals: {msg}&quot;)    chat.getresponse()checkpoint = &quot;chat.jsonl&quot;msgs = [&quot;%d&quot; % i for i in range(1, 10)]# process the datachats = process_chats(msgs[:5], msg2chat, checkpoint, clearfile=True)# process the rest data, and read the cache from the last timecontinue_chats = process_chats(msgs, msg2chat, checkpoint)```Example 3, process data in batch (asynchronous), print hello using different languages, and use two coroutines:```pythonfrom openai_api_call import async_chat_completion, load_chatslangs = [&quot;python&quot;, &quot;java&quot;, &quot;Julia&quot;, &quot;C++&quot;]chatlogs = [&quot;print hello using %s&quot; % lang for lang in langs]async_chat_completion(chatlogs, chkpoint=&quot;async_chat.jsonl&quot;, ncoroutines=2)chats = load_chats(&quot;async_chat.jsonl&quot;)```## LicenseThis package is licensed under the MIT license. See the LICENSE file for more details.## update logCurrent version `1.0.0` is a stable version, with the redundant feature `function call` removed, and the asynchronous processing tool added.### Beta version- Since version `0.2.0`, `Chat` type is used to handle data- Since version `0.3.0`, you can use different API Key to send requests.- Since version `0.4.0`, this package is mantained by [cubenlp](https://github.com/cubenlp).- Since version `0.5.0`, one can use `process_chats` to process the data, with a customized `msg2chat` function and a checkpoint file.- Since version `0.6.0`, the feature [function call](https://platform.openai.com/docs/guides/gpt/function-calling) is added.</longdescription>
</pkgmetadata>