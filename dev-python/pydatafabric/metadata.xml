<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># SHINSEGAE DataFabric Python Package[![Linter &amp;&amp; Formatting](https://github.com/emartdt/datafabric-python-dist/actions/workflows/Flake8.yml/badge.svg)](https://github.com/emartdt/datafabric-python-dist/actions/workflows/Flake8.yml)[![Publish to TestPyPI](https://github.com/emartdt/datafabric-python-dist/actions/workflows/TestPyPI.yml/badge.svg)](https://github.com/emartdt/datafabric-python-dist/actions/workflows/TestPyPI.yml)[![Publish to PyPI](https://github.com/emartdt/datafabric-python-dist/actions/workflows/PyPI.yml/badge.svg)](https://github.com/emartdt/datafabric-python-dist/actions/workflows/PyPI.yml)This is highly site dependent package. Resources are abstracted into package structure.## UsageGet pandas dataframe from parquet file in hdfs```pythonfrom pydatafabric.ye import parquet_to_pandaspandas_df = parquet_to_pandas(hdfs_path)```Save pandas dataframe as parquet in hdfs```pythonfrom pydatafabric.ye import get_sparkfrom pydatafabric.ye import pandas_to_parquetspark = get_spark()pandas_to_parquet(pandas_df, hdfs_path, spark)  # we need spark for this operationspark.stop()```Work with spark```pythonfrom pydatafabric.ye import get_sparkspark = get_spark()# do with spark sessionspark.stop()```Work with spark-bigquery-connector```python# SELECTfrom pydatafabric.gcp import bq_table_to_pandaspandas_df = bq_table_to_pandas(&quot;dataset&quot;, &quot;table_name&quot;, [&quot;col_1&quot;, &quot;col_2&quot;], &quot;2020-01-01&quot;, &quot;cust_id is not null&quot;)# INSERT from pydatafabric.gcp import pandas_to_bq_tablepandas_to_bq_table(pandas_df, &quot;dataset&quot;, &quot;table_name&quot;, &quot;2022-02-22&quot;)```Send slack message```pythonfrom pydatafabric.ye import slack_sendtext = 'Hello'username = 'airflow'channel = '#leavemealone'slack_send(text=text, username=username, channel=channel)# Send dataframe as textdf = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})slack_send(text=df, username=username, channel=channel, dataframe=True)```Get bigquery client```pythonfrom pydatafabric.gcp import get_bigquery_clientbq = get_bigquery_client(project=&quot;emart-datafabric&quot;)bq.query(query)```IPython BigQuery Magic```pythonfrom pydatafabric.gcp import import_bigquery_ipython_magicimport_bigquery_ipython_magic()query_params = {    &quot;p_1&quot;: &quot;v_1&quot;,    &quot;dataset&quot;: &quot;common_dev&quot;,}``````python%% bq --params $query_paramsSELECT c_1 FROM {dataset}.user_logsWHERE c_1 = @p_1```Use NES CLI```basnes input_notebook_url -p k1 v1 -p k2 v2 -p k3 v3```Use github util```pythonfrom pydatafabric.ye import get_github_utilg = get_github_util# query graphqlres = g.query_gql(graph_ql)# get file in github repositorybyte_object = g.download_from_git(github_url_path)```## Installation```sh$ pip install pydatafabric --upgrade```If you would like to install submodules for Emart Inc.```sh$ pip install pydatafabric[emart] --upgrade```</longdescription>
</pkgmetadata>