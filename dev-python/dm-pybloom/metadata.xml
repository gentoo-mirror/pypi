<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>dm_pybloom=======.. image:: https://travis-ci.org/jaybaird/python-bloomfilter.svg?branch=master    :target: https://travis-ci.org/jaybaird/python-bloomfilter``dm_pybloom`` is a module that includes a Bloom Filter data structure along withan implmentation of Scalable Bloom Filters as discussed in:P. Almeida, C.Baquero, N. Pregui√ßa, D. Hutchison, Scalable Bloom Filters,(GLOBECOM 2007), IEEE, 2007.Bloom filters are great if you understand what amount of bits you need to setaside early to store your entire set. Scalable Bloom Filters allow your bloomfilter bits to grow as a function of false positive probability and size.A filter is &quot;full&quot; when at capacity: M * ((ln 2 ^ 2) / abs(ln p)), where Mis the number of bits and p is the false positive probability. When capacityis reached a new filter is then created exponentially larger than the lastwith a tighter probability of false positives and a larger number of hashfunctions... code-block:: python    &gt;&gt;&gt; from dm_pybloom import BloomFilter    &gt;&gt;&gt; f = BloomFilter(capacity=1000, error_rate=0.001)    &gt;&gt;&gt; [f.add(x) for x in range(10)]    [False, False, False, False, False, False, False, False, False, False]    &gt;&gt;&gt; all([(x in f) for x in range(10)])    True    &gt;&gt;&gt; 10 in f    False    &gt;&gt;&gt; 5 in f    True    &gt;&gt;&gt; f = BloomFilter(capacity=1000, error_rate=0.001)    &gt;&gt;&gt; for i in xrange(0, f.capacity):    ...     _ = f.add(i)    &gt;&gt;&gt; (1.0 - (len(f) / float(f.capacity))) &lt;= f.error_rate + 2e-18    True    &gt;&gt;&gt; from dm_pybloom import ScalableBloomFilter    &gt;&gt;&gt; sbf = ScalableBloomFilter(mode=ScalableBloomFilter.SMALL_SET_GROWTH)    &gt;&gt;&gt; count = 10000    &gt;&gt;&gt; for i in xrange(0, count):    ...     _ = sbf.add(i)    ...    &gt;&gt;&gt; (1.0 - (len(sbf) / float(count))) &lt;= sbf.error_rate + 2e-18    True    # len(sbf) may not equal the entire input length. 0.01% error is well    # below the default 0.1% error threshold. As the capacity goes up, the    # error will approach 0.1%.</longdescription>
</pkgmetadata>