<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>parquet-python==============.. image:: https://travis-ci.org/jcrobak/parquet-python.svg?branch=master    :target: https://travis-ci.org/jcrobak/parquet-pythonparquet-python is a pure-python implementation (currently with onlyread-support) of the `parquetformat &lt;https://github.com/Parquet/parquet-format&gt;`_. It comes with ascript for reading parquet files and outputting the data to stdout asJSON or TSV (without the overhead of JVM startup). Performance has notyet been optimized, but it's useful for debugging and quick viewing ofdata in files.Not all parts of the parquet-format have been implemented yet or testede.g. nested dataâ€”see Todos below for a full list. With that said,parquet-python is capable of reading all the data files from the`parquet-compatability &lt;https://github.com/Parquet/parquet-compatibility&gt;`_project.requirements============parquet-python has been tested on python 2.7, 3.6, and 3.7. It dependson ``pythrift2`` and optionally on ``python-snappy`` (for snappy compressedfiles, please also install ``parquet-python[snappy]``).getting started===============parquet-python is available via PyPi and can be installed using`pip install parquet`. The package includes the `parquet`command for reading python files, e.g. `parquet test.parquet`.See `parquet --help` for full usage.Example-------parquet-python currently has two programatic interfaces with similarfunctionality to Python's csv reader. First, it supports a DictReaderwhich returns a dictionary per row. Second, it has a reader whichreturns a list of values for each row. Both function require a file-likeobject and support an optional ``columns`` field to only read thespecified columns... code:: python    import parquet    import json    ## assuming parquet file with two rows and three columns:    ## foo bar baz    ## 1   2   3    ## 4   5   6    with open(&quot;test.parquet&quot;) as fo:       # prints:       # {&quot;foo&quot;: 1, &quot;bar&quot;: 2}       # {&quot;foo&quot;: 4, &quot;bar&quot;: 5}       for row in parquet.DictReader(fo, columns=['foo', 'bar']):           print(json.dumps(row))    with open(&quot;test.parquet&quot;) as fo:       # prints:       # 1,2       # 4,5       for row in parquet.reader(fo, columns=['foo', 'bar]):           print(&quot;,&quot;.join([str(r) for r in row]))Todos=====-  Support the deprecated bitpacking-  Fix handling of repetition-levels and definition-levels-  Tests for nested schemas, null data-  Support reading of data from HDFS via snakebite and/or webhdfs.-  Implement writing-  performance evaluation and optimization (i.e. how does it compare to   the c++, java implementations)Contributing============Is done via Pull Requests. Please include tests with your changes andfollow `pep8 &lt;http://www.python.org/dev/peps/pep-0008/&gt;`_.To run the tests you must install and execute ``tox`` (``pip install tox``) torun for all supported versions. If you want to run just for your currentversion, execute: ``pip install -r requirements-development.txt`` and then``nosetests``.</longdescription>
</pkgmetadata>