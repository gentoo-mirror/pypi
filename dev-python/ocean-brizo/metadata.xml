<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![banner](https://raw.githubusercontent.com/oceanprotocol/art/master/github/repo-banner%402x.png)](https://oceanprotocol.com)# Brizo&gt; Helping publishers provide extended data services (e.g. storage and compute).&gt; [oceanprotocol.com](https://oceanprotocol.com)___&quot;üèÑ‚ôÄÔ∏èüåä Brizo is an ancient Greek goddess who was known as the protector of mariners, sailors, and fishermen.She was worshipped primarily by the women of Delos, who set out food offerings in small boats. Brizo was also known as a prophet specializing in the interpretation of dreams.&quot;___[![Docker Build Status](https://img.shields.io/docker/build/oceanprotocol/brizo.svg)](https://hub.docker.com/r/oceanprotocol/brizo/)[![Travis (.com)](https://img.shields.io/travis/com/oceanprotocol/brizo.svg)](https://travis-ci.com/oceanprotocol/brizo)[![Codacy coverage](https://img.shields.io/codacy/coverage/40dd4c27169a4db4865f72317172bd9e.svg)](https://app.codacy.com/project/ocean-protocol/brizo/dashboard)[![PyPI](https://img.shields.io/pypi/v/ocean-brizo.svg)](https://pypi.org/project/ocean-brizo/)[![GitHub contributors](https://img.shields.io/github/contributors/oceanprotocol/brizo.svg)](https://github.com/oceanprotocol/brizo/graphs/contributors)---**üê≤ü¶ë THERE BE DRAGONS AND SQUIDS. This is in alpha state and you can expect running into problems. If you run into them, please open up [a new issue](https://github.com/oceanprotocol/brizo/issues). ü¶ëüê≤**---## Table of Contents- [Features](#features)- [Running Locally, for Dev and Test](#running-locally-for-dev-and-test)- [API documentation](#api-documentation)- [Configuration](#configuration)- [Dependencies](#dependencies)- [Code Style](#code-style)- [Testing](#testing)- [Debugging](#debugging)- [New Version](#new-version)- [License](#license)---## FeaturesIn the Ocean ecosystem, Brizo is the technical component executed by the Publishers allowing them to provide extended data services (e.g. storage and compute). Brizo, as part of the Publisher ecosystem, includes the credentials to interact with the infrastructure (initially cloud, but could be on-premise).The main features available in Brizo:* Data access - using the `/services/consume` endpoint. The data set file(s) are streamed back to the user without exposing the actual URL* Compute-to-data - using the `/services/compute` endpoint. The compute algorithm is executed remotely use the compute provider's Service Operator endpoint.Details of the main features can be found in the [Brizo API documentation ](https://docs.oceanprotocol.com/references/brizo/)## Running Locally, for Dev and TestIf you want to contribute to the development of Brizo, then you could do the following. (If you want to run a Brizo in production, then you will have to do something else.)First, clone this repository:```bashgit clone git@github.com:oceanprotocol/brizo.gitcd brizo/```Before running it locally we recommend to set up virtual environment:```bashvirtualenv venv -p python3.6source venv/bin/activate ```And install all the requirements:```pip install -r requirements_dev.txt```Then run some things that Brizo expects to be running:```bashgit clone git@github.com:oceanprotocol/barge.gitcd bargebash start_ocean.sh --no-brizo --no-commons```Barge is the repository where all the Ocean Docker Compose files are located. We are running the script `start_ocean.sh --no-brizo`: the easy way to have Ocean projects up and running. We run without a Brizo instance.To learn more about Barge, visit [the Barge repository](https://github.com/oceanprotocol/barge).Note that it runs an Aquarius instance and an Elasticsearch instance but Aquarius can also work with BigchainDB or MongoDB.The most simple way to start is:```bashpip install -r requirements_dev.txtexport FLASK_APP=brizo/run.pyexport CONFIG_FILE=config.ini./scripts/wait_for_migration_and_extract_keeper_artifacts.shexport PROVIDER_ADDRESS=&quot;your ethereum address goes here&quot;# Set one of the followingexport PROVIDER_KEY=&quot;the private key&quot;export PROVIDER_ENCRYPTED_KEY=&quot;The encrypted key json from the keyfile&quot;export PROVIDER_KEYFILE=&quot;your ethereum address goes here&quot;# and set the password if using either PROVIDER_KEYFILE or PROVIDER_ENCRYPTED_KEYexport PROVIDER_PASSWORD=&quot;password to allow decrypting the encrypted key&quot;flask run --port=8030```That will use HTTP (i.e. not SSL/TLS).The proper way to run the Flask application is using an application server such as Gunicorn. This allow you to run using SSL/TLS. You can generate some certificates for testing by doing:```bashopenssl req -x509 -newkey rsa:4096 -nodes -out cert.pem -keyout key.pem -days 365```and when it asks for the Common Name (CN), answer `localhost`Then edit the config file `config.ini` so that:```yamlbrizo.url = https://localhost:8030```Then execute this command:```bashgunicorn --certfile cert.pem --keyfile key.pem -b 0.0.0.0:8030 -w 1 brizo.run:app```## API documentationOnce you have Brizo running you can get access to the API documentation at:```bashhttps://127.0.0.1:8030/api/v1/docs```There is also some [Brizo API documentation in the official Ocean docs](https://docs.oceanprotocol.com/references/brizo/).## ConfigurationTo get configuration settings, Brizo first checks to see if there is a non-empty environment variable named CONFIG_FILE. It there is, it will look in a config file at that path. Otherwise it will look in a config file named `config.ini`. Note that some settings in the config file can be overridden by setting certain environment variables; there are more details below.See the [example config.ini file in this repo](config.ini). You will see that there are three sections: `[keeper-contracts]`, `[resources]` and `[osmosis]`.### The [keeper-contracts] and [resources] SectionsThe `[keeper-contracts]` section is used to setup connection to the keeper nodes and load keeper-contracts artifacts.The `[resources]` sections is used to configure:* Default Metadata store (Aquarius) URI* Default Brizo URI* Operator Service URI for for requesting compute services### The [osmosis] SectionThe `[osmosis]` section of the config file is where a provider puts their own credentials for various third-party services, such as Azure Storage.Brizo could support files with the following kinds of URLs:- files in Azure Storage: files with &quot;core.windows.net&quot; in their URLs- files in Amazon S3 storage: files with &quot;s3://&quot; in their URLs- files on ipfs: files URLs starting with &quot;ipfs://&quot;- files in on-premise storage: all other files with resolvable URLsA publisher can choose to support any of the above or build their own custom driver. It depends on which cloud providers they use.If a publisher wants to store some files in Azure Storage (and make them available from there), then they must get and set the following config settings in the [osmosis] section of the config file. There is an [Ocean tutorial about how to get all those credentials from Azure](https://docs.oceanprotocol.com/tutorials/azure-for-brizo/).```ini[osmosis]azure.account.name = &lt;Azure Storage Account Name (for storing files)&gt;azure.account.key = &lt;Azure Storage Account key&gt;azure.resource_group = &lt;Azure resource group&gt;azure.location = &lt;Azure Region&gt;azure.client.id = &lt;Azure Application ID&gt;azure.client.secret = &lt;Azure Application Secret&gt;azure.tenant.id = &lt;Azure Tenant ID&gt;azure.subscription.id = &lt;Azure Subscription&gt;; azure.share.input and azure.share.output are only used; for Azure Compute data assets (not for Azure Storage data assets).; If you're not supporting Azure Compute, just leave their values; as compute and output, respectively.azure.share.input = computeazure.share.output = output```You can override any of those config file settings by setting one or more of the following environment variables. You will want to do that if you're running Brizo in a container.```textAZURE_ACCOUNT_NAMEAZURE_ACCOUNT_KEYAZURE_RESOURCE_GROUPAZURE_LOCATIONAZURE_CLIENT_IDAZURE_CLIENT_SECRETAZURE_TENANT_IDAZURE_SUBSCRIPTION_ID# Just always set AZURE_SHARE_INPUT='compute' for nowAZURE_SHARE_INPUT='compute'# Just always set AZURE_SHARE_OUTPUT='output' for nowAZURE_SHARE_OUTPUT='output'```If a publisher wants to store some files in Amazon S3 storage (and make them available from there), then there are no AWS-related config settings to set in the config file. AWS credentials actually get stored elsewhere. See [the Ocean tutorial about how to set up Amazon S3 storage](https://docs.oceanprotocol.com/tutorials/amazon-s3-for-brizo/).If a publisher wants to support files on IPFS storage, the only requirement is to set the environment variable `IPFS_GATEWAY` which defaults to &quot;https://gateway.ipfs.io&quot;in the `osmosis-ipfs-driver`.If a publisher wants to store some files on-premise (and make them available from there), then there are no special config settings to set in the config file. The only requirement is that the file URLs must be resolvable by Brizo. See [the Ocean tutorial about how to set up on-premise storage](https://docs.oceanprotocol.com/tutorials/on-premise-for-brizo/).## Compute-to-Data setupDo the following to support the Compute to data feature:* Set the Operator Service URI using one of the following:  * In config.ini under `operator_service.url` in the `resources` section  * Environment variable `OPERATOR_SERVICE_URL`* Add the Provider ethereum address to the Operator Service list of providers. The Operator Service only accepts requests signed by known providers* Setup the Operator Service, Operator Engine and the Kubernetes infrastructure, more details here [Operator Service](https://github.com/oceanprotocol/operator-service) ## DependenciesBrizo relies on the following Ocean libraries:- [ocean-utils](https://github.com/oceanprotocol/common-utils-py) provides common functions and datastructures for interaction with the Ocean Protocol components- [ocean-keeper](https://github.com/oceanprotocol/keeper-py-lib) handles all of the `keeper` interactions- [ocean-secret-store-client](https://github.com/oceanprotocol/secret-store-client-py) to encrypt/decrypt the dataset urls- [osmosis-azure-driver](https://github.com/oceanprotocol/osmosis-azure-driver) mediates access to assets in Azure- [osmosis-aws-driver](https://github.com/oceanprotocol/osmosis-aws-driver) mediates access to assets in AWS- [osmosis-on-premise-driver](https://github.com/oceanprotocol/osmosis-on-premise-driver) mediates access to on-premise assets## Code StyleInformation about our Python code style is documented in the [python-developer-guide](https://github.com/oceanprotocol/dev-ocean/blob/master/doc/development/python-developer-guide.md)and the [python-style-guide](https://github.com/oceanprotocol/dev-ocean/blob/master/doc/development/python-style-guide.md).## TestingAutomatic tests are setup via Travis (in .travis.yaml config file), executing `tox` (see the tox.ini file).Our tests use the pytest framework.## DebuggingTo debug Brizo using PyCharm, follow the next instructions:1. Clone [barge](https://github.com/oceanprotocol/barge) repository.2. Run barge omitting `brizo`. (i.e.:`bash start_ocean.sh --no-brizo --no-commons --local-nile-node`)3. In PyCharm, go to _Settings &gt; Project Settings &gt; Python Debugger_, and select the option _Gevent Compatible_4. Configure a new debugger configuration: _Run &gt; Edit Configurations..._, there click on _Add New Configuration_5. Configure as shown in the next image:![Pycharm Debugger configuration](imgs/debugger_configuration.png)6. Set the following environment variables:    ```text    PYTHONUNBUFFERED=1    CONFIG_FILE=config.ini    AZURE_ACCOUNT_NAME=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_TENANT_ID=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_SUBSCRIPTION_ID=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_LOCATION=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_CLIENT_SECRET=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_CLIENT_ID=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_ACCOUNT_KEY=&lt;COMPLETE_WITH_YOUR_DATA&gt;    AZURE_RESOURCE_GROUP=&lt;COMPLETE_WITH_YOUR_DATA&gt;    OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES    ```   The option `OBJC_DISABLE_INITIALIZE_FORK_SAFETY` is needed if you run in last versions of MacOS.7. Now you can configure your breakpoints and debug brizo.## New VersionThe `bumpversion.sh` script helps to bump the project version. You can execute the script using as first argument {major|minor|patch} to bump the version accordingly.## License```textCopyright 2018 Ocean Protocol Foundation Ltd.Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);you may not use this file except in compliance with the License.You may obtain a copy of the License at   http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an &quot;AS IS&quot; BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.```</longdescription>
</pkgmetadata>