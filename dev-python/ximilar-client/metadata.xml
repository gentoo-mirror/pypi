<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Ximilar API Python Client![](logo.png)This Python 3.9+ Client library is lightweight wrapper for `ximilar.com` and `vize.ai`. ## InstallationPyPI (https://pypi.org/project/ximilar-client/):    # we recommend to install ximilar-client to new virtualenv    pip install ximilar-clientManual installation with latest changes:    1. Cloning the repo    git clone https://gitlab.com/ximilar-public/ximilar-client.git    2. Install it with pip to your virtualenv    pip install -e ximilar-clientThis will install also urllib3, requests, tqdm and pytest library. This will not install python-opencv which is required if you want to upload local images to the Ximilar system. For more information about installing opencv on different systems we have a small page in our [docs](https://docs.ximilar.com/quickstart/credits/).***You will need to install one of opencv-python or opencv-contrib-python (or headless) manually.***##  UsageFirst you need to register via `app.ximilar.com` and obtain your `API TOKEN` for communication with ximilar rest endpoints. You can obtain the token from the [Ximilar App](https://app.ximilar.com/) at your profile page. After you obtain the token, the usage is quite straightforward. First, import this package and create specific rest client (reconition/vize, tagging, colors, search, ...).  In following example we will create client for `Ximilar Recognition Service` (vize.ai). For all other Ximilar Services as Tagging, Custom Object Detection you will need to contact `tech@ximilar.com` first, so they will provide you access to the service: ```pythonfrom ximilar.client import RecognitionClient, DetectionClientfrom ximilar.client import DominantColorProductClient, DominantColorGenericClientfrom ximilar.client import FashionTaggingClient, GenericTaggingClientapp_client = RecognitionClient(token=&quot;__API_TOKEN__&quot;)detect_client = DetectionClient(token=&quot;__API_TOKEN__&quot;)...```## WorkspacesWith a new version of Ximilar App you are able to work also with workspaces. Workspaces are entities where all your task, labels and images live. Each user has by default workspace with name `Default` (it will be used if you do not specify workspace when working with Image, Label, Task). However you can specify id of workspace in the constructor.```pythonclient = RecognitionClient(token=&quot;__API_TOKEN__&quot;, workspace='__UUID_OF_YOUR_WORKSPACE__')client = DetectionClient(token=&quot;__API_TOKEN__&quot;, workspace='__UUID_OF_YOUR_WORKSPACE__')```## Ximilar RecognitionThis client allows you to work with Ximilar Recognition Service. With this client you are able to create classification or tagging tasks based on latest trends in machine learning and neural networks.After creating client object you can for example load your existing task and call train:```pythontask, status = client.get_task(task_id='__ID_TASK_')# Every label in the task must have at least 20 images before training.# The training can take up to several hours as we are trying to achieve really high quality# solution. This endpoint will immediately return success if your task is in training queue.task.train() # or you can list all your available taskstasks, status = client.get_all_tasks()# or you can create new classification task# each Task, Image, Label is identified by unique IDtask, status = client.create_task('__TASK_NAME__')```#### TaskCurrently there are two types of task to create. User can select 'multi_class' (default) or 'multi_label'. See ximilar.docs for more info.```python# categorization/classification or multi class task means that image is assigned to exactly one label# labels are exclusive which means image can contain only 'cat' or only 'dog'classification_task, status = client.create_task('__TASK_NAME__')# tagging or multi label task means that image can have one or more labels# for example image can contain 'cat', 'dog' and 'animal' labels if there are on the picturetagging_task, status = client.create_task('__TASK_NAME__', type='multi_label')# removing task is possible through client object or task itselfclient.remove_task(task.id)task.remove()```#### ClassifySuppose you want to use the task to predict the result on your images. Please, always try to send image bigger than 200px and lower than 600px for quality and speed:```python# you can send image in _file, _url or _base64 format# the _file format is intenally converted to _base64 as rgb imageresult = task.classify([{'_url': '__URL_PATH_TO_IMG__'}, {'_file', '__LOCAL_FILE_PATH__'}, {'_base64': '__BASE64_DATA__'}])# the result is in json/dictionary format and you can access it in following way:best_label = result['records'][0]['best_label']```#### LabelsLabels are connected to the task. Depends which task you are working with (Tagging/multi_label or Categorization/multi_class) you can create Tag or Category labels. Working with the labels are pretty simple:```python# getting existing labelexisting_label, status = client.get_label('__ID_LABEL__')# creating new label (CATEGORY, which is default) and attaching it to existing Categorization task (multi class)label, status = client.create_label(name='__NEW_LABEL_NAME__')task.add_label(label.id)# creating new label (TAG) for Tagging task (multi label)label, status = client.create_label(name='__NEW_LABEL_NAME__', label_type='tag')# get all labels which are connected to the tasklabels, status = task.get_labels()for label in labels:    print(label.id, label.name)# get label with exact name which is also connected to specific tasklabel, status = task.get_label_by_name(name='__LABEL_NAME__')# detaching (not deleting) existing label from existing tasktask.detach_label(label.id)# remove label (which also detach label from all tasks)client.remove_label(label.id)# detach image from labellabel.detach_image(image.id)# search labels which contains given substring in namelabels, status = client.get_labels_by_substring('__LABEL_NAME__')```#### Working with training imagesImage is main entity in Ximilar system. Every image can have multiple labels (Recognition service) or multiple objects (Detection service).```python# getting all images of label (paginated result)images, next_page, status = label.get_training_images()while images:    for image in images:        print(str(image.id))    if not next_page:        break    images, next_page, status = label.get_training_images(next_page)# basic operationsimage, status = client.get_image(image_id=image.id)image.add_label(label.id)# detach label from imageimage.detach_label(label.id)# deleting image client.remove_image(image.id)```Let's say you want to upload a training image and add several labels to this image:```pythonimages, status = client.upload_images([{'_url': '__URL_PATH_TO_IMAGE__', 'labels': [label.id for label in labels], &quot;meta_data&quot;: {&quot;field&quot;: &quot;key&quot;}},                                       {'_file': '__LOCAL_FILE_PATH__', 'labels': [label.id for label in labels]},                                       {'_base64': '__BASE64_DATA__', 'labels': [label.id for label in labels]}])# and maybe add another label to the first imageimages[0].add_label(&quot;__SOME_LABEL_ID__&quot;)```Upload image without resizing it (for example Custom Object Detection requires high resolution images):```pythonimages, status = client.upload_images([{'_url': '__URL_PATH_TO_IMAGE__', &quot;noresize&quot;: True}])```Every image can have some meta data stored:```pythonimage.add_meta_data({&quot;__KEY_1__&quot;: &quot;value&quot;, &quot;__KEY_2__&quot;: {&quot;THIS CAB BE&quot;:&quot;COMPLEX&quot;}})image.clear_meta_data()```Every image can be marked with **test** flag (for evaluation on independent test dataset only):```pythonimage.set_test(True)```Every image can be marked as real (default) or product. Product image should be images where is dominant one object on nice solid background. We can do more augmentations on these images.```pythonimage.set_real(False) # will mark image as product```## Ximilar FlowsThe client is able to get flow of the json or process images/records by the flow.```pythonfrom ximilar.client import FlowsClientclient = FlowsClient(&quot;__API_TOKEN__&quot;)# get flowflow, _ = client.get_flow(&quot;__FLOW_ID__&quot;)# two way to call the flow on recordsclient.process_flow(flow.id, records)flow.proces(records)```## Ximilar Object DetectionXimilar Object Detection is service which will help you find exact location (Bounding Box/Object with four coordinates xmin, ymin, xmax, ymax).In similar way as Ximilar Recognition, here we also have Tasks, Labels and Images. However one more entity called Object is present in Ximilar Object Detection.First you need to create/get Detection Task:```pythonclient = DetectionClient(&quot;__API_TOKEN__&quot;)detection_task, status = client.create_task(&quot;__DETECTION_TASK_NAME__&quot;)detection_task, status = client.get_task(task.id)```Second you need to create Detection Label and connect it to the task:```pythondetection_label, status = client.create_label(&quot;__DETECTION_LABEL_NAME__&quot;)detection_label, status = client.get_label(&quot;__DETECTION_LABEL_ID__&quot;)detection_task.add_label(detection_label.id)```Lastly you need to create Objects/Bounding box annotations of some type (Label) on the images:```pythonimage, status = client.get_image(&quot;__IMAGE_ID__&quot;)d_object, status = client.create_object(&quot;__DETECTION_LABEL_ID__&quot;, &quot;__IMAGE_ID__&quot;, [xmin, ymin, xmax, ymax])d_object, status = client.get_object(d_object.id)# get all objects of imaged_objects, status = client.get_objects_of_image(&quot;__IMAGE_ID__&quot;)```Then you can create your task:```pythondetection_task.train()```Removing entities is same as in recognition client:```pythonclient.remove_task(&quot;__DETECTION_TASK_ID__&quot;)client.remove_label(&quot;__DETECTION_LABEL_ID__&quot;) # this will delete all objects which were created as this labelclient.remove_object(&quot;__DETECTION_OBJECT_ID__&quot;)client.remove_image(&quot;__IMAGE_ID__&quot;)task.remove()label.remove()object1 = client.get_object(&quot;__DETECTION_OBJECT_ID__&quot;)object1.remove()image.remove()```Getting Detection Result:```pythonresult = detection_task.detect([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])```Extracting object from image:```pythonimage,  status = client.get_image(&quot;59f7240d-ca86-436b-b0cd-30f4b94705df&quot;)object1, status = client.get_object(&quot;__DETECTION_OBJECT_ID__&quot;)extracted_image_record = image.extract_object_data(object1.data)```## Speeding it up with Parallel ProcessingIf you are uploading/classifying thousands of images and really need to speed it up, then you can use method parallel_records_processing:```python# classifying images in Ximilar Custom Recognition serviceresult = client.parallel_records_processing([{&quot;_url&quot;: image} for image in images], method=task.classify, output=True, max_workers=3)# detection images in Ximilar Custom Object Detectionresult = client.parallel_records_processing([{&quot;_url&quot;: image} for image in images], method=task.detect, output=True, max_workers=3)# uploading imagesresult = client.parallel_records_processing([{&quot;_url&quot;: image, &quot;labels&quot;: [&quot;__LABEL_ID_1__&quot;]} for image in images], method=client.upload_images, output=True)```This method works only for getting result for classification, tagging, detection, color extraction or uploading images (All methods which use json records as input).## Ximilar Visual SearchService for visual fashion search. For more information see docs.ximilar.com```pythonfrom ximilar.client.visual import SimilarityFashionClientclient = SimilarityFashionClient(token='__API_TOKEN__', collection_id='__COLLECTION_ID__')# inserting image requires _id and product_idclient.insert([{&quot;_id&quot;: &quot;__IMAGE_ID__&quot;, &quot;product_id&quot;: &quot;__PRODUCT_ID__&quot;, &quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])result = client.detect([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])# search in collectionresult = client.search([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])```## Ximilar Dominant ColorsYou can select the service for extracting dominant colors by type of your image. If the image is from Product/Fashion domain, which means that product is tipically on some solid background then us `DominanColorProductClient`.```pythonfrom ximilar.client import DominantColorProductClient, DominantColorGenericClientproduct_client = DominantColorProductClient(token=&quot;__API_TOKEN__&quot;)generic_client = DominantColorGenericClient(token=&quot;__API_TOKEN__&quot;)result = product_client.dominantcolor([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])print(result['records'][0]['_dominant_colors'])```## Ximilar Generic and Fashion TaggingTagging contains two clients in similar way as DominanColors do.```pythonfrom ximilar.client import FashionTaggingClient, GenericTaggingClientfashion_client = FashionTaggingClient(token=&quot;__API_TOKEN__&quot;)generic_client = GenericTaggingClient(token=&quot;__API_TOKEN__&quot;)result = generic_client.tags([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])print(result['records'][0]['_tags'])result = fashion_client.tags([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])print(result['records'][0]['_tags'])result = fashion_client.meta_tags([{&quot;_url&quot;: &quot;__URL_PATH_TO_IMAGE__&quot;}])print(result['records'][0]['_tags_meta_simple'])```## Ximilar Photo and Product similarityThese two services provides visual search (similarity search) for generic (stock) photos or products (e-commerce, fashion, ...).When initializing client you need to specify both `token` and your `collection_id` that we created for you.```pythonfrom ximilar.client.search import SimilarityPhotosClient, SimilarityProductsClientclient = SimilarityPhotosClient(token='__API_TOKEN__', collection_id='__COLLECTION_ID__')client = SimilarityProductsClient(token='__API_TOKEN__', collection_id='__COLLECTION_ID__')# get random 7 items from database and return also _url if is present in itemresult = client.random(count=7, fields_to_return=['_id', '_url'])# search 10 most visually similar items for item in your indexresult = client.search({'_id': '__ITEM_ID__'}, k=10)# search 5 most visually similar items for external item (not in index) defined by _url fieldresult = client.search({'_url': '__URL_PATH_TO_IMAGE__'}, k=5)# search visually similar items, return also _url field if present in item and # search only for items defined by filter (mongodb syntax)result = client.search({'_id': '__ITEM_ID__'}, fields_to_return=['_id', '_url'],                       filter={                            'meta-category-x': { '$in': ['__SOME_VALUE_1__', '__SOME_VALUE_2__']},                            'some-field': '__SOME_VALUE__'                       })```All crud operations:```python# get list of items from indexresult = client.get_records([{'_id': '__ITEM_ID__'}, {'_id': '__ITEM_ID__'}])# insert item tot he index with your _id, and onr of _url | _base64, and other fields (meta-info) which you can # then use when applying filter in search or random menthodsresult = client.insert([{'_id': '__ITEM_ID__', '_url': '__URL_PATH_TO_IMAGE__',                         'meta-category-x': '__CATEGORY_OF_ITEM__',                         'meta-info-y': '__ANOTHER_META_INFO__'}])# delete item from idresult = client.remove([{'_id': '__ITEM_ID__'}])# update item in index with all additional fields and meta-inforesult = client.update([{'_id': '__ITEM_ID__', 'some-additional-field': '__VALUE__'}])```## Custom SimilarityThis service let you train your custom image similarity model.Creating entities is similar to recognition or detection service.```pythonfrom ximilar.client.similarity import CustomSimilarityClientclient = CustomSimilarityClient(&quot;__API__TOKEN__&quot;)tasks, _ = client.get_all_tasks()task, _ = client.create_task(&quot;__NAME__&quot;,  &quot;__DESCRIPTION__&quot;)type1, _ = client.create_type(&quot;__NAME__&quot;, &quot;__DESCRIPTION__&quot;)group, _ = client.create_group(&quot;__NAME__&quot;, &quot;__DESCRIPTION__&quot;, type1.id)```Add/Remove types to/from task:```pythontask.add_type(type1.id)task.remove_type(type1.id)```Add/Remove images to/from group:```pythongroup.add_images([&quot;__IMAGE_ID_1__&quot;])group.remove_images([&quot;__IMAGE_ID_1__&quot;])group.refresh()```Add/Remove groups to/from group:```pythongroup.add_groups([&quot;__GROUP_ID_1__&quot;])group.remove_groups([&quot;__GROUP_ID_1__&quot;])group.refresh()```Set unset group as test (test flag is for evaluation dataset):```pythongroup.set_test(True) # or False if unsetting from eval datasetgroup.refresh()```Searching groups with name:```pythonclient.get_all_groups_by_name(&quot;__NAME__&quot;)```# ToolsIn our `tools` folder you can find some useful scripts for:* `uploader.py` for uploading all images from specific folder* `data_saver.py` for saving entire recognition and detection workspace including images* `data_wiper.py` for removing entire workspace and all your data in workspace* `detection_cutter.py` cutting objects from images</longdescription>
</pkgmetadata>