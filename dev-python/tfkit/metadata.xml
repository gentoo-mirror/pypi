<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p  align=&quot;center&quot;&gt;    &lt;br&gt;    &lt;img src=&quot;https://raw.githubusercontent.com/voidful/TFkit/master/docs/img/tfkit.png&quot; width=&quot;300&quot;/&gt;    &lt;br&gt;&lt;/p&gt;&lt;br/&gt;&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://pypi.org/project/tfkit/&quot;&gt;        &lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/tfkit&quot;&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/voidful/tfkit&quot;&gt;        &lt;img alt=&quot;Download&quot; src=&quot;https://img.shields.io/pypi/dm/tfkit&quot;&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/voidful/tfkit&quot;&gt;        &lt;img alt=&quot;Build&quot; src=&quot;https://img.shields.io/github/workflow/status/voidful/tfkit/Python package&quot;&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/voidful/tfkit&quot;&gt;        &lt;img alt=&quot;Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/voidful/tfkit&quot;&gt;    &lt;/a&gt;    &lt;a href=&quot;https://www.codefactor.io/repository/github/voidful/tfkit/overview/master&quot;&gt;        &lt;img src=&quot;https://www.codefactor.io/repository/github/voidful/tfkit/badge/master&quot; alt=&quot;CodeFactor&quot; /&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/voidful/tfkit&quot;&gt;        &lt;img src=&quot;https://visitor-badge.glitch.me/badge?page_id=voidful.tfkit&quot; alt=&quot;Visitor&quot; /&gt;    &lt;/a&gt;    &lt;a href=&quot;https://codecov.io/gh/voidful/TFkit&quot;&gt;      &lt;img src=&quot;https://codecov.io/gh/voidful/TFkit/branch/master/graph/badge.svg&quot; /&gt;    &lt;/a&gt;&lt;/p&gt;## What is itTFKit is a tool kit mainly for language generation.  It leverages the use of transformers on many tasks with different models in this all-in-one framework.   All you need is a little change of config.  ## Task SupportedWith transformer models - BERT/ALBERT/T5/BART......  |  |  ||-|-|| Text Generation | :memo: seq2seq language model || Text Generation | :pen: causal language model || Text Generation | :printer: once generation model / once generation model with ctc loss || Text Generation | :pencil: onebyone generation model |# Getting StartedLearn more from the [document](https://voidful.github.io/TFkit/).  ## How To Use### Step 0: InstallSimple installation from PyPI```bashpip install git+https://github.com/voidful/TFkit.git@refactor-dataset```### Step 1: Prepare dataset in csv format[Task format](https://voidful.tech/TFkit/tasks/)``` input, target```### Step 2: Train model```bashtfkit-train \--task clas \--config xlm-roberta-base \--train training_data.csv \--test testing_data.csv \--lr 4e-5 \--maxlen 384 \--epoch 10 \--savedir roberta_sentiment_classificer```### Step 3: Evaluate```bashtfkit-eval \--task roberta_sentiment_classificer/1.pt \--metric clas \--valid testing_data.csv```## Advanced features&lt;details&gt;  &lt;summary&gt;Multi-task training &lt;/summary&gt;  ```bash  tfkit-train \    --task clas clas \    --config xlm-roberta-base \    --train training_data_taskA.csv training_data_taskB.csv \    --test testing_data_taskA.csv testing_data_taskB.csv \    --lr 4e-5 \    --maxlen 384 \    --epoch 10 \    --savedir roberta_sentiment_classificer_multi_task  ```&lt;/details&gt;## Not maintained taskDue to time constraints, the following tasks are temporarily not supported|  |  ||-|-|| Classification  | :label: multi-class and multi-label classification || Question Answering  | :page_with_curl: extractive qa || Question Answering  | :radio_button: multiple-choice qa || Tagging  | :eye_speech_bubble: sequence level tagging / sequence level with crf  || Self-supervise Learning | :diving_mask: mask language model |## Supplement- [transformers models list](https://huggingface.co/models): you can find any pretrained models here   - [nlprep](https://github.com/voidful/NLPrep): download and preprocessing data in one line     - [nlp2go](https://github.com/voidful/nlp2go): create demo api as quickly as possible.## ContributingThanks for your interest.There are many ways to contribute to this project. Get started [here](https://github.com/voidful/tfkit/blob/master/CONTRIBUTING.md).## License ![PyPI - License](https://img.shields.io/github/license/voidful/tfkit)* [License](https://github.com/voidful/tfkit/blob/master/LICENSE)## Icons referenceIcons modify from &lt;a href=&quot;http://www.freepik.com/&quot; title=&quot;Freepik&quot;&gt;Freepik&lt;/a&gt; from &lt;a href=&quot;https://www.flaticon.com/&quot; title=&quot;Flaticon&quot;&gt;www.flaticon.com&lt;/a&gt;      Icons modify from &lt;a href=&quot;https://www.flaticon.com/authors/nikita-golubev&quot; title=&quot;Nikita Golubev&quot;&gt;Nikita Golubev&lt;/a&gt; from &lt;a href=&quot;https://www.flaticon.com/&quot; title=&quot;Flaticon&quot;&gt;www.flaticon.com&lt;/a&gt;      </longdescription>
</pkgmetadata>