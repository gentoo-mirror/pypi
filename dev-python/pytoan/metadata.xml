<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>#  Library of pytoan## Introduction## Installing```shpip install pytoan```## Usage1. Example model with MNIST```pythonfrom pytoan.pytorch import Learningimport torch import torch.nn as nnimport torchvisionimport torchvision.transforms as transformsfrom pathlib import Path# Hyper parametersnum_classes = 10batch_size = 100learning_rate = 0.001# MNIST datasettrain_dataset = torchvision.datasets.MNIST(root='../../data/',                                           train=True,                                            transform=transforms.ToTensor(),                                           download=True)test_dataset = torchvision.datasets.MNIST(root='../../data/',                                          train=False,                                           transform=transforms.ToTensor())train_loader = torch.utils.data.DataLoader(dataset=train_dataset,                                           batch_size=batch_size,                                            shuffle=True,                                           pin_memory=True)test_loader = torch.utils.data.DataLoader(dataset=test_dataset,                                          batch_size=batch_size,                                           shuffle=False,                                          pin_memory=True)class ConvNet(nn.Module):    def __init__(self, num_classes=10):        super(ConvNet, self).__init__()        self.layer1 = nn.Sequential(            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),            nn.BatchNorm2d(16),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2))        self.layer2 = nn.Sequential(            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),            nn.BatchNorm2d(32),            nn.ReLU(),            nn.MaxPool2d(kernel_size=2, stride=2))        self.fc = nn.Linear(7*7*32, num_classes)    def forward(self, x):        out = self.layer1(x)        out = self.layer2(out)        out = out.reshape(out.size(0), -1)        out = self.fc(out)        return outdef accuracy_score(output, target):    with torch.no_grad():        pred = torch.argmax(output, dim=1)        assert pred.shape[0] == len(target)        correct = 0        correct += torch.sum(pred == target).item()    return correct / len(target)model = ConvNet(num_classes)criterion = nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)metric_ftns = [accuracy_score]device = [0]num_epoch = 100gradient_clipping = 0.1gradient_accumulation_steps = 1early_stopping = 10validation_frequency = 1tensorboard = Truecheckpoint_dir = Path('./', type(model).__name__)checkpoint_dir.mkdir(exist_ok=True, parents=True)resume_path = Nonelearning = Learning(model=model,                    criterion=criterion,                    optimizer=optimizer,                    scheduler = scheduler,                    metric_ftns=metric_ftns,                    device=device,                    num_epoch=num_epoch,                    grad_clipping = gradient_clipping,                    grad_accumulation_steps = gradient_accumulation_steps,                    early_stopping = early_stopping,                    validation_frequency = validation_frequency,                    tensorboard = tensorboard,                    checkpoint_dir = checkpoint_dir,                    resume_path=resume_path)```2. For Training and Validation```pythonlearning.train(train_loader, test_loader)```Log:![MNIST_EXAMPLE](./data/images/mnist_ex.png)3. For Testing```pythonlearning.test(test_loader) # but not complete```</longdescription>
</pkgmetadata>