<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Arbok=====Arbok (**A**\ utoml w\ **r**\ apper tool\ **b**\ ox for **o**\ penml**c**\ ompatibility) provides wrappers for TPOT and Auto-Sklearn, as acompatibility layer between these tools and OpenML.The wrapper extends Sklearnâ€™s ``BaseSearchCV`` and provides all theinternal parameters that OpenML needs, such as ``cv_results_``,``best_index_``, ``best_params_``, ``best_score_`` and ``classes_``.Installation------------::    pip install arbokSimple example--------------.. code:: python    import openml    from arbok import AutoSklearnWrapper, TPOTWrapper    task = openml.tasks.get_task(31)    dataset = task.get_dataset()    # Get the AutoSklearn wrapper and pass parameters like you would to AutoSklearn    clf = AutoSklearnWrapper(        time_left_for_this_task=3600, per_run_time_limit=360    )    # Or get the TPOT wrapper and pass parameters like you would to TPOT    clf = TPOTWrapper(        generations=100, population_size=100, verbosity=2    )    # Execute the task    run = openml.runs.run_model_on_task(task, clf)    run.publish()    print('URL for run: %s/run/%d' % (openml.config.server, run.run_id))Preprocessing data------------------To make the wrapper more robust, we need to preprocess the data. We canfill the missing values, and one-hot encode categorical data.First, we get a mask that tells us whether a feature is a categoricalfeature or not... code:: python    dataset = task.get_dataset()    _, categorical = dataset.get_data(return_categorical_indicator=True)    categorical = categorical[:-1]  # Remove last index (which is the class)Next, we setup a pipeline for the preprocessing. We are using a``ConditionalImputer``, which is an imputer which is able to usedifferent strategies for categorical (nominal) and numerical data... code:: python    from sklearn.pipeline import make_pipeline    from sklearn.preprocessing import OneHotEncoder    from arbok import ConditionalImputer    preprocessor = make_pipeline(        ConditionalImputer(            categorical_features=categorical,            strategy=&quot;mean&quot;,            strategy_nominal=&quot;most_frequent&quot;        ),        OneHotEncoder(            categorical_features=categorical, handle_unknown=&quot;ignore&quot;, sparse=False        )    )And finally, we put everything together in one of the wrappers... code:: python    clf = AutoSklearnWrapper(        preprocessor=preprocessor, time_left_for_this_task=3600, per_run_time_limit=360    )Limitations~~~~~~~~~~~-  Currently only the classifiers are implemented. Regression is   therefore not possible.-  For TPOT, the ``config_dict`` variable can not be set, because this   causes problems with the API.Benchmarking------------Installing the ``arbok`` package includes the ``arbench`` cli tool. Wecan generate a json file like this:.. code:: python    from arbok.bench import Benchmark    bench = Benchmark()    config_file = bench.create_config_file(        # Wrapper parameters        wrapper={&quot;refit&quot;: True, &quot;verbose&quot;: False, &quot;retry_on_error&quot;: True},        # TPOT parameters        tpot={            &quot;max_time_mins&quot;: 6,              # Max total time in minutes            &quot;max_eval_time_mins&quot;: 1          # Max time per candidate in minutes        },        # Autosklearn parameters        autosklearn={            &quot;time_left_for_this_task&quot;: 360,  # Max total time in seconds            &quot;per_run_time_limit&quot;: 60         # Max time per candidate in seconds        }    )And then, we can call arbench like this:.. code:: bash    arbench --classifier autosklearn --task-id 31 --config config.jsonOr calling arbok as a python module:.. code:: bash    python -m arbok --classifier autosklearn --task-id 31 --config config.jsonRunning a benchmark on batch systems------------------------------------To run a large scale benchmark, we can create a configuration file likeabove, and generate and submit jobs to a batch system as follows... code:: python    # We create a benchmark setup where we specify the headers, the interpreter we    # want to use, the directory to where we store the jobs (.sh-files), and we give    # it the config-file we created earlier.    bench = Benchmark(        headers=&quot;#PBS -lnodes=1:cpu3\n#PBS -lwalltime=1:30:00&quot;,        python_interpreter=&quot;python3&quot;,  # Path to interpreter        root=&quot;/path/to/project/&quot;,        jobs_dir=&quot;jobs&quot;,        config_file=&quot;config.json&quot;,        log_file=&quot;log.json&quot;    )    # Create the config file like we did in the section above    config_file = bench.create_config_file(        # Wrapper parameters        wrapper={&quot;refit&quot;: True, &quot;verbose&quot;: False, &quot;retry_on_error&quot;: True},        # TPOT parameters        tpot={            &quot;max_time_mins&quot;: 6,              # Max total time in minutes            &quot;max_eval_time_mins&quot;: 1          # Max time per candidate in minutes        },        # Autosklearn parameters        autosklearn={            &quot;time_left_for_this_task&quot;: 360,  # Max total time in seconds            &quot;per_run_time_limit&quot;: 60         # Max time per candidate in seconds        }    )    # Next, we load the tasks we want to benchmark on from OpenML.    # In this case, we load a list of task id's from study 99.    tasks = openml.study.get_study(99).tasks    # Next, we create jobs for both tpot and autosklearn.    bench.create_jobs(tasks, classifiers=[&quot;tpot&quot;, &quot;autosklearn&quot;])    # And finally, we submit the jobs using qsub    bench.submit_jobs()Preprocessing parameters------------------------.. code:: python    from arbok import ParamPreprocessor    import numpy as np    from sklearn.feature_selection import VarianceThreshold    from sklearn.pipeline import make_pipeline    X = np.array([        [1, 2, True, &quot;foo&quot;, &quot;one&quot;],        [1, 3, False, &quot;bar&quot;, &quot;two&quot;],        [np.nan, &quot;bar&quot;, None, None, &quot;three&quot;],        [1, 7, 0, &quot;zip&quot;, &quot;four&quot;],        [1, 9, 1, &quot;foo&quot;, &quot;five&quot;],        [1, 10, 0.1, &quot;zip&quot;, &quot;six&quot;]    ], dtype=object)    # Manually specify types, or use types=&quot;detect&quot; to automatically detect types    types = [&quot;numeric&quot;, &quot;mixed&quot;, &quot;bool&quot;, &quot;nominal&quot;, &quot;nominal&quot;]    pipeline = make_pipeline(ParamPreprocessor(types=&quot;detect&quot;), VarianceThreshold())    pipeline.fit_transform(X)Output:::    [[-0.4472136  -0.4472136   1.41421356 -0.70710678 -0.4472136  -0.4472136       2.23606798 -0.4472136  -0.4472136  -0.4472136   0.4472136  -0.4472136      -0.85226648  1.        ]     [-0.4472136   2.23606798 -0.70710678 -0.70710678 -0.4472136  -0.4472136      -0.4472136  -0.4472136  -0.4472136   2.23606798  0.4472136  -0.4472136      -0.5831297  -1.        ]     [ 2.23606798 -0.4472136  -0.70710678 -0.70710678 -0.4472136  -0.4472136      -0.4472136  -0.4472136   2.23606798 -0.4472136  -2.23606798  2.23606798      -1.39054004 -1.        ]     [-0.4472136  -0.4472136  -0.70710678  1.41421356 -0.4472136   2.23606798      -0.4472136  -0.4472136  -0.4472136  -0.4472136   0.4472136  -0.4472136       0.49341743 -1.        ]     [-0.4472136  -0.4472136   1.41421356 -0.70710678  2.23606798 -0.4472136      -0.4472136  -0.4472136  -0.4472136  -0.4472136   0.4472136  -0.4472136       1.031691    1.        ]     [-0.4472136  -0.4472136  -0.70710678  1.41421356 -0.4472136  -0.4472136      -0.4472136   2.23606798 -0.4472136  -0.4472136   0.4472136  -0.4472136       1.30082778  1.        ]]</longdescription>
</pkgmetadata>