<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Tapdata Python Sdk[English](https://github.com/tapdata/tapdata/tree/master/tapshell/docs/Python-Sdk.md)*Applicable version*- tapshell / Python-Sdk: ^2.3.0- tapdata: ^2.9## Install1. Install python3.7、pip；2. Run ```pip install tapdata_cli``` to install sdk；3. if use Poetry, run ```poetry add tapdata_cli``` to install dependence.## Initial```pythonserver = &quot;127.0.0.1:3000&quot;access_code = &quot;3324cfdf-7d3e-4792-bd32-571638d4562f&quot;from tapdata_cli import clicli.init(server, access_code)```**Multi-thread concurrency is not supported**It will send a request to the server to obtain the identity information and save it as a global variable. Therefore, after multiple init the 'server' and 'access_code' variable will be overwritten.For situations where you need to use different servers and access_codes concurrently, use Python's multiprocess.## DataSource### Create DataSourceTo create DataSource by Python Sdk, you can do it by form or uri mode.Example for uri mode:```pythonfrom tapdata_cli import cliconnector = &quot;mongodb&quot;  # 数据源类型，mongodb mysql postgresmongo = cli.DataSource(&quot;mongodb&quot;, name=&quot;mongo&quot;)mongo.uri(&quot;mongodb://localhost:8080&quot;)  # 数据源urimongo.save()```or form mode:```pythonfrom tapdata_cli import climongo = cli.DataSource(&quot;mongodb&quot;, name=&quot;mongo&quot;)mongo.host(&quot;localhost:27017&quot;).db(&quot;source&quot;).username(&quot;user&quot;).password(&quot;password&quot;).props(&quot;&quot;)mongo.type(&quot;source&quot;)  # 数据源类型，source -&gt; 只可作为源，target -&gt; 只可作为目标，source_and_target -&gt; 可以作为源和目标（默认）mongo.save()  # success -&gt; True, Failure -&gt; False```More infomation to create DataSource, please read [this file](https://github.com/tapdata/tapdata/blob/master/tapshell/docs/Param-Check_zh-hans.md).### DataSource List```pythonfrom tapdata_cli import clicli.DataSource().list()# return datastruct{    &quot;total&quot;: 94,    &quot;items&quot;: [{        &quot;id&quot;: &quot;&quot;,        &quot;lastUpdBy&quot;: &quot;&quot;,        &quot;name&quot;: &quot;&quot;,        &quot;config&quot;: {},        &quot;connection_type&quot;: &quot;&quot;,        &quot;database_type&quot;: &quot;&quot;,        &quot;definitionScope&quot;: &quot;&quot;,        &quot;definitionVersion&quot;: &quot;&quot;,        &quot;definitionGroup&quot;: &quot;&quot;,        &quot;definitionPdkId&quot;: &quot;&quot;,        ...        }]        }        ```### get datasource by id/name```pythonfrom tapdata_cli import clicli.DataSource(id=&quot;&quot;)  # 根据id获取数据源信息cli.DataSource(name=&quot;&quot;)  # 根据name获取数据源信息```## Pipeline### Migrate job```pythonfrom tapdata_cli import cli# Create DataSourcecli.DataSource(&quot;mongodb&quot;, name=&quot;source&quot;).uri(&quot;&quot;).save()cli.DataSource(&quot;mongodb&quot;, name=&quot;target&quot;).uri(&quot;&quot;).save()# Create Source and target nodesource = cli.Source(&quot;source&quot;)target = cli.Sink(&quot;target&quot;)# copy all table by default;# copy by tables you want to, use table=[]# filter table, by table_resource = cli.Source(&quot;source&quot;, table=[&quot;table_1&quot;, &quot;table_2&quot;, &quot;table_3&quot;], table_re=&quot;table_*&quot;)source.config({&quot;migrateTableSelectType&quot;: &quot;custom&quot;})  # change migrateTableSelectType: from all to custom# init pipeline installp = cli.Pipeline(name=&quot;example_job&quot;)p.readFrom(source).writeTo(target)# startp.start()# stopp.stop()# deletep.delete()# check statusp.status()# job listcli.Job.list()```Job is th underlying implementation of Pipeline，so you can start job by `job.start()` like `pipeline.start()`。```python# init job (get job info) by idfrom tapdata_cli import clijob = cli.Job(id=&quot;some id string&quot;)job.save() # success -&gt; True, failure -&gt; Falsejob.start() # success -&gt; True, failure -&gt; False```### Sync jobBefore you start a sync job, update job mode to `sync`.```pythonfrom tapdata_cli import clicli.DataSource(&quot;mongodb&quot;, name=&quot;source&quot;).uri(&quot;&quot;).save()  # create datasourcecli.DataSource(&quot;mongodb&quot;, name=&quot;target&quot;).uri(&quot;&quot;).save()  # create targetp = cli.Pipeline(name=&quot;sync_job&quot;, mode=&quot;sync&quot;)  # update to sync mode, or use p.dag.jobType = JobType.syncp.mode(cli.JobType.sync)  # or you can update to sync mode by this way# read sourcep = p.readFrom(&quot;source.player&quot;) # source is db, player is tablep = p.readFrom(cli.Source(&quot;source&quot;, table=&quot;player&quot;, mode=&quot;sync&quot;))  # or you init a Source Node in sync mode# continue to complex operation next# filter cli.FilterType.keep (keep data) / cli.FilterType.delete (delete data)p = p.filter(&quot;id &gt; 2&quot;, cli.FilterType.keep)# filerColumn cli.FilterType.keep (keep column) / cli.FilterType.delete (delete column)p = p.filterColumn([&quot;name&quot;], cli.FilterType.delete)# renamep = p.rename(&quot;name&quot;, &quot;player_name&quot;)# valueMapp = p.valueMap(&quot;position&quot;, 1)# jsp = p.js(&quot;return record;&quot;)p.writeTo(&quot;target.player&quot;)  # target is db, player is tablep.writeTo(cli.Sink(&quot;target&quot;, table=&quot;player&quot;, mode=&quot;sync&quot;)```Master-slave Merge：```pythonp2 = cli.Pipeline(name=&quot;source_2&quot;)  # create pipeline which will be mergedp3 = p.merge(p2, [('id', 'id')])  # merge p2 and set joinkey, then writeTo a tablep3.writeTo(&quot;target.player&quot;)  # target is db, player is table```### Initial_syncIt's &quot;initial_sync+cdc&quot; mode by default. You can create a &quot;initial_sync&quot; job by this way:```pythonfrom tapdata_cli import clip = cli.Pipeline(name=&quot;&quot;)p.readFrom(&quot;source&quot;).writeTo(&quot;target&quot;)config = {&quot;type&quot;: &quot;initial_sync&quot;}  # initial_sync jobp1 = p.config(config=config)p1.start()```Change config by config method like `{&quot;type&quot;: &quot;cdc&quot;}` to create a initial_sync job。Python sdk has built-in param verification, you can update config by Pipeline.config, to see more configuration, you can see [this file](https://github.com/tapdata/tapdata/blob/master/tapshell/tapdata_cli/params/job.py)## Api Operation### Create/Update Apiserver```pythonfrom tapdata_cli import cli# Createcli.ApiServer(name=&quot;test&quot;, uri=&quot;http://127.0.0.1:3000/&quot;).save()# Update# 1.Get ApiServer idapi_server_id = cli.ApiServer.list()[&quot;id&quot;]# 2.Update ApiServer and savecli.ApiServer(id=api_server_id, name=&quot;test_2&quot;, uri=&quot;http://127.0.0.1:3000/&quot;).save()# delete apiservercli.ApiServer(id=api_server_id).delete()```### Publish Api```pythonfrom tapdata_cli import clicli.Api(name=&quot;test&quot;, table=&quot;source.player&quot;).publish() # source is db, player is table```### Unpublish Api```pythonfrom tapdata_cli import clicli.Api(name=&quot;test&quot;).unpublish()```### Delete api```pythonfrom tapdata_cli import clicli.Api(name=&quot;test&quot;).delete()```### Check api status```pythonfrom tapdata_cli import clicli.Api().status(&quot;test&quot;)  # success -&gt; &quot;pending&quot; or &quot;active&quot; / failure -&gt; None```</longdescription>
</pkgmetadata>