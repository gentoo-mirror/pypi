<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># clipcrop- Extract sections of images from your image by using OpenAI's CLIP and Facebooks Detr implemented on HuggingFace Transformers- Added new capability for segmentation using CLIP and Detr segmentation models# Why Detr?Facebook's Detr is one of most effective object detection algorithm developed in the recent years. It simply expands to Detection Transformers and effectively a CNN architecture followed by Transformers encoders and decoders. It uses biopartite matching loss to compare objects detected in an image and reasons the predictions with the global image. Images are processed via CNN and encoder layer to output hidden states [number of images, seq_length, d_model] and object_queries [number of images, num of objects, d_model] are sent through decoders to get the neccessary logits for classification and MLP for regression(bounding box) Below are reason why you should prefer Detr over some popular algorithms- It's single step detector and it's efficiency is on par and better than two stage detectors like RCNN and Fast RCNN.- Compared to Yolo and SSD which are one stage detector DeTr performs detection on the whole image rather than grids of images unlike what we see in Yolo.# Installation```pythonpip install clipcrop```## Clip CropExtract sections of images from your image by using OpenAI's CLIP and Facebooks Detr implemented on HuggingFace Transformers (Inspired from [@vijishmadhavan](https://github.com/vijishmadhavan/Crop-CLIP/))### Implementation```pythonfrom clipcrop import clipcropclipc = clipcrop.ClipCrop(&quot;/content/nm.jpg&quot;, &quot;woman in white frock&quot;)DFE, DM, CLIPM, CLIPP = clipc.load_models()result = clipc.extract_image(DFE, DM, CLIPM, CLIPP)# gives a list of dicitonary of top images and its relative similarity score and you can override this by setting num = 5  to get top 5 etc while initiating the class```&lt;!-- ### Result&lt;p style=&quot;font-style: italic;&quot;&gt;clipcrop = ClipCrop(&quot;/content/nm.jpg&quot;, &quot;woman in white frock&quot;)&lt;/p&gt;&lt;p float=&quot;left&quot;&gt;&lt;img src=&quot;/nm.jpg&quot; width=&quot;600&quot; height=&quot;350&quot;&gt;&lt;img src=&quot;/clipcrop.jpeg&quot; width=&quot;150&quot; height=&quot;300&quot;&gt;&lt;/p&gt;&lt;br&gt;&lt;p style=&quot;font-style: italic;&quot;&gt;cc = ClipCrop('/content/rd.jpg', 'woman walking', 2)&lt;/p&gt;&lt;p float=&quot;left&quot;&gt;&lt;img src=&quot;/rd.jpg&quot; width=&quot;600&quot; height=&quot;350&quot;&gt;&lt;img src=&quot;/rmc.jpeg&quot; width=&quot;150&quot; height=&quot;300&quot;&gt;&lt;/p&gt; --&gt;### CaptchaSolve captacha images using CLIP and Object detection models.```pythonfrom clipcrop import clipcrop# second arguement is the text prompt eg:image of carsclipc = clipcrop.ClipCrop(image_path, &quot;image of cars&quot;)#loading models, processors, feature extractorsDFE, DM, CLIPM, CLIPP = clipc.load_models()#generally keep high threshold to avoid noisesresult = clipc.captcha(CLIPM, CLIPP, 4)```## Clip SegmentationSegment out images using Detr Panoptic segmentation pipeline and leverage CLIP models to derive at the most probable one for your query### Implementation```pythonfrom clipcrop import clipcropclipseg = clipcrop.ClipSeg(&quot;/content/input.png&quot;, &quot;black colored car&quot;)segmentor, clipmodel, clipprocessor = clipseg.load_models()result = clipseg.segment_image(segmentor, clipmodel, clipprocessor)# gives a list of dicitonary of top images and its relative similarity score and you can override this by setting num = 5  to get top 5 etc```</longdescription>
</pkgmetadata>