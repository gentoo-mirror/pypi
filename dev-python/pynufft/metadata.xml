<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># PyNUFFT: Python non-uniform fast Fourier transform![](g5738.jpeg)A minimal &quot;getting start&quot; tutorial is available at http://jyhmiinlin.github.io/pynufft/ . This package reimplements the min-max interpolator (Fessler, Jeffrey A., and Bradley P. Sutton. &quot;Nonuniform fast Fourier transforms using min-max interpolation.&quot; IEEE transactions on signal processing 51.2 (2003): 560-574.) for Python.### NewsAdd experimental support for cupy, PyTorch and TensorFlow Eager mode with test files. ### Some recent research works using PyNUFFT https://ieeexplore.ieee.org/document/10012099/https://iopscience.iop.org/article/10.1088/1361-6560/ab9358/meta (deep learning)https://arxiv.org/abs/2103.09203 (deep learning)https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.14809 (deep learning)https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579232 (deep learning)https://joss.theoj.org/papers/10.21105/joss.02825 (gravitational lens)https://joss.theoj.org/papers/10.21105/joss.02578 (Off-resonance CorrecTion OPen soUrce Software)## Installation$ pip3 install pynufft --user### Using Numpy/Scipy```$ pythonPython 3.6.11 (default, Aug 23 2020, 18:05:39) [GCC 7.5.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from pynufft import NUFFT&gt;&gt;&gt; import numpy&gt;&gt;&gt; A = NUFFT()&gt;&gt;&gt; om = numpy.random.randn(10,2)&gt;&gt;&gt; Nd = (64,64)&gt;&gt;&gt; Kd = (128,128)&gt;&gt;&gt; Jd = (6,6)&gt;&gt;&gt; A.plan(om, Nd, Kd, Jd)0&gt;&gt;&gt; x=numpy.random.randn(*Nd)&gt;&gt;&gt; y = A.forward(x)```### Using PyCUDA```&gt;&gt;&gt; from pynufft import NUFFT, helper&gt;&gt;&gt; import numpy&gt;&gt;&gt; A2= NUFFT(helper.device_list()[0])&gt;&gt;&gt; A2.device&lt;reikna.cluda.cuda.Device object at 0x7f9ad99923b0&gt;&gt;&gt;&gt; om = numpy.random.randn(10,2)&gt;&gt;&gt; Nd = (64,64)&gt;&gt;&gt; Kd = (128,128)&gt;&gt;&gt; Jd = (6,6)&gt;&gt;&gt; A2.plan(om, Nd, Kd, Jd)0&gt;&gt;&gt; x=numpy.random.randn(*Nd)&gt;&gt;&gt; y = A2.forward(x)```### Using Pytorch CPU (experimental)```&gt;&gt;&gt; from pynufft import NUFFT_torch, helper&gt;&gt;&gt; import numpy&gt;&gt;&gt; A2= NUFFT_torch()&gt;&gt;&gt; A2= NUFFT_torch()KeyboardInterrupt&gt;&gt;&gt; om = numpy.random.randn(10,2)&gt;&gt;&gt; Nd = (64,64)&gt;&gt;&gt; Kd = (128,128)&gt;&gt;&gt; Jd = (6,6)&gt;&gt;&gt; A2.plan(om, Nd, Kd, Jd)0&gt;&gt;&gt; x=numpy.random.randn(*Nd)&gt;&gt;&gt; y = A2.forward(x)&gt;&gt;&gt; x2 = A2.adjoint(y)&gt;&gt;&gt; x2.shapetorch.Size([64, 64])&gt;&gt;&gt; y.shapetorch.Size([10])```### Using TensorFlow CPU Eager mode (experimental)```&gt;&gt;&gt; from pynufft import NUFFT_tf_eager, helper&gt;&gt;&gt; import numpy&gt;&gt;&gt; A2= NUFFT_tf_eager()&gt;&gt;&gt; om = numpy.random.randn(10,2)&gt;&gt;&gt; A2.plan(om, Nd, Kd, Jd)2022-09-05 12:19:33.954058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMATo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.0&gt;&gt;&gt; x=numpy.random.randn(*Nd)&gt;&gt;&gt; y = A2.forward(x)&gt;&gt;&gt; x2 = A2.adjoint(y)&gt;&gt;&gt; x2.shape TensorShape([64, 64])&gt;&gt;&gt; y.shapeTensorShape([10])```## Testing GPU acceleration```Python 3.6.11 (default, Aug 23 2020, 18:05:39) [GCC 7.5.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from pynufft import tests&gt;&gt;&gt; tests.test_init(0)device name =  &lt;reikna.cluda.cuda.Device object at 0x7f41d4098688&gt;0.065760693550109870.006289639472961426error gx2= 2.0638987e-07error gy= 1.0912560261408778e-07acceleration= 10.45539952374201517.97926664352417 2.710083246231079acceleration in solver= 6.634211944790991```## Test Torch, TensorFlow and cupy (experimental)```Python 3.10.4 (main, Jun 29 2022, 12:14:53) [GCC 11.2.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from pynufft import tests as t&gt;&gt;&gt; t.test_torch()/home/sram/.local/lib/python3.10/site-packages/pynufft-2022.2.3rc1-py3.10.egg/pynufft/tests/test_torch.py:173: UserWarning: Module pynufft was already imported from /home/sram/.local/lib/python3.10/site-packages/pynufft-2022.2.3rc1-py3.10.egg/pynufft/__init__.py, but /home/sram/github/pynufft_online is being added to sys.path  import pkg_resourcesForward Error between torch and numpy 1.5022443208777513e-07Adjoint Error between torch and numpy 2.091061e-07&gt;&gt;&gt; t.test_tf_eager()2022-09-05 12:15:50.556015: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMATo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.Forward error between tf and numpy 1.801203473553717e-06Adjoint Error between tf and numpy 3.861161e-06&gt;&gt;&gt; t.test_cupy()Forward Error between cupy and numpy 2.2403478444672691e-07Adjoint Error between cupy and numpy 2.1125161308793866e-07```### Comparisons![](comparison.png)The comparison may not imply the clinical quality of third-party packages.### Contact informationIf you have professional requests related to the project, please contactemail: pynufft@gmail.com### Recent NUFFT functions available in PythonYou can also find other very useful Python nufft/nfft functions at:1. SigPy (Ong, F., and M. Lustig. &quot;SigPy: a python package for high performance iterative reconstruction.&quot; Proceedings of the ISMRM 27th Annual Meeting, Montreal, Quebec, Canada. Vol. 4819. 2019. Note the order starts from the last axi&gt;2. gpuNUFFT: (Knoll, Florian, et al. &quot;gpuNUFFT-an open source GPU library for 3D regridding with direct Matlab interface.&quot; Proceedings of the 22nd annual meeting of ISMRM, Milan, Italy. 2014.): https://github.com/andyschwarzl/gpuNUFFT/&gt;3. mrrt.nufft (mrrt.mri demos for the ISMRM 2020 Data Sampling Workshop in Sedona, AZ with raw cuda kernels): https://github.com/mritools/mrrt.nufft4. pyNFFT (Keiner, J., Kunis, S., and Potts, D. ''Using NFFT 3 - a software library for various nonequispaced fast Fourier transforms'' ACM Trans. Math. Software,36, Article 19, 1-30, 2009. The python wrapper of NFFT): https://pythonho&gt;5. python-NUFFT: Please see: https://github.com/dfm/python-nufft, &quot;Python bindings by Dan Foreman-Mackey, Thomas Arildsen, and Marc T. Henry de Frahan but the code that actually does the work is from the Greengard lab at NYU (see the w&gt;6. finufft (Barnett, Alexander H., Jeremy Magland, and Ludvig af Klinteberg. &quot;A Parallel Nonuniform Fast Fourier Transform Library Based on an â€œExponential of Semicircle&quot; Kernel.&quot; SIAM Journal on Scientific Computing 41.5 (2019): C479-&gt;7. torchkbnufft (M. J. Muckley, R. Stern, T. Murrell, F. Knoll, TorchKbNufft: A High-Level, Hardware-Agnostic Non-Uniform Fast Fourier Transform, 2020 ISMRM Workshop on Data Sampling and Image Reconstruction): https://github.com/mmuckl&gt;8. tfkbnufft (adapt torchkbnufft for TensorFlow): https://github.com/zaccharieramzi/tfkbnufft9. TFNUFFT (adapt the min-max interpolator in PyNUFFT for tensorflow): https://github.com/yf0726/TFNUFFT10. tensorflow-nufft: https://github.com/mrphys/tensorflow-nufft</longdescription>
</pkgmetadata>