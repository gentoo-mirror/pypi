<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Lakestream==========Lakestream is a tool for interacting with object stores such as S3. It is built from the ground up in Rust, with APIs available for both Python and the web via JS/WASM.The idea behind Lakestream is to create a high-performance and future-proof data tool that can scale with new (AI-driven) networking and usage patterns. This includes the ability to work in both client and service mode, and a modular design to allow compute functions on the network.In the short term, the focus is on implementing basic features such as List, Copy, and Delete. The current version (0.0.2) enables listing and searching items on an S3 bucket or Local Filesystem.Prerequisites-------------- Python or Rust- Optional: S3 account with valid access key and secret keyInstallation------------Lakestream can be used via Python (API) or directly via Rust (CLI).A (local-first) browser-based version is on the short-term roadmap.Python (API)~~~~~~~~~~~~~~~~~~~~~~Only Linux and MacOS wheels are pre-compiled. A Windows version should follow soon... code-block:: console    pip install lakestreamRust (CLI)~~~~~~~~~~~~~~~~~~~~Clone the repository and compile the project using Cargo:.. code-block:: console    git clone https://github.com/serverlessnext/lakestream.git    cd lakestream    cargo build --releaseNext, copy the binary from `./target/release/lakestream` to your local path.Usage-----Quickstart~~~~~~~~~~~~~~.. code-block:: console    # for s3://buckets: AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY must be set    export AWS_ACCESS_KEY_ID=your_access_key    export AWS_SECRET_ACCESS_KEY=your_secret_key    export AWS_REGION=us-east-1  # optional.. code-block:: console    # Find all files in the &quot;reports&quot; directory, with names containing &quot;2023&quot; and    # modified within the last 30 days, in a given S3 bucket.    lakestream ls s3://bucket-name/reports/ --name &quot;*2023*&quot; --mtime &quot;-30D    # Find all files in the current directory, larger than 100 MB and modified    # within the last 2 days.    lakestream ls . --size &quot;+100M&quot; --mtime &quot;-2D&quot;    Find all files larger than 1 megabyte (MB) in a given S3 Bucket    lakestream ls s3://bucket-name/ --size &quot;+1M&quot; --recursive    # Find all files modified more than 1 hour ago, recursively    lakestream ls . --mtime &quot;+1h&quot; --recursiveMore **CLI** examples `here &lt;https://lakestream.dev/cli_list.html&gt;`__.Python can also be used as a CLI. Arguments are mapped 1:1 to the Rust library... code-block:: console    # Python    python -m lakestream ls ./    # Rust    lakestream ls ./Python API~~~~~~~~~~.. code-block:: python    import lakestream    client = lakestream.Client()    # Define a filter dictionary    filter_dict = {        &quot;name&quot;: &quot;example.txt&quot;,        &quot;size&quot;: &quot;5&quot;,        &quot;mtime&quot;: &quot;1D&quot;,    }    # List the contents of a storage location with the filter    result = client.list(&quot;s3://your-bucket&quot;, recursive=True, filter_dict=filter_dict)    print(result)Python API Documentation `here &lt;https://lakestream.dev/python_api.html&gt;`__.Contributing------------Contributions to the Lakestream project are welcome. Please open an issue or submit a pull request on the GitHub repository.License-------Lakestream is released under the MIT license. See LICENSE for more details.Links-----Documentation: https://lakestream.dev</longdescription>
</pkgmetadata>