<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Anthropic Python API library[![PyPI version](https://img.shields.io/pypi/v/anthropic.svg)](https://pypi.org/project/anthropic/)The Anthropic Python library provides convenient access to the Anthropic REST API from any Python 3.7+application. It includes type definitions for all request params and response fields,and offers both synchronous and asynchronous clients powered by [httpx](https://github.com/encode/httpx).For the AWS Bedrock API, see [`anthropic-bedrock`](https://github.com/anthropics/anthropic-bedrock-python).## Migration from v0.2.x and belowIn `v0.3.0`, we introduced a fully rewritten SDK.The new version uses separate sync and async clients, unified streaming, typed params and structured response objects, and resource-oriented methods:**Sync before/after:**```diff- client = anthropic.Client(os.environ[&quot;ANTHROPIC_API_KEY&quot;])+ client = anthropic.Anthropic(api_key=os.environ[&quot;ANTHROPIC_API_KEY&quot;])  # or, simply provide an ANTHROPIC_API_KEY environment variable:+ client = anthropic.Anthropic()- rsp = client.completion(**params)- rsp[&quot;completion&quot;]+ rsp = client.completions.create(**params)+ rsp.completion```**Async before/after:**```diff- client = anthropic.Client(os.environ[&quot;ANTHROPIC_API_KEY&quot;])+ client = anthropic.AsyncAnthropic(api_key=os.environ[&quot;ANTHROPIC_API_KEY&quot;])- await client.acompletion(**params)+ await client.completions.create(**params)```The `.completion_stream()` and `.acompletion_stream()` methods have been removed;simply pass `stream=True`to `.completions.create()`.Streaming responses are now incremental; the full text is not sent in each message,as v0.3 sends the `Anthropic-Version: 2023-06-01` header.&lt;details&gt;&lt;summary&gt;Example streaming diff&lt;/summary&gt;```diff py  import anthropic- client = anthropic.Client(os.environ[&quot;ANTHROPIC_API_KEY&quot;])+ client = anthropic.Anthropic()  # Streams are now incremental diffs of text  # rather than sending the whole message every time:  text = &quot;- stream = client.completion_stream(**params)- for data in stream:-     diff = data[&quot;completion&quot;].replace(text, &quot;&quot;)-     text = data[&quot;completion&quot;]+ stream = client.completions.create(**params, stream=True)+ for data in stream:+     diff = data.completion # incremental text+     text += data.completion      print(diff, end=&quot;&quot;)  print(&quot;Done. Final text is:&quot;)  print(text)```&lt;/details&gt;## DocumentationThe API documentation can be found [here](https://docs.anthropic.com/claude/reference/).## Installation```shpip install anthropic```## UsageThe full API of this library can be found in [api.md](https://www.github.com/anthropics/anthropic-sdk-python/blob/main/api.md).```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = Anthropic(    # defaults to os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)    api_key=&quot;my api key&quot;,)completion = anthropic.completions.create(    model=&quot;claude-2&quot;,    max_tokens_to_sample=300,    prompt=f&quot;{HUMAN_PROMPT} how does a court case get to the Supreme Court?{AI_PROMPT}&quot;,)print(completion.completion)```While you can provide an `api_key` keyword argument,we recommend using [python-dotenv](https://pypi.org/project/python-dotenv/)to add `ANTHROPIC_API_KEY=&quot;my-anthropic-api-key&quot;` to your `.env` fileso that your API Key is not stored in source control.## Async usageSimply import `AsyncAnthropic` instead of `Anthropic` and use `await` with each API call:```pythonfrom anthropic import AsyncAnthropic, HUMAN_PROMPT, AI_PROMPTanthropic = AsyncAnthropic(    # defaults to os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)    api_key=&quot;my api key&quot;,)async def main():    completion = await anthropic.completions.create(        model=&quot;claude-2&quot;,        max_tokens_to_sample=300,        prompt=f&quot;{HUMAN_PROMPT} how does a court case get to the Supreme Court?{AI_PROMPT}&quot;,    )    print(completion.completion)asyncio.run(main())```Functionality between the synchronous and asynchronous clients is otherwise identical.## Streaming ResponsesWe provide support for streaming responses using Server Side Events (SSE).```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = Anthropic()stream = anthropic.completions.create(    prompt=f&quot;{HUMAN_PROMPT} Your prompt here{AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-2&quot;,    stream=True,)for completion in stream:    print(completion.completion, end=&quot;&quot;, flush=True)```The async client uses the exact same interface.```pythonfrom anthropic import AsyncAnthropic, HUMAN_PROMPT, AI_PROMPTanthropic = AsyncAnthropic()stream = await anthropic.completions.create(    prompt=f&quot;{HUMAN_PROMPT} Your prompt here{AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-2&quot;,    stream=True,)async for completion in stream:    print(completion.completion, end=&quot;&quot;, flush=True)```## Token countingYou can estimate billing for a given request with the `client.count_tokens()` method, eg:```pyclient = Anthropic()client.count_tokens('Hello world!')  # 3```## Using typesNested request parameters are [TypedDicts](https://docs.python.org/3/library/typing.html#typing.TypedDict). Responses are [Pydantic models](https://docs.pydantic.dev), which provide helper methods for things like serializing back into JSON ([v1](https://docs.pydantic.dev/1.10/usage/models/), [v2](https://docs.pydantic.dev/latest/usage/serialization/)). To get a dictionary, call `model.model_dump()`.Typed requests and responses provide autocomplete and documentation within your editor. If you would like to see type errors in VS Code to help catch bugs earlier, set `python.analysis.typeCheckingMode` to `basic`.## Handling errorsWhen the library is unable to connect to the API (for example, due to network connection problems or a timeout), a subclass of `anthropic.APIConnectionError` is raised.When the API returns a non-success status code (that is, 4xx or 5xxresponse), a subclass of `anthropic.APIStatusError` is raised, containing `status_code` and `response` properties.All errors inherit from `anthropic.APIError`.```pythonimport anthropicclient = anthropic.Anthropic()try:    client.completions.create(        prompt=f&quot;{anthropic.HUMAN_PROMPT} Your prompt here{anthropic.AI_PROMPT}&quot;,        max_tokens_to_sample=300,        model=&quot;claude-2&quot;,    )except anthropic.APIConnectionError as e:    print(&quot;The server could not be reached&quot;)    print(e.__cause__)  # an underlying Exception, likely raised within httpx.except anthropic.RateLimitError as e:    print(&quot;A 429 status code was received; we should back off a bit.&quot;)except anthropic.APIStatusError as e:    print(&quot;Another non-200-range status code was received&quot;)    print(e.status_code)    print(e.response)```Error codes are as followed:| Status Code | Error Type                 || ----------- | -------------------------- || 400         | `BadRequestError`          || 401         | `AuthenticationError`      || 403         | `PermissionDeniedError`    || 404         | `NotFoundError`            || 422         | `UnprocessableEntityError` || 429         | `RateLimitError`           || &gt;=500       | `InternalServerError`      || N/A         | `APIConnectionError`       |### RetriesCertain errors are automatically retried 2 times by default, with a short exponential backoff.Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict,429 Rate Limit, and &gt;=500 Internal errors are all retried by default.You can use the `max_retries` option to configure or disable retry settings:```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT# Configure the default for all requests:anthropic = Anthropic(    # default is 2    max_retries=0,)# Or, configure per-request:anthropic.with_options(max_retries=5).completions.create(    prompt=f&quot;{HUMAN_PROMPT} Can you help me effectively ask for a raise at work?{AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-2&quot;,)```### TimeoutsBy default requests time out after 10 minutes. You can configure this with a `timeout` option,which accepts a float or an [`httpx.Timeout`](https://www.python-httpx.org/advanced/#fine-tuning-the-configuration) object:```pythonfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT# Configure the default for all requests:anthropic = Anthropic(    # default is 10 minutes    timeout=20.0,)# More granular control:anthropic = Anthropic(    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),)# Override per-request:anthropic.with_options(timeout=5 * 1000).completions.create(    prompt=f&quot;{HUMAN_PROMPT} Where can I get a good coffee in my neighbourhood?{AI_PROMPT}&quot;,    max_tokens_to_sample=300,    model=&quot;claude-2&quot;,)```On timeout, an `APITimeoutError` is thrown.Note that requests that time out are [retried twice by default](#retries).## Default HeadersWe automatically send the `anthropic-version` header set to `2023-06-01`.If you need to, you can override it by setting default headers per-request or on the client object.Be aware that doing so may result in incorrect types and other unexpected or undefined behavior in the SDK.```pythonfrom anthropic import Anthropicclient = Anthropic(    default_headers={&quot;anthropic-version&quot;: &quot;My-Custom-Value&quot;},)```## Advanced### LoggingWe use the standard library [`logging`](https://docs.python.org/3/library/logging.html) module.You can enable logging by setting the environment variable `ANTHROPIC_LOG` to `debug`.```shell$ export ANTHROPIC_LOG=debug```### How to tell whether `None` means `null` or missingIn an API response, a field may be explicitly `null`, or missing entirely; in either case, its value is `None` in this library. You can differentiate the two cases with `.model_fields_set`:```pyif response.my_field is None:  if 'my_field' not in response.model_fields_set:    print('Got json like {}, without a &quot;my_field&quot; key present at all.')  else:    print('Got json like {&quot;my_field&quot;: null}.')```### Accessing raw response data (e.g. headers)The &quot;raw&quot; Response object can be accessed by prefixing `.with_raw_response.` to any HTTP method call.```pyfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPTanthropic = Anthropic()response = anthropic.completions.with_raw_response.create(    model=&quot;claude-2&quot;,    max_tokens_to_sample=300,    prompt=f&quot;{HUMAN_PROMPT} how does a court case get to the Supreme Court?{AI_PROMPT}&quot;,)print(response.headers.get('X-My-Header'))completion = response.parse()  # get the object that `completions.create()` would have returnedprint(completion.completion)```These methods return an [`APIResponse`](https://github.com/anthropics/anthropic-sdk-python/tree/main/src/anthropic/_response.py) object.### Configuring the HTTP clientYou can directly override the [httpx client](https://www.python-httpx.org/api/#client) to customize it for your use case, including:- Support for proxies- Custom transports- Additional [advanced](https://www.python-httpx.org/advanced/#client-instances) functionality```pythonimport httpxfrom anthropic import Anthropicclient = Anthropic(    base_url=&quot;http://my.test.server.example.com:8083&quot;,    http_client=httpx.Client(        proxies=&quot;http://my.test.proxy.example.com&quot;,        transport=httpx.HTTPTransport(local_address=&quot;0.0.0.0&quot;),    ),)```### Managing HTTP resourcesBy default the library closes underlying HTTP connections whenever the client is [garbage collected](https://docs.python.org/3/reference/datamodel.html#object.__del__). You can manually close the client using the `.close()` method if desired, or with a context manager that closes when exiting.## VersioningThis package generally follows [SemVer](https://semver.org/spec/v2.0.0.html) conventions, though certain backwards-incompatible changes may be released as minor versions:1. Changes that only affect static types, without breaking runtime behavior.2. Changes to library internals which are technically public but not intended or documented for external use. _(Please open a GitHub issue to let us know if you are relying on such internals)_.3. Changes that we do not expect to impact the vast majority of users in practice.We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.We are keen for your feedback; please open an [issue](https://www.github.com/anthropics/anthropic-sdk-python/issues) with questions, bugs, or suggestions.## RequirementsPython 3.7 or higher.</longdescription>
</pkgmetadata>