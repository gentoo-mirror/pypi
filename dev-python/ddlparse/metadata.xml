<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># DDL Parse[![PyPI version](https://img.shields.io/pypi/v/ddlparse.svg)](https://pypi.org/project/ddlparse/)[![Python version](https://img.shields.io/pypi/pyversions/ddlparse.svg)](https://pypi.org/project/ddlparse/)[![Travis CI Build Status](https://travis-ci.com/shinichi-takii/ddlparse.svg?branch=master)](https://travis-ci.com/shinichi-takii/ddlparse)[![Coveralls Coverage Status](https://coveralls.io/repos/github/shinichi-takii/ddlparse/badge.svg?branch=master)](https://coveralls.io/github/shinichi-takii/ddlparse?branch=master)[![codecov Coverage Status](https://codecov.io/gh/shinichi-takii/ddlparse/branch/master/graph/badge.svg)](https://codecov.io/gh/shinichi-takii/ddlparse)[![Requirements Status](https://requires.io/github/shinichi-takii/ddlparse/requirements.svg?branch=master)](https://requires.io/github/shinichi-takii/ddlparse/requirements/?branch=master)[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://github.com/shinichi-takii/ddlparse/blob/master/LICENSE.md)*DDL parase and Convert to BigQuery JSON schema and DDL statements module, available in Python.*----## Features- DDL parse and get table schema information.- Currently, only the `CREATE TABLE` statement is supported.- Convert to [BigQuery JSON schema](https://cloud.google.com/bigquery/docs/schemas#creating_a_json_schema_file) and [BigQuery DDL statements](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language).- Supported databases are MySQL/MariaDB, PostgreSQL, Oracle, Redshift.## Requirement1. Python &gt;= 3.51. [pyparsing](https://github.com/pyparsing/pyparsing)## Installation### Installpip install:```bash$ pip install ddlparse```command install:```bash$ python setup.py install```### Updatepip update:```bash$ pip install ddlparse --upgrade```## Usage### Example```pythonimport jsonfrom ddlparse import DdlParsesample_ddl = &quot;&quot;&quot;CREATE TABLE My_Schema.Sample_Table (  Id integer PRIMARY KEY COMMENT 'User ID',  Name varchar(100) NOT NULL COMMENT 'User name',  Total bigint NOT NULL,  Avg decimal(5,1) NOT NULL,  Point int(10) unsigned,  Zerofill_Id integer unsigned zerofill NOT NULL,  Created_At date, -- Oracle 'DATE' -&gt; BigQuery 'DATETIME'  UNIQUE (NAME));&quot;&quot;&quot;# parse pattern (1-1)table = DdlParse().parse(sample_ddl)# parse pattern (1-2) : Specify source databasetable = DdlParse().parse(ddl=sample_ddl, source_database=DdlParse.DATABASE.oracle)# parse pattern (2-1)parser = DdlParse(sample_ddl)table = parser.parse()print(&quot;* BigQuery Fields * : normal&quot;)print(table.to_bigquery_fields())# parse pattern (2-2) : Specify source databaseparser = DdlParse(ddl=sample_ddl, source_database=DdlParse.DATABASE.oracle)table = parser.parse()# parse pattern (3-1)parser = DdlParse()parser.ddl = sample_ddltable = parser.parse()# parse pattern (3-2) : Specify source databaseparser = DdlParse()parser.source_database = DdlParse.DATABASE.oracleparser.ddl = sample_ddltable = parser.parse()print(&quot;* BigQuery Fields * : Oracle&quot;)print(table.to_bigquery_fields())print(&quot;* TABLE *&quot;)print(&quot;schema = {} : name = {} : is_temp = {}&quot;.format(table.schema, table.name, table.is_temp))print(&quot;* BigQuery Fields *&quot;)print(table.to_bigquery_fields())print(&quot;* BigQuery Fields - column name to lower case / upper case *&quot;)print(table.to_bigquery_fields(DdlParse.NAME_CASE.lower))print(table.to_bigquery_fields(DdlParse.NAME_CASE.upper))print(&quot;* COLUMN *&quot;)for col in table.columns.values():    col_info = {}    col_info[&quot;name&quot;]                  = col.name    col_info[&quot;data_type&quot;]             = col.data_type    col_info[&quot;length&quot;]                = col.length    col_info[&quot;precision(=length)&quot;]    = col.precision    col_info[&quot;scale&quot;]                 = col.scale    col_info[&quot;is_unsigned&quot;]           = col.is_unsigned    col_info[&quot;is_zerofill&quot;]           = col.is_zerofill    col_info[&quot;constraint&quot;]            = col.constraint    col_info[&quot;not_null&quot;]              = col.not_null    col_info[&quot;PK&quot;]                    = col.primary_key    col_info[&quot;unique&quot;]                = col.unique    col_info[&quot;auto_increment&quot;]        = col.auto_increment    col_info[&quot;distkey&quot;]               = col.distkey    col_info[&quot;sortkey&quot;]               = col.sortkey    col_info[&quot;encode&quot;]                = col.encode    col_info[&quot;default&quot;]               = col.default    col_info[&quot;character_set&quot;]         = col.character_set    col_info[&quot;bq_legacy_data_type&quot;]   = col.bigquery_legacy_data_type    col_info[&quot;bq_standard_data_type&quot;] = col.bigquery_standard_data_type    col_info[&quot;comment&quot;]               = col.comment    col_info[&quot;description(=comment)&quot;] = col.description    col_info[&quot;bigquery_field&quot;]        = json.loads(col.to_bigquery_field())    print(json.dumps(col_info, indent=2, ensure_ascii=False))print(&quot;* DDL (CREATE TABLE) statements *&quot;)print(table.to_bigquery_ddl())print(&quot;* DDL (CREATE TABLE) statements - dataset name, table name and column name to lower case / upper case *&quot;)print(table.to_bigquery_ddl(DdlParse.NAME_CASE.lower))print(table.to_bigquery_ddl(DdlParse.NAME_CASE.upper))print(&quot;* Get Column object (case insensitive) *&quot;)print(table.columns[&quot;total&quot;])print(table.columns[&quot;total&quot;].data_type)```## License[BSD 3-Clause License](https://github.com/shinichi-takii/ddlparse/blob/master/LICENSE.md)## AuthorShinichi Takii &lt;shinichi.takii@shaketh.com&gt;## Links- Repository : https://github.com/shinichi-takii/ddlparse- PyPI Package : https://pypi.org/project/ddlparse/## Special Thanks- pyparsing : https://github.com/pyparsing/pyparsing</longdescription>
</pkgmetadata>