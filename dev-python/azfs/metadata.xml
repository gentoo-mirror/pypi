<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># AzFS[![pytest](https://github.com/gsy0911/azfs/workflows/pytest/badge.svg)](https://github.com/gsy0911/azfs/actions?query=workflow%3Apytest)[![codecov](https://codecov.io/gh/gsy0911/azfs/branch/master/graph/badge.svg)](https://codecov.io/gh/gsy0911/azfs)[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/gsy0911/azfs.svg?logo=lgtm&amp;logoWidth=18)](https://lgtm.com/projects/g/gsy0911/azfs/context:python)[![Documentation Status](https://readthedocs.org/projects/azfs/badge/?version=latest)](https://azfs.readthedocs.io/en/latest/?badge=latest)[![PythonVersion](https://img.shields.io/badge/python-3.6|3.7|3.8-blue.svg)](https://www.python.org/downloads/release/python-377/)[![PiPY](https://img.shields.io/pypi/v/azfs.svg)](https://pypi.org/project/azfs/)[![Downloads](https://pepy.tech/badge/azfs)](https://pepy.tech/project/azfs) AzFS is to provide convenient Python read/write functions for Azure Storage Account.`AzFS` can* list files in blob (also with wildcard `*`),* check if file exists,* read csv as pd.DataFrame, and json as dict from blob,* write pd.DataFrame as csv, and dict as json to blob.## install```bash$ pip install azfs```## usageFor `Blob` Storage.```pythonimport azfsfrom azure.identity import DefaultAzureCredentialimport pandas as pd# credential is not required if your environment is on AAD(Azure Active Directory)azc = azfs.AzFileClient()# credential is required if your environment is not on AADcredential = &quot;[your storage account credential]&quot;# orcredential = DefaultAzureCredential()azc = azfs.AzFileClient(credential=credential)# connection_string is also supportedconnection_string = &quot;DefaultEndpointsProtocol=https;AccountName=xxxx;AccountKey=xxxx;EndpointSuffix=core.windows.net&quot;azc = azfs.AzFileClient(connection_string=connection_string)# data pathscsv_path = &quot;https://testazfs.blob.core.windows.net/test_caontainer/test_file.csv&quot;# read csv as pd.DataFramedf = azc.read_csv(csv_path, index_col=0)# orwith azc:    df = pd.read_csv_az(csv_path, header=None)# write csvazc.write_csv(path=csv_path, df=df)# orwith azc:    df.to_csv_az(path=csv_path, index=False)# you can read multiple filescsv_pattern_path = &quot;https://testazfs.blob.core.windows.net/test_caontainer/*.csv&quot; df = azc.read().csv(csv_pattern_path)# to apply additional filter or another processdf = azc.read().apply(function=lambda x: x[x['id'] == 'AAA']).csv(csv_pattern_path)# in addition, you can use multiprocessingdf = azc.read(use_mp=True).apply(function=lambda x: x[x['id'] == 'AAA']).csv(csv_pattern_path)```For `Queue` Storage```pythonimport azfsqueue_url = &quot;https://{storage_account}.queue.core.windows.net/{queue_name}&quot;azc = azfs.AzFileClient()queue_message = azc.get(queue_url)# message will not be deleted if `delete=False`# queue_message = azc.get(queue_url, delete=False)# get message contentqueue_content = queue_message.get('content')```For `Table` Storage```pythonimport azfscons = {    &quot;account_name&quot;: &quot;{storage_account_name}&quot;,    &quot;account_key&quot;: &quot;{credential}&quot;,    &quot;database_name&quot;: &quot;{database_name}&quot;}table_client = azfs.TableStorageWrapper(**cons)# put data, according to the keyword you puttable_client.put(id_=&quot;1&quot;, message=&quot;hello_world&quot;)# get datatable_client.get(id_=&quot;1&quot;)```check more details in  [![Documentation Status](https://readthedocs.org/projects/azfs/badge/?version=latest)](https://azfs.readthedocs.io/en/latest/?badge=latest)### types of authorizationSupported authentication types are* [Azure Active Directory (AAD) token credential](https://docs.microsoft.com/azure/storage/common/storage-auth-aad).* connection_string, like `DefaultEndpointsProtocol=https;AccountName=xxxx;AccountKey=xxxx;EndpointSuffix=core.windows.net` ### types of storage account kindThe table below shows if `AzFS` provides read/write functions for the storage. | account kind | Blob | Data Lake | Queue | File | Table ||:--|:--:|:--:|:--:|:--:|:--:|| StorageV2 | O | O | O | X | O || StorageV1 | O | O | O | X | O || BlobStorage | O | - | - | - | - |* O: provides basic functions* X: not provides* -: storage type unavailable## dependencies```pandasazure-identity &gt;= &quot;1.3.1&quot;azure-storage-blob &gt;= &quot;12.3.0&quot;azure-storage-file-datalake &gt;= &quot;12.0.0&quot;azure-storage-queue &gt;= &quot;12.1.1&quot;azure-cosmosdb-table```## references* [azure-sdk-for-python/storage](https://github.com/Azure/azure-sdk-for-python/tree/master/sdk/storage)* [filesystem_spec](https://github.com/intake/filesystem_spec)</longdescription>
</pkgmetadata>