<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Visual Wake Words DatasetPython library to work with the [Visual Wake Words Dataset](https://arxiv.org/abs/1906.05721), comparable to [pycococools](https://github.com/cocodataset/cocoapi) for the COCO dataset.`pyvww.utils.VisualWakeWords` inherits from `pycocotools.coco.COCO` and can be used in an similar fashion.`pyvww.pytorch.VisualWakeWordsClassification` is a pytorch `Dataset` which can be used like any image classification dataset. --- ### Installation The code is implemented in Python 3.7 and can be installed with pip: ```bash pip install pyvww ``` ### Usage The Visual Wake Words Dataset is derived from the publicly available [COCO](cocodataset.org/#/home) dataset. To download the COCO dataset use the script `download_coco.sh` ```bashbash scripts/download_mscoco.sh path-to-COCO-dataset year```Where `year` is an optional argument that can be either 2014 (default) or 2017.The Visual Wake Words Dataset evaluates the accuracy on the [minival image ids](https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_minival_ids.txt),and for training uses the remaining 115k images of the COCO training/validation dataset.To create COCO annotation files that converts the 2014 or 2017 split to the minival split use:`scripts/create_coco_train_minival_split.py````bashTRAIN_ANNOTATIONS_FILE=&quot;path-to-mscoco-dataset/annotations/instances_train2014.json&quot;VAL_ANNOTATIONS_FILE=&quot;path-to-mscoco-dataset/annotations/instances_val2014.json&quot;DIR=&quot;path-to-mscoco-dataset/annotations/&quot;python scripts/create_coco_train_minival_split.py \  --train_annotations_file=&quot;${TRAIN_ANNOTATIONS_FILE}&quot; \  --val_annotations_file=&quot;${VAL_ANNOTATIONS_FILE}&quot; \--output_dir=&quot;${DIR}&quot;```(2014 can be replaced by 2017 if you downloaded the 2017 dataset)The process of creating the Visual Wake Words dataset from COCO dataset is as follows.Each image is assigned a label 1 or 0. The label 1 is assigned as long as it has at least one bounding box corresponding to the object of interest (e.g. person) with the box area greater than a certain threshold (e.g. 0.5% of the image area).To generate the new annotations, use the script `scripts/create_visualwakewords_annotations.py`.```bashMAXITRAIN_ANNOTATIONS_FILE=&quot;path-to-mscoco-dataset/annotations/instances_maxitrain.json&quot;MINIVAL_ANNOTATIONS_FILE=&quot;path-to-mscoco-dataset/annotations/instances_minival.json&quot;VWW_OUTPUT_DIR=&quot;new-path-to-visualwakewords-dataset/annotations/&quot;python scripts/create_visualwakewords_annotations.py \  --train_annotations_file=&quot;${MAXITRAIN_ANNOTATIONS_FILE}&quot; \  --val_annotations_file=&quot;${MINIVAL_ANNOTATIONS_FILE}&quot; \  --output_dir=&quot;${VWW_OUTPUT_DIR}&quot; \  --threshold=0.005 \  --foreground_class='person'```The generated annotations follow the [COCO Data format](http://cocodataset.org/#format-data).```{  &quot;info&quot; : info,   &quot;images&quot; : [image],   &quot;annotations&quot; : [annotation],   &quot;licenses&quot; : [license],}info{  &quot;year&quot; : int,   &quot;version&quot; : str,   &quot;description&quot; : str,   &quot;url&quot; : str, }image{  &quot;id&quot; : int,   &quot;width&quot; : int,   &quot;height&quot; : int,   &quot;file_name&quot; : str,   &quot;license&quot; : int,   &quot;flickr_url&quot; : str,   &quot;coco_url&quot; : str,   &quot;date_captured&quot; : datetime,}license{  &quot;id&quot; : int,   &quot;name&quot; : str,   &quot;url&quot; : str,}annotation{  &quot;id&quot; : int,   &quot;image_id&quot; : int,   &quot;category_id&quot; : int,   &quot;area&quot; : float,   &quot;bbox&quot; : [x,y,width,height],   &quot;iscrowd&quot; : 0 or 1,}```### Pytorch DatasetThe `pyvww.pytorch.VisualWakeWordsClassification` can be used in pytorch like any other pytorch image classificationdataset such as MNIST or ImageNet.```pythonimport torchimport pyvwwtrain_dataset = pyvww.pytorch.VisualWakeWordsClassification(root=&quot;path-to-mscoco-dataset/all&quot;,                     annFile=&quot;.../visualwakewords/annotations/instances_train.json&quot;)```</longdescription>
</pkgmetadata>