<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;!--![aio-scrapy](./doc/images/aio-scrapy.png)--&gt;### aio-scrapyAn asyncio + aiolibs crawler  imitate scrapy frameworkEnglish | [中文](./doc/README_ZH.md)### Overview- aio-scrapy framework is base on opensource project Scrapy &amp; scrapy_redis.- aio-scrapy implements compatibility with scrapyd.- aio-scrapy implements redis queue and rabbitmq queue.- aio-scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages.- Distributed crawling/scraping.### Requirements- Python 3.9+- Works on Linux, Windows, macOS, BSD### InstallThe quick way:```shell# Install the latest aio-scrapypip install git+https://github.com/conlin-huang/aio-scrapy# defaultpip install aio-scrapy# Install all dependencies pip install aio-scrapy[all]# When you need to use mysql/httpx/rabbitmq/mongopip install aio-scrapy[aiomysql,httpx,aio-pika,mongo]```### Usage#### create project spider:```shellaioscrapy startproject project_quotes``````cd project_quotesaioscrapy genspider quotes ```quotes.py```pythonfrom aioscrapy.spiders import Spiderclass QuotesMemorySpider(Spider):    name = 'QuotesMemorySpider'    start_urls = ['https://quotes.toscrape.com']    async def parse(self, response):        for quote in response.css('div.quote'):            yield {                'author': quote.xpath('span/small/text()').get(),                'text': quote.css('span.text::text').get(),            }        next_page = response.css('li.next a::attr(&quot;href&quot;)').get()        if next_page is not None:            yield response.follow(next_page, self.parse)if __name__ == '__main__':    QuotesMemorySpider.start()```run the spider:```shellaioscrapy crawl quotes```#### create single script spider:```shellaioscrapy genspider single_quotes -t single```single_quotes.py:```pythonfrom aioscrapy.spiders import Spiderclass QuotesMemorySpider(Spider):    name = 'QuotesMemorySpider'    custom_settings = {        &quot;USER_AGENT&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&quot;,        'CLOSE_SPIDER_ON_IDLE': True,        # 'DOWNLOAD_DELAY': 3,        # 'RANDOMIZE_DOWNLOAD_DELAY': True,        # 'CONCURRENT_REQUESTS': 1,        # 'LOG_LEVEL': 'INFO'    }    start_urls = ['https://quotes.toscrape.com']    @staticmethod    async def process_request(request, spider):        &quot;&quot;&quot; request middleware &quot;&quot;&quot;        pass    @staticmethod    async def process_response(request, response, spider):        &quot;&quot;&quot; response middleware &quot;&quot;&quot;        return response    @staticmethod    async def process_exception(request, exception, spider):        &quot;&quot;&quot; exception middleware &quot;&quot;&quot;        pass    async def parse(self, response):        for quote in response.css('div.quote'):            yield {                'author': quote.xpath('span/small/text()').get(),                'text': quote.css('span.text::text').get(),            }        next_page = response.css('li.next a::attr(&quot;href&quot;)').get()        if next_page is not None:            yield response.follow(next_page, self.parse)    async def process_item(self, item):        print(item)if __name__ == '__main__':    QuotesMemorySpider.start()```run the spider:```shellaioscrapy runspider quotes.py```### more commands:```shellaioscrapy -h```### Documentation[doc](./doc/documentation.md)### Readyplease submit your sugguestion to owner by issue## Thanks[aiohttp](https://github.com/aio-libs/aiohttp/)[scrapy](https://github.com/scrapy/scrapy)</longdescription>
</pkgmetadata>