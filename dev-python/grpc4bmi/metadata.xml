<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># grpc4bmi[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1462641.svg)](https://doi.org/10.5281/zenodo.1462641)[![CI](https://github.com/eWaterCycle/grpc4bmi/workflows/CI/badge.svg)](https://github.com/eWaterCycle/grpc4bmi/actions?query=workflow%3ACI)[![Documentation Status](https://readthedocs.org/projects/grpc4bmi/badge/?version=latest)](https://grpc4bmi.readthedocs.io/en/latest/?badge=latest)[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=grpc4bmi&amp;metric=alert_status)](https://sonarcloud.io/dashboard?id=grpc4bmi)[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=grpc4bmi&amp;metric=coverage)](https://sonarcloud.io/dashboard?id=grpc4bmi)## PurposeThis software allows you to wrap your [Basic Model Interface (BMI)](https://github.com/csdms/bmi) implementation in a server process and communicate with it via the included Python client. The communication is serialized to protocol buffers by [GRPC](https://grpc.io/) and occurs over network ports. Can run models in isolated containers using Docker or Apptainer.## InstallationOptionally, create your virtual environment and activate it, Then, run```bashpip install grpc4bmi```on the client (Python) side. If your server model is implemented in Python, do the same in the server environment (e.g. docker container). If the model is implemented in R, run instead```bashpip install grpc4bmi[R]```If the model is implemented in Julia, run instead```bashpip install grpc4bmi[julia]```in the server environment. For bleeding edge version from GitHub use```bashpip install git+https://github.com/eWaterCycle/grpc4bmi.git#egg=grpc4bmi```Finally if the model is implemented in C or C++, clone this git repo and run```bashmakemake install```in the cpp folder.## Usage### Model written in PythonA model should be a subclass of the `Bmi` class from the [bmipy](https://pypi.org/project/bmipy/2.0/) package.For inspiration look at the [example](test/fake_models.py) in the test directory. To start a server process that allows calls to your BMI implementation, type```bashrun-bmi-server --name &lt;PACKAGE&gt;.&lt;MODULE&gt;.&lt;CLASS&gt; --port &lt;PORT&gt; --path &lt;PATH&gt;```where ```&lt;PACKAGE&gt;, &lt;MODULE&gt;``` are the python package and module containing your implementation, ```&lt;CLASS&gt;``` is yourbmi model class name, ```&lt;PORT&gt;``` is any available port on the host system, and optionally ```&lt;PATH&gt;``` denotes anadditional path that should be added to the system path to make your implementation work. The name option above isoptional, and if not provided the script will look at the environment variables ```BMI_PACKAGE```, ```BMI_MODULE``` and```BMI_CLASS```. Similarly, the port can be defined by the environment variable ```BMI_PORT```.This software assumes that your implementation constructor has no parameters.### Model written in C/C++ (beta)Create an executable along the lines of cpp/run-bmi-server.cc. You can copy the file and replace the function```C++Bmi* create_model_instance(){    /* Return your new BMI instance pointer here... */}```with the instantiation of your model BMI. The model needs to implement the csdms BMI for C, but you may also implement our more object-oriented C++ interface [BmiCppExtension](https://github.com/eWaterCycle/grpc4bmi/blob/main/cpp/bmi_cpp_extension.h).### Model written in RThe grpc4bmi Python package can also run BMI models written in R if the model is a subclass of [AbstractBmi](https://github.com/eWaterCycle/bmi-r/blob/master/R/abstract-bmi.R#L9)See [https://github.com/eWaterCycle/bmi-r](https://github.com/eWaterCycle/bmi-r) for instruction on R and Docker.Run the R model a server with```bashrun-bmi-server --lang R [--path &lt;R file with BMI model&gt;] --name [&lt;PACKAGE&gt;::]&lt;CLASS&gt; --port &lt;PORT&gt;```For example with [WALRUS](https://github.com/eWaterCycle/grpc4bmi-examples/tree/master/walrus) use```bashrun-bmi-server --lang R --path ~/git/eWaterCycle/grpc4bmi-examples/walrus/walrus-bmi.r --name WalrusBmi --port 55555```### Models written in JuliaThe grpc4bmi Python package can also run BMI models written in Julia if the model has an implementation of the [BasicModelInterface.jl](https://github.com/Deltares/BasicModelInterface.jl).Run the Julia model in Python with```bashfrom grpc4bmi.bmi_julia_model import BmiJuliamymodel = BmiJulia.from_name('&lt;package&gt;.&lt;model&gt;', 'BasicModelInterface')```For example with [Wflow.jl](https://github.com/Deltares/Wflow.jl/) use```bash# Install Wflow.jl package in the Julia environment managed by the juliacall Python package.from juliacall import Main as jljl.Pkg.add(&quot;Wflow&quot;)# Create the modelfrom grpc4bmi.bmi_julia_model import BmiJuliamymodel = BmiJulia.from_name('Wflow.Model', 'Wflow.bmi.BMI')```A Julia model has to be run locally. It can not be run in the default gRPC client/server Docker container mode because:1. Julia has no gRPC server implementation2. Calling Julia methods from Python gRPC server causes 100% CPU usage and no progress3. Calling Julia methods from C++ gRPC server causes segmentation faults### The client sideThe client side has only a Python implementation. The default BMI client assumes a running server process on a given port.```pythonfrom grpc4bmi.bmi_grpc_client import BmiClientimport grpcmymodel = BmiClient(grpc.insecure_channel(&quot;localhost:&lt;PORT&gt;&quot;))print mymodel.get_component_name()mymodel.initialize(&lt;FILEPATH&gt;)...further BMI calls...```The package contains also client implementation that own the server process, either as a Python subprocess or a Dockercontainer or a Singularity container or a Apptainer container running the ```run-bmi-server``` script. For instance```pythonfrom grpc4bmi.bmi_client_subproc import BmiClientSubProcessmymodel = BmiClientSubProcess(&lt;PACKAGE&gt;.&lt;MODULE&gt;.&lt;CLASS&gt;)```will automatically launch the server in a sub-process and```pythonfrom grpc4bmi.bmi_client_docker import BmiClientDockermymodel = BmiClientDocker(&lt;IMAGE&gt;, &lt;WORK DIR TO MOUNT&gt;, input_dirs=[&lt;INPUT DIRECTORIES TO MOUNT&gt;])```will launch a Docker container based on supplied Docker imageand will mount supplied directories to share files between the container and host.```pythonfrom grpc4bmi.bmi_client_singularity import BmiClientSingularitymymodel = BmiClientSingularity(&lt;IMAGE&gt;, &lt;WORK DIR TO MOUNT&gt;, input_dirs=[&lt;INPUT DIRECTORIES TO MOUNT&gt;])```will launch a singularity container on based supplied Singularity imageand will mount supplied directories to share files between the container and host.```pythonfrom grpc4bmi.bmi_client_apptainer import BmiClientApptainermymodel = BmiClientApptainer(&lt;IMAGE&gt;, &lt;WORK DIR TO MOUNT&gt;, input_dirs=[&lt;INPUT DIRECTORIES TO MOUNT&gt;])```will launch a Apptainer container on based supplied Apptainer imageand will mount supplied directories to share files between the container and host.For more documentation see [https://grpc4bmi.readthedocs.io/](https://grpc4bmi.readthedocs.io/).## Development: generating the gRPC codeWhen developers change the proto-file, it is necessary to install gRPC tools Python packages in your Python environment:```bash# Create virtual envpython3 -m venv .venv. venv/bin/activate# Make sure latest pip and wheel are installpip install -U pip wheelpip install -r dev-requirements.txt# For R integration also install the R extras withpip install -e .[R]# For building docs (cd docs &amp;&amp; make html) also install the docs extras withpip install -e .[docs]```and install the C++ runtime and `protoc` command as described in &lt;https://github.com/google/protobuf/blob/master/src/README.md&gt;.After this, simply executing the `proto_gen.sh` script should do the job.</longdescription>
</pkgmetadata>