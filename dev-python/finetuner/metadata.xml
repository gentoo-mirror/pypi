<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;br&gt;&lt;br&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/jina-ai/finetuner/blob/main/docs/_static/finetuner-logo-ani.svg?raw=true&quot; alt=&quot;Finetuner logo: Finetuner helps you to create experiments in order to improve embeddings on search tasks. It accompanies you to deliver the last mile of performance-tuning for neural search applications.&quot; width=&quot;150px&quot;&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Task-oriented finetuning for better embeddings on neural search&lt;/b&gt;&lt;/p&gt;&lt;p align=center&gt;&lt;a href=&quot;https://pypi.org/project/finetuner/&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/finetuner?label=Release&amp;style=flat-square&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://codecov.io/gh/jina-ai/finetuner&quot;&gt;&lt;img alt=&quot;Codecov branch&quot; src=&quot;https://img.shields.io/codecov/c/github/jina-ai/finetuner/main?logo=Codecov&amp;logoColor=white&amp;style=flat-square&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://pypistats.org/packages/finetuner&quot;&gt;&lt;img alt=&quot;PyPI - Downloads from official pypistats&quot; src=&quot;https://img.shields.io/pypi/dm/finetuner?style=flat-square&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://discord.jina.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1106542220112302130?logo=discord&amp;logoColor=white&amp;style=flat-square&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;!-- start elevator-pitch --&gt;Fine-tuning is an effective way to improve performance on [neural search](https://jina.ai/news/what-is-neural-search-and-learn-to-build-a-neural-search-engine/) tasks.However, setting up and performing fine-tuning can be very time-consuming and resource-intensive.Jina AI's Finetuner makes fine-tuning easier and faster by streamlining the workflow and handling all the complexity and infrastructure in the cloud.With Finetuner, you can easily enhance the performance of pre-trained models,making them production-ready [without extensive labeling](https://jina.ai/news/fine-tuning-with-low-budget-and-high-expectations/) or expensive hardware.üéè **Better embeddings**: Create high-quality embeddings for semantic search, visual similarity search, cross-modal text&lt;-&gt;image search, recommendation systems,clustering, duplication detection, anomaly detection, or other uses.‚è∞ **Low budget, high expectations**: Bring considerable improvements to model performance, making the most out of as little as a few hundred training samples, and finish fine-tuning in as little as an hour.üìà **Performance promise**: Enhance the performance of pre-trained models so that they deliver state-of-the-art performance on domain-specific applications.üî± **Simple yet powerful**: Easy access to 40+ mainstream loss functions, 10+ optimizers, layer pruning, weightfreezing, dimensionality reduction, hard-negative mining, cross-modal models, and distributed training. ‚òÅ **All-in-cloud**: Train using our GPU infrastructure, manage runs, experiments, and artifacts on Jina AI Cloudwithout worrying about resource availability, complex integration, or infrastructure costs.&lt;!-- end elevator-pitch --&gt;## [Documentation](https://finetuner.jina.ai/)## Pretrained Text Embedding Models| name                   | parameter | dimension | Huggingface                                            ||------------------------|-----------|-----------|--------------------------------------------------------|| jina-embedding-t-en-v1 | 14m       | 312             | [link](https://huggingface.co/jinaai/jina-embedding-t-en-v1) || jina-embedding-s-en-v1 | 35m       | 512             | [link](https://huggingface.co/jinaai/jina-embedding-s-en-v1) || jina-embedding-b-en-v1 | 110m      | 768             | [link](https://huggingface.co/jinaai/jina-embedding-b-en-v1) || jina-embedding-l-en-v1 | 330m      | 1024            | [link](https://huggingface.co/jinaai/jina-embedding-l-en-v1) |## Benchmarks&lt;table&gt;&lt;thead&gt;  &lt;tr&gt;    &lt;th&gt;Model&lt;/th&gt;    &lt;th&gt;Task&lt;/th&gt;    &lt;th&gt;Metric&lt;/th&gt;    &lt;th&gt;Pretrained&lt;/th&gt;    &lt;th&gt;Finetuned&lt;/th&gt;    &lt;th&gt;Delta&lt;/th&gt;    &lt;th&gt;Run it!&lt;/th&gt;  &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;  &lt;tr&gt;    &lt;td rowspan=&quot;2&quot;&gt;BERT&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://www.kaggle.com/c/quora-question-pairs&quot;&gt;Quora&lt;/a&gt; Question Answering&lt;/td&gt;    &lt;td&gt;mRR&lt;/td&gt;    &lt;td&gt;0.835&lt;/td&gt;    &lt;td&gt;0.967&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;15.8%&lt;/span&gt;&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;p align=center&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1Ui3Gw3ZL785I7AuzlHv3I0-jTvFFxJ4_?usp=sharing&quot;&gt;&lt;img alt=&quot;Open In Colab&quot; src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;Recall&lt;/td&gt;    &lt;td&gt;0.915&lt;/td&gt;    &lt;td&gt;0.963&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;5.3%&lt;/span&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td rowspan=&quot;2&quot;&gt;ResNet&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;Visual similarity search on &lt;a href=&quot;https://sites.google.com/view/totally-looks-like-dataset&quot;&gt;TLL&lt;/a&gt;&lt;/td&gt;    &lt;td&gt;mAP&lt;/td&gt;    &lt;td&gt;0.110&lt;/td&gt;    &lt;td&gt;0.196&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;78.2%&lt;/span&gt;&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;p align=center&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1QuUTy3iVR-kTPljkwplKYaJ-NTCgPEc_?usp=sharing&quot;&gt;&lt;img alt=&quot;Open In Colab&quot; src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;Recall&lt;/td&gt;    &lt;td&gt;0.249&lt;/td&gt;    &lt;td&gt;0.460&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;84.7%&lt;/span&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td rowspan=&quot;2&quot;&gt;CLIP&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html&quot;&gt;Deep Fashion&lt;/a&gt; text-to-image search&lt;/td&gt;    &lt;td&gt;mRR&lt;/td&gt;    &lt;td&gt;0.575&lt;/td&gt;    &lt;td&gt;0.676&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;17.4%&lt;/span&gt;&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;p align=center&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1yKnmy2Qotrh3OhgwWRsMWPFwOSAecBxg?usp=sharing&quot;&gt;&lt;img alt=&quot;Open In Colab&quot; src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;Recall&lt;/td&gt;    &lt;td&gt;0.473&lt;/td&gt;    &lt;td&gt;0.564&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;19.2%&lt;/span&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td rowspan=&quot;2&quot;&gt;M-CLIP&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://xmrec.github.io/&quot;&gt;Cross market&lt;/a&gt; product recommendation (German)&lt;/td&gt;    &lt;td&gt;mRR&lt;/td&gt;    &lt;td&gt;0.430&lt;/td&gt;    &lt;td&gt;0.648&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;50.7%&lt;/span&gt;&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;p align=center&gt;&lt;a href=&quot;https://colab.research.google.com/drive/10Wldbu0Zugj7NmQyZwZzuorZ6SSAhtIo&quot;&gt;&lt;img alt=&quot;Open In Colab&quot; src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;Recall&lt;/td&gt;    &lt;td&gt;0.247&lt;/td&gt;    &lt;td&gt;0.340&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;37.7%&lt;/span&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td rowspan=&quot;2&quot;&gt;PointNet++&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;a href=&quot;https://modelnet.cs.princeton.edu/&quot;&gt;ModelNet40&lt;/a&gt; 3D Mesh Search&lt;/td&gt;    &lt;td&gt;mRR&lt;/td&gt;    &lt;td&gt;0.791&lt;/td&gt;    &lt;td&gt;0.891&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;12.7%&lt;/span&gt;&lt;/td&gt;    &lt;td rowspan=&quot;2&quot;&gt;&lt;p align=center&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1lIMDFkUVsWMshU-akJ_hwzBfJ37zLFzU?usp=sharing&quot;&gt;&lt;img alt=&quot;Open In Colab&quot; src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr&gt;    &lt;td&gt;Recall&lt;/td&gt;    &lt;td&gt;0.154&lt;/td&gt;    &lt;td&gt;0.242&lt;/td&gt;    &lt;td&gt;&lt;span style=&quot;color:green&quot;&gt;57.1%&lt;/span&gt;&lt;/td&gt;  &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;sub&gt;&lt;sup&gt;All metrics were evaluated for k@20 after training for 5 epochs using the Adam optimizer with learning rates of 1e-4 for ResNet, 1e-7 for CLIP and 1e-5 for the BERT models, 5e-4 for PointNet++&lt;/sup&gt;&lt;/sub&gt;&lt;!-- start install-instruction --&gt;## InstallMake sure you have Python 3.8+ installed. Finetuner can be installed via `pip` by executing:```bashpip install -U finetuner```If you want to submit a fine-tuning job on the cloud, please use```bashpip install &quot;finetuner[full]&quot;```&lt;!-- end install-instruction --&gt;&gt; ‚ö†Ô∏è Starting with version 0.5.0, Finetuner computing is performed on Jina AI Cloud. The last local version is `0.4.1`. &gt; This version is still available for installation via `pip`. See [Finetuner git tags and releases](https://github.com/jina-ai/finetuner/releases).&lt;!-- start finetuner-articles --&gt;## Articles about FinetunerCheck out our published blogposts and tutorials to see Finetuner in action!- [Fine-tuning with Low Budget and High Expectations](https://jina.ai/news/fine-tuning-with-low-budget-and-high-expectations/)- [Hype and Hybrids: Search is more than Keywords and Vectors](https://jina.ai/news/hype-and-hybrids-multimodal-search-means-more-than-keywords-and-vectors-2/)- [Improving Search Quality for Non-English Queries with Fine-tuned Multilingual CLIP Models](https://jina.ai/news/improving-search-quality-non-english-queries-fine-tuned-multilingual-clip-models/)- [How Much Do We Get by Finetuning CLIP?](https://jina.ai/news/applying-jina-ai-finetuner-to-clip-less-data-smaller-models-higher-performance/)&lt;!-- end finetuner-articles --&gt;&lt;!-- start citations --&gt;If you find Jina Embeddings useful in your research, please cite the following paper:```text@misc{g√ºnther2023jina,      title={Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models},       author={Michael G√ºnther and Louis Milliken and Jonathan Geuter and Georgios Mastrapas and Bo Wang and Han Xiao},      year={2023},      eprint={2307.11224},      archivePrefix={arXiv},      primaryClass={cs.CL}}```&lt;!-- end citations --&gt;&lt;!-- start support-pitch --&gt;## Support- Use [Discussions](https://github.com/jina-ai/finetuner/discussions) to talk about your use cases, questions, and  support queries.- Join our [Discord community](https://discord.jina.ai) and chat with other community members about ideas.- Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to discuss your use case and learn Jina AI new features.    - **When?** The second Tuesday of every month    - **Where?**      Zoom ([see our public events calendar](https://calendar.google.com/calendar/embed?src=c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com&amp;ctz=Europe%2FBerlin)/[.ical](https://calendar.google.com/calendar/ical/c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com/public/basic.ics))      and [live stream on YouTube](https://youtube.com/c/jina-ai)- Subscribe to the latest video tutorials on our [YouTube channel](https://youtube.com/c/jina-ai)## Join UsFinetuner is backed by [Jina AI](https://jina.ai) and licensed under [Apache-2.0](./LICENSE). [We are actively hiring](https://jobs.jina.ai) AI engineers and solution engineers to build the next generation ofopen-source AI ecosystems.&lt;!-- end support-pitch --&gt;</longdescription>
</pkgmetadata>