<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![FastETL's logo. It's a Swiss army knife with some open tools](docs/images/logo.svg)&lt;p align=&quot;center&quot;&gt;    &lt;em&gt;FastETL framework, modern, versatile, does almost everything.&lt;/em&gt;&lt;/p&gt;Este texto tambÃ©m estÃ¡ disponÃ­vel em portuguÃªs: ðŸ‡§ðŸ‡·[LEIAME.md](LEIAME.md).---[![CI Tests](https://github.com/gestaogovbr/FastETL/actions/workflows/ci-tests.yml/badge.svg)](https://github.com/gestaogovbr/FastETL/actions/workflows/ci-tests.yml)**FastETL** is a plugins package for Airflow for building data pipelinesfor a number of common scenarios.Main features:* Full or incremental **replication** of tables in SQL Server, Postgres  and MySQL databases* Load data from **GSheets** and from spreadsheets on **Samba/Windows**  networks* Extracting **CSV** from SQL* Clean data using custom data patching tasks (e.g. for messy  geographical coordinates, mapping canonical values for columns, etc.)* Querying the Brazilian National Official Gazette's (**DOU**'s) API* Using a [Open Street Routing Machine](https://project-osrm.org/)  service to calculate route distances* Using [CKAN](https://docs.ckan.org/en/2.10/api/index.html) or  dados.gov.br's API to update dataset metadata* Using Frictionless  [Tabular Data Packages](https://specs.frictionlessdata.io/tabular-data-package/)  to write OpenDocument Text format data dictionaries&lt;!-- Contar a histÃ³ria da origem do FastETL --&gt;This framework is maintained by a network of developers from many teamsat the Ministry of Management and Innovation in Public Services and isthe cumulative result of using[Apache Airflow](https://airflow.apache.org/), a free and open sourcetool, starting in 2019.**For government:** FastETL is widely used for replication of data queriedvia Quartzo (DaaS) from Serpro.# Installation in AirflowFastETL implements the standards for Airflow plugins. To install it,simply add the `apache-airflow-providers-fastetl` package to yourPython dependencies in your Airflow environment.Or install it with```bashpip install apache-airflow-providers-fastetl```To see an example of an Apache Airflow container that uses FastETL,check out the[airflow2-docker](https://github.com/gestaogovbr/airflow2-docker)repository.To ensure appropriate results, please make sure to install the`msodbcsql17` and `unixodbc-dev` libraries on your Apache Airflow workers.# TestsThe test suite uses Docker containers to simulate a complete useenvironment, including Airflow and the databases. For that reason, toexecute the tests, you first need to install Docker and docker-compose.For people using Ubuntu 20.04, you can just type on the terminal:```bashsnap install docker```For other versions and operating systems, see the[official Docker documentation](https://docs.docker.com/get-docker/).To build the containers:```bashmake setup```To run the tests, use:```bashmake setup &amp;&amp; make tests```To shutdown the environment, use:```bashmake down```# Usage examplesThe main FastETL feature is the `DbToDbOperator` operator. It copies databetween `postgres` and `mssql` databases. MySQL is also supported as asource.Here goes an example:```pythonfrom datetime import datetimefrom airflow import DAGfrom fastetl.operators.db_to_db_operator import DbToDbOperatordefault_args = {    &quot;start_date&quot;: datetime(2023, 4, 1),}dag = DAG(    &quot;copy_db_to_db_example&quot;,    default_args=default_args,    schedule_interval=None,)t0 = DbToDbOperator(    task_id=&quot;copy_data&quot;,    source={        &quot;conn_id&quot;: airflow_source_conn_id,        &quot;schema&quot;: source_schema,        &quot;table&quot;: table_name,    },    destination={        &quot;conn_id&quot;: airflow_dest_conn_id,        &quot;schema&quot;: dest_schema,        &quot;table&quot;: table_name,    },    destination_truncate=True,    copy_table_comments=True,    chunksize=10000,    dag=dag,)```More detail about the parameters and the workings of `DbToDbOperator`can bee seen on the following files:* [fast_etl.py](fastetl/custom_functions/fast_etl.py)* [db_to_db_operator.py](fastetl/operators/db_to_db_operator.py)# How to contributeTo be written on the `CONTRIBUTING.md` document (issue[#4](/gestaogovbr/FastETL/issues/4)).</longdescription>
</pkgmetadata>