<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![Python 3.7, 3.8, 3.9](https://img.shields.io/badge/Python-3.7%2C%203.8%2C%203.9-3776ab.svg?maxAge=2592000)[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&amp;labelColor=ef8336)](https://pycqa.github.io/isort/)### GhanaNews Scraper  A simple unofficial python package to scrape data from   [GhanaWeb](https://www.ghanaweb.com),  [MyJoyOnline](https://www.myjoyonline.com),  [DailyGraphic](https://www.graphic.com.gh),  [CitiBusinessNews](https://citibusinessnews.com),  [YenGH](https://www.yen.com.gh),  [3News](https://www.3news.com),  [MyNewsGh](https://www.mynewsgh.com),  [PulseGh](https://www.pulse.com.gh)  Affiliated to [Bank of Ghana Fx Rates](https://pypi.org/project/bank-of-ghana-fx-rates/) and   [GhanaShops-Scraper](https://pypi.org/project/ghanashops-scraper/)### How to install```shellpip install ghananews-scraper```### Example Google Colab Notebook   Click Here: [![Google Colab Notebook](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1jZo8TUictFbZBCglXWxZPtbVDYtp_eUn?usp=sharing)![#f03c15](https://placehold.co/15x15/f03c15/f03c15.png) `Warning: DO NOT RUN GHANAWEB CODE IN ONLINE Google Colabs)`### Some GhanaWeb Urls:```markdownurls = [    &quot;https://www.ghanaweb.com/GhanaHomePage/regional/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/editorial/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/health/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/diaspora/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/tabloid/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/africa/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/religion/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/NewsArchive/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/business/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/SportsArchive/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/entertainment/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/africa/&quot;    &quot;https://www.ghanaweb.com/GhanaHomePage/television/&quot;]```### Outputs  - All outputs will be saved in a `.csv` file. Other file formats not yet supported.### Usage```pythonfrom ghanaweb.scraper import GhanaWeburl = 'https://www.ghanaweb.com/GhanaHomePage/politics/'# url = &quot;https://www.ghanaweb.com/GhanaHomePage/NewsArchive/&quot;# url = 'https://www.ghanaweb.com/GhanaHomePage/health/'# url = 'https://www.ghanaweb.com/GhanaHomePage/crime/'# url = 'https://www.ghanaweb.com/GhanaHomePage/regional/'# url = 'https://www.ghanaweb.com/GhanaHomePage/year-in-review/'# web = GhanaWeb(url='https://www.ghanaweb.com/GhanaHomePage/politics/')web = GhanaWeb(url=url)# scrape data and save to `current working dir`web.download(output_dir=None)```### Scrape list of articles from [GhanaWeb](https://ghanaweb.com)```pythonfrom ghanaweb.scraper import GhanaWeburls = [        'https://www.ghanaweb.com/GhanaHomePage/politics/',        'https://www.ghanaweb.com/GhanaHomePage/health/',        'https://www.ghanaweb.com/GhanaHomePage/crime/',        'https://www.ghanaweb.com/GhanaHomePage/regional/',        'https://www.ghanaweb.com/GhanaHomePage/year-in-review/'    ]for url in urls:    print(f&quot;Downloading: {url}&quot;)    web = GhanaWeb(url=url)    # download to current working directory    # if no location is specified    # web.download(output_dir=&quot;/Users/tsiameh/Desktop/&quot;)    web.download(output_dir=None)```### Scrape data from [MyJoyOnline](https://myjoyonline.com)```pythonfrom myjoyonline.scraper import MyJoyOnlineurl = 'https://www.myjoyonline.com/news/'print(f&quot;Downloading data from: {url}&quot;)joy = MyJoyOnline(url=url)# download to current working directory# if no location is specified# joy.download(output_dir=&quot;/Users/tsiameh/Desktop/&quot;)joy.download()``````pythonfrom myjoyonline.scraper import MyJoyOnlineurls = [        'https://www.myjoyonline.com/news/',        'https://www.myjoyonline.com/entertainment/',        'https://www.myjoyonline.com/business/',        'https://www.myjoyonline.com/sports/',        'https://www.myjoyonline.com/opinion/'    ]for url in urls:    print(f&quot;Downloading data from: {url}&quot;)    joy = MyJoyOnline(url=url)    # download to current working directory    # if no location is specified    # joy.download(output_dir=&quot;/Users/tsiameh/Desktop/&quot;)    joy.download()```### Scrape data from [CitiBusinessNews](https://citibusinessnews.com)  + Here are some list of publisher names:    + `citibusinessnews`    + `aklama`    + `ellen`    + `emmanuel-oppong`    + `nerteley`    + `edna-agnes-boakye`    + `nii-larte-lartey`    + `naa-shika-caesar`    + `ogbodu`      * Note: using publisher names fetches more data than the url.```pythonfrom citionline.scraper import CitiBusinessOnlineurls = [    &quot;https://citibusinessnews.com/ghanabusinessnews/features/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/telecoms-technology/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/international/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/news/government/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/news/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/business/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/news/economy/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/news/general/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/news/top-stories/&quot;,    &quot;https://citibusinessnews.com/ghanabusinessnews/business/tourism/&quot;]for url in urls:    print(f&quot;Downloading data from: {url}&quot;)    citi = CitiBusinessOnline(url=url)    citi.download()# OR: scrape using publisher namefrom citionline.authors import CitiBusinessciti = CitiBusiness(author=&quot;citibusinessnews&quot;, limit_pages=4)citi.download()```### Scrape data from [DailyGraphic](https://www.graphic.com.gh/)```pythonfrom graphiconline.scraper import GraphicOnlineurls = [    &quot;https://www.graphic.com.gh/news.html&quot;,    &quot;https://www.graphic.com.gh/news/politics.html&quot;,    &quot;https://www.graphic.com.gh/lifestyle.html&quot;,    &quot;https://www.graphic.com.gh/news/education.html&quot;,    &quot;https://www.graphic.com.gh/native-daughter.html&quot;,    &quot;https://www.graphic.com.gh/international.html&quot;]for url in urls:    print(f&quot;Downloading data from: {url}&quot;)    graphic = GraphicOnline(url=url)    graphic.download()```### Scrape data from [YenGH](https://www.yen.com.gh/)```pythonfrom yen.scraper import Yenurls = [    &quot;https://www.yen.com.gh/&quot;,    &quot;https://yen.com.gh/people/&quot;,    &quot;https://yen.com.gh/ghana/&quot;,    &quot;https://yen.com.gh/education/&quot;,    &quot;https://yen.com.gh/entertainment/&quot;,    &quot;https://yen.com.gh/business-economy/&quot;,    &quot;https://www.yen.com.gh/politics/&quot;,    &quot;https://www.yen.com.gh/world/&quot;,    &quot;https://www.yen.com.gh/world/europe/&quot;,    &quot;https://www.yen.com.gh/world/asia/&quot;,    &quot;https://www.yen.com.gh/world/africa/&quot;]for url in urls:    print(f&quot;Downloading data from: {url}&quot;)    yen = Yen(url=url)    yen.download()```### Scrape data from [MyNewsGh](https://mynewsgh.com)```pythonfrom mynewsgh.scraper import MyNewsGh# scrape from multiple URLsurls = [  &quot;https://www.mynewsgh.com/category/politics/&quot;,  &quot;https://www.mynewsgh.com/category/news/&quot;,  &quot;https://www.mynewsgh.com/category/entertainment/&quot;,  &quot;https://www.mynewsgh.com/category/business/&quot;,  &quot;https://www.mynewsgh.com/category/lifestyle/&quot;,  &quot;https://www.mynewsgh.com/tag/feature/&quot;,  &quot;https://www.mynewsgh.com/category/world/&quot;,  &quot;https://www.mynewsgh.com/category/sports/&quot;]for url in urls:    print(f&quot;Downloading data from: {url}&quot;)    my_news = MyNewsGh(url=url, limit_pages=50)    my_news.download()# scrape from a single URLfrom mynewsgh.scraper import MyNewsGhurl = &quot;https://www.mynewsgh.com/category/politics/&quot;my_news = MyNewsGh(url=url, limit_pages=None)my_news.download()```### Scrape data from [3News](https://3news.com)```pythonfrom threenews.scraper import ThreeNews# DO NOT RUN ALL AUTHORS: select ONLY few# DO NOT CHANGE THE AUTHOR NAMESauthors = [  &quot;laud-nartey&quot;,  &quot;3xtra&quot;,  &quot;essel-issac&quot;,  &quot;arabaincoom&quot;,  &quot;bbc&quot;,  &quot;betty-kankam-boadu&quot;,  &quot;kwameamoh&quot;,  &quot;fiifi_forson&quot;,  &quot;fdoku&quot;,  &quot;frankappiah&quot;,  &quot;godwin-asediba&quot;,  &quot;afua-somuah&quot;,  &quot;irene&quot;,  &quot;joyce-sesi&quot;,  &quot;3news_user&quot;,  &quot;ntollo&quot;,  &quot;pwaberi-denis&quot;,  &quot;sonia-amade&quot;,  &quot;effah-steven&quot;,  &quot;michael-tetteh&quot;]for author in authors:    print(f&quot;Downloading data from author: {author}&quot;)    three_news = ThreeNews(author=author, limit_pages=50)    three_news.download()# ORfrom threenews.scraper import ThreeNewsthree = ThreeNews(author=&quot;laud-nartey&quot;, limit_pages=None)three.download()```### Scrape data from [PulseGh](https://pulse.com.gh)  + select ONLY few urls  + news, entertainment, business, lifestyle has 40 pages  + business/domestic has 25 pages  + business/international has 40 pages  + sports/football has 99 pages  + news/politics has 40 pages  + news/local has 40 pages  + news/world has 40 pages  + news/filla has 38 pages  + entertainment/celebrities has 40 pages  + lifestyle/fashion has 40 pages    * Note: these values may change```pythonfrom pulsegh.scraper import PulseGhurls = [  &quot;https://www.pulse.com.gh/news&quot;,  &quot;https://www.pulse.com.gh/news/politics&quot;,  &quot;https://www.pulse.com.gh/entertainment&quot;,  &quot;https://www.pulse.com.gh/lifestyle&quot;,  &quot;https://www.pulse.com.gh/sports&quot;,  &quot;https://www.pulse.com.gh/sports/football&quot;,  &quot;https://www.pulse.com.gh/business/international&quot;,  &quot;https://www.pulse.com.gh/business/domestic&quot;,  &quot;https://www.pulse.com.gh/business&quot;,  &quot;https://www.pulse.com.gh/quizzes&quot;]for url in urls:    print(f&quot;Downloading data from: {url}&quot;)    pulse = PulseGh(url=url, limit_pages=5)    pulse.download()# news has 40 pagesfrom pulsegh.scraper import PulseGhpulse = PulseGh(url=&quot;https://www.pulse.com.gh/news&quot;, total_pages = 40, limit_pages=20)pulse.download()# Sports/football has 99 pagesfrom pulsegh.scraper import PulseGhpulse = PulseGh(url=&quot;https://www.pulse.com.gh/sports/football&quot;, total_pages=99, limit_pages=None)pulse.download()```BuyMeCoffee-----------[![Build](https://www.buymeacoffee.com/assets/img/custom_images/yellow_img.png)](https://www.buymeacoffee.com/theodondrew)Credits--------  `Theophilus Siameh`&lt;div&gt;    &lt;a href=&quot;https://twitter.com/tsiameh&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/tsiameh?color=blue&amp;logo=twitter&amp;style=flat&quot; alt=&quot;tsiameh twitter&quot;&gt;&lt;/a&gt;&lt;/div&gt;</longdescription>
</pkgmetadata>