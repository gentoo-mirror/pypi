<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[![PyPI](https://img.shields.io/pypi/v/english-words.svg)](https://pypi.org/project/english-words/)# english-words-pyReturns sets of English words created by combining different wordslists together. Example usage: to get a set of English words from the&quot;web2&quot; word list, including only lower-case letters, you write thefollowing:```python3&gt;&gt;&gt; from english_words import get_english_words_set&gt;&gt;&gt; web2lowerset = get_english_words_set(['web2'], lower=True)```## UsageFrom the main package, import `get_english_words_set` as demonstratedabove. This function takes a number of arguments; the first is a list ofword list identifiers for the word lists to combine and the rest areflags. These arguments are described here (in the following order):- `sources` is an iterable containing stringscorresponding to word list identifiers (see &quot;Word lists&quot; subsectionbelow)- `alpha` (default `False`) is a flag specifying that all  non-alphanumeric characters (e.g.: `-`, `'`) should be stripped- `lower` (default `False` ) is a flag specifying that all upper-case  letters should be converted to lower-caseEach word list is pre-processed to handle the above flags, so using anycombination of options will not cause the function to run slower.Note that some care needs to be used when combining word lists. Forexample, only proper nouns in the `web2` word list are capitalized, butmost words in the `gcide` word list are capitalized.### Word lists| Name/URL | Identifier | Notes || :--- | :--- | :--- || [GCIDE 0.53 index](https://ftp.gnu.org/gnu/gcide/) | `gcide` | Words found in GNU Collaborative International Dictionary of English 0.53. Most words capitalized (not exactly sure what the capitalization convention is). Contains some entries with multiple words (currently you must use the alpha option to exclude these).&lt;br/&gt;&lt;br/&gt;Unicode characters are currently unprocessed; for example `&lt;ae/` is present in the dictionary instead of `Ã¦`. Ideally, these should all be converted. || [web2 revision 326913](https://svnweb.freebsd.org/base/head/share/dict/web2?view=markup&amp;pathrev=326913) | `web2` | |## Adding additional word listsTo add a word list, say with identifier `x`, put the word list (one wordper line), into a plain text file `x.txt` in the [`raw_data`](raw_data)directory at the root of the repository. Then, to process the word list(and all others in the directory) run the script[`process_raw_data.py`](scripts/process_raw_data.py).## InstallationInstall this with pip with```pip install english-words```This package is unfortunately rather large (~20MB), and will run intoscaling issues if more word lists or (especially) options are added.When that bridge is crossed, word lists should possibly be chosen by theuser instead of simply including all of them; word lists could also bepreprocessed on the client side instead of being included in thepackage.</longdescription>
</pkgmetadata>