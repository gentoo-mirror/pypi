<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![lokii-logo](https://github.com/dorukerenaktas/lokii/assets/20422563/fe774eba-ddd0-4bad-a093-553bb980f54c)![PyPI](https://img.shields.io/pypi/v/lokii)![PyPI - Downloads](https://img.shields.io/pypi/dm/lokii)![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/dorukerenaktas/lokii/python-app.yml)![Libraries.io dependency status for GitHub repo](https://img.shields.io/librariesio/github/dorukerenaktas/lokii)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)[![Licence](https://img.shields.io/pypi/l/lokii.svg)](https://github.com/dorukerenaktas/lokii)**`lokii`** is a powerful package that enables the generation of relational datasets, specifically tailored tofacilitate the creation of robust development environments. With **`lokii`**, you can effortlessly generate diversedatasets that mimic real-world scenarios, allowing for comprehensive end-to-end testing of your applications.![lokii_animated](https://github.com/dorukerenaktas/lokii/assets/20422563/9145c764-2db2-4c16-9019-e1feca323ae8)# Project structure**`lokii`** leverages the hierarchical structure of the file system to discover groups and nodes. Each datasetconsists of nodes, which are defined using `.node.py` files. For instance, in the context of a database, eachnode represents a table. Furthermore, you can even group nodes under database schemas within the database. Groupsdefines how generated node data will be exported. You can recognize group files by their `.group.py` file extension.```shell# example project directory structureproj_dir    ├── group_1    │   ├── group_1.group.py    │   ├── node_2.node.py    │   └── node_2.node.py    ├── group_2    │   ├── node_3.node.py    │   └── node_4.node.py    ├── group_3.group.py    ├── node_5.node.py    └── node_6.node.py```## Node DefinitionNode file defines how each item will be generated. There are special variables and functions in nodedefinition files.- `name`: Name of the node, filename will be used if not provided- `source`: Source query for retrieve dependent parameters for each item- `item`: Generation function that will return each item in node```python# offices.node.pyfrom faker import Faker# use your favorite tools to generate data# you can even use database connection, filesystem or AIfake = Faker()# if you want you can override the node name if not provided filename will be used# can be used in source queries if you want to retrieve rows that depends on another node# name = &quot;business.offices&quot;# define a query that returns one or more rowssource = &quot;SELECT * FROM range(10)&quot;# item function will be called for each row in `source` query resultdef item(args):    address = fake.address().split(&quot;\n&quot;)    return {        &quot;officeCode&quot;: args[&quot;id&quot;],        &quot;city&quot;: fake.city(),        &quot;phone&quot;: fake.phone_number(),        &quot;addressLine1&quot;: address[0],        &quot;addressLine2&quot;: address[1],        &quot;state&quot;: fake.city(),        &quot;country&quot;: fake.country(),        &quot;postalCode&quot;: fake.postcode(),        &quot;territory&quot;: fake.administrative_unit(),    }```## Group DefinitionGroup file defines how each node data will be exported. There are special functions in group definition files.- `before`: Called once before export operation- `export`: Called for every node in the group- `after`: Called once after export operation```python# filesystem.group.pyimport osimport shutilfrom csv import DictWriterout_path = &quot;out_data&quot;def before(args):    &quot;&quot;&quot;    Executed before export function.    :param args: contains node names that belongs to this group    :type args: {&quot;nodes&quot;: list[str]}     &quot;&quot;&quot;    if os.path.exists(out_path):        # always clear your storage before starting a new export        shutil.rmtree(out_path)    os.makedirs(out_path)def export(args):    &quot;&quot;&quot;    Executed for all nodes that belongs to this group    :param args: contains node name, node columns and a batch iterator    :type args: {&quot;name&quot;: str, &quot;cols&quot;: list[str], &quot;batches&quot;: list[dict]}     &quot;&quot;&quot;    node_name = args[&quot;name&quot;]    node_cols = args[&quot;cols&quot;]    batches = args[&quot;batches&quot;]    # out_data/offices.csv    out_file_path = os.path.join(out_path, node_name + &quot;.csv&quot;)    with open(out_file_path, 'w+', newline='', encoding='utf-8') as outfile:        writer = DictWriter(outfile, fieldnames=node_cols)        writer.writeheader()        for batch in batches:            writer.writerows(batch)def after(args):    &quot;&quot;&quot;    Executed after export function.    :param args: contains node names that belongs to this group    :type args: {&quot;nodes&quot;: list[str]}     &quot;&quot;&quot;    pass```## Upload to PyPIYou can create the source distribution of the package by running the command given below:```shellpython3 setup.py sdist```Install twine and upload pypi for `finnetdevlab` username.```shellpip3 install twinetwine upload dist/*```## RequirementsPackage requirements are handled using pip. To install them do```pip install -r requirements.txtpip install -r requirements.dev.txt```## TestsTesting is set up using [pytest](http://pytest.org) and coverage is handledwith the pytest-cov plugin.Run your tests with ```py.test``` in the root directory.Coverage is run by default and is set in the ```pytest.ini``` file.</longdescription>
</pkgmetadata>