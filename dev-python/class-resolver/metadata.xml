<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;!--&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;docs/source/logo.png&quot; height=&quot;150&quot;&gt;&lt;/p&gt;--&gt;&lt;h1 align=&quot;center&quot;&gt;  Class Resolver&lt;/h1&gt;&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://github.com/cthoyt/class-resolver/actions?query=workflow%3ATests&quot;&gt;        &lt;img alt=&quot;Tests&quot; src=&quot;https://github.com/cthoyt/class-resolver/workflows/Tests/badge.svg&quot; /&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/cthoyt/cookiecutter-python-package&quot;&gt;        &lt;img alt=&quot;Cookiecutter template from @cthoyt&quot; src=&quot;https://img.shields.io/badge/Cookiecutter-snekpack-blue&quot; /&gt;     &lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/class_resolver&quot;&gt;        &lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/class_resolver&quot; /&gt;    &lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/class_resolver&quot;&gt;        &lt;img alt=&quot;PyPI - Python Version&quot; src=&quot;https://img.shields.io/pypi/pyversions/class_resolver&quot; /&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/cthoyt/class-resolver/blob/main/LICENSE&quot;&gt;        &lt;img alt=&quot;PyPI - License&quot; src=&quot;https://img.shields.io/pypi/l/class-resolver&quot; /&gt;    &lt;/a&gt;    &lt;a href='https://class_resolver.readthedocs.io/en/latest/?badge=latest'&gt;        &lt;img src='https://readthedocs.org/projects/class_resolver/badge/?version=latest' alt='Documentation Status' /&gt;    &lt;/a&gt;    &lt;a href=&quot;https://codecov.io/gh/cthoyt/class-resolver/branch/main&quot;&gt;        &lt;img src=&quot;https://codecov.io/gh/cthoyt/class-resolver/branch/main/graph/badge.svg&quot; alt=&quot;Codecov status&quot; /&gt;    &lt;/a&gt;      &lt;a href=&quot;https://zenodo.org/badge/latestdoi/343741010&quot;&gt;        &lt;img src=&quot;https://zenodo.org/badge/343741010.svg&quot; alt=&quot;DOI&quot;&gt;    &lt;/a&gt;    &lt;a href=&quot;https://github.com/psf/black&quot;&gt;        &lt;img src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot; alt=&quot;Code style: black&quot; /&gt;    &lt;/a&gt;&lt;/p&gt;Lookup and instantiate classes with style.## üí™ Getting Started```pythonfrom class_resolver import ClassResolverfrom dataclasses import dataclassclass Base: pass@dataclassclass A(Base):   name: str@dataclassclass B(Base):   name: str# Indexresolver = ClassResolver([A, B], base=Base)# Lookupassert A == resolver.lookup('A')# Instantiate with a dictionaryassert A(name='hi') == resolver.make('A', {'name': 'hi'})# Instantiate with kwargsassert A(name='hi') == resolver.make('A', name='hi')# A pre-instantiated class will simply be passed throughassert A(name='hi') == resolver.make(A(name='hi'))```## ü§ñ Writing Extensible Machine Learning Models with `class-resolver`Assume you've implemented a simple multi-layer perceptron in PyTorch:```pythonfrom itertools import chainfrom more_itertools import pairwisefrom torch import nnclass MLP(nn.Sequential):    def __init__(self, dims: list[int]):        super().__init__(chain.from_iterable(            (                nn.Linear(in_features, out_features),                nn.ReLU(),            )            for in_features, out_features in pairwise(dims)        ))```This MLP uses a hard-coded rectified linear unit as the non-linear activationfunction between layers. We can generalize this MLP to use a variety ofnon-linear activation functions by adding an argument to its`__init__()` function like in:```pythonfrom itertools import chainfrom more_itertools import pairwisefrom torch import nnclass MLP(nn.Sequential):    def __init__(self, dims: list[int], activation: str = &quot;relu&quot;):        if activation == &quot;relu&quot;:            activation = nn.ReLU()        elif activation == &quot;tanh&quot;:            activation = nn.Tanh()        elif activation == &quot;hardtanh&quot;:            activation = nn.Hardtanh()        else:            raise KeyError(f&quot;Unsupported activation: {activation}&quot;)        super().__init__(chain.from_iterable(            (                nn.Linear(in_features, out_features),                activation,            )            for in_features, out_features in pairwise(dims)        ))```The first issue with this implementation is it relies on a hard-coded set ofconditional statements and is therefore hard to extend. It can be improvedby using a dictionary lookup:```pythonfrom itertools import chainfrom more_itertools import pairwisefrom torch import nnactivation_lookup: dict[str, nn.Module] = {   &quot;relu&quot;: nn.ReLU(),   &quot;tanh&quot;: nn.Tanh(),   &quot;hardtanh&quot;: nn.Hardtanh(),}class MLP(nn.Sequential):    def __init__(self, dims: list[int], activation: str = &quot;relu&quot;):        activation = activation_lookup[activation]        super().__init__(chain.from_iterable(            (                nn.Linear(in_features, out_features),                activation,            )            for in_features, out_features in pairwise(dims)        ))```This approach is rigid because it requires pre-instantiation of the activations.If we needed to vary the arguments to the `nn.HardTanh` class, the previousapproach wouldn't work. We can change the implementation to lookup on the class *before instantiation* then optionally pass some arguments:```pythonfrom itertools import chainfrom more_itertools import pairwisefrom torch import nnactivation_lookup: dict[str, type[nn.Module]] = {   &quot;relu&quot;: nn.ReLU,   &quot;tanh&quot;: nn.Tanh,   &quot;hardtanh&quot;: nn.Hardtanh,}class MLP(nn.Sequential):    def __init__(        self,         dims: list[int],         activation: str = &quot;relu&quot;,         activation_kwargs: None | dict[str, any] = None,    ):        activation_cls = activation_lookup[activation]        activation = activation_cls(**(activation_kwargs or {}))        super().__init__(chain.from_iterable(            (                nn.Linear(in_features, out_features),                activation,            )            for in_features, out_features in pairwise(dims)        ))```This is pretty good, but it still has a few issues:1. you have to manually maintain the `activation_lookup` dictionary,2. you can't pass an instance or class through the `activation` keyword3. you have to get the casing just right4. the default is hard-coded as a string, which means this has to get copied   (error-prone) in any place that creates an MLP5. you have to re-write this logic for all of your classesEnter the `class_resolver` package, which takes care of all of thesethings using the following:```pythonfrom itertools import chainfrom class_resolver import ClassResolver, Hintfrom more_itertools import pairwisefrom torch import nnactivation_resolver = ClassResolver(    [nn.ReLU, nn.Tanh, nn.Hardtanh],    base=nn.Module,    default=nn.ReLU,)class MLP(nn.Sequential):    def __init__(        self,         dims: list[int],         activation: Hint[nn.Module] = None,  # Hint = Union[None, str, nn.Module, type[nn.Module]]        activation_kwargs: None | dict[str, any] = None,    ):        super().__init__(chain.from_iterable(            (                nn.Linear(in_features, out_features),                activation_resolver.make(activation, activation_kwargs),            )            for in_features, out_features in pairwise(dims)        ))```Because this is such a common pattern, we've made it available through contribmodule in `class_resolver.contrib.torch`:```pythonfrom itertools import chainfrom class_resolver import Hintfrom class_resolver.contrib.torch import activation_resolverfrom more_itertools import pairwisefrom torch import nnclass MLP(nn.Sequential):    def __init__(        self,         dims: list[int],         activation: Hint[nn.Module] = None,        activation_kwargs: None | dict[str, any] = None,    ):        super().__init__(chain.from_iterable(            (                nn.Linear(in_features, out_features),                activation_resolver.make(activation, activation_kwargs),            )            for in_features, out_features in pairwise(dims)        ))```Now, you can instantiate the MLP with any of the following:```pythonMLP(dims=[10, 200, 40])  # uses default, which is ReLUMLP(dims=[10, 200, 40], activation=&quot;relu&quot;)  # uses lowercaseMLP(dims=[10, 200, 40], activation=&quot;ReLU&quot;)  # uses stylizedMLP(dims=[10, 200, 40], activation=nn.ReLU)  # uses classMLP(dims=[10, 200, 40], activation=nn.ReLU())  # uses instanceMLP(dims=[10, 200, 40], activation=&quot;hardtanh&quot;, activation_kwargs={&quot;min_val&quot;: 0.0, &quot;max_value&quot;: 6.0})  # uses kwargsMLP(dims=[10, 200, 40], activation=nn.HardTanh, activation_kwargs={&quot;min_val&quot;: 0.0, &quot;max_value&quot;: 6.0})  # uses kwargsMLP(dims=[10, 200, 40], activation=nn.HardTanh(0.0, 6.0))  # uses instance```In practice, it makes sense to stick to using the strings in combination withhyper-parameter optimization libraries like [Optuna](https://optuna.org/).## ‚¨áÔ∏è InstallationThe most recent release can be installed from[PyPI](https://pypi.org/project/class_resolver/) with:```bash$ pip install class_resolver```The most recent code and data can be installed directly from GitHub with:```bash$ pip install git+https://github.com/cthoyt/class-resolver.git```To install in development mode, use the following:```bash$ git clone git+https://github.com/cthoyt/class-resolver.git$ cd class-resolver$ pip install -e .```## üôè ContributingContributions, whether filing an issue, making a pull request, or forking, are appreciated. See[CONTRIBUTING.rst](https://github.com/cthoyt/class-resolver/blob/master/CONTRIBUTING.rst) for moreinformation on getting involved.## üëã Attribution### ‚öñÔ∏è LicenseThe code in this package is licensed under the MIT License.### üç™ CookiecutterThis package was created with [@audreyfeldroy](https://github.com/audreyfeldroy)'s[cookiecutter](https://github.com/cookiecutter/cookiecutter) package using [@cthoyt](https://github.com/cthoyt)'s[cookiecutter-snekpack](https://github.com/cthoyt/cookiecutter-snekpack) template.## üõ†Ô∏è For Developers&lt;details&gt;  &lt;summary&gt;See developer instructions&lt;/summary&gt;The final section of the README is for if you want to get involved by making a code contribution.### ‚ùì TestingAfter cloning the repository and installing `tox` with `pip install tox`, the unit tests in the `tests/` folder can berun reproducibly with:```shell$ tox```Additionally, these tests are automatically re-run with each commit in a [GitHub Action](https://github.com/{{cookiecutter.github_organization_name}}/{{cookiecutter.github_repository_name}}/actions?query=workflow%3ATests).### üì¶ Making a ReleaseAfter installing the package in development mode and installing`tox` with `pip install tox`, the commands for making a new release are contained within the `finish` environmentin `tox.ini`. Run the following from the shell:```shell$ tox -e finish```This script does the following:1. Uses BumpVersion to switch the version number in the `setup.cfg` and   `src/{{cookiecutter.package_name}}/version.py` to not have the `-dev` suffix2. Packages the code in both a tar archive and a wheel3. Uploads to PyPI using `twine`. Be sure to have a `.pypirc` file configured to avoid the need for manual input at this   step4. Push to GitHub. You'll need to make a release going with the commit where the version was bumped.5. Bump the version to the next patch. If you made big changes and want to bump the version by minor, you can   use `tox -e bumpversion minor` after.&lt;/details&gt;</longdescription>
</pkgmetadata>