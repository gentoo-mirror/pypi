<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![linkrot logo](https://github.com/marshalmiller/linkrot/blob/6e6fb45239f8d06e89671e2ec68a11629747355d/branding/Asset%207@4x.png)# IntroductionScans pdfs for links written in plaintext and checks if they are active or returns an error code. It then generates a report of its findings. Extract references (pdf, url, doi, arxiv) and metadata from a PDF.Check out our sister project, [Rotting Research](https://github.com/marshalmiller/rottingresearch), for a web app implementation of this project.# Features- Extract references and metadata from a given PDF.  - Detects pdf, url, arxiv and doi references.- Archives valid links using Internet Archive's Wayback Machine.- Checks for valid SSL certificate.  - Find broken hyperlinks (using the -c flag).  - Output as text or JSON (using the -j flag).  - Extract the PDF text (using the --text flag).  - Use as command-line tool or Python package.  - Works with local and online pdfs.  # InstallationGrab a copy of the code with pip: ```bashpip install linkrot```# Usagelinkrot can be used to extract info from a PDF in two ways:- Command line/Terminal tool `linkrot`- Python library `import linkrot`## 1. Command Line/Terminal tool```bashlinkrot [pdf-file-or-url]```Run linkrot -h to see the help output:```bashlinkrot -h```usage: ```bash linkrot [-h] [-d OUTPUT_DIRECTORY] [-c] [-j] [-v] [-t] [-o OUTPUT_FILE] [--version] pdf```Extract metadata and references from a PDF, and optionally download allreferenced PDFs.### Arguments#### positional arguments:  pdf                   (Filename or URL of a PDF file)  #### optional arguments:    -h, --help            (Show this help message and exit)      -d OUTPUT_DIRECTORY,  --download-pdfs OUTPUT_DIRECTORY (Download all referenced PDFs into specified directory)      -c, --check-links     (Check for broken links)      -j, --json            (Output infos as JSON (instead of plain text))      -v, --verbose         (Print all references (instead of only PDFs))      -t, --text            (Only extract text (no metadata or references))      -a, --archive  (Archive actvice links)    -o OUTPUT_FILE,        --output-file OUTPUT_FILE (Output to specified file instead of console)      --version             (Show program's version number and exit)  ### PDF SamplesFor testing purposes, you can find pdf samples on a [shared MEGA folder](https://mega.nz/folder/uwBxVSzS#lpBtSz49E9dqHtmrQwp0Ig).### Examples#### Extract text to console```bashlinkrot https://example.com/example.pdf -t```#### Extract text to file```bashlinkrot https://example.com/example.pdf -t -o pdf-text.txt```#### Check Links```bashlinkrot https://example.com/example.pdf -c```## 2. Main Python LibraryImport the library: ```pythonimport linkrot```Create an instance of the linkrot class like so: ```pythonpdf = linkrot.linkrot(&quot;filename-or-url.pdf&quot;) #pdf is the instance of the linkrot class```Now the following function can be used to extract specific data from the pdf:### get_metadata()Arguments: NoneUsage: ```pythonmetadata = pdf.get_metadata() #pdf is the instance of the linkrot class``` Return type: Dictionary `&lt;class 'dict'&gt;`Information Provided: All metadata, secret metadata associated with the PDF including Creation date, Creator, Title, etc...### get_text()Arguments: NoneUsage: ```pythontext = pdf.get_text() #pdf is the instance of the linkrot class```Return type: String `&lt;class 'str'&gt;`Information Provided: The entire content of the PDF in string form.### get_references(reftype=None, sort=False)Arguments: reftype: The type of reference that is needed  values: 'pdf', 'url', 'doi', 'arxiv'.  default: Provides all reference types.sort: Whether reference should be sorted or not      values: True or False.       default: Is not sorted.Usage: ```pythonreferences_list = pdf.get_references() #pdf is the instance of the linkrot class```Return type: Set `&lt;class 'set'&gt;` of `&lt;linkrot.backends.Reference object&gt;`linkrot.backends.Reference object has 3 member variables:- ref: actual URL/PDF/DOI/ARXIV- reftype: type of reference- page: page on which it was referencedInformation Provided: All references with their corresponding type and page number. ### get_references_as_dict(reftype=None, sort=False)Arguments: reftype: The type of reference that is needed  values: 'pdf', 'url', 'doi', 'arxiv'.  default: Provides all reference types.sort: Whether reference should be sorted or not      values: True or False.       default: Is not sorted.Usage: ```pythonreferences_dict = pdf.get_references_as_dict() #pdf is the instance of the linkrot class```Return type: Dictionary `&lt;class 'dict'&gt;` with keys 'pdf', 'url', 'doi', 'arxiv' that each have a list `&lt;class 'list'&gt;` of refs of that type.Information Provided: All references in their corresponding type list.### download_pdfs(target_dir)Arguments: target_dir: The path of the directory to which the reference pdfs should be downloaded Usage: ```pythonpdf.download_pdfs(&quot;target-directory&quot;) #pdf is the instance of the linkrot class```Return type: NoneInformation Provided: Downloads all the reference pdfs to specified directory.## 3. Linkrot downloader functionsImport:```pythonfrom linkrot.downloader import sanitize_url, get_status_code, check_refs```### sanitize_url(url)Arguments: url: The url to be sanitized.Usage: ```pythonnew_url = sanitize_url(old_url) ```Return type: String `&lt;class 'str'&gt;`Information Provided: URL is prefixed with 'http://' if it was not before and makes sure it is in utf-8 format.### get_status_code(url)Arguments: url: The url to be checked for its status. Usage: ```pythonstatus_code = get_status_code(url) ```Return type: String `&lt;class 'str'&gt;`Information Provided: Checks if the url is active or broken.### check_refs(refs, verbose=True, max_threads=MAX_THREADS_DEFAULT)Arguments: refs: set of linkrot.backends.Reference objectsverbose: whether it should print every reference with its code or just the summary of the link checkermax_threads: number of threads for multithreadingUsage: ```pythoncheck_refs(pdf.get_references()) #pdf is the instance of the linkrot class```Return type: NoneInformation Provided: Prints references with their status code and a summary of all the broken/active links on terminal.## 4. Linkrot extractor functionsImport:```pythonfrom linkrot.extractor import extract_urls, extract_doi, extract_arxiv```Get pdf text:```pythontext = pdf.get_text() #pdf is the instance of the linkrot class```### extract_urls(text)Arguments: text: String of text to extract urls fromUsage: ```pythonurls = extract_urls(text)```Return type: Set `&lt;class 'set'&gt;` of URLsInformation Provided: All URLs in the text### extract_arxiv(text)Arguments: text: String of text to extract arxivs fromUsage: ```pythonarxiv = extract_arxiv(text)```Return type: Set `&lt;class 'set'&gt;` of arxivsInformation Provided: All arxivs in the text### extract_doi(text)Arguments: text: String of text to extract dois fromUsage: ```pythondoi = extract_doi(text)```Return type: Set `&lt;class 'set'&gt;` of doisInformation Provided: All dois in the text# Code of ConductTo view our code of conduct please visit our [Code of Conduct page](https://github.com/marshalmiller/rottingresearch/blob/main/code_of_conduct.md).            # LicenseThis program is licensed with an [MIT License](https://github.com/marshalmiller/linkrot/blob/main/LICENSE).</longdescription>
</pkgmetadata>