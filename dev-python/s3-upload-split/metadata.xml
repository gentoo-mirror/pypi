<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Python S3 Upload SplitS3 Upload Split is used to stream the content of an iterator to multiple S3 objects based on a provided regular expression. The iterator must be a list of dictionary, typically the resulset of a SQL query. Files will be called `data-{pattern}.json` where `{pattern}` is the match found using your regex.## Install`pip install s3-upload-split`## Usage### Import```pythonimport refrom sqlalchemy import create_enginefrom s3_upload_split import SplitUploadS3bucket = 'YOUR_BUCKET_NAME' # ex: my-bucketprefix = 'OUTPUT_PATH' # ex: db1/output/dev/regex = re.compile(r'YOUR_REGEX') # ex: \\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\D+(\\d{4}-\\d{2})-\\d{2}engine = create_engine('sqlite:///bookstore.db') # https://github.com/pranaymethuku/bookstore-database/blob/master/database/bookstore.dbwith engine.connect() as con:    iterator = con.execute('SELECT * FROM book')    SplitUploadS3(bucket, prefix, regex, iterator).handle_content()```## LimitationsIt creates one thread per matched pattern using your regex, so take it into account when you use that module. This is typically useful if your regex matches months in the input iterator. </longdescription>
</pkgmetadata>