<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># 项目描述ChatGPT 工具包，支持连续对话、流式对话（逐字显示）、对话存档与载入、对话回滚、对话伪造、轮询 api_key 池、限制历史消息数量、异步请求、群聊多角色模拟。# 作者信息昵称：lcctoor.com[主页](https://lcctoor.github.io/arts/) \| [微信](https://lcctoor.github.io/arts/arts/static/static-files/WeChatQRC.jpg) \| [Github](https://github.com/lcctoor) \| [PyPi](https://pypi.org/user/lcctoor) \| [Python交流群](https://lcctoor.github.io/arts/arts/static/static-files/PythonWeChatGroupQRC.jpg) \| [邮箱](mailto:lcctoor@outlook.com) \| [域名](http://lcctoor.com) \| [捐赠](https://lcctoor.github.io/arts/arts/static/static-files/DonationQRC-0rmb.jpg)# [主要贡献者](https://lcctoor.github.io/arts/arts/openai2/major_contributors)👈# Bug提交、功能提议您可以通过 [Github-Issues](https://github.com/lcctoor/arts/issues)、[微信](https://lcctoor.github.io/arts/arts/static/static-files/WeChatQRC.jpg) 与我联系。# 安装```pip install openai2```# 获取api_key[获取链接1](https://platform.openai.com/account/api-keys)[获取链接2](https://www.baidu.com/s?wd=%E8%8E%B7%E5%8F%96%20openai%20api_key)# 教程 ([查看美化版](https://lcctoor.github.io/arts/?pk=openai2)👈)#### 导入```pythonfrom openai2 import Chat```#### 创建对话```pythonapi_key = 'api_key'  # 更换成自己的api_keyTony = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)Lucy = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)  # 每个实例可使用 相同 或者 不同 的api_key```#### 对话```pythonTony.request('自然数50的后面是几?')  # &gt;&gt;&gt; 51Lucy.request('自然数100的后面是几?')  # &gt;&gt;&gt; 101Tony.request('再往后是几?')  # &gt;&gt;&gt; 52Lucy.request('再往后是几?')  # &gt;&gt;&gt; 102Tony.request('再往后呢?')  # &gt;&gt;&gt; 53Lucy.request('再往后呢?')  # &gt;&gt;&gt; 103```#### 流式对话 ([演示视频](https://lcctoor.github.io/arts/arts/static/programming-tutorial/001-Python/021-OpenAI/001-openai2/流式对话演示.mp4)👈)```pythonfor answer in Lucy.stream_request('世界上最大的海洋是哪个?'):    print(answer)世界上最大的海洋是太平洋。```#### 存档```pythonTony.dump('./talk_record.json')  # 可使用相对路径或绝对路径```#### 载入存档```pythonJenny = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)Jenny.load('./talk_record.json')Jenny.request('再往后呢?')  # &gt;&gt;&gt; 54```#### 对话回滚```pythonAnna = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)Anna.request('自然数1的后面是几?')  # &gt;&gt;&gt; 2Anna.request('再往后是几?')  # &gt;&gt;&gt; 3Anna.request('再往后呢?')  # &gt;&gt;&gt; 4Anna.request('再往后呢?')  # &gt;&gt;&gt; 5Anna.request('再往后呢?')  # &gt;&gt;&gt; 6Anna.request('再往后呢?')  # &gt;&gt;&gt; 7Anna.request('再往后呢?')  # &gt;&gt;&gt; 8# 回滚1轮对话Anna.rollback()  # &gt;&gt;&gt; [user]:再往后呢? [assistant]:7# 再回滚3轮对话Anna.rollback(n=3)  # &gt;&gt;&gt; [user]:再往后呢? [assistant]:4Anna.request('再往后呢?')  # &gt;&gt;&gt; 5```注：1、执行 `Anna.rollback(n=x)` 可回滚 x 轮对话。2、`Anna.rollback()` 相当于 `Anna.rollback(n=1)` 。#### 轮询 api_key 池```pythonfrom openai2 import Chat, AKPool# 创建 api_key 池AK1 = 'sk-ug8w...'AK2 = AKPool(['sk-mf40...', 'sk-m6g7...', ...])AK3 = AKPool(['sk-affe...', 'sk-fam4...', ...])AK4 = AKPool(['sk-detg...', 'sk-adle...', ...])Duke = Chat(api_key=AK1, model=&quot;gpt-3.5-turbo&quot;)  # 令 Duke 使用固定的 api_keyCarl = Chat(api_key=AK2, model=&quot;gpt-3.5-turbo&quot;)  # 令 Carl 和 Denny 使用同一个'api_key池', 系统将自动充分利用每个api_keyDenny = Chat(api_key=AK2, model=&quot;gpt-3.5-turbo&quot;)Chris = Chat(api_key=AK3, model=&quot;gpt-3.5-turbo&quot;)  # 令 Chris 使用独立的'api_key池'Dick = Chat(api_key=AK4, model=&quot;gpt-3.5-turbo&quot;)  # 令 Dick 使用独立的'api_key池'```注：允许（而非不允许）同一个 api_key 投放到不同的 api_key 池中，但每个 api_key 池都是独立调度，不会互相通信。#### 重置 api_key```pythonAK5 = 'sk-jg93...'AK6 = AKPool(['sk-vb7l...', 'sk-d3lv...'])...Carl.reset_api_key(AK5)  # 重置 api_keyCarl.reset_api_key(AK6)  # 再次重置 api_key...```#### 伪造对话```pythonfrom openai2 import Chat, user_msg, assistant_msgMickey = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)Mickey.forge(    user_msg('请问1+1=几?'),    assistant_msg('1+1=10'),    user_msg('那10+10=几?'),    assistant_msg('10+10=你大爷, 你提的这些问题真弱智!'),)answer = Mickey.request('哦吼, 你还敢骂我呀?')print(answer)  # &gt;&gt;&gt; 非常抱歉，我刚才的回答有些不适当。1+1=2, 10+10=20。非常抱歉给你带来困扰！```注：伪造对话可以穿插在对话中的任何时刻。#### 查看对话记录```pythonAriel = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)Ariel.request('自然数1的后面是几?')  # &gt;&gt;&gt; 2Ariel.request('再往后是几?')  # &gt;&gt;&gt; 3Ariel.fetch_messages()# 返回:# [#     {'role': 'user', 'content': '自然数1的后面是几?'},#     {'role': 'assistant', 'content': '2'},#     {'role': 'user', 'content': '再往后是几?'},#     {'role': 'assistant', 'content': '3'}# ]```#### 异步请求```pythonimport asynciofrom openai2 import ChatTony = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)async def main():    answer = await Tony.async_request('世界上最大的海洋是哪个')    print(answer)asyncio.run(main())  # &gt;&gt;&gt; 太平洋```#### 异步流式对话```pythonasync for answer in Tony.async_stream_request('世界上最大的海洋是哪个?'):    print(answer)世界上最大的海洋是太平洋。```#### 限制历史消息数量##### 限制历史消息数量随着对话次数越来越多，最终上下文长度就会超出 openai 接口限定的最大 token 数量，此时可使用 MsgMaxCount 参数来限制历史消息数量。当消息数量超出 MsgMaxCount 后，程序会自动移除最早的记录，使消息数量减少到恰好等于 MsgMaxCount 。```pythonMsgMaxCount = 6  # 最多保留6条历史消息Ariel = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;, MsgMaxCount=MsgMaxCount)Ariel.request('英国的首都是什么？')  # &gt;&gt;&gt; '伦敦'Ariel.request('日本首都是什么？')  # &gt;&gt;&gt; '东京'Ariel.request('意大利的首都是什么？')  # &gt;&gt;&gt; '罗马'Ariel.request('美国的首都是什么？')  # &gt;&gt;&gt; '华盛顿'Ariel.request('世界上国土面积最大的国家是哪个？')  # &gt;&gt;&gt; '俄罗斯'Ariel.request('法国的首都叫什么？')  # &gt;&gt;&gt; '巴黎'Ariel.request('青蛙的幼体叫什么？')  # &gt;&gt;&gt; '蝌蚪'Ariel.request('世界上最大的海洋是什么？')  # &gt;&gt;&gt; '太平洋'Ariel.fetch_messages()# 返回:# [#     {'role': 'user', 'content': '法国的首都叫什么？'},#     {'role': 'assistant', 'content': '巴黎'},#     {'role': 'user', 'content': '青蛙的幼体叫什么？'},#     {'role': 'assistant', 'content': '蝌蚪'},#     {'role': 'user', 'content': '世界上最大的海洋是什么？'},#     {'role': 'assistant', 'content': '太平洋'}# ]```##### 锁定消息当程序自动移除消息记录时，也许我们希望某些消息不要被移除，此时可将这些消息锁定。```pythonMsgMaxCount = 6Ariel = Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;, MsgMaxCount=MsgMaxCount)Ariel.request('英国的首都是什么？')  # &gt;&gt;&gt; '伦敦'Ariel.request('日本首都是什么？')  # &gt;&gt;&gt; '东京'Ariel.request('意大利的首都是什么？')  # &gt;&gt;&gt; '罗马'```此时共有 6 条消息记录：| 消息                 | 正序索引 | 逆序索引 || -------------------- | :------: | :------: || 英国的首都是什么？   |    0    |    -6    || 伦敦                 |    1    |    -5    || 日本首都是什么？     |    2    |    -4    || 东京                 |    3    |    -3    || 意大利的首都是什么？ |    4    |    -2    || 罗马                 |    5    |    -1    |锁定索引为 0、-2、-1 的消息：```pythonAriel.pin(0, -2, -1)  # 索引无须按顺序填写: pin(0, 1, 2) 与 pin(0, 2, 1) 等价.```继续请求：```pythonAriel.request('美国的首都是什么？')  # &gt;&gt;&gt; '华盛顿'```由于设置了 MsgMaxCount = 6，此时共有 6 条消息记录：| 消息                 | 正序索引 | 逆序索引 | 锁定状态 || -------------------- | :------: | :------: | :------: || 英国的首都是什么？   |    0    |    -6    |  已锁定  || 东京                 |    1    |    -5    |    -    || 意大利的首都是什么？ |    2    |    -4    |  已锁定  || 罗马                 |    3    |    -3    |  已锁定  || 美国的首都是什么？   |    4    |    -2    |    -    || 华盛顿               |    5    |    -1    |    -    |继续执行：```pythonAriel.pin(-2)  # 锁定'美国的首都是什么？'Ariel.request('世界上国土面积最大的国家是哪个？')  # &gt;&gt;&gt; '俄罗斯'Ariel.request('法国的首都叫什么？')  # &gt;&gt;&gt; '巴黎'Ariel.request('青蛙的幼体叫什么？')  # &gt;&gt;&gt; '蝌蚪'Ariel.request('世界上最大的海洋是什么？')  # &gt;&gt;&gt; '太平洋'Ariel.fetch_messages()# 返回:# [#     {'role': 'user', 'content': '英国的首都是什么？'},       # 被锁定的消息#     {'role': 'user', 'content': '意大利的首都是什么？'},     # 被锁定的消息#     {'role': 'assistant', 'content': '罗马'},               # 被锁定的消息#     {'role': 'user', 'content': '美国的首都是什么？'},       # 被锁定的消息#     {'role': 'user', 'content': '世界上最大的海洋是什么？'},#     {'role': 'assistant', 'content': '太平洋'}# ]```注：pin 方法也允许传入“已锁定的消息”的索引，这使得当不确定某些消息的状态时，可以放心地将它们的索引传进去。##### 解锁消息可使用 unpin 方法将已锁定的消息解除锁定。```pythonAriel.unpin(0, -2, -1)  # 解锁索引为 0、-2、-1 的消息```注：unpin 方法也允许传入“未锁定的消息”的索引，这使得当不确定某些消息的状态时，可以放心地将它们的索引传进去。#### 群聊多角色模拟```pythonfrom json import loads as jsonLoadsfrom openai2 import GroupChatapi_key = '...'  # 更换成自己的 api_keygroup = GroupChat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;)# 设置角色group.roles['苏轼'] = '宋朝诗人，他的词风格独特，既有儒家的教诲，又有生活的乐趣。'group.roles['李清照'] = '宋代著名的女词人，其词句优美，情感真挚。'group.roles['杜甫'] = '唐朝著名诗人。'# 添加角色历史对话group.add_dialog(speaker='苏轼', audiences=['李清照'], remark='你好呀')group.add_dialog(speaker='李清照', audiences=['苏轼'], remark='好久不见, 你最近在忙什么?')group.add_dialog(speaker='杜甫', audiences=['苏轼'], remark='上次托你帮我写的那首《茅屋为秋风所破歌》写好了吗?')# 让 ChatGPT 模拟回答answer = group.request([    ('苏轼', ['李清照']),  # 第 1 个元素表示说话人, 第 2 个元素表示对谁说话. 由于一个人可以同时对多个人说话, 因此第 2 个元素为列表    ('苏轼', ['杜甫']),])try:    print( jsonLoads(answer) )except:    print(answer)# 返回:[    {        &quot;speaker&quot;: &quot;苏轼&quot;,        &quot;audiences&quot;: &quot;李清照&quot;,        &quot;remark&quot;: &quot;最近我在写一首新的诗，题目是《听雨》&quot;    },    {        &quot;speaker&quot;: &quot;苏轼&quot;,        &quot;audiences&quot;: &quot;杜甫&quot;,        &quot;remark&quot;: &quot;那首《茅屋为秋风所破歌》已经写好啦，我在信里寄给你了，请查收&quot;    }]```注：同一个 group 会记住各个角色的历史对话，无须重复传。#### 更多方法openai2.Chat 底层调用了 [openai.ChatCompletion.create](https://platform.openai.com/docs/api-reference/chat/create?lang=python)，在实例化时，支持 openai.ChatCompletion.create 的所有参数，例如：`Chat(api_key=api_key, model=&quot;gpt-3.5-turbo&quot;, max_tokens=100)` 。</longdescription>
</pkgmetadata>