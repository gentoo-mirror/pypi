<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>## tasknet : simple multi-task transformer fine-tuning with Trainer and HuggingFace datasets. `tasknet` is an interface between Huggingface [datasets](https://huggingface.co/datasets) and Huggingface [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer).## Task templates`tasknet` relies on task templates to avoid boilerplate codes. The task templates correspond to Transformers AutoClasses:- `SequenceClassification` - `TokenClassification`- `MultipleChoice`- `Seq2SeqLM` (experimental support)The task templates follow the same interface. They implement `preprocess_function`, a data collator and `compute_metrics`.Look at [tasks.py](https://github.com/sileod/tasknet/blob/main/src/tasknet/tasks.py) and use existing templates as a starting point to implement a custom task template.## Task instances and exampleEach task template has fields that should be matched with specific dataset columns. Classification has two text fields `s1`,`s2`, and a label `y`. Pass a dataset to a template, and fill-in the mapping between the tempalte fields and the dataset columns to instanciate a task. ```pyimport tasknet as tn; from datasets import load_datasetrte = tn.Classification(    dataset=load_dataset(&quot;glue&quot;, &quot;rte&quot;),    s1=&quot;sentence1&quot;, s2=&quot;sentence2&quot;, y=&quot;label&quot;) #s2 is optionalclass hparams:  model_name='microsoft/deberta-v3-base' # deberta models have the best results (and tasknet support)  learning_rate = 3e-5 # see hf.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments tasks = [rte]model = tn.Model(tasks, hparams)trainer = tn.Trainer(model, tasks, hparams)trainer.train()trainer.evaluate()p = trainer.pipeline()p([{'text':x.premise,'text_pair': x.hypothesis}]) # HuggingFace pipeline for inference```Tasknet is multitask by design. `model.task_models_list` contains one model per task, with shared encoder.## Installation`pip install tasknet`## Additional examples:### Colab:https://colab.research.google.com/drive/15Xf4Bgs3itUmok7XlAK6EEquNbvjD9BD?usp=sharing## tasknet vs jiant[jiant](https://github.com/nyu-mll/jiant/) is another library comparable to tasknet.  tasknet is a minimal extension of `Trainer` centered on task templates, while jiant builds a `Trainer` equivalent from scratch called [`runner`](https://github.com/nyu-mll/jiant/blob/master/jiant/proj/main/runner.py).`tasknet` is leaner and closer to Huggingface native tools. Jiant is config-based and command line focused while tasknet is designed for interative use and python scripting.## CreditThis code uses some part of the examples of the [transformers](https://github.com/huggingface/transformers/tree/main/src/transformers) library and some code from [multitask-learning-transformers](https://github.com/shahrukhx01/multitask-learning-transformers).## ContactYou can request features on github or reach me at `damien.sileo@inria.fr````bib@misc{sileod22-tasknet,  author = {Sileo, Damien},  doi = {10.5281/zenodo.561225781},  month = {11},  title = {{tasknet, multitask interface between Trainer and datasets}},  url = {https://github.com/sileod/tasknet},  version = {1.5.0},  year = {2022}}```</longdescription>
</pkgmetadata>