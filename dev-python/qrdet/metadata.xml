<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># QRDet**QRDet** is a robust **QR Detector** based on &lt;a href=&quot;https://github.com/ultralytics/ultralytics&quot; target=&quot;_blank&quot;&gt;YOLOv8&lt;/a&gt;.**QRDet** will detect &amp; segment **QR** codes even in **difficult** positions or **tricky** images. If you are looking for a complete **QR Detection** + **Decoding** pipeline, take a look at &lt;a href=&quot;https://github.com/Eric-Canas/qreader&quot; target=&quot;_blank&quot;&gt;QReader&lt;/a&gt;.  ## InstallationTo install **QRDet**, simply run:```bashpip install qrdet```## UsageThere is only one function you'll need to call to use **QRDet**, ``detect``:```pythonfrom qrdet import QRDetectorimport cv2detector = QRDetector(model_size='s')image = cv2.imread(filename='resources/qreader_test_image.jpeg')detections = detector.detect(image=image, is_bgr=True)# Draw the detectionsfor detection in detections:    x1, y1, x2, y2 = detections['bbox_xyxy']    confidence = detections['confidence']    segmenation_xy = detections['quadrilateral_xy']    cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)    cv2.putText(image, f'{confidence:.2f}', (x1, y1 - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX,                fontScale=1, color=(0, 255, 0), thickness=2)# Save the resultscv2.imwrite(filename='resources/qreader_test_image_detections.jpeg', img=image)```&lt;img alt=&quot;detections_output&quot; title=&quot;detections_output&quot; src=&quot;https://raw.githubusercontent.com/Eric-Canas/qrdet/main/resources/qreader_test_image_detections.jpeg&quot; width=&quot;100%&quot;&gt;## API Reference### QReader.detect(image, is_bgr = False, **kwargs)- ``image``: **np.ndarray|'PIL.Image'|'torch.Tensor'|str**. `np.ndarray` of shape **(H, W, 3)**, `PIL.Image`, `Tensor` of shape **(1, 3, H, W)**, or `path`/`url` to the image to predict. `'screen'` for grabbing a screenshot.- ``is_bgr``: **bool**. If `True` the image is expected to be in **BGR**. Otherwise, it will be expected to be **RGB**. Only used when image is `np.ndarray` or `torch.tensor`. Default: `False`- ``legacy``: **bool**. If sent as **kwarg**, will parse the output to make it identical to 1.x versions. Not Recommended. Default: False.- **Returns**: **tuple[dict[str, np.ndarray|float|tuple[float|int, float|int]]]**. A tuple of dictionaries containing all the information of every detection. Contains the following keys.| Key              | Value Desc.                                 | Value Type                 | Value Form                  ||------------------|---------------------------------------------|----------------------------|-----------------------------|| `confidence`     | Detection confidence                        | `float`                    | `conf.`                     || `bbox_xyxy`      | Bounding box                                | np.ndarray (**4**)         | `[x1, y1, x2, y2]`          || `cxcy`           | Center of bounding box                      | tuple[`float`, `float`]    | `(x, y)`                    || `wh`             | Bounding box width and height               | tuple[`float`, `float`]    | `(w, h)`                    || `polygon_xy`     | Precise polygon that segments the _QR_      | np.ndarray (**N**, **2**)  | `[[x1, y1], [x2, y2], ...]` || `quad_xy`        | Four corners polygon that segments the _QR_ | np.ndarray (**4**, **2**)  | `[[x1, y1], ..., [x4, y4]]` || `padded_quad_xy` |`quad_xy` padded to fully cover `polygon_xy` | np.ndarray (**4**, **2**)  | `[[x1, y1], ..., [x4, y4]]` || `image_shape`    | Shape of the input image                    | tuple[`float`, `float`]    | `(h, w)`                    |  &gt; **NOTE:**&gt; - All `np.ndarray` values are of type `np.float32` &gt; - All keys (except `confidence` and `image_shape`) have a normalized ('n') version. For example,`bbox_xyxy` represents the bbox of the QR in image coordinates [[0., im_w], [0., im_h]], while `bbox_xyxyn` contains the same bounding box in normalized coordinates [0., 1.].&gt; - `bbox_xyxy[n]` and `polygon_xy[n]` are clipped to `image_shape`. You can use them for indexing without further management## AcknowledgementsThis library is based on the following projects:- &lt;a href=&quot;https://github.com/ultralytics/ultralytics&quot; target=&quot;_blank&quot;&gt;YoloV8&lt;/a&gt; model for **Object Segmentation**.- &lt;a href=&quot;https://github.com/Eric-Canas/quadrilateral-fitter&quot; target=&quot;_blank&quot;&gt;QuadrilateralFitter&lt;/a&gt; for fitting 4 corners polygons from noisy **segmentation outputs**.</longdescription>
</pkgmetadata>