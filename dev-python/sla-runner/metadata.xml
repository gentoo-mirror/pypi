<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># SLA Monitor WorkerThis is the test runner portion of the SLA monitor/reporter. It performs tests (or any command you want) repeatedly, and publishes success/failure to an SNS topic for external processing (for example, using lambda to write to a custom cloudwatch metric), as well as optionally uploading logs to an S3 bucket.TODO: Unit tests not working## InstallingTo install simply install via pip```bashpip install --user sla-runner```Highly recommended is iam-docker run:```bashpip install --user iam-docker-run```This project assumes you are using role based authentication, as would be used in a production environment in AWS. This mimics that environment by running with an actual role.## TerraformExcute the following in the root folder to run terraform. Obviously, have Terraform installed. Set the bucket and table variables to existing backend resources for remote state.```shell# pip install iam-startercd terraformexport AWS_ENV=&quot;dev&quot;export TF_DATA_DIR=&quot;./.$AWS_ENV-terraform/&quot;export AWS_DEFAULT_REGION=&quot;us-east-1&quot;export TF_STATE_REGION=&quot;us-east-1&quot;export TF_STATE_BUCKET=&quot;mycompany-tfstate-$AWS_ENV&quot;export TF_STATE_TABLE=&quot;tfstate_$AWS_ENV&quot;iam-starter \    --profile $AWS_ENV \    --command \        &quot;terraform init \        -backend-config=\&quot;region=$TF_STATE_REGION\&quot; \        -backend-config=\&quot;bucket=$TF_STATE_BUCKET\&quot; \        -backend-config=\&quot;dynamodb_table=$TF_STATE_TABLE\&quot; &amp;&amp; \        terraform apply \        -var \&quot;aws_env=$AWS_ENV\&quot; \        -var \&quot;aws_region=$AWS_DEFAULT_REGION\&quot;&quot;```## UsingUse iam-docker-run outside of AWS to run tests. In real life scenarios on ECS, instead install sla-runner via pypi in your service container, and set `--image` to the image of the service container which contains your test.```bashdocker build -t sla-monitor/sla-runner:latest .export AWS_ENV=&quot;dev&quot;iam-docker-run \    -e SLARUNNER_COMMAND=&quot;/bin/bash /src/test-scripts/run-tests.sh&quot; \    -e SLARUNNER_SERVICE=example-service \    -e SLARUNNER_GROUPS=&quot;dev-team,critical&quot; \    -e SLARUNNER_DELAY=30 \    -e SLARUNNER_SNSTOPICNAME=&quot;sla-monitor-result-published-$AWS_ENV&quot; \    -e SLARUNNER_S3BUCKETNAME=&quot;sla-monitoring-logs-$AWS_ENV&quot; \    --full-entrypoint &quot;sla-runner&quot; \    --region us-east-1 \    --profile $AWS_ENV \    --role sla-monitor-runner-role-$AWS_ENV \    --image sla-monitor/sla-runner:latest```In ECS, add these as environment variables in the task definition or load from ssm via ssm-starter:```--full-entrypoint &quot;ssm-starter --ssm-name slarunner --command 'sla-runner'&quot;```## VariablesThe runner takes the following values which are provided by environment variable. ### Global variablesWhen loading variables via SSM and ssm-starter, you can define default variables by adding a globals path before the service path.For example, in your task definition in terraform:```json    &quot;entryPoint&quot;: [&quot;ssm-starter&quot;],    &quot;command&quot;: [        &quot;--ssm-name&quot;, &quot;sla-monitor-globals&quot;,        &quot;--ssm-name&quot;, &quot;${var.application}&quot;,        &quot;--command&quot;, &quot;sla-runner&quot; // or script that runs sla-runner    ]```#### command$SLARUNNER_COMMANDCommand to be run repeatedly. Pretty straightforward. If there is an interrupt, the runner will attempt to finish the command gracefully before exit.#### service$SLARUNNER_SERVICEName of the component service you're testing. This will be used as the prefix for s3 uploads, and will be passed in the JSON event as &quot;service&quot; to SNS.#### groups$SLARUNNER_GROUPSName of the grouping of components you're testing, in csv format. This will be passed in the JSON event as &quot;groups&quot; to SNS as a list, and is meant to provide secondary statistics if multiple services are part of the same component.#### delay$SLARUNNER_DELAYHow long to wait between commands being run in seconds.#### disabled$SLARUNNER_DISABLEDTo disable sla-runner at startup.#### sns-topic-arn$SLARUNNER_SNSTOPICARNSNS topic arn to publish results to. It will be published as a JSON object. For example, the command above would produce the following:```json{    &quot;service&quot;: &quot;example-service&quot;,    &quot;group&quot;: [&quot;dev-team&quot;, &quot;critical&quot;],    &quot;succeeded&quot;: true,    &quot;timestamp&quot;: &quot;1574515200&quot;,    &quot;testExecutionSecs&quot;: &quot;914&quot;}```#### s3-bucket-name$SLARUNNER_S3BUCKETNAMEBucket to write logs to. This is an optional parameter. The object will be named as the timestamp followed by the result for easily searching by result, and will be prefixed by the service name. For example &quot;example-service/1574514000_SUCCESS&quot;#### dry-run$SLARUNNER_DRYRUNIf there is any value at all in this variable, the test will run once, output the sns topic it would publish to, the result message, the log output of the command, and the name of the object that would be written to the bucket. It will NOT publish to sns or write the object to s3. Only for testing purposes.## Development and Testing```bashdocker build -t sla-runner:latest .``````bashiam-docker-run \    --image sla-runner:latest \    --role sla-monitor-runner-role \    --profile dev \    --region us-east-1 \    --host-source-path . \    --container-source-path /src \    --shell```## Publishing Updates to PyPiFor the maintainer - to publish an updated version of ssm-search, increment the version number in version.py and run the following:docker build -t sla-runner . &amp;&amp; \docker run --rm -it --entrypoint make sla-runner publishAt the prompts, enter the username and password to the pypi.org repo.</longdescription>
</pkgmetadata>