<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Luga==============================- A blazing fast language detection using fastText's language models.![Languages](https://user-images.githubusercontent.com/14926709/143822756-8fd6437f-6c99-4a9f-9718-37f086955583.png)_Luga_ is a Swahili word for language. [fastText](https://github.com/facebookresearch/fastText) provides blazing-fastlanguage detection tool. Lamentably, [fastText's](https://fasttext.cc/docs/en/support.html) API is beauty-less, and the documentation is a bit fuzzy.It is also funky that we have to manually [download](https://fasttext.cc/docs/en/language-identification.html) and load models.Here is where _luga_ comes in. We abstract unnecessary steps and allow you to do precisely one thing: detecting text language.#### cover image[Stand Still. Stay Silent](http://sssscomic.com/index.php) - The relationships between Indo-European and Uralic languages by Minna Sundberg.### Show, don't tell![Luga in Action](example.gif)### Installation```bashpython -m pip install -U luga```### Usage:⚠️ Note: The first usage downloads the model for you. It will take a bit longer to import depending on internet speed.It is done only once.```pythonfrom luga import languageprint(language(&quot;the world ended yesterday&quot;))# Language(name='en', score=0.9804665446281433)```With the list of texts, we can create a mask for a filtering pipeline, that can be used, for example, with DataFrames```pythonfrom luga import languageimport pandas as pdexamples = [&quot;Jeg har ikke en rød reje&quot;, &quot;Det blæser en halv pelican&quot;, &quot;We are not robots yet&quot;]languages(texts=examples, only_language=True, to_array=True) == &quot;en&quot;# output# array([False, False, True])dataf = pd.DataFrame({&quot;text&quot;: examples})dataf.loc[lambda d: languages(texts=d[&quot;text&quot;].to_list(), only_language=True, to_array=True) == &quot;en&quot;]# output# 2    We are not robots yet# Name: text, dtype: object```### Without Luga:Download the model```bashwget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -O /tmp/lid.176.bin```Load and use```pythonimport fasttextPATH_TO_MODEL = '/tmp/lid.176.bin'fmodel = fasttext.load_model(PATH_TO_MODEL)fmodel.predict([&quot;the world has ended yesterday&quot;])# ([['__label__en']], [array([0.98046654], dtype=float32)])```### Dev:```bashpoetry run pre-commit install```## Release Flow```bash# assumes git push is completedgit tag -l #  lists tagsgit tag v*.*.* # Major.Minor.Fixgit push origin tag v*.*.*# to delete tag:git tag -d v*.*.* &amp;&amp; git push origin tag -d v*.*.*# change project_toml and __init__.py to reflect new version```#### TODO:- [X] refactor artifacts.py- [X] auto checkers with pre-commit | invoke- [X] write more tests- [X] write github actions- [ ] create an intelligent data checker (a fast List[str], what do with none strings)- [ ] make it faster with Cython- [ ] get NDArray typing correctly- [ ] fix `artifacts.py` line 111 cast to List[str] that causes issues- [ ] remove nptyping when more packages move to numpy &gt; 1.21</longdescription>
</pkgmetadata>