<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># rubicon-ml[![Test Package](https://github.com/capitalone/rubicon-ml/actions/workflows/test-package.yml/badge.svg)](https://github.com/capitalone/rubicon-ml/actions/workflows/test-package.yml)[![Publish Package](https://github.com/capitalone/rubicon-ml/actions/workflows/publish-package.yml/badge.svg)](https://github.com/capitalone/rubicon-ml/actions/workflows/publish-package.yml)[![Publish Docs](https://github.com/capitalone/rubicon-ml/actions/workflows/publish-docs.yml/badge.svg)](https://github.com/capitalone/rubicon-ml/actions/workflows/publish-docs.yml)[![edgetest](https://github.com/capitalone/rubicon-ml/actions/workflows/edgetest.yml/badge.svg)](https://github.com/capitalone/rubicon-ml/actions/workflows/edgetest.yml)[![Conda Version](https://img.shields.io/conda/vn/conda-forge/rubicon-ml.svg)](https://anaconda.org/conda-forge/rubicon-ml)[![PyPi Version](https://img.shields.io/pypi/v/rubicon_ml.svg)](https://pypi.org/project/rubicon-ml/)[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/capitalone/rubicon-ml/main?labpath=binder%2Fwelcome.ipynb)## Purposerubicon-ml is a data science tool that captures and stores model training andexecution information, like parameters and outcomes, in a repeatable andsearchable way. Its `git` integration associates these inputs and outputsdirectly with the model code that produced them to ensure full auditability andreproducibility for both developers and stakeholders alike. While experimenting,the dashboard makes it easy to explore, filter, visualize, and sharerecorded work.p.s. If you're looking for Rubicon, the Java/ObjC Python bridge, visit[this](https://pypi.org/project/rubicon/) instead.---## Componentsrubicon-ml is composed of three parts:* A Python library for storing and retrieving model inputs, outputs, and  analyses to filesystems that’s powered by  [`fsspec`](https://filesystem-spec.readthedocs.io/en/latest/?badge=latest)* A dashboard for exploring, comparing, and visualizing logged data built with  [`dash`](https://dash.plotly.com/)* And a process for sharing a selected subset of logged data with collaborators  or reviewers that leverages [`intake`](https://intake.readthedocs.io/en/latest/)## WorkflowUse `rubicon_ml` to capture model inputs and outputs over time. It can beeasily integrated into existing Python models or pipelines and supports bothconcurrent logging (so multiple experiments can be logged in parallel) andasynchronous communication with S3 (so network reads and writes won’t block).Meanwhile, periodically review the logged data within the Rubicon dashboard tosteer the model tweaking process in the right direction. The dashboard lets youquickly spot trends by exploring and filtering your logged results andvisualizes how the model inputs impacted the model outputs.When the model is ready for review, Rubicon makes it easy to share specificsubsets of the data with model reviewers and stakeholders, giving them thecontext necessary for a complete model review and approval.## UseCheck out the [interactive notebooks in this Binder](https://mybinder.org/v2/gh/capitalone/rubicon-ml/main?labpath=binder%2Fwelcome.ipynb)to try `rubicon_ml` for yourself.Here's a simple example:```pythonfrom rubicon_ml import Rubiconrubicon = Rubicon(    persistence=&quot;filesystem&quot;, root_dir=&quot;/rubicon-root&quot;, auto_git_enabled=True)project = rubicon.create_project(    &quot;Hello World&quot;, description=&quot;Using rubicon to track model results over time.&quot;)experiment = project.log_experiment(    training_metadata=[SklearnTrainingMetadata(&quot;sklearn.datasets&quot;, &quot;my-data-set&quot;)],    model_name=&quot;My Model Name&quot;,    tags=[&quot;my_model_name&quot;],)experiment.log_parameter(&quot;n_estimators&quot;, n_estimators)experiment.log_parameter(&quot;n_features&quot;, n_features)experiment.log_parameter(&quot;random_state&quot;, random_state)accuracy = rfc.score(X_test, y_test)experiment.log_metric(&quot;accuracy&quot;, accuracy)```Then explore the project by running the dashboard:```rubicon_ml ui --root-dir /rubicon-root```## DocumentationFor a full overview, visit the [docs](https://capitalone.github.io/rubicon-ml/). Ifyou have suggestions or find a bug, [please open anissue](https://github.com/capitalone/rubicon-ml/issues/new/choose).## InstallThe Python library is available on Conda Forge via `conda` and PyPi via `pip`.```conda config --add channels conda-forgeconda install rubicon-ml```or```pip install rubicon-ml```## DevelopThe project uses conda to manage environments. First, install[conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html).Then use conda to setup a development environment:```bashconda env create -f environment.ymlconda activate rubicon-ml-dev```Finally, install `rubicon_ml` locally into the newly created environment.```bashpip install -e &quot;.[all]&quot;```## TestingThe tests are separated into unit and integration tests. They can be rundirectly in the activated dev environment via `pytest tests/unit` or `pytesttests/integration`. Or by simply running `pytest` to execute all of them.**Note**: some integration tests are intentionally `marked` to control when theyare run (i.e. not during CICD). These tests include:* Integration tests that write to physical filesystems - local and S3. Local  files will be written to `./test-rubicon` relative to where the tests are run.  An S3 path must also be provided to run these tests. By default, these  tests are disabled. To enable them, run:    ```    pytest -m &quot;write_files&quot; --s3-path &quot;s3://my-bucket/my-key&quot;    ```* Integration tests that run Jupyter notebooks. These tests are a bit slower  than the rest of the tests in the suite as they need to launch Jupyter servers.  By default, they are enabled. To disable them, run:    ```    pytest -m &quot;not run_notebooks and not write_files&quot;    ```    **Note**: When simply running `pytest`, `-m &quot;not write_files&quot;` is the    default. So, we need to also apply it when disabling notebook tests.## Code FormattingInstall and configure pre-commit to automatically run `black`, `flake8`, and`isort` during commits:* [install pre-commit](https://pre-commit.com/#installation)* run `pre-commit install` to set up the git hook scriptsNow `pre-commit` will run automatically on git commit and will ensure consistentcode format throughout the project. You can format without committing via`pre-commit run` or skip these checks with `git commit --no-verify`.</longdescription>
</pkgmetadata>