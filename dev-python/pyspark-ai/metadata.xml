<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;![English SDK for Apache Spark](./docs/_static/english-sdk-spark.svg)&lt;/div&gt;![![image](https://github.com/pyspark-ai/pyspark-ai/actions/workflows/build_and_test.yml/badge.svg?branch=master)](https://github.com/pyspark-ai/pyspark-ai/actions/workflows/build_and_test.yml/badge.svg?branch=master)![PyPI - Downloads](https://img.shields.io/pypi/dm/pyspark-ai)[![PyPI version](https://badge.fury.io/py/pyspark-ai.svg)](https://badge.fury.io/py/pyspark-ai)## IntroductionThe English SDK for Apache Spark is an extremely simple yet powerful tool. It takes English instructions and compile them into PySpark objects like DataFrames.Its goal is to make Spark more user-friendly and accessible, allowing you to focus your efforts on extracting insights from your data.For a more comprehensive introduction and background to our project, we have the following resources:- [Blog Post](https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark): A detailed walkthrough of our project.- [Demo Video](https://www.youtube.com/watch?v=yj7XlTB1Jvc&amp;t=511s): 2023 Data + AI summit announcement video with demo.- [Breakout Session](https://www.youtube.com/watch?v=ZunjkL3L62o&amp;t=73s): A deep dive into the story behind the English SDK, its features, and future works at DATA+AI summit 2023.## Installationpyspark-ai can be installed via pip from [PyPI](https://pypi.org/project/pyspark-ai/):```bashpip install pyspark-ai```pyspark-ai can also be installed with optional dependencies to enable certain functionality. For example, to install pyspark-ai with the optional dependencies to plot data from a DataFrame:```bashpip install &quot;pyspark-ai[plot]&quot;```To install all optionall dependencies:```bashpip install &quot;pyspark-ai[all]&quot;```For a full list of optional dependencies, see [Installation and Setup](./docs/installation_and_setup.md).## Configuring OpenAI LLMsAs of July 2023, we have found that the GPT-4 works optimally with the English SDK. This superior AI model is readily accessible to all developers through the OpenAI API.To use OpenAI's Language Learning Models (LLMs), you can set your OpenAI secret key as the `OPENAI_API_KEY` environment variable. This key can be found in your [OpenAI account](https://platform.openai.com/account/api-keys). Example:```bashexport OPENAI_API_KEY='sk-...'```By default, the `SparkAI` instances will use the GPT-4 model. However, you're encouraged to experiment with creating and implementing other LLMs, which can be passed during the initialization of `SparkAI` instances for various use-cases.## Usage### Initialization```pythonfrom pyspark_ai import SparkAIspark_ai = SparkAI()spark_ai.activate()  # active partial functions for Spark DataFrame```You can also pass other LLMs to construct the SparkAI instance. For example, by following [this guide](https://python.langchain.com/docs/integrations/chat/azure_chat_openai):```pythonfrom langchain.chat_models import AzureChatOpenAIfrom pyspark_ai import SparkAIllm = AzureChatOpenAI(    deployment_name=...,    model_name=...)spark_ai = SparkAI(llm=llm)spark_ai.activate()  # active partial functions for Spark DataFrame```Using the Azure OpenAI service can provide better data privacy and security, as per [Microsoft's Data Privacy page](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy).### DataFrame TransformationGiven the following DataFrame `df`:```pythondf = spark_ai._spark.createDataFrame(    [        (&quot;Normal&quot;, &quot;Cellphone&quot;, 6000),        (&quot;Normal&quot;, &quot;Tablet&quot;, 1500),        (&quot;Mini&quot;, &quot;Tablet&quot;, 5500),        (&quot;Mini&quot;, &quot;Cellphone&quot;, 5000),        (&quot;Foldable&quot;, &quot;Cellphone&quot;, 6500),        (&quot;Foldable&quot;, &quot;Tablet&quot;, 2500),        (&quot;Pro&quot;, &quot;Cellphone&quot;, 3000),        (&quot;Pro&quot;, &quot;Tablet&quot;, 4000),        (&quot;Pro Max&quot;, &quot;Cellphone&quot;, 4500)    ],    [&quot;product&quot;, &quot;category&quot;, &quot;revenue&quot;])```You can write English to perform transformations. For example:```pythondf.ai.transform(&quot;What are the best-selling and the second best-selling products in every category?&quot;).show()```| product  |category| revenue ||----------|--------|---------|| Foldable |Cellphone| 6500    || Nromal   |Cellphone| 6000    || Mini      |Tablet| 5500    || Pro |Tablet| 4000    |```pythondf.ai.transform(&quot;Pivot the data by product and the revenue for each product&quot;).show()```| Category  | Normal | Mini | Foldable |  Pro | Pro Max ||-----------|--------|------|----------|------|---------|| Cellphone |   6000 | 5000 |     6500 | 3000 |    4500 || Tablet    |   1500 | 5500 |     2500 | 4000 |    null |For a detailed walkthrough of the transformations, please refer to our [transform_dataframe.ipynb](https://github.com/databrickslabs/pyspark-ai/blob/master/examples/transform_dataframe.ipynb) notebook.### Transform Accuracy Improvement: Vector Similarity Search To improve the accuracy of transform query generation, you can also optionally enable vector similarity search. This is done by specifying a `vector_store_dir` location for the vector files when you initialize SparkAI. For example:```pythonfrom pyspark_ai import SparkAIspark_ai = SparkAI(vector_store_dir=&quot;vector_store/&quot;) # vector files will be stored in the dir &quot;vector_store&quot;spark_ai.activate() ```Now when you call df.ai.transform as before, the agent will use word embeddings to generate accurate query values.For a detailed walkthrough, please refer to our [vector_similarity_search.ipynb](./examples/vector_similarity_search.ipynb).### PlotLet's create a DataFrame for car sales in the U.S.```python# auto sales data from https://www.carpro.com/blog/full-year-2022-national-auto-sales-by-branddata = [('Toyota', 1849751, -9), ('Ford', 1767439, -2), ('Chevrolet', 1502389, 6),        ('Honda', 881201, -33), ('Hyundai', 724265, -2), ('Kia', 693549, -1),        ('Jeep', 684612, -12), ('Nissan', 682731, -25), ('Subaru', 556581, -5),        ('Ram Trucks', 545194, -16), ('GMC', 517649, 7), ('Mercedes-Benz', 350949, 7),        ('BMW', 332388, -1), ('Volkswagen', 301069, -20), ('Mazda', 294908, -11),        ('Lexus', 258704, -15), ('Dodge', 190793, -12), ('Audi', 186875, -5),        ('Cadillac', 134726, 14), ('Chrysler', 112713, -2), ('Buick', 103519, -42),        ('Acura', 102306, -35), ('Volvo', 102038, -16), ('Mitsubishi', 102037, -16),        ('Lincoln', 83486, -4), ('Porsche', 70065, 0), ('Genesis', 56410, 14),        ('INFINITI', 46619, -20), ('MINI', 29504, -1), ('Alfa Romeo', 12845, -30),        ('Maserati', 6413, -10), ('Bentley', 3975, 0), ('Lamborghini', 3134, 3),        ('Fiat', 915, -61), ('McLaren', 840, -35), ('Rolls-Royce', 460, 7)]auto_df = spark_ai._spark.createDataFrame(data, [&quot;Brand&quot;, &quot;US_Sales_2022&quot;, &quot;Sales_Change_Percentage&quot;])```We can visualize the data with the plot API:```python# call plot() with no args for LLM-generated plotauto_df.ai.plot()```![2022 USA national auto sales by brand](docs/_static/auto_sales.png)To plot with an instruction:```pythonauto_df.ai.plot(&quot;pie chart for US sales market shares, show the top 5 brands and the sum of others&quot;)```![2022 USA national auto sales_market_share by brand](docs/_static/auto_sales_pie_char.png)Please refer to [example.ipynb](https://github.com/databrickslabs/pyspark-ai/blob/master/examples/example.ipynb) for more APIs and detailed usage examples.## ContributingWe're delighted that you're considering contributing to the English SDK for Apache Spark project! Whether you're fixing a bug or proposing a new feature, your contribution is highly appreciated.Before you start, please take a moment to read our [Contribution Guide](./CONTRIBUTING.md). This guide provides an overview of how you can contribute to our project. We're currently in the early stages of development and we're working on introducing more comprehensive test cases and Github Action jobs for enhanced testing of each pull request.If you have any questions or need assistance, feel free to open a new issue in the GitHub repository.Thank you for helping us improve the English SDK for Apache Spark. We're excited to see your contributions!## LicenseLicensed under the Apache License 2.0.</longdescription>
</pkgmetadata>