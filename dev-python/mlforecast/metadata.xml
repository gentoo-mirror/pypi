<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Nixtla ¬†[![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Statistical%20Forecasting%20Algorithms%20by%20Nixtla%20&amp;url=https://github.com/Nixtla/statsforecast&amp;via=nixtlainc&amp;hashtags=StatisticalModels,TimeSeries,Forecasting)¬†[![Slack](https://img.shields.io/badge/Slack-4A154B?&amp;logo=slack&amp;logoColor=white.png)](https://join.slack.com/t/nixtlacommunity/shared_invite/zt-1pmhan9j5-F54XR20edHk0UtYAPcW4KQ)================&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;&lt;div align=&quot;center&quot;&gt;&lt;center&gt;&lt;img src=&quot;https://raw.githubusercontent.com/Nixtla/neuralforecast/main/nbs/imgs_indx/logo_mid.png&quot;&gt;&lt;/center&gt;&lt;h1 align=&quot;center&quot;&gt;Machine Learning ü§ñ Forecast&lt;/h1&gt;&lt;h3 align=&quot;center&quot;&gt;Scalable machine learning for time series forecasting&lt;/h3&gt;[![CI](https://github.com/Nixtla/mlforecast/actions/workflows/ci.yaml/badge.svg)](https://github.com/Nixtla/mlforecast/actions/workflows/ci.yaml)[![Python](https://img.shields.io/pypi/pyversions/mlforecast.png)](https://pypi.org/project/mlforecast/)[![PyPi](https://img.shields.io/pypi/v/mlforecast?color=blue.png)](https://pypi.org/project/mlforecast/)[![conda-forge](https://img.shields.io/conda/vn/conda-forge/mlforecast?color=blue.png)](https://anaconda.org/conda-forge/mlforecast)[![License](https://img.shields.io/github/license/Nixtla/mlforecast.png)](https://github.com/Nixtla/mlforecast/blob/main/LICENSE)**mlforecast** is a framework to perform time series forecasting usingmachine learning models, with the option to scale to massive amounts ofdata using remote clusters.&lt;/div&gt;## Install### PyPI`pip install mlforecast`If you want to perform distributed training, you can instead use`pip install &quot;mlforecast[distributed]&quot;`, which will also install[dask](https://dask.org/). Note that you‚Äôll also need to install either[LightGBM](https://github.com/microsoft/LightGBM/tree/master/python-package)or[XGBoost](https://xgboost.readthedocs.io/en/latest/install.html#python).### conda-forge`conda install -c conda-forge mlforecast`Note that this installation comes with the required dependencies for thelocal interface. If you want to perform distributed training, you mustinstall dask (`conda install -c conda-forge dask`) and either[LightGBM](https://github.com/microsoft/LightGBM/tree/master/python-package)or[XGBoost](https://xgboost.readthedocs.io/en/latest/install.html#python).## Quick Start**Minimal Example**``` pythonimport lightgbm as lgbfrom mlforecast import MLForecastfrom sklearn.linear_model import LinearRegressionmlf = MLForecast(    models = [LinearRegression(), lgb.LGBMRegressor()],    lags=[1, 12],    freq = 'M')mlf.fit(df)mlf.predict(12)```**Get Started with this [quickguide](https://nixtla.github.io/mlforecast/docs/quick_start_local.html).****Follow this [end-to-endwalkthrough](https://nixtla.github.io/mlforecast/docs/end_to_end_walkthrough.html)for best practices.**## Why?Current Python alternatives for machine learning models are slow,inaccurate and don‚Äôt scale well. So we created a library that can beused to forecast in production environments. `MLForecast` includesefficient feature engineering to train any machine learning model (with`fit` and `predict` methods such as[`sklearn`](https://scikit-learn.org/stable/)) to fit millions of timeseries.## Features- Fastest implementations of feature engineering for time series  forecasting in Python.- Out-of-the-box compatibility with Spark, Dask, and Ray.- Probabilistic Forecasting with Conformal Prediction.- Support for exogenous variables and static covariates.- Familiar `sklearn` syntax: `.fit` and `.predict`.Missing something? Please open an issue or write us in[![Slack](https://img.shields.io/badge/Slack-4A154B?&amp;logo=slack&amp;logoColor=white.png)](https://join.slack.com/t/nixtlaworkspace/shared_invite/zt-135dssye9-fWTzMpv2WBthq8NK0Yvu6A)## Examples and Guidesüìö [End to EndWalkthrough](https://nixtla.github.io/mlforecast/docs/end_to_end_walkthrough.html):model training, evaluation and selection for multiple time series.üîé [ProbabilisticForecasting](https://nixtla.github.io/mlforecast/docs/prediction_intervals.html):use Conformal Prediction to produce prediciton intervals.üë©üî¨ [CrossValidation](https://nixtla.github.io/mlforecast/docs/cross_validation.html):robust model‚Äôs performance evaluation.üîå [Predict DemandPeaks](https://nixtla.github.io/mlforecast/docs/electricity_peak_forecasting.html):electricity load forecasting for detecting daily peaks and reducingelectric bills.üìà [TransferLearning](https://nixtla.github.io/mlforecast/docs/transfer_learning.html):pretrain a model using a set of time series and then predict another oneusing that pretrained model.üå°Ô∏è [DistributedTraining](https://nixtla.github.io/mlforecast/docs/quick_start_distributed.html):use a Dask cluster to train models at scale.## How to useThe following provides a very basic overview, for a more detaileddescription see the[documentation](https://nixtla.github.io/mlforecast/).### Data setupStore your time series in a pandas dataframe in long format, that is,each row represents an observation for a specific serie and timestamp.``` pythonfrom mlforecast.utils import generate_daily_seriesseries = generate_daily_series(    n_series=20,    max_length=100,    n_static_features=1,    static_as_categorical=False,    with_trend=True)series.head()```&lt;div&gt;&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;  &lt;thead&gt;    &lt;tr style=&quot;text-align: right;&quot;&gt;      &lt;th&gt;&lt;/th&gt;      &lt;th&gt;unique_id&lt;/th&gt;      &lt;th&gt;ds&lt;/th&gt;      &lt;th&gt;y&lt;/th&gt;      &lt;th&gt;static_0&lt;/th&gt;    &lt;/tr&gt;  &lt;/thead&gt;  &lt;tbody&gt;    &lt;tr&gt;      &lt;th&gt;0&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-01-01&lt;/td&gt;      &lt;td&gt;1.751917&lt;/td&gt;      &lt;td&gt;72&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;1&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-01-02&lt;/td&gt;      &lt;td&gt;9.196715&lt;/td&gt;      &lt;td&gt;72&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;2&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-01-03&lt;/td&gt;      &lt;td&gt;18.577788&lt;/td&gt;      &lt;td&gt;72&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;3&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-01-04&lt;/td&gt;      &lt;td&gt;24.520646&lt;/td&gt;      &lt;td&gt;72&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;4&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-01-05&lt;/td&gt;      &lt;td&gt;33.418028&lt;/td&gt;      &lt;td&gt;72&lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;### ModelsNext define your models. If you want to use the local interface this canbe any regressor that follows the scikit-learn API. For distributedtraining there are `LGBMForecast` and `XGBForecast`.``` pythonimport lightgbm as lgbimport xgboost as xgbfrom sklearn.ensemble import RandomForestRegressormodels = [    lgb.LGBMRegressor(),    xgb.XGBRegressor(),    RandomForestRegressor(random_state=0),]```### Forecast objectNow instantiate a `MLForecast` object with the models and the featuresthat you want to use. The features can be lags, transformations on thelags and date features. The lag transformations are defined as[numba](http://numba.pydata.org/) *jitted* functions that transform anarray, if they have additional arguments you can either supply a tuple(`transform_func`, `arg1`, `arg2`, ‚Ä¶) or define new functions fixing thearguments. You can also define differences to apply to the series beforefitting that will be restored when predicting.``` pythonfrom mlforecast import MLForecastfrom mlforecast.target_transforms import Differencesfrom numba import njitfrom window_ops.expanding import expanding_meanfrom window_ops.rolling import rolling_mean@njitdef rolling_mean_28(x):    return rolling_mean(x, window_size=28)fcst = MLForecast(    models=models,    freq='D',    lags=[7, 14],    lag_transforms={        1: [expanding_mean],        7: [rolling_mean_28]    },    date_features=['dayofweek'],    target_transforms=[Differences([1])],)```### TrainingTo compute the features and train the models call `fit` on your`Forecast` object.``` pythonfcst.fit(series)```    MLForecast(models=[LGBMRegressor, XGBRegressor, RandomForestRegressor], freq=&lt;Day&gt;, lag_features=['lag7', 'lag14', 'expanding_mean_lag1', 'rolling_mean_28_lag7'], date_features=['dayofweek'], num_threads=1)### PredictingTo get the forecasts for the next `n` days call `predict(n)` on theforecast object. This will automatically handle the updates required bythe features using a recursive strategy.``` pythonpredictions = fcst.predict(14)predictions```&lt;div&gt;&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;  &lt;thead&gt;    &lt;tr style=&quot;text-align: right;&quot;&gt;      &lt;th&gt;&lt;/th&gt;      &lt;th&gt;unique_id&lt;/th&gt;      &lt;th&gt;ds&lt;/th&gt;      &lt;th&gt;LGBMRegressor&lt;/th&gt;      &lt;th&gt;XGBRegressor&lt;/th&gt;      &lt;th&gt;RandomForestRegressor&lt;/th&gt;    &lt;/tr&gt;  &lt;/thead&gt;  &lt;tbody&gt;    &lt;tr&gt;      &lt;th&gt;0&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-04-04&lt;/td&gt;      &lt;td&gt;69.082830&lt;/td&gt;      &lt;td&gt;67.761337&lt;/td&gt;      &lt;td&gt;68.226556&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;1&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-04-05&lt;/td&gt;      &lt;td&gt;75.706024&lt;/td&gt;      &lt;td&gt;74.588699&lt;/td&gt;      &lt;td&gt;75.484774&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;2&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-04-06&lt;/td&gt;      &lt;td&gt;82.222473&lt;/td&gt;      &lt;td&gt;81.058289&lt;/td&gt;      &lt;td&gt;82.853684&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;3&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-04-07&lt;/td&gt;      &lt;td&gt;89.577638&lt;/td&gt;      &lt;td&gt;88.735947&lt;/td&gt;      &lt;td&gt;90.351212&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;4&lt;/th&gt;      &lt;td&gt;id_00&lt;/td&gt;      &lt;td&gt;2000-04-08&lt;/td&gt;      &lt;td&gt;44.149095&lt;/td&gt;      &lt;td&gt;44.981384&lt;/td&gt;      &lt;td&gt;46.291173&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;...&lt;/th&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;      &lt;td&gt;...&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;275&lt;/th&gt;      &lt;td&gt;id_19&lt;/td&gt;      &lt;td&gt;2000-03-23&lt;/td&gt;      &lt;td&gt;30.151270&lt;/td&gt;      &lt;td&gt;31.814825&lt;/td&gt;      &lt;td&gt;32.592799&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;276&lt;/th&gt;      &lt;td&gt;id_19&lt;/td&gt;      &lt;td&gt;2000-03-24&lt;/td&gt;      &lt;td&gt;31.418104&lt;/td&gt;      &lt;td&gt;32.653374&lt;/td&gt;      &lt;td&gt;33.563294&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;277&lt;/th&gt;      &lt;td&gt;id_19&lt;/td&gt;      &lt;td&gt;2000-03-25&lt;/td&gt;      &lt;td&gt;32.843567&lt;/td&gt;      &lt;td&gt;33.586033&lt;/td&gt;      &lt;td&gt;34.530912&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;278&lt;/th&gt;      &lt;td&gt;id_19&lt;/td&gt;      &lt;td&gt;2000-03-26&lt;/td&gt;      &lt;td&gt;34.127210&lt;/td&gt;      &lt;td&gt;34.541473&lt;/td&gt;      &lt;td&gt;35.507559&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;      &lt;th&gt;279&lt;/th&gt;      &lt;td&gt;id_19&lt;/td&gt;      &lt;td&gt;2000-03-27&lt;/td&gt;      &lt;td&gt;34.329202&lt;/td&gt;      &lt;td&gt;35.450943&lt;/td&gt;      &lt;td&gt;36.425001&lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;280 rows √ó 5 columns&lt;/p&gt;&lt;/div&gt;### Visualize results``` pythonimport matplotlib.pyplot as pltimport pandas as pdfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 6), gridspec_kw=dict(hspace=0.3))for i, (uid, axi) in enumerate(zip(series['unique_id'].unique(), ax.flat)):    fltr = lambda df: df['unique_id'].eq(uid)    pd.concat([series.loc[fltr, ['ds', 'y']], predictions.loc[fltr]]).set_index('ds').plot(ax=axi)    axi.set(title=uid, xlabel=None)    if i % 2 == 0:        axi.legend().remove()    else:        axi.legend(bbox_to_anchor=(1.01, 1.0))fig.savefig('figs/index.png', bbox_inches='tight')plt.close()```![](https://raw.githubusercontent.com/Nixtla/mlforecast/main/figs/index.png)## Sample notebooks- [m5](https://www.kaggle.com/code/lemuz90/m5-mlforecast-eval)- [m4](https://www.kaggle.com/code/lemuz90/m4-competition)- [m4-cv](https://www.kaggle.com/code/lemuz90/m4-competition-cv)## How to contributeSee[CONTRIBUTING.md](https://github.com/Nixtla/mlforecast/blob/main/CONTRIBUTING.md).</longdescription>
</pkgmetadata>