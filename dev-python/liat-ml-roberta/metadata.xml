<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># liat_ml_robertaRoBERTa trained on Wikipedia Dump.## How to installCan use pip to install.~~~bashpip install liat_ml_roberta~~~## How to useThe loaded models and configurations can be used in the same way as [transformers.roberta](https://huggingface.co/docs/transformers/model_doc/roberta).~~~pythonfrom liat_ml_roberta import RoBERTaTokenizerdef main():    tokenizer = RoBERTaTokenizer.from_pretrained(version=&quot;en_20190121_m10000_v24000_base&quot;)    print(tokenizer.tokenize(&quot;This is a pen.&quot;))    config = RoBERTaConfig.from_pretrained(&quot;roberta_base_en_20190121_m10000_v24000_u125000&quot;)    model = RoBERTaModel.from_pretrained(&quot;roberta_base_en_20190121_m10000_v24000_u125000&quot;, config=config)if __name__ == &quot;__main__&quot;:    main()~~~## Models|name|lang|size|bpe merges|vocab size|updates|wikipedia version|  |:---:|:---:|:---:|:---:|:---:|:---:|:---:|  |roberta_base_ja_20190121_m10000_v24000_u125000|ja|roberta-base|10000|24000|125000|20190121|  |roberta_base_ja_20190121_m10000_v24000_u500000|ja|roberta-base|10000|24000|500000|20190121|  |roberta_base_en_20190121_m10000_v24000_u125000|en|roberta-base|10000|24000|125000|20190121|  |roberta_base_en_20190121_m10000_v24000_u500000|en|roberta-base|10000|24000|500000|20190121|  |roberta_base_fr_20190121_m10000_v24000_u500000|fr|roberta-base|10000|24000|500000|20190121|  |roberta_base_de_20190121_m10000_v24000_u500000|de|roberta-base|10000|24000|500000|20190121|  </longdescription>
</pkgmetadata>