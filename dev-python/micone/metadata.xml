<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># MiCoNE - Microbial Co-occurrence Network Explorer![Build Status](https://github.com/segrelab/MiCoNE/workflows/build/badge.svg)[![Documentation Status](https://readthedocs.org/projects/micone/badge/?version=latest)](https://micone.readthedocs.io/en/latest/?badge=latest)[![codecov](https://codecov.io/gh/segrelab/MiCoNE/branch/master/graph/badge.svg?token=2tKiI0lUJb)](https://codecov.io/gh/segrelab/MiCoNE)[![CodeFactor](https://www.codefactor.io/repository/github/segrelab/micone/badge)](https://www.codefactor.io/repository/github/segrelab/micone)[![Updates](https://pyup.io/repos/github/segrelab/MiCoNE/shield.svg)](https://pyup.io/repos/github/segrelab/MiCoNE/)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)`MiCoNE`, is a flexible and modular pipeline for 16S data analysis.It incorporates various popular, publicly available tools as well as custom Python modules and scripts to facilitate inference of co-occurrence networks from 16S data.&lt;div align=&quot;center&quot;&gt;⚠️ &lt;p&gt;&lt;strong&gt;The package is under active development and breaking changes are possible&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;-   Free software: MIT license-   Documentation: &lt;https://micone.readthedocs.io/&gt;Manuscript can be found on [bioRxiv](https://www.biorxiv.org/content/10.1101/2020.09.23.309781v2)## Features-   Plug and play architecture: allows easy additions and removal of new tools-   Flexible and portable: allows running the pipeline on local machine, compute cluster or the cloud with minimal configuration change. Uses the [nextflow](www.nextflow.io) under the hood-   Parallelization: automatic parallelization both within and across samples (needs to be enabled in the `config` file)-   Ease of use: available as a minimal `Python` library (without the pipeline) or the full `conda` package## InstallationInstalling the minimal `Python` library:```shpip install micone```Installing the `conda` package:```shgit clone https://github.com/segrelab/MiCoNE.gitcd MiCoNEconda env create -n micone -f env.ymlpip install .```&gt; NOTE:&gt; The `conda` package is currently being updated and will be available soon.## Workflow![pipeline](assets/pipeline.png)It supports the conversion of raw 16S sequence data or counts matrices into co-occurrence networks through multiple methods. Each process in the pipeline supports alternate tools for performing the same task, users can use the configuration file to change these values.## UsageThe `MiCoNE` pipelines comes with an easy to use CLI. To get a list of subcommands you can type:```bashmicone --help```Supported subcommands:1. `init` - Creates `conda` environments for various pipeline processes2. `run` - The main subcommand that runs the pipeline3. `clean` - Cleans temporary data, log files and other extraneous filesTo run the pipeline:```bashmicone run -p local -c run.toml -m 4```This runs the pipeline in the `local` machine using `run.toml` for the pipeline configuration and with a maximum of 4 processes in parallel at a time.## ConfigurationThe configuration of the pipeline can be done using a `.toml` file.The details can be found in the relevant section in the docs.Here is an example `config` file that performs:1. grouping of OTUs by taxonomy level2. correlation of the taxa using `fastspar`3. calculates p-values4. constructs the networks```tomltitle = &quot;A example pipeline for testing&quot;order = &quot;&quot;&quot;  otu_processing.filter.group  otu_processing.export.biom2tsv  network_inference.bootstrap.resample  network_inference.correlation.sparcc  network_inference.bootstrap.pvalue  network_inference.network.make_network_with_pvalue&quot;&quot;&quot;output_location = &quot;/home/dileep/Documents/results/sparcc_network&quot;[otu_processing.filter.group]  [[otu_processing.filter.group.input]]    datatype = &quot;otu_table&quot;    format = [&quot;biom&quot;]    location = &quot;correlations/good/deblur/deblur.biom&quot;  [[otu_processing.filter.group.parameters]]    process = &quot;group&quot;    tax_levels = &quot;['Family', 'Genus', 'Species']&quot;[otu_processing.export.biom2tsv][network_inference.bootstrap.resample]  [[network_inference.bootstrap.resample.parameters]]    process = &quot;resample&quot;    bootstraps = 10[network_inference.correlation.sparcc]  [[network_inference.correlation.sparcc.parameters]]    process = &quot;sparcc&quot;    iterations = 5[network_inference.bootstrap.pvalue][network_inference.network.make_network_with_pvalue]  [[network_inference.network.make_network_with_pvalue.input]]    datatype = &quot;metadata&quot;    format = [&quot;json&quot;]    location = &quot;correlations/good/deblur/deblur_metadata.json&quot;  [[network_inference.network.make_network_with_pvalue.input]]    datatype = &quot;computational_metadata&quot;    format = [&quot;json&quot;]    location = &quot;correlations/good/deblur/deblur_cmetadata.json&quot;```Other example `config` files can be found at `tests/data/pipelines`## CreditsThis package was created with [Cookiecutter](https://github.com/audreyr/cookiecutter) and the [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage) project template.</longdescription>
</pkgmetadata>