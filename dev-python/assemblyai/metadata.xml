<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;img src=&quot;https://github.com/AssemblyAI/assemblyai-python-sdk/blob/master/assemblyai.png?raw=true&quot; width=&quot;500&quot;/&gt;---[![CI Passing](https://github.com/AssemblyAI/assemblyai-python-sdk/actions/workflows/test.yml/badge.svg)](https://github.com/AssemblyAI/assemblyai-python-sdk/actions/workflows/test.yml)[![GitHub License](https://img.shields.io/github/license/AssemblyAI/assemblyai-python-sdk)](https://github.com/AssemblyAI/assemblyai-python-sdk/blob/master/LICENSE)[![PyPI version](https://badge.fury.io/py/assemblyai.svg)](https://badge.fury.io/py/assemblyai)[![PyPI Python Versions](https://img.shields.io/pypi/pyversions/assemblyai)](https://pypi.python.org/pypi/assemblyai/)![PyPI - Wheel](https://img.shields.io/pypi/wheel/assemblyai)[![AssemblyAI Twitter](https://img.shields.io/twitter/follow/AssemblyAI?label=%40AssemblyAI&amp;style=social)](https://twitter.com/AssemblyAI)[![AssemblyAI YouTube](https://img.shields.io/youtube/channel/subscribers/UCtatfZMf-8EkIwASXM4ts0A)](https://www.youtube.com/@AssemblyAI)# AssemblyAI's Python SDK&gt; _Build with AI models that can transcribe and understand audio_With a single API call, get access to AI models built on the latest AI breakthroughs to transcribe and understand audio and speech data securely at large scale.# Overview- [Documentation](#documentation)- [Installation](#installation)- [Example](#examples)  - [Core Examples](#core-examples)  - [LeMUR Examples](#lemur-examples)  - [Audio Intelligence+ Examples](#audio-intelligence-examples)- [Playgrounds](#playgrounds)- [Advanced](#advanced-todo)# DocumentationVisit our [AssemblyAI API Documentation](https://www.assemblyai.com/docs) to get an overview of our models!# Quick Start## Installation```bashpip install -U assemblyai```## ExamplesBefore starting, you need to set the API key. If you don't have one yet, [**sign up for one**](https://www.assemblyai.com/dashboard/signup)!```pythonimport assemblyai as aai# set the API keyaai.settings.api_key = f&quot;{ASSEMBLYAI_API_KEY}&quot;```---### **Core Examples**&lt;details&gt;  &lt;summary&gt;Transcribe a local Audio File&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;./my-local-audio-file.wav&quot;)print(transcript.text)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Transcribe an URL&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)print(transcript.text)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Add Punctuation, Casing, and Formatting to a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaiconfig = aai.TranscriptionConfig(  punctuate = True,  format_text = True,)transcriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;, config)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Export Subtitles of an Audio File&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)# in SRT formatprint(transcript.export_subtitles_srt())# in VTT formatprint(transcript.export_subtitles_vtt())```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;List all Sentences and Paragraphs&lt;/summary&gt;```pythonimport assemblyai as aaiconfig = aai.TranscriptionConfig(  punctuate = True,  format_text = True,)transcriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;, config)sentences = transcript.get_sentences()for sentence in sentences:  print(sentence.text)paragraphs = transcript.get_paragraphs()for paragraph in paragraphs:  print(paragraph.text)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Search for Words in a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;)matches = transcript.word_search([&quot;price&quot;, &quot;product&quot;])for match in matches:  print(f&quot;Found '{match.text}' {match.count} times in the transcript&quot;)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Add Custom Spellings on a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaiconfig = aai.TranscriptionConfig()config.set_custom_spelling(  {    &quot;Kubernetes&quot;: [&quot;k8s&quot;],    &quot;SQL&quot;: [&quot;Sequel&quot;],  })transcriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;, config)print(transcript.text)```&lt;/details&gt;---### **LeMUR Examples**&lt;details&gt;  &lt;summary&gt;Use LeMUR to Summarize Multiple Transcripts&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript_group = transcriber.transcribe_group(    [        &quot;https://example.org/customer1.mp3&quot;,        &quot;https://example.org/customer2.mp3&quot;,    ],)summary = transcript_group.lemur.summarize(context=&quot;Customers asking for cars&quot;, answer_format=&quot;TLDR&quot;)print(summary)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Use LeMUR to Get Feedback from the AI Coach on Multiple Transcripts&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript_group = transcriber.transcribe_group(    [        &quot;https://example.org/interviewee1.mp3&quot;,        &quot;https://example.org/interviewee2.mp3&quot;,    ],)feedback = transcript_group.lemur.ask_coach(context=&quot;Who was the best interviewee?&quot;)print(feedback)```&lt;/details&gt;&lt;details&gt;  &lt;summary&gt;Use LeMUR to Ask Questions on a Single Transcript&lt;/summary&gt;```pythonimport assemblyai as aaitranscriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/customer.mp3&quot;)# ask some questionsquestions = [    aai.LemurQuestion(question=&quot;What car was the customer interested in?&quot;),    aai.LemurQuestion(question=&quot;What price range is the customer looking for?&quot;),]results = transcript.lemur.question(questions)for result in result:    print(f&quot;Question: {result.question}&quot;)    print(f&quot;Answer: {result.answer}&quot;)```&lt;/details&gt;---### **Audio Intelligence+ Examples**&lt;details&gt;  &lt;summary&gt;PII Redact a Transcript&lt;/summary&gt;```pythonimport assemblyai as aaiconfig = aai.TranscriptionConfig()config.set_pii_redact(  # What should be redacted  policies=[      aai.PIIRedactionPolicy.credit_card_number,      aai.PIIRedactionPolicy.email_address,      aai.PIIRedactionPolicy.location,      aai.PIIRedactionPolicy.person_name,      aai.PIIRedactionPolicy.phone_number,  ],  # How it should be redacted  substitution=aai.PIISubstitutionPolicy.hash,)transcriber = aai.Transcriber()transcript = transcriber.transcribe(&quot;https://example.org/audio.mp3&quot;, config)```&lt;/details&gt;---## PlaygroundsVisit one of our Playgrounds:- [LeMUR Playground](https://www.assemblyai.com/playground/v2/source)- [Transcription Playground](https://www.assemblyai.com/playground)# Advanced (TODO)## Synchronous vs AsynchronousCurrently, the SDK provides two ways to transcribe audio files.The synchronous approach halts the application's flow until the transcription has been completed.The asynchronous approach allows the application to continue running while the transcription is being processed. The caller receives a [`concurrent.futures.Future`](https://docs.python.org/3/library/concurrent.futures.html) object which can be used to check the status of the transcription at a later time.You can identify those two approaches by the `_async` suffix in the `Transcriber`'s method name (e.g. `transcribe` vs `transcribe_async`).</longdescription>
</pkgmetadata>