<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>My toolbox for dynamic programming#to be documented#Chapter: tf-idffrom anarcute import *import requests, jsonsentence=&quot;Eat more of those french fries and drink cola&quot;alice=requests.get(&quot;https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt&quot;).textprint(tf_idf(sentence,alice))&gt;&gt; {'eat': 168.7962962962963, 'more': 62.006802721088434, 'of': 5.9111543450064845, 'those': 303.8333333333333, 'french': 759.5833333333333, 'and': 3.4843272171253816, 'drink': 434.047619047619}#If text is too big it's frequencies can be pre-cached.filename=&quot;alice.json&quot;vector=vectorize(alice)open(filename,&quot;w+&quot;).write(json.dumps(vector))vector=json.load(open(filename,&quot;r+&quot;))print(tf_idf(sentence,vector))&gt;&gt;{'eat': 168.7962962962902, 'more': 62.00680272108618, 'of': 5.91115434500627, 'those': 303.8333333333223, 'french': 759.5833333333056, 'and': 3.484327217125255, 'drink': 434.0476190476033}#we can sort by valueprint(sort_by_value(tf_idf(sentence,vector)))&gt;&gt;{'french': 759.5833333332979, 'drink': 434.04761904759886, 'those': 303.8333333333192, 'eat': 168.7962962962885, 'more': 62.006802721085556, 'of': 5.911154345006209, 'and': 3.4843272171252204}#Chapter: Google#We have Google Translate and Google Custom Search Engine nowkey=&quot;MY_GOOGLE_KEY&quot;gt=GT(key)gt.translate(&quot;pl&quot;,&quot;en&quot;,&quot;Jeszcze Polska nie zginęła, Kiedy my żyjemy. Co nam obca przemoc wzięła, Szablą odbierzemy.&quot;)&gt;&gt; {'data': {'translations': [{'translatedText': 'Poland is not dead yet, When we live. What foreign violence has taken from us, we will take away the Saber.'}]}}cx=&quot;MY_CUSTOM_SEARCH_ENGINE_KEY&quot;gs=GS(cx,key)gs.search(&quot;krakauer sausage recipe&quot;)&gt;&gt; dict with search result, up to 10 itemsgs.items(&quot;krakauer sausage recipe&quot;&quot;)&gt;&gt; array of results, up to 100 items#Chapter: Multithreading#based on multithreading_on_dill library#let's reverse every string of Alice in Wonderlandurl=&quot;https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt&quot;alice=requests.get(url).textalice_reversed=mapp(lambda s: str(s[::-1]),alice.split('\n'))#as you see we have no problem with lambda#by default the number of processes equals to cpu number, but you can make it bigger for highly async tasks or smaller to prevent overloadalice_reversed=mapp(lambda s: str(s[::-1]),alice.split('\n'),processes=2)#decorator @timeit also included in the library@timeitdef test(p=None):    r=mapp(lambda s: math.factorial(150*len(s)),alice.split('\n'),processes=p)    return Nonetest()&gt;&gt; 'test' 2563.11 mstest(1)&gt;&gt; 'test' 5287.27 ms#multithreading filteralice_special=filterp(lambda s: &quot;alice&quot; in s.lower(),alice.split('\n'))#run one async functionrun(print,[&quot;A B C&quot;])#you can wait for it's result when you need to catch upp=run(lambda x: request.get(x).text,url)some_other_stuff()p.join()#apply - function that executes functions. Used to run few different functions in one multithreading processr=mapp(apply,[lambda:requests.get(&quot;https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt&quot;).text,lambda: math.factorial(9000)])#Chapter predicates#in_or(a,b) - returns if at least one element of array is in array/string ba=[&quot;Some&quot;,&quot;important&quot;,&quot;array&quot;]b=[&quot;Another&quot;,&quot;array&quot;]in_or(a,b)&gt;&gt; Truec=[&quot;Something&quot;, &quot;Else&quot;]in_or(a,c)&gt;&gt; Falsed=&quot;Some string&quot;in_or(a,d)&gt;&gt; True</longdescription>
</pkgmetadata>