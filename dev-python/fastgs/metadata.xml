<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>Welcome to fastgs================&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;## Introduction**This library is currently in *alpha*, neither the functionality northe API is stable**. Feedback / PR’s welcome!This library provides geospatial multi-spectral image support forfastai. FastAI already has extensive support for RGB images in thepipeline. I try to achieve feature parity for multi-spectral images withthis library, specifically in the context of Sentinel 2 geospatialimaging.## Demo NotebooksComplete examples are provided in the following notebooks1.  working with a netCDF sample    [KappaSet](https://www.kaggle.com/code/restlessronin/netcdf-demo-fastai-using-fastgs).    demo code for brightness factor calculation by    [@wrignj08](https://github.com/wrignj08). Shows how to load images    with all channels stored in a single netCDF file.2.  working with the kaggle [38-cloud/95-cloud landsat    dataset](https://www.kaggle.com/code/restlessronin/cloud95-fastai-with-fastgs-multispectral-support).    Shows how to load images stored in a “single channel per file”    format (seems to be the common case).3.  working on a segmentation problem with a [Sentinel 2    dataset](https://www.kaggle.com/code/restlessronin/lila-sentinel-2-segmentation-with-fastai)These are boths works in progress and optimized to display the featuresof the library, rather than the best possible results. Even so, the“cloud 95” notebook is providing results comparable to other hiqhquality notebooks on the same dataset.## Install``` shpip install -Uqq fastgs`````` shconda install -c restlessronin fastgs```## Multi-spectral visualizationOne key problem that is solved is visualization of multi-spectral data,which has more than the three R, G, B channels.We introduce a new category of pytorch tensor,[`TensorImageMS`](https://restlessronin.github.io/fastgs/vision.core.html#tensorimagems),that shows multiple images. In addition to the normal RGB image, ithandles extra channels by displaying them as additional images, eitherin sets of false-colour RGB images, or as ‘monochrome’ images (one perchannel).There is also [experimentalsupport](07a_vision.core.ipynb#animating-multiple-images) (notintegrated into the API yet) for mapping multi-spectral images to ananimation of multiple images. Feedback on it’s usefulness is welcome!The first use-case is Sentinel 2 images, which are naturally “dark”.There is a provision to provide “brightening” multipliers duringdisplay, customizable per channel.## Image data classA high-level API,[`MSData`](https://restlessronin.github.io/fastgs/multispectral.html#msdata)is exposed that knows how to load multispectral images given someparameters.``` pythonfrom fastgs.multispectral import *```The following code creates a class that can load 11 Sentinel 2 channelsinto a[`TensorImageMS`](https://restlessronin.github.io/fastgs/vision.core.html#tensorimagems).The first parameter is a descriptor that provides mapping from Sentinel2 channels to brightening factors and other parameters specific to theinputs. This will generally be tailored to your image dataset.``` pythonfrom fastgs.test.io import * # defines file naming and io for our test samplessentinel2 = createSentinel2Descriptor()snt12_imgs = MSData.from_files(    sentinel2,    # B04 and B02 are transposed so that the first 3 channels are natural R,G,B channels    [&quot;B04&quot;,&quot;B03&quot;,&quot;B02&quot;,&quot;B05&quot;,&quot;B06&quot;,&quot;B07&quot;,&quot;B08&quot;,&quot;B8A&quot;,&quot;B11&quot;,&quot;B12&quot;,&quot;AOT&quot;],    [[&quot;B04&quot;,&quot;B03&quot;,&quot;B02&quot;],[&quot;B07&quot;,&quot;B06&quot;,&quot;B05&quot;],[&quot;B12&quot;,&quot;B11&quot;,&quot;B8A&quot;],[&quot;B08&quot;]],    get_channel_filenames,    read_multichan_files)```The second parameter is a list of ids of channel to be loaded into theimage tensor, in the order in which they are loaded.The third parameter is a list of 4 channel lists. Each channel listdescribes one image that will be displayed. The lists that have 3channel ids will map those channels to the R,G,B inputs of a“false-colour” image. Lists with a single channel id will be mapped tomonochrome images.In this example, we will display 4 images per MS image. The first mapsthe “real” RGB channels (B04, B03, B02) of Sentinel 2 data to an RGBimage, which makes this a true-colour image. The second image mapschannels B07, B06, B05 to a false-colour image. Likewise the third imagemaps B12, B11, B8A to a false-colour image. Finally the one remainingchannel B08 is mapped to a monochrome image. Thus all the channels inthe image are displayed.The fourth parameter is a function that maps channel id’s to filenamesthat provide the image data for a single channel. The final parameter isan IO function that loads a complete TensorImageMS given the list offiles corresponding to individual channels.## Image displayThe simplest use of the high-level wrapper class is to load an indvidualMS image.``` pythonimg12 = snt12_imgs.load_image(66)img12.show()```    [&lt;AxesSubplot:title={'center':'B04,B03,B02'}&gt;,     &lt;AxesSubplot:title={'center':'B07,B06,B05'}&gt;,     &lt;AxesSubplot:title={'center':'B12,B11,B8A'}&gt;,     &lt;AxesSubplot:title={'center':'B08'}&gt;]![](index_files/figure-commonmark/cell-4-output-2.png)Note that the single MS image is displayed as 4 images, eachcorresponding to one of the channel lists we provided. The first imageis the true-colour image, the next 2 are false colour, and the final oneis monochrome.## High level wrapper [`FastGS`](https://restlessronin.github.io/fastgs/multispectral.html#fastgs) for semantic segmentationWe also provide a high-level wrapper[`FastGS`](https://restlessronin.github.io/fastgs/multispectral.html#fastgs)which generates fastai dataloaders and learners for semanticsegmentation using unets. Providing support for other models and forclassification should be straightforward.### [`MaskData`](https://restlessronin.github.io/fastgs/multispectral.html#maskdata)Continuing our example, we provide mask information using a wrapperclass for segmentation mask loading (this is analogous to the[`MSData`](https://restlessronin.github.io/fastgs/multispectral.html#msdata)class, but for ‘normal’ `TensorImage`s).``` pythonmsks = MaskData.from_files(&quot;LC&quot;,get_channel_filenames,read_mask_file,[&quot;non-building&quot;,&quot;building&quot;])```### [`MSAugment`](https://restlessronin.github.io/fastgs/multispectral.html#msaugment)We also provide a wrapper class that can specify which (if any)augmentations to use during training and validation, using thealbumentations library (which works for multi-spectral data).``` pythonimport albumentations as A```Here we just use demo augmentations``` pythonaugs = MSAugment.from_augs(train_aug=A.Rotate(p=1),valid_aug=A.HorizontalFlip(p=0.33))```Now we create the actual high level wrapper``` pythonfastgs = FastGS.for_training(snt12_imgs,msks,augs)```Create a datablock and a data loader``` pythondb = fastgs.create_data_block()dl = db.dataloaders(source=[66]*10,bs=8) # repeat the sample image 10 times```Now we can see the visualization support in action. Let’s look at sometraining and validation batches (with augmentation). Each row shows theimage in 4 columns and the mask in the 5th.``` pythonfrom fastai.vision.all import *from fastgs.vision.data import *from fastgs.vision.learner import *from fastgs.vision.augment import *`````` pythondl.train.show_batch(max_n=3,mskovl=False) # don't overlay mask```![](index_files/figure-commonmark/cell-11-output-1.png)``` pythondl.valid.show_batch(mskovl=False)```![](index_files/figure-commonmark/cell-12-output-1.png)We create and train a unet learner and look at results. Image is infirst 4 columns, mask in the 5th and prediction in the 6th.``` pythonlearner = fastgs.create_learner(dl,reweight=&quot;avg&quot;) # weights of n &gt; 3 channels are set to average of first 3 channelslearner.fit_one_cycle(1)learner.show_results(mskovl=False)```    /opt/homebrew/Caskroom/miniforge/base/envs/fastgs/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.      warnings.warn(    /opt/homebrew/Caskroom/miniforge/base/envs/fastgs/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.      warnings.warn(msg)&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;  &lt;thead&gt;    &lt;tr style=&quot;text-align: left;&quot;&gt;      &lt;th&gt;epoch&lt;/th&gt;      &lt;th&gt;train_loss&lt;/th&gt;      &lt;th&gt;valid_loss&lt;/th&gt;      &lt;th&gt;dice&lt;/th&gt;      &lt;th&gt;time&lt;/th&gt;    &lt;/tr&gt;  &lt;/thead&gt;  &lt;tbody&gt;    &lt;tr&gt;      &lt;td&gt;0&lt;/td&gt;      &lt;td&gt;0.872479&lt;/td&gt;      &lt;td&gt;0.691804&lt;/td&gt;      &lt;td&gt;0.044623&lt;/td&gt;      &lt;td&gt;00:27&lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/table&gt;![](index_files/figure-commonmark/cell-13-output-6.png)Finally, we can look at the top losses``` pythoninterp = SegmentationInterpretation.from_learner(learner)interp.plot_top_losses(k=1,mskovl=False)```![](index_files/figure-commonmark/cell-14-output-5.png)## AcknowledgementsThis library is inspired by the following notebooks (and related worksby the authors)- [@cordmaur](https://github.com/cordmaur) - Mauricio Cordeiro’s  [multi-spectral segmentation fastai  pipeline](https://www.kaggle.com/code/cordmaur/remotesensing-fastai2-multiband-augmentations/notebook)- [@wrignj08](https://github.com/wrignj08) - Nick Wright’s  [multi-spectral classification  notebook](https://dpird-dma.github.io/blog/Multispectral-image-classification-Transfer-Learning//)</longdescription>
</pkgmetadata>